

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="2025年10月02日 08:52发言人   00:01Good afternoon, everybody. Welcome, good to see you. Hope you all have started your attack labs. Everybody started. Be a good time to start, I think. Anyway, I hope you’re">
<meta property="og:type" content="article">
<meta property="og:title" content="深入理解计算机系统 011-The Memory Hierarchy">
<meta property="og:url" content="http://example.com/2025/10/12/15213-011/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="2025年10月02日 08:52发言人   00:01Good afternoon, everybody. Welcome, good to see you. Hope you all have started your attack labs. Everybody started. Be a good time to start, I think. Anyway, I hope you’re">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-12T02:00:10.000Z">
<meta property="article:modified_time" content="2025-10-12T13:13:54.248Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>深入理解计算机系统 011-The Memory Hierarchy - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="深入理解计算机系统 011-The Memory Hierarchy"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-12 10:00" pubdate>
          2025年10月12日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          16k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          137 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">深入理解计算机系统 011-The Memory Hierarchy</h1>
            
            
              <div class="markdown-body">
                
                <p>2025年10月02日 08:52<br>发言人   00:01<br>Good afternoon, everybody. Welcome, good to see you. Hope you all have started your attack labs. Everybody started. Be a good time to start, I think. Anyway, I hope you’re enjoying it. That’s a new one this semester. That’s I think, really, really interesting and modern and current.<br>大家下午好。欢迎，很高兴见到你。希望你们都已经开始了你们的攻击实验室。每个人都开始了。我想这可能是一个开始的好时机。无论如何，我希望你喜欢它。这是这学期的新课时。我认为那是非常有趣、现代和现代的。</p>
<p>发言人   00:26<br>Okay, today we’re going to, today we’re going to talk about something called the memory hierarchy. Now, so far in the class, we’ve thought of memory when we’re looking at our assembly language programs, we’ve thought of memory as a an array of bytes, just a big array of bytes that we can access with an index called an address. But in actuality, the memory system is a very complex hierarchy of devices that provides this abstraction of this large linear array. And so today, we’re going to look at how memory hierarchies are built, why they’re built the way they are. And what we’ll see is that this sort of beautiful confluence properties of storage devices and the properties of programs come together to create this.<br>好的，今天我们要，今天我们要谈论一种叫做记忆层次结构的东西。到目前为止，在课堂上，当我们查看汇编语言程序时，我们已经想到了内存，我们已经把内存看作是一个字节数组，只是一个我们可以通过称为地址的索引访问的一个大的字节数组。但实际上，存储系统是一个非常复杂的设备层次结构，它提供了这种大型线性阵列的抽象。所以今天，我们将看看内存层次结构是如何建立的，为什么它们是这样建立的。我们将看到的是，存储设备的这种美丽的融合特性和程序的特性结合在一起，创造了这一点。</p>
<p>发言人   01:24<br>This beautiful design called the memory hierarchy. So we’re going to quickly kind of do a high level tour of storage technologies and trends. We’re not going to go into a whole lot of detail. The point in looking at these the properties of these technologies is that there are some fundamental properties that determine their performance and their speed, determine limits on their performance and speed. And so I want you to have just some high level idea of what those properties are. And then we’ll look at a property of programs called locality of reference. And we’ll see how that locality, the properties of storage devices come together to suggest this design of memory systems as a hierarchy.<br>这个美丽的设计被称为记忆层次结构。因此，我们将快速地对存储技术和趋势进行高层次的介绍。我们不会详细讲解。研究这些技术的属性的重点是，有一些基本属性决定了它们的性能和速度，决定了它们的性能和速度限制。所以我希望你对这些属性有一些高层次的想法。然后我们将研究程序的一个属性，称为引用局部性。我们将看到存储设备的局部性和属性如何结合在一起，建议将存储系统的设计作为层次结构。</p>
<p>发言人   02:17<br>So we’ll look at memories first. Now, the workhorse memory is called a random access memory, or Ram. It’s traditionally packaged up as a chip, and then you put multiple chips together to form your main memory, and there’s a basic storage unit called a cell where each cell stores 1 b.<br>所以我们先看看记忆。现在，主要内存被称为随机访问存储器，或Ram。它传统上打包为芯片，然后将多个芯片放在一起形成主存储器，有一个称为单元的基本存储单元，每个单元存储1 b。</p>
<p>发言人   02:38<br>There’s comes in two varieties, There’s SRAM and DRAM, and they’re distinguished by the way that those cells are implemented. An SRAM? Requires it’s more complex than DRAM, It requires like 4 to 6 transistors per bit, whereas DRAM only requires one transistor. So you’ll see that Srams are going to be more expensive, lots more expensive because they’re more complex.<br>有两种类型，分别是SRAM和DRAM，它们的区别在于这些细胞的实现方式。一个SRAM？要求它比DRAM更复杂，每比特需要4到6个晶体管，而DRAM只需要一个晶体管。所以你会发现Srams会更昂贵，因为它们更复杂。</p>
<p>发言人   03:13<br>Each cell is more complex, but they’re also much faster, like 10 order of magnitude faster than Drams. And they have, there’s some other properties too, like SRAM constantly. A DRAM constantly needs to be refreshed. If you don’t hit it with A with a voltage, it loses a charge DRAM while it needs to be plugged in and have an electric charge, it doesn’t need to be refreshed. SRAM is a lot more reliable than DRAM, so there’s less need for error detection and correction. And so because of this difference, the Srams are costlier, smaller, and faster than Drams.<br>每个细胞都更复杂，但它们也更快，比Drams快10个数量级。他们有，还有一些其他的属性，比如不断地SRAM。DRAM需要不断刷新。如果你没有用电压击中它，它会在需要插入并充电时失去电荷，不需要刷新。SRAM比DRAM可靠得多，因此对错误检测和纠正的需求更少。因此，由于这种差异，Srams比Drams更昂贵，更小，更快。</p>
<p>发言人   04:01<br>We find Srams being used in these small, fast memories on ship called cache memories, and we’re going to learn all about those on Thursday. And then DRAM is the workhorse used in main memories and the frame buffers associated with graphics.<br>我们发现Srams被用于船上这些小而快速的存储器，称为缓存存储器，我们将在星期四学习所有这些存储器。然后DRAM是在主内存和与图形相关的帧缓冲区中使用的主力。</p>
<p>发言人   04:22<br>Graphics cards Now DRAM and SRAM are volatile in the sense that if if they’re powered off, they lose all the information. So this is why when you turn your computer off, you lose everything in your memory and you to when you turn it back on, you have to sort of reload everything from your disk. But there’s another kind of memory called the non-volatile memory, which retains its information when it’s powered off. And there’s a whole bunch of these things, so icall the read only memories. So the generic name for these non volatile memories, read only memories of Roms, and there’s a whole bunch of different kinds sort of going back in time, the original read only memories were Roms and they can only be programmed once when the chip was produced. And then over time, gradually over a period of like 20 or 30 years, there were improvements in the way that Roms could be programmed, how they were erased, so they could be re-programmed, What we have today, the modern form of read only memory is called flash memory, which provides the capability of.<br>图形卡现在DRAM和SRAM是不稳定的，感知如果它们被关闭，它们会丢失所有信息。因此，这就是为什么当您关闭计算机时，您会丢失内存中的所有内容，并且当您重新打开计算机时，您必须从磁盘中重新加载所有内容。但是还有另一种存储器，称为非易失性存储器，在断电时保留其信息。有一大堆这样的东西，所以只有只读记忆。因此，这些非挥发性存储器的通用名称是只读存储器的只读存储器，并且有很多不同种类的时光倒流，最初的只读存储器是只读存储器，它们只能在芯片生产时被编程一次。然后随着时间的推移，在大约20到30年的时间里，存储器的编程方式有所改进，它们如何被擦除，因此可以被重新编程，我们今天所拥有的现代形式的只读存储器被称为闪存。这提供了能力。</p>
<p>发言人   05:38<br>Easing, you can erase just chunks of the flash memory called blocks. And then the downside is that these things wear out after about 100000 erasures. So you can erase and reprogram 100000 times then, and then it’s you’re bricked.<br>轻松，您可以仅擦除称为块的闪存块。缺点是这些东西在大约100000次擦除后会磨损。所以你可以擦除并重新编程100000次，然后你就被砖砌了。</p>
<p>发言人   05:59<br>Now these non volatile memories show up in so called the firmware, which is software that’s that’s programmed into a Rom and you see those the BIOS of computer. So when you power on your computer, the very first instructions that execute are stored in a Rom. If you’re wondered like where do those things come from? So they’re stored in a Rom and then there’s a boot process where gradually more and more information is and instructions are loaded into memory.<br>现在，这些非易失性存储器出现在所谓的固件中，固件是一种被编程到Rom中的软件，你可以看到这些计算机的BIOS。因此，当您打开计算机的电源时，执行的第一个指令存储在Rom中。如果你想知道这些东西是从哪里来的？所以它们存储在Rom中，然后有一个引导过程，逐渐越来越多的信息和指令被加载到内存中。</p>
<p>发言人   06:33<br>IO IO devices have little computers in them call controllers. These controllers consist of instructions and data that are stored in Roms, and you see them all over the place in these solid state disks that to the system look like a rotating Dis, but they’re built of flash memories. And these are, you see these in thumb drives, smartphones, tablets, and laptops. And they’re even starting to show up in servers now.<br>IO IO设备中的小型计算机称为控制器。这些控制器由存储在存储器中的指令和数据组成，您可以在这些固态磁盘中看到它们遍布各地，对系统来说看起来像旋转磁盘，但它们是由闪存构建的。你可以在拇指驱动器、智能手机、平板电脑和笔记本电脑中看到这些。它们现在甚至开始出现在服务器中。</p>
<p>发言人   07:14<br>So the memories are connected to the CPU using wires that are collectively called buses. So data flows across the wires back and forth from the we have the CPU chip, and it consists of register file. These are the general purpose registers, rax, RDI, and so on. And there’s an arithmetic logic unit that reads and writes data from the register files and then manipulates that data in some way by doing some kind of arithmetic operation or some logical operation.<br>因此存储器使用统称为 “总线” 的电线连接到CPU。因此，数据从我们拥有的CPU芯片来回流经电线，并且它由注册文件组成。这些是通用寄存器，rax，RDI等。还有一个算术逻辑单元，它从寄存器文件中读取和写入数据，然后通过进行某种算术运算或逻辑运算以某种方式操作该数据。</p>
<p>发言人   07:53<br>And if instructions need to access memory, so you’re doing a move, a move instruction that reads or writes to memory, then that’s handled by a bus interface, which is connected to a, what we’ll call a system bus. And then that’s connected to an IO bridge. And this is another collection of chips. Intel calls this what I’m calling the IO bridge. They call the chipset, but it’s a collection of chips separate from the CPU chip, and then the IO bridge is connected to another bus called the memory bus, which connects the main memory, this is kind of an abstraction.<br>如果指令需要访问内存，那么你正在执行移动指令，读取或写入内存，然后由总线接口处理，该接口连接到我们称之为系统总线的总线。然后它连接到一个IO桥。这是另一个芯片集合。英特尔称之为我所称的IO桥。他们称之为芯片组，但它是与CPU芯片分开的芯片集合，然后IO桥连接到另一个称为内存总线的总线，该总线连接主存储器，这是一种抽象。</p>
<p>发言人   08:40<br>I don’t want you to take this too literally, but it gives you the idea of how information flows in the system. Modern modern systems use proprietary bus designs, and they’re very arcane and increasingly complex, so we’re just going to use a fairly simple abstraction for these buses.<br>我不希望你把这个看得太重，但它让你了解信息如何在系统中流动。现代系统使用专有的总线设计，它们非常神秘且越来越复杂，因此我们只对这些总线使用相当简单的抽象。</p>
<p>发言人   09:04<br>Now suppose you do a load operation like move C 8 B at address into Rax. So we call that a load because we’re loading from the point of view of the CPU, we’re loading data into the CPU, but we’re loading data from memory into the CPU. So when the CPU executes a move instruction like this, it first places the address of A on the memory bus. And then the main memory senses that address, and it reads the contents, the 8 B at address A, so it retrieves the word 8 B word from address A and places it back on the bus. Those bits travel through the IO bridge to the bus interface. And then the CPU reads the word X from the data word X from the bus, and then copies it into register Rax.<br>现在假设您执行一个加载操作，例如将地址为c8b的地址移动到Rax中。所以我们称之为加载，因为我们是从CPU的角度加载的，我们是将数据加载到CPU中，但我们是将数据从内存加载到CPU中。因此，当CPU执行这样的move指令时，它首先将a的地址放在内存总线上。然后主存储器感知该地址，并读取内容，即地址A的8 B，因此它从地址A中检索单词8 B并将其放回总线上。这些位通过IO桥传输到总线接口。然后，CPU从总线上的数据字X中读取字X，然后将其复制到寄存器Rax中。</p>
<p>发言人   10:08<br>So now writing is similar again. So here we’re doing a move instruction, move Q from rax into address A and main memory. So the CPU starts as before by placing the address A on the bus, main memory reads that address, and then it waits for the data to arrive on the bus. So the CPU then places the contents of Rax on the bus, and those contents travel across to main memory, which then reads that word from the bus and stores that address A, so the point of all this is that operations that occur reads and writes of registers because the register file is very close to the Alu, These happen on the order of a few cycles.<br>所以现在写作又相似了。在这里，我们正在执行一个移动指令，将Q从rax移动到地址a和主内存。所以CPU像以前一样通过将地址A放在总线上开始，主内存读取该地址，然后等待数据到达总线上。因此，CPU然后将Rax的内容放在总线上，这些内容经过主内存，然后主内存从总线读取该单词并存储该地址，所以所有这些的重点是寄存器的读写操作，因为寄存器文件非常接近Alu，这些操作发生在几个周期的顺序上。</p>
<p>发言人   11:04<br>The register is very close to the Alu, so those operations happen very quickly, whereas memories actually, this is a set of chips that are very far away, relatively speaking from the CPU, and there’s a lot going on when if you have to read or write memory you have to do multiple operations on the bus. Data has to travel, propagate across that bus, all the stuff takes time. So memory operations, reads and writes are typically maybe 50 nanoseconds, 100 nanoseconds, whereas operations that occur between registers are sub nanosecond. So you’re talking about one to two orders of magnitude difference if you have to go off chip to retrieve something from memory. So that’s the first sort of big takeaway item about memory systems.<br>寄存器与Alu非常接近，因此这些操作发生得非常快，而内存实际上是一组非常远的芯片，相对于CPU来说，如果你需要读或写内存，就必须在总线上进行多个操作，这有很多事情需要处理。数据必须通过公共汽车传播，所有这些都需要时间。所以内存操作，读取和写入通常是50纳秒，100纳秒，而在寄存器之间发生的操作是亚纳秒。所以你说的是一到两个数量级的差异，如果你必须离开芯片从内存中检索某些东西。所以这是关于记忆系统的第一个重要要点。</p>
<p>发言人   12:05<br>Now, another popular storage technology is rotating discs. And I don’t know if you’ve ever torn one apart, they’re kind of interesting. There’s a series of platters. Each platter is coated with a magnetic material, and then bits, ones, and zeros are encoded in that, in that magnetic material. And then there’s this arm that can, it’s hinged right here, and then it floats over the platter, so it floats on a thin layer of air over the platter, read, write head at the very end that can sense the changes in the magnetic field that encode the bits. So these platters are spinning around like counterclockwise like this, and this arm can go back and forth. So there’s a lot of mechanical gear so that this is all mechanical, So the mechanical nature of a rotating disc means it’s going to be slower than Drams and Srams, and there’s also electronics, like it’s like a little computer in firmware that actually controls the operation of this drive, controls how this arm goes back and forth, and controls how the data is read off of the read write head.<br>现在，另一种流行的存储技术是旋转光盘。我不知道你是否曾经撕开过一个，它们有点有趣。有一系列的拼盘。每个盘片都涂有磁性材料，然后将位、一和零编码在磁性材料中。然后是这个手臂，它在这里铰接，然后它漂浮在盘片上，所以它漂浮在盘片上的一层薄薄的空气上，在最后读取，写磁头可以感知编码比特的磁场的变化。所以这些盘片像这样逆时针旋转，这个手臂可以来回旋转。所以有很多机械齿轮，所以这都是机械的，所以旋转盘的机械性质意味着它会比Drams和Srams慢，还有电子设备，就像固件中的一个小电脑，实际上控制着这个驱动器的操作。控制该臂来回传送的方式，并控制从读写头读取数据的方式。</p>
<p>发言人   13:26<br>So just in a little more detail, we can think of these discs consists of platters, each platter has two surfaces, a top and a bottom. And then each surface consists of these concentric rings called tracks, and then each track it consists of. Sectors which contain the data. So typically 512. Bits I’m sorry by it. And then these tracks are separated by gaps. These gaps like right here, that don’t contain data. Now platters are aligned on top of each other on this spindle. And so tracks that are aligned on the different surfaces, such as this track here, the collection of those tracks form what we call a cylinder because it has a cylindrical shape.<br>所以稍微详细一点，我们可以认为这些光盘是由盘片组成的，每个盘片有两个表面，一个顶部和一个底部。然后每个表面都由这些称为轨道的同心环组成，然后每个轨道都由它组成。包含数据的部门。所以通常是512。我很抱歉。然后这些轨道被间隙分开。这些差距就像这里，不包含数据。现在，在此主轴上，盘片彼此对齐。所以在不同表面上对齐的轨迹，例如这里的这个轨迹，这些轨迹的集合形成了我们所谓的圆柱体，因为它具有圆柱体的形状。</p>
<p>发言人   14:34<br>Now, the capacity of disks is the number of bits that can be stored. Vendors of all disk vendors use, they quote the capacity in gigabytes. But where a gigabyte is 10 to the ninth bytes instead of two to the 20th like you would expect. So I’m not sure why they do this, but it allows by quoting their capacity in gigabytes in 10 to the ninth bytes. It’s a bigger number, so it looks better. It looks like there’s more information. It’s a little, I don’t really know why they do it, but I think that’s why it is. And so it’s one of those little bit annoying things that we just have to just know about and get used to.<br>现在，磁盘的容量就是可以存储的位数。所有磁盘供应商都使用的容量 (以千兆字节为单位)。但是一个千兆字节是10的第九个字节，而不是你所期望的两个到20的字节。所以我不确定他们为什么这样做，但它允许在10到第九个字节中以千兆字节引用他们的容量。这是一个更大的数字，所以看起来更好。看起来还有更多的信息。有点，我真的不知道他们为什么这样做，但我认为这就是原因。所以这是我们只需要知道并习惯的那些有点烦人的事情之一。</p>
<p>发言人   15:29<br>Now, the capacity is determined by two independent technology factors, 1 is the recording density. So that’s how many bits can you pack into a single sector or. Or at least a portion of a track. And then the track density, which is sort of how close can you put those tracks together? And then the product of those two is what’s called the aerial density. And that determines the overall capacity of the disk. So the aerial capacity, the more bits you can squeeze onto that surface.<br>现在，容量由两个独立的技术因素决定，1是记录密度。这就是你可以将多少位打包到一个扇区中。或者至少是轨道的一部分。然后是轨道密度，也就是你能把这些轨道放在一起的距离有多近？这两者的乘积就是所谓的空中密度。这决定了磁盘的总容量。所以天线容量，你可以挤在表面上的比特越多。</p>
<p>发言人   16:13<br>In the old days, when aerial densities were fairly low, each track on the surface would have the same number of sectors. So there was a constant number of sectors per track. So now what happens as you as your tracks go from near the hole by the spindle, as they go, as they move outward, if you have the same number of sectors with the same?<br>在过去，当空中密度相当低时，表面上的每个轨道将具有相同数量的扇区。因此，每个轨道的扇区数量恒定不变。那么现在，如果你有相同数量的扇区，当你的轨道从主轴附近的洞口移动时，当它们向外移动时，会发生什么呢？</p>
<p>发言人   16:44<br>Bit density, the gaps between sectors are going to get bigger and bigger as you go out and you’re going to be wasting more and more of your of your space. So when aerial densities were fairly low, this was OK. But after a while, it just became not okay to waste that much room.<br>位密度，随着您的外出，扇区之间的间隙将越来越大，您将浪费越来越多的空间。所以当空中密度相当低时，这是可以的。但过了一段时间，浪费那么多空间就变得不合适了。</p>
<p>发言人   17:02<br>So what modern systems do is they partition the tracks into these so called recording zones, where each recording zones, such as this right here, each recording zone has a conson number of sectors. So each track in a recording zone has the same number of sectors. And of course, as you move outward, if you move outward in the recording zone, you’re going to have bigger and bigger gaps. But then you start a new recording zone that will have more sectors per track. And then within that, so you can see in this outer, in this outer zone, you have more sectors than you do on this inner zone. So that’s a way to kind of deal with sort of that growth in the gaps to keep it from getting too large.<br>所以现代系统所做的是将轨道划分成这些所谓的记录区域，每个记录区域，比如这里，每个记录区域都有一个康森数目的扇区。因此，记录区域中的每个轨道具有相同数量的扇区。当然，当你向外移动时，如果你在记录区域向外移动，你将会有越来越大的间隙。然后你开始一个新的录制区域，每个轨道将有更多的扇区。然后在这个内部，你可以看到在这个外部区域，你拥有的扇区比你在这个内部区域拥有的要多。所以这是一种处理差距增长的方法，以防止差距变得太大。</p>
<p>发言人   17:58<br>And so because we don’t really have the number of sectors per track is in constant, we’ll use an average, the average sectors per track across all recording zones when we do sort of our capacity estimates.<br>因为我们并没有每个轨道的扇区数量是恒定的，所以当我们进行容量估计时，我们将使用平均值，即所有记录区域中每条轨道的平均扇区。</p>
<p>发言人   18:14<br>Okay? So as you can imagine, the formula for computing the disk capacity is fairly straightforward. It’s the number of bytes per sector, the average number of sectors per track times, the average number of tracks per surface times the number of surfaces per platter, times the number of platters per disk.<br>好吗？所以你可以想象，计算磁盘容量的公式相当简单。它是每个扇区的字节数、每个磁道的平均扇区数、每个表面的平均磁道数、每个盘片的表面数、每个磁盘的盘片数。</p>
<p>发言人   18:36<br>Now let’s look at how disks work. So these surfaces are spinning at a fixed rotational rate. Now, a typical rate, maybe 7200 Rpms, is a fairly common rotational rate. So the disc is spinning around, you can see this. Som pretty proud of that. So it’s spinning around counterclockwise, and then the arm moves radially, here we go. The arm moves radially and it can go over any of the tracks, okay? All right, that’s enough.<br>现在让我们看看磁盘是如何工作的。所以这些表面以固定的旋转速率旋转。现在，一个典型的速率，可能是7200 Rpms，是一个相当常见的旋转速率。所以圆盘在旋转，你可以看到这个。我为此感到非常自豪。所以它在逆时针旋转，然后手臂径向移动，我们开始。手臂径向移动，可以越过任何轨道，好吗？好的，够了。</p>
<p>发言人   19:23<br>Now, when you have multiple platters, each one of these, each one of there’s actually multiple arms and there’s a read right head on each surface. So if the platter has, if each side of the platter is coated with this magnetic material, then you have a read write head on each side. And then these are all connected and they kind of move together. Now, originally, these read write heads would be they were rigid because the track densities weren’t that high. So they could just sort of like, and even though the tracks didn’t align perfectly, they could just sort of, they could, the read-write heads could still cover the tracks fixed with these fixed arms. But nowadays the densities are so high that they actually, the controller can actually move the read write heads a little bit so that it matches up with all of the tracks on all of the surfaces.<br>现在，当你有多个盘片时，每个盘片实际上都有多个臂，每个表面上都有一个读取右磁头。因此，如果盘片的每一侧都涂有这种磁性材料，那么每一侧都有一个读写磁头。然后这些都是相互联系的，并且它们有点一起移动。现在，最初，这些读写头会是刚性的，因为磁道密度不是那么高。因此，即使轨道没有完美对齐，他们也可以，读写头仍然可以覆盖用这些固定臂固定的轨道。但现在的密度是如此之高，以至于控制器实际上可以稍微移动读写头，使其与所有表面上的所有轨迹匹配。</p>
<p>发言人   20:31<br>Okay, so let’s look at how this works, how we read data. So we have. This is our arm. And the tip of the arrow is the read write head. And it’s positioned. And the platter is rotating counterclockwise, and it’s positioned just ready to read the blue sector. So as the blue sector spins underneath the read right head, it sends those bits and sends them up to the controller, which passes them back up to the CPU. And now the CPU is requested that the disk, it’s requested the data from the red sector. So we have to take the controller, takes that read write head, moves it back to reds track, and then waits for it to spin around.<br>好的，让我们看看这是如何工作的，我们如何读取数据。所以我们有。这是我们的手臂。箭头的尖端是读写头。它的位置。并且盘片逆时针旋转，它的位置刚刚准备好读取蓝色扇区。因此，当蓝色扇区在读取右侧的磁头下方旋转时，它将这些位发送并将它们发送到控制器，再将它们传递回CPU。现在，CPU被请求了磁盘，它被请求了来自红色扇区的数据。所以我们必须拿控制器，拿那个读写头，把它移回红色轨道，然后等待它旋转。</p>
<p>发言人   21:26<br>To the read, write head. And then it reads that red sector. So when we first, so there’s really three components going on here that determine how long it takes to read one of these sectors. When we moved the head, that’s called the Sq. When we waited for the red track to sort of rotate around, that’s called the rotational latency. So however long it takes, on average, it’ll be half of the half of the time it takes for the entire to circle all the way around. And then there’s the data transfer, which is sort of how long it takes for that track to pass under the read write hood.<br>读、写的头。然后它显示了那个红色区域。所以当我们第一次时，这里实际上有三个组成部分决定了读取其中一个扇区所需的时间。当我们移动头部时，那就是所谓的平方。当我们等待红色轨迹旋转时，这被称为旋转延迟。因此，无论花费多长时间，平均而言，整个循环所需的时间只有一半。然后是数据传输，也就是读取写入路径所需的时间。</p>
<p>发言人   22:17<br>Now, the reason it’s important to know this is that these three components, you add them together, and that’s your average time it takes to access data. That time is dominated by the seek time. So seek times are measured in milliseconds. So we’re moving this head, there’s a servo that has to fire up, and there’s actual mechanical motion that takes time, and it’s on the order of 3 to 9 milliseconds. And this has been true for decades, so this value is not changing. There’s a sort of fundamental mechanical limits that make it very difficult to decrease this value.<br>现在，知道这一点很重要的原因是，这三个组件，你把它们加在一起，这就是你访问数据所需的平均时间。时间被寻道时间所支配。所以寻道时间以毫秒为单位测量。所以我们正在移动这个头，有一个必须启动的伺服装置，还有实际的机械运动需要时间，大约是3到9毫秒。这几十年来一直如此，所以这个值不会改变。有一种基本的机械限制，使得降低这个值非常困难。</p>
<p>发言人   23:05<br>Now, the rotational latency. The time that it takes to spin around will, we’ll call that the T average rotation. And then the time it takes to read the bits, we’ll call T average transfer T average, which is this CQ time, rotational latency, and transfer time.<br>现在，旋转延迟。旋转所需的时间，我们称之为T平均旋转。然后是读取比特所需的时间，我们称之为T平均传输T平均，也就是这个CQ时间、旋转延迟和传输时间。</p>
<p>发言人   23:31<br>And now if we just take some typical numbers and plug those in, you see that our seek time is on the order of milliseconds. The rotational rate is also on the order of milliseconds. So there’s also mechanical limits and how fast you can, you can spin these around, access time and the transfer time. It’s very small. So it’s orders of magnitude smaller because you just have to read a few the bits that are in one sector. So if you look, you can see that the total access time is dominated by Sq and rotational latency. So you a good rule of thumb just for sort of estimating how long it takes to read from a disk is just take twice the sequence, the seek time, and you’ll be pretty close. And basically transfer time is you get that for free.<br>现在，如果我们只取一些典型的数字并插入这些数字，您会发现我们的寻道时间大约是毫秒级。旋转速率也在毫秒级。因此，还有机械限制，以及您可以旋转这些旋转速度、访问时间和传输时间。它非常小。所以它要小几个数量级，因为你只需要读取一个扇区中的几个位。因此，如果您查看，您可以看到总访问时间由平方和旋转延迟主导。因此，估计从磁盘读取所需时间的一个好的经验法则就是只需要两倍的序列，寻道时间，你就会非常接近。基本上，转移时间是你免费获得的。</p>
<p>发言人   24:28<br>Now, here’s the important thing to know about disks. We SRAM access times about 4 nanoseconds to get a double word. DRAM is about 60 nanoseconds. So DRAM is an order of magnitude slower than SRAM, but disk is 40000 times slower than SRAM, so that’s 4000 orders of magnitude difference. That’s huge, it’s 250 times orders of magnitude slower than Drams, so. There’s a big gap between DRAM and SRAM, and there’s an even bigger gap between disk and other memory types.<br>现在，这是关于磁盘需要了解的重要事情。我们大约需要4纳秒的访问时间才能得到一个双字。DRAM大约是60纳秒。所以DRAM比SRAM慢一个数量级，但磁盘比SRAM慢40000倍，所以这是4000个数量级的差异。这是巨大的，它比Drams慢250倍。DRAM和SRAM之间有很大的差距，磁盘和其他内存类型之间还有更大的差距。</p>
<p>发言人   25:18<br>Now, modern disks present a much simpler view. So than this, this track cylinder sector geometry. So modern disk controllers actually present to the CPU. They present the disk as a sequence of logical blocks where each block is a multiple of a sector size. So in the simplest case, a block is just think of a logical block is one sector, and then blocks are numbered starting at 0, and they just go all the way up to some large number. And then the Dis controller keeps the mapping, maintains the mapping between logical blocks and the actual physical sectors.<br>现在，现代磁盘提供了一个更简单的视图。比这更重要的是，这个轨道圆柱体扇区的几何形状。所以现代磁盘控制器实际上存在于CPU中。它们将磁盘呈现为逻辑块的序列，其中每个块是扇区大小的倍数。所以在最简单的情况下，一个区块只是把逻辑区块想象成一个扇区，然后区块从0开始编号，然后它们一直编号到某个很大的数字。然后，Dis控制器保持映射，维护逻辑块和实际物理扇区之间的映射。</p>
<p>发言人   26:05<br>As in the old saying is most interesting ideas in computer science involve some form of indirection. So this is a level of indirection that provides this mapping between logical blocks and physical blocks. So it allows disk controllers to take some cylinders and reserve them as spare cylinders that aren’t mapped any logical blocks. And then if one of the sectors goes bad in a cylinder, the disc controller can can copy the data over to a spare cylinder and then just keep going. And so this is why your formatted capacity is less than sort of if you counted the number of actual cylinders on the disk, you formatted capacity is less than the maximum capacity because some of those cylinders are being reserved for failures. Now, devices like disks are connected to the CPU and the memory via the IO bridge over another kind of bus called an IO bus.<br>正如老话所说，计算机科学中最有趣的思想涉及某种间接形式。所以这是一个间接级别，提供逻辑块和物理块之间的映射。因此，它允许磁盘控制器将一些柱面保留为不映射任何逻辑块的备用柱面。然后，如果其中一个扇区在圆柱体中发生故障，磁盘控制器可以将数据复制到备用圆柱体中，然后继续运行。因此，这就是为什么您格式化的容量小于磁盘上实际柱体的数量的原因，如果您计算磁盘上实际柱体的数量，您格式化的容量小于最大容量，因为其中一些柱体是为故障保留的。现在，像磁盘这样的设备通过IO桥通过另一种称为IO总线的总线连接到CPU和内存。</p>
<p>发言人   27:14<br>What I’m showing you, what I’m showing you now is actually not representative of modern systems. It’s representative what was called the PCI bus about five years ago. Modern buses now are the PCI bus is a broadcast bus, meaning it’s just a single set of wires. So if any device changes the values on those wires, every device on that bus can see those values. That’s called the broadcast bus. And it’s the simplest kind of way to hook things together.<br>我现在向你展示的东西实际上并不代表现代系统。它代表了大约五年前所谓的PCI总线。现代的公共汽车现在是PCI总线，是一种广播总线，这意味着它只是一组电线。因此，如果任何设备更改了这些线路上的值，该总线上的每个设备都可以看到这些值。这就是所谓的广播巴士。这是把事情联系在一起的最简单的方式。</p>
<p>发言人   27:49<br>Modern systems use a bus structure called PCI Express, which although it has the word PCI and it’s completely different, it’s point to point devices are connected by a set of point to point connections arbitrated by some kind of a switch. And we won’t go into it. It’s the same idea. It’s a much more efficient design, it’s much faster, but it provides the same capability. Mainly it just attaches, it allows you to attach all of your devices to your to your CPU.<br>现代系统使用一种称为PCI Express的总线结构，尽管它有单词PCI并且完全不同，但它的点到点设备是通过一组由某种开关仲裁的点到点连接连接来连接的。我们不会去研究它。这是同样的想法。这是一个更高效的设计，更快，但它提供了相同的功能。主要是它只是附加，它允许您将所有设备连接到CPU。</p>
<p>发言人   28:24<br>So just think of this bus as this sort of a single set of wires where each wire carries a bit and every device attached to it can see all the values of all the wires. And so there are some devices that are just built directly into the motherboard and they attach to the bus. Disks are just plugged directly into and sockets on the motherboard and your graphics adapter, the USB controller, and then the system presents an interface so you can plug mouse things like mouse, mice, and keyboards into the USB controller. And then there’s expansion slots that allow you that are connect to the wires in the bus that allow you to add other devices, like maybe network if you want to put a network adapter in there.<br>因此，只需将此总线视为一组电线，每根电线都携带一个位，连接到它的每个设备都可以看到所有电线的所有值。因此，有一些设备直接内置在主板上，并连接到总线上。磁盘只需直接插入主板上的插槽和图形适配器，USB控制器，然后系统提供一个接口，以便您可以将鼠标，鼠标和键盘等鼠标插入USB控制器。然后有扩展插槽，允许您连接到总线中的电线，允许您添加其他设备，例如网络，如果您想在其中放置网络适配器。</p>
<p>发言人   29:16<br>Now, what happens when we want to read a disk sector? Well, the CPU initiates this read by writing a triple. So it writes three different values. It writes a command like say, read, it writes a logical block number. So I want to read a logical block number, and I want to place the contents of that logical block at a certain address in memory. Okay? So it’s a command logical block number and a memory address. The disk controller reads whatever sector corresponds to that logical block. So we’ll assume that logical blocks there consist of one sector, and then it does this interesting thing, it copies, it takes control of the bus, and it copies the data.<br>现在，当我们想要读取磁盘扇区时会发生什么？嗯，CPU通过写入三元组来启动此读取。所以它写入三个不同的值。它写一个命令，比如读，它写一个逻辑块编号。所以我想读取一个逻辑块编号，并将该逻辑块的内容放置在内存中的某个地址。好吗？所以它是一个命令逻辑块编号和一个内存地址。磁盘控制器读取与该逻辑块对应的任何扇区。所以我们假设逻辑块由一个扇区组成，然后它做这个有趣的事情，它复制，它控制总线，然后它复制数据。</p>
<p>发言人   30:04<br>This is the Dis controller now copies the data across the IO bus, through the IO bridge, and directly to main memory without ever notifying the CPU. So the CPU is completely. Oblivious to the fact that this transfer is going on.<br>这是Dis控制器，现在可以通过IO总线、IO桥直接将数据复制到主内存，而无需通知CPU。所以CPU是完全的。无视这种转移正在进行的事实。</p>
<p>发言人   30:24<br>And once it’s transferred the data to main memory, then it notifies the CPU using this mechanism called an interrupt. So it actually asserts a Pin on the actual CPU chip itself, so changes the value of that pin from 0 to 1. And that triggers an interrupt, which notifies the CPU that that sector has been copied.<br>一旦它将数据传输到主存，它就会使用这种称为中断的机制通知CPU。因此，它实际上在实际的CPU芯片上设置了一个引脚，因此将该引脚的值从0更改为1。这会触发一个中断，通知CPU该扇区已被复制。</p>
<p>发言人   30:52<br>So then the CPU, there’s some program somewhere waiting for that data to be read into memory. Now the CPU can execute that program and deal with that memory. So what this mechanism allows, and the reason they do this is because discs are just so god-awful.<br>因此，CPU在某处有一些程序等待数据读入内存。现在CPU可以执行该程序并处理该内存。所以这种机制允许什么，他们这样做的原因是因为光盘太可怕了。</p>
<p>发言人   31:15<br>Within 10 milliseconds, a system could be executing millions and millions of instructions. The CPU could be executing millions and millions of instructions. It would be a terrible waste if the CPU waited for that data to come off the disk. So what it does is it issues this request to the disk controller. And then while that really slow, laborious process is going on, the CPU can be executing other instructions and doing other useful work. So this is really essential to sort of getting reasonable performance and from keeping this really slow disk system from slowing the system down.<br>在10毫秒内，一个系统可能会执行数百万条指令。CPU可能正在执行数百万条指令。如果CPU等待数据从磁盘中出来，那将是一种可怕的浪费。所以它的作用是向磁盘控制器发出这个请求。然后，当那个非常缓慢、费力的过程正在进行时，CPU可以执行其他指令并做其他有用的工作。因此，这对于获得合理的性能和防止这个非常缓慢的磁盘系统降低系统速度非常重要。</p>
<p>发言人   31:57<br>Now there’s. Interesting high kind of disk called a solid state disk, which is kind of halfway between rotating discs and DRAM memories, and a solid state disk to the CPU. It looks exactly like a rotating disk. It has the same socket plug. It has the same physical interface that has the same packaging. It looks like a rotating disk. But instead of having all these mechanical parts, it’s actually built entirely out of flash memory and firmware that acts the controller. So inside of a solid state disk, there’s a firmware, a set of firmware called the flash translation layer, which serves the purpose as the same purpose as the disk controller does in a rotating disk.<br>现在有了。有趣的高级磁盘称为固态磁盘，它介于旋转磁盘和动态内存以及CPU的固态磁盘之间。它看起来就像一个旋转的圆盘。它具有相同的插座插头。它具有具有相同打包的相同物理接口。它看起来像一个旋转的圆盘。但它并没有所有这些机械部件，实际上它完全由闪存和固件构建，作为控制器的作用。因此，在固态磁盘内部，有一个固件，一组称为闪存翻译层的固件，其用途与旋转磁盘中的磁盘控制器相同。</p>
<p>发言人   32:56<br>And then the memory itself, the read data can be read and written from the flash memory in units of pages, which, depending on the technology, can be 512K bytes to 4 Kbytes. And then a sequence of pages forms a block.<br>然后是存储器本身，读取的数据可以以页面为单位从闪存中读写，根据技术的不同，页面可以是512k字节到4 k字节。然后一系列页面形成一个块。</p>
<p>发言人   33:17<br>Now, these blocks are different from the logical blocks that the CPU does. So it’s kind of an unfortunate overlap of terms. But the? Trick is, I guess the limitation is that data is written in units of pages, but a page can only be written after the entire block has been erased. So that seems kind of weird, but that’s the way it works. So what that means is if you want to write, if you want to write to a page, you have to find a block somewhere that’s been erased. You have to copy all of the other pages in your target block over to that new block, and then you can do the right. So you can see that writes now become fairly complex operation reads.<br>现在，这些块不同于CPU的逻辑块。所以这是一种不幸的术语重叠。但是这个？技巧是，我想限制在于数据以页面为单位写入，但是只有在整个块被擦除后才能写入页面。这看起来有点奇怪，但这就是它的工作方式。所以这意味着，如果你想写，如果你想写入一个页面，你必须在某个地方找到一个被擦除的块。你必须将目标块中的所有其他页面复制到该新块中，然后你才能执行正确的操作。因此，您可以看到写入现在变得相当复杂的操作读取。</p>
<p>发言人   34:15<br>You can read anything and then like all flash. So it’s kind of inefficient, right? Because you’re writing one page. But to do that, you have to sort of copy all the other pages in that block, and you have to erase the whole. And then when you finish, then you erase this block so it can be used for other rights.<br>你可以阅读任何东西，然后就像所有的闪光灯一样。所以有点低效，对吧？因为你正在写one page。但是要做到这一点，你必须复制该块中的所有其他页面，并且必须清除整个页面。然后当您完成时，您将清除此块，以便它可以用于其他权限。</p>
<p>发言人   34:37<br>So eventually, after 100000 repeated rites, these wear out. Now, the flash translation layers in modern systems do all kinds of fancy proprietary algorithms to sort of extend the life. They use caching and various tricks to extend the life of these SSD. So in practice, it’s not really a problem, which I’ll show you in a second.<br>所以最终，在100000次重复的仪式之后，这些磨损了。现在，现代系统中的闪存翻译层采用各种花哨的专有算法来延长寿命。他们使用缓存和各种技巧来延长这些固态硬盘的寿命。所以在实践中，这并不是一个真正的问题，我一会儿就会给你展示。</p>
<p>发言人   35:02<br>So the performance characteristics of Ssds. Now you can think of a typical hard drive you might be able to get you. I mean, when I measure them, when I measure my drives, maybe 40, 50 MB per second, that would be a typical rate. These Ssd’s are 10 times faster than that. So for sequential reads, you can get about 550 MB.<br>因此，Ssds的性能特点。现在你可以想象一个典型的硬盘驱动器，你可能能够得到它。我的意思是，当我测量它们时，当我测量我的驱动器时，可能是每秒40、50个MB，这将是一个典型的速率。这些Ssd的速度比那个快10倍。因此，对于顺序读取，您可以获得大约550个MB。</p>
<p>发言人   35:28<br>Sequential writes are a little bit slower. Random access, whether you’re reading or writing, is a little bit slower than sequential access. And as we’ll see, this is fairly common in memory systems. It’s almost always better to do things sequentially than to jump around. And random writes are slower because erasing takes about a millisecond. So now we’re back up to that, that millisecond range, which is slow. And as I mentioned, if you modify one page, you have to all the other pages in that block have to be copied.<br>顺序写入有点慢。随机访问，无论您是阅读还是写作，都比顺序访问慢一点。正如我们将看到的，这在内存系统中相当普遍。按顺序做事几乎总是比跳来跳去好。而随机写入速度较慢，因为擦除大约需要一毫秒。所以现在我们回到了毫秒范围，速度很慢。正如我所提到的，如果你修改了one page，你必须复制该块中的所有其他页面。</p>
<p>发言人   36:10<br>Now, earlier Ssd’s had a huge gap between random writes and. Sequential reads. But because of sort of improvements in the flash translation layer, these aren’t really that that difference reading and writing, writing is slower, but they’re doing all kinds of interesting, amazing things to get these numbers fairly close. So when we have a model of Ssd’s, we really don’t need to distinguish any more of that between reads and writes.<br>现在，早期的Ssd在随机写入和之间存在巨大的差距。顺序读取。但是由于闪存翻译层的改进，这些并不是读写的区别，写作比较慢，但他们正在做各种有趣的、令人惊奇的事情，以使这些数字相当接近。因此，当我们有了一个Ssd模型时，我们真的不需要再区分读和写。</p>
<p>发言人   36:47<br>Okay, so Ssds, because they have no moving parts, they’re faster, they take less power, they’re more rugged, which is why they’re good for thumb drives and ipods and things like that. But they have this potential to wear out, which could be a problem in practice. It’s not, for example Intel guarantees that you can do 128 PB of rights before your SSD is no longer good. So that’s a lot of data to write. I mean, think about how many years it would take to write that much data. And as of 2015, as of now, they’re a lot more expensive per byte than rotating discs. So rotating disks are much bigger, but they’re slower. Ssd’s are smaller and they’re faster.<br>好的，所以Ssds，因为它们没有运动部件，速度更快，功耗更低，更加坚固，这就是为什么它们适合使用拇指驱动器和ipod之类的东西。但它们有可能被磨损，这在实践中可能是一个问题。这不是，例如，英特尔保证您可以在固态硬盘不再有效之前执行128 PB的权利。所以这是很多数据要写。我的意思是，想想写那么多数据需要多少年。截至2015年，截至目前，它们每个字节比旋转磁盘贵得多。因此，旋转磁盘要大得多，但速度较慢。Ssd更小，更快。</p>
<p>发言人   37:41<br>Now take, if you look at the performance characteristics of these different storage devices relative to CPU, over time, you get this really interesting graph. Now, this graph shows on the Y AIS a time in nanoseconds in a log scale. Each one of these, each change in units from 1000 to 10000 represents an order of magnitude difference in axis time on the X axis. I’ve plotted time going from 1985 to 2015, and then I’ve plotted the sort of the access time or the cycle time of the access time of these devices, disk SSD DRAM and SRAM, and the cycle time of processors. So let’s look at on the bottom, we have the cycle time of processors over time. And what you see is it’s going down at this sort of exponential rate from 1985 to 2003. There’s a doubling basically every 18 months or two years in clock frequency and a resulting halving of the cycle time over this 18 month or two year period.<br>现在，如果你观察这些不同存储设备相对于CPU的性能特征，随着时间的推移，你会得到这个非常有趣的图表。现在，这个图表显示了Y AIS上的时间，以对数刻度为纳秒。每个单位从1000到10000的变化代表了x轴上时间轴上的一个数量级差异。我绘制了从1985年到2015年的时间，然后绘制了这些设备的访问时间或访问时间的周期时间，磁盘固态硬盘DRAM和SRAM，以及处理器的周期时间。让我们看一下底部，我们有处理器随时间的循环时间。你所看到的是，从1985年到2003年，它以指数级的速度下降。基本上每18个月或两年时钟频率就会翻一番，从而在这18个月或两年的时间内将循环时间减半。</p>
<p>发言人   39:12<br>What manufacturers did until 2003 to make their processors faster was they would just double the clock frequency. They decrease the feature size of the chips that they were making, and that would allow them to put things closer together. That and then. Increase the clock frequency by a proportional amount.<br>制造商直到2003年之前为了让他们的处理器更快所做的就是将时钟频率加倍。他们缩小了他们正在制造的芯片的特征尺寸，这将使他们能够将东西更紧密地结合在一起。然后。按比例增加时钟频率。</p>
<p>发言人   39:39<br>Now, this all ended 2003 was an interesting year in computer history. Because of this, there’s this sort of unfortunate property that the power that you consume is proportional to your frequency. So the more power, I mean, the higher the frequency, the more power you consume.<br>现在，这一切都结束了2003年，这是计算机历史上有趣的一年。因此，有一种不幸的特性，即你消耗的功率与你的频率成正比。所以功率越大，我的意思是，频率越高，消耗的功率就越多。</p>
<p>发言人   39:58<br>By 2003, the processor that Intel was getting ready to ship was going to burn about 800 W of power. Think about 800 W light bulbs inside your laptop. And I actually saw an early prototype of one of these devices and the heat sink to absorb the power from the chip was about this big, it was about 4 square inches. It was a giant thing just sitting on the motherboard.<br>到2003年，英特尔准备出货的处理器将消耗约800瓦的功率。想想你的笔记本电脑里有800瓦的灯泡。我实际上看到了这些设备之一的早期原型，用于吸收芯片功率的散热器大约是这么大，大约4平方英寸。这是一个巨大的东西，只是坐在主板上。</p>
<p>发言人   40:32<br>So that’s what we say is that processor design hit the Powerwall in 2003, they can no longer just continue to increase clock frequencies to get faster, to make faster computers. And so what they had to do after 2003 instead of increasing the clock frequency, instead of doubling the clock frequency, they put more processor cores onto the chips. So now they subdivided a CPU chip into individual processor cores. Each one could execute its own instructions. And by running in parallel, you could do more effective work. So the effective cycle time could continue to go down.<br>所以我们说的是，处理器设计在2003年进入了Powerwall，它们不能再继续增加时钟频率来变得更快，制造更快的计算机。因此，2003年之后他们必须做的不是提高时钟频率，而是将更多的处理器内核放入芯片中，而不是将时钟频率加倍。所以现在他们将CPU芯片细分成单独的处理器内核。每个人都可以执行自己的指令。通过并行运行，你可以做更有效的工作。因此，有效周期时间可能会继续缩短。</p>
<p>发言人   41:21<br>So what I plotted here on the bottom is the effective cycle time. So basically, the cycle time divided by the number of cores. So here in 2005, the first systems used 2 cores. So now you can run two independent threads or two independent programs, and currently it’s about 4 cores, server class systems, you can get 8 cores, there’s even some 12 core chips.<br>所以我在底部绘制的是有效循环时间。基本上，循环时间除以内核数量。所以在2005年，第一批系统使用了2个核心。所以现在你可以运行两个独立的线程或两个独立的程序，目前大约有4个核心，服务器级系统，你可以得到8个核心，甚至还有一些12个核心的芯片。</p>
<p>发言人   41:47<br>So in the future, what’s going to happen is that the clock frequencies are going to stay fairly constant. So you can, you can see the cycle times. They actually increased a little bit here. And then they’re slowly going down, but it’s generally flat. And so the only way to really get more performance going forward is to increase the number of independent cores, and that’s just.<br>所以在未来，时钟频率将保持相当恒定。所以你可以看到循环时间。他们实际上在这里增加了一点。然后它们慢慢地下降，但总体上是平的。因此，真正获得更高性能的唯一方法是增加独立内核的数量，而这只是。</p>
<p>发言人   42:15<br>The way it’s got to be now here in the black circle, the second line I’ve plotted the access time for SRAM over time. And you can see that SRAM is tracking CPU pretty good, and it’s an order of magnitude slower. It’s tracking the CPU performance pretty well.<br>现在它必须在黑色圆圈中，我已经绘制了SRAM访问时间的第二条线。你可以看到，SRAM跟踪CPU的速度相当不错，而且要慢一个数量级。它很好地跟踪了CPU的性能。</p>
<p>发言人   42:37<br>DRAM, you can see there’s a huge gap between the CPU and the DRAM, several orders of magnitude. And in the last few years Drams have gotten a little better, but they’ve proven surprisingly difficult to make faster. Ssds are kind of in between disks and Drams. And then disks up here, you can see at a million nanoseconds, that’s a milliseconds. So you can see disks are sort of in this, in this sort of millisecond range with access times, and they’ve gone down a little bit, but not really too much. So the point I want to make is that there’s this huge gap between DRAM SSD disk and Cpu’s. And in some cases, it’s even getting worse as time goes by. So that’s a problem, right?<br>你可以看到，CPU和DRAM之间存在几个数量级的巨大差距。在过去的几年里，Drams的性能有所改善，但事实证明，要让它们变得更快是非常困难的。Ssds介于磁盘和dams之间。然后磁盘在这里，你可以看到一百万纳秒，那是毫秒。所以你可以看到磁盘有点像这样，在这种毫秒范围内的访问时间，它们已经下降了一点，但不是太多。所以我想要说明的是，DRAM固态硬盘磁盘和Cpu之间存在巨大的差距。在某些情况下，随着时间的推移，情况甚至变得更糟。所以这是个问题，对吧？</p>
<p>发言人   43:33<br>How our programs all need data. Our data is stored in memory and disk. So if our computers are getting faster and our storage devices are staying relatively the same or relatively slower, then we’ve got a problem. Increases in our and computer performance will, it’ll be hard to make our programs run faster because it’ll be limited by the time it takes to access the data. So that’s sort of the fundamental problem that we have to deal with.<br>我们的程序都需要数据。我们的数据存储在内存和磁盘中。因此，如果我们的计算机变得更快，而我们的存储设备保持相对不变或相对较慢，那么我们就有问题了。在我们和计算机性能提高的情况下，很难让我们的程序运行得更快，因为它会受到访问数据所需时间的限制。这就是我们必须处理的基本问题。</p>
<p>发言人   44:08<br>And it turns out that the key to bridging this gap between the CPU and memory is this very basic fundamental property of programs called locality. And so this is an essential sort of fundamental, enduring property of programs, So we say that so programs have this property called locality. And what this means is that I’m sorry, just I have to read it because it’s really accurate definitions.<br>事实证明，弥合CPU和内存之间的差距的关键是程序的一种非常基本的基本属性，称为局部性。因此，这是程序的基本的、持久的属性的基本类型，因此我们说程序具有称为局部性的属性。这意味着我很抱歉，我必须阅读它，因为它的定义非常准确。</p>
<p>发言人   44:47<br>So programs tend to use data and instructions whose addresses are near or equal to those that they have used recently. So if a program accesses a data item, the chances are very high that it’s going to access that data item or a nearby data item sometime in the near future. That likelihood that the program is going to access that data item or a nearby at data item in the near future is this property called locality.<br>因此，程序倾向于使用地址接近或等于它们最近使用的地址的数据和指令。因此，如果一个程序访问一个数据项，它将在不久的将来访问该数据项或附近的数据项的可能性非常高。该程序在不久的将来访问该数据项或附近的数据项的可能性是这个称为 “局部性” 的属性。</p>
<p>发言人   45:23<br>Well, we typically distinguish two different kinds of locality. Temporal locality is the property that recently referenced items are likely to be referenced again in the near future. So if you read a variable, chances are you’re going to read that variable again. For example, suppose you’re summing into a variable inside of a loop. Each loop iteration, you’re going to access that, that variable. Spatial locality is that the tendency for items with nearby addresses that items, if we access, if we access one item, chances are high we’re going to access a nearby item. So let’s look at this little snippet of code and see if we can identify all the different kinds of locality in this code.<br>好的，我们通常区分两种不同的地点。时间局部性是最近引用的项目在不久的将来可能再次被引用的属性。所以如果你读了一个变量，很有可能你会再次读那个变量。例如，假设你在循环内求和一个变量。每次循环迭代，您都将访问那个变量。空间局部性是指具有附近地址的项目的趋势，如果我们访问某个项目，我们很有可能访问附近的项目。让我们看一下这段代码，看看我们是否可以识别这段代码中所有不同类型的位置。</p>
<p>发言人   46:17<br>So we have two different kinds of references. There’s data references, and then there’s instructions. So we’re reading instructions out of memory, and those instructions are referencing data.<br>所以我们有两种不同的参考文献。有数据参考，然后有说明。所以我们从内存中读取指令，而这些指令引用数据。</p>
<p>发言人   46:29<br>So first of all, notice that we’re referencing the elements of an array in succession. So we’re increasing I by one each time. And then so we’re incrementing each iteration through the loop, and we’re reading AI. So this is called a stride one reference pattern. The stride is how much we’re incrementing this index. So since we’re incrementing it by one, we call that a stride 1 pattern.<br>首先，请注意我们正在连续引用数组的元素。所以我们每次将I增加一个。然后，我们通过循环递增每个迭代，并阅读AI。所以这被称为步幅一参考模式。步幅是我们增加这个指数的幅度。所以，由于我们将其递增一，我们称之为步幅1模式。</p>
<p>发言人   46:58<br>So what kind of locality is the repeated references to AI, spatial or temporal. Spatial because we’re accessing nearby items. What about referencing this variable sum inside the loop? That’s temporal.<br>那么对AI的重复引用是什么样的地点，是空间的还是时间的。空间，因为我们正在访问附近的物品。在循环中引用这个变量的总和怎么样？这是暂时的。</p>
<p>发言人   47:22<br>Now, what about instructions? Ween each loop iteration? We’re executing a sequence of instructions. So what kind of locality is that? Within each loop iteration, No, that’s spatial, right? Because we’re just executing a sequence of instructions within each loop iteration. But then we cycle through the loop repeatedly. Chances, so each loop iteration, we’re going to access each of those instructions that we access the previous loop iteration. So we go up and we, we’re just going to keep executing the same assembly language instructions that implement this loop body. Now in this simple example, it’s probably one instruction, but in general, your loop can have multiple instructions.<br>那么，指令呢？是否每个循环迭代？我们正在执行一系列指令。那是一个什么样的地方？在每个循环迭代中，不，那是空间的，对吧？因为我们只是在每个循环迭代中执行一系列指令。但是随后我们反复循环循环。机会，所以每次循环迭代，我们将访问我们访问前一次循环迭代的每条指令。所以我们向上走，我们将继续执行与实现此循环体相同的汇编语言指令。现在在这个简单的例子中，它可能是一条指令，但一般来说，你的循环可以有多条指令。</p>
<p>发言人   48:16<br>Now, what I claim to you, and one of the main sort of points of this whole course is that as a professional programmer, it’s an essential skill that you be able to look at code and you get a qualitative sense of its locality. Because as we’ll see, good locality turns into good performance.<br>现在，我向你声称，这整个课程的主要观点之一是，作为一名专业程序员，能够查看代码并获得其局部性的定性感知是一项基本技能。因为正如我们将要看到的，好的地方变成了好的表现。</p>
<p>发言人   48:40<br>The way that systems are built these days. So as a programmer, it’s very important for you to be able to kind of look at code and get some qualitative sense, like that’s pretty good locality, that’s terrible locality. And what you want to do is avoid the terrible locality in your code.<br>这些天系统的构建方式。所以作为一名程序员，能够查看代码并获得一些定性感知非常重要，比如这是相当好的局部性，那是可怕的局部性。你想要做的是避免代码中的可怕局部性。</p>
<p>发言人   48:59<br>So let’s look at a simple example here to see what I mean by this. So what I’m doing is I’m taking an array, a two dimensional array A with m rows and n columns, and within a doubly nested loop, iterating on I and J I’m summing the elements of that array. It seems this is a very simple operation, what could go wrong, right? So it turns out if you write this code to have bad locality, it’ll run order of magnitude slower. So just look at this. If you look at this, do you think this has good locality or bad locality? I mean, let’s look at with respect to the accesses of A.<br>那么让我们来看一个简单的例子，看看我的意思是什么。所以我正在做的是获取一个数组，一个具有m行和n列的二维数组a，并在一个双重嵌套循环中迭代I和J，我正在求和该数组的元素。看起来这是一个非常简单的操作，可能会出错，对吧？所以事实证明，如果你编写这个代码具有错误的局部性，它会运行得慢几个数量级。所以看看这个。如果你看看这个，你认为这里的地点是好还是坏？我的意思是，让我们看看A的访问权限。</p>
<p>发言人   49:56<br>Good or bad?<br>好还是坏？</p>
<p>发言人   50:03<br>Well, so how is a laid out in memory, right? It’s rho y, so c uses lays out arrays, rho y, so all the elements of the first row, followed by all the elements of. The second row, followed by all the elements of the third row.<br>那么，在记忆中如何铺开呢？它是rho y，因此c使用布局数组rho y，因此第一行的所有元素，后面跟着的所有元素。第二行，后面跟着第三行的所有元素。</p>
<p>发言人   50:24<br>So how are we accessing this array? We’re accessing aij, and we’re varying j the fastest. So we hold I constant, and then we vary j, and then we all, so we hold I constant to access row I, and then we vary j to access all the columns in that row. So each each iter, and then we increase, and then we go back and increase I so now we’re accessing the next row. So if we were to look at the addresses of aij, the sequence of addresses that are being read, those would correspond to a stride 1 AIS. And so we’d be accessing all the elements of of a sequentially in order. So that’s really good spatial locality. That’s the best you can do.<br>那么我们如何访问这个数组呢？我们正在访问aij，并且我们以最快的速度变化j。所以我们保持I不变，然后改变j，然后我们全部，所以我们保持I不变以访问第I行，然后我们改变j以访问该行中的所有列。所以每个iter，然后我们增加，然后我们返回并增加I，现在我们正在访问下一行。因此，如果我们查看aij的地址，即正在读取的地址序列，这些地址将对应于步幅1 AIS。因此，我们将按顺序访问的所有元素。所以这是非常好的空间局部性。这是你能做的最好的了。</p>
<p>发言人   51:22<br>Now, what about? And then we have temporal locality on some. So that’s good. So everything about this is pretty good. So this is the good case.<br>现在，怎么样？然后我们有一些时间局部性。这很好。所以这方面的一切都相当不错。所以这是一个好的案例。</p>
<p>发言人   51:35<br>Now what about this, what I’ve done? I’ve taken the same program and I’ve just inverted the loops, so I have loop on J first, and then on I, and then I just have the same inner loop body. Now, what does that do to the spatial locality of our accesses? Of a terrible because it’s going? You should be offended when you see this.<br>现在怎么样，我做了什么？我已经使用了相同的程序，并且我刚刚反转了循环，所以我首先循环J，然后循环I，然后我只有相同的内部循环体。现在，这对我们访问的空间局部性有什么影响？可怕的，因为它正在发生？当你看到这个时，你应该感到生气。</p>
<p>发言人   52:08<br>This is awful, but it’s terrible, right? Because so now J, we’re holding j constant, and then we’re iterating through the jth element of each row. So that’s skipping, We have n elements in each row, so we’re doing a stride n access through memory. So we’re like this, and then we’re then, then we’re incrementing the column by one, and then we’re doing this again. So it’s terrible spatial locality. This is the worst spatial locality we could get.<br>这很糟糕，但也很糟糕，对吧？因为现在J，我们保存j常量，然后迭代每行的第J个元素。所以这是跳过，我们每一行有n个元素，所以我们通过内存进行跨步访问。所以我们是这样的，然后我们将列递增一，然后我们再次这样做。所以这是可怕的空间局部性。这是我们能得到的最糟糕的空间位置。</p>
<p>发言人   52:51<br>Now let’s look at a three dimensional array. And let me pose the following question. Can you, based on this sort of qualitative idea, this idea that you want to try to get a stride one reference pattern? So how would you permute these given this, given this inner body, aka ij, how would you permute these loop indices to give a stride one reference pattern? That’s right, k ij is right. So in general, what we want to do is we want to go going from right to left. We want those indices to be changing the fastest. So we want j, we want k, and I to be held constant on, and then we want to change j, then we want to increment I, and then for that, those values of k and I, we want to sequence through all the values of j again.<br>现在让我们来看一个三维数组。让我提出以下问题。基于这种定性的想法，你想尝试获得跨步参考模式的想法可以吗？那么，在给定这个内部身体，也就是ij的情况下，您将如何对这些循环索引进行排列，以提供一个步幅一个参考模式？这是对的，k ij是对的。一般来说，我们想要做的是从右到左前进。我们希望这些指数变化最快。所以我们希望j，我们希望k和I保持不变，然后我们想要改变j，然后我们想要增加I，为此，我们想要对j的所有值进行排序。</p>
<p>发言人   54:00<br>Okay, so we’ve looked at properties of of storage technologies. And there’s this sort of basic, sort of fundamental principle that cheaper storage. Bigger storage, higher capacity storage is cheaper. More expensive storage is smaller because we can’t spend enough money. There’s this gap. There’s this gap between our storage devices and the CPU that, at least in the case of disks, they’re getting bigger. And we have programs that exhibit locality. These three things, these properties, storage technologies, and properties of our programs complement each other in this beautiful way to suggest and inform the design of our storage systems. And this design is something called the memory hierarchy.<br>好的，我们已经研究了存储技术的特性。而且有一种基本的、基本的原则，就是更便宜的存储。更大的存储，更高容量的存储更便宜。更昂贵的存储空间更小，因为我们不能花足够的钱。有这个差距。我们的存储设备和CPU之间存在着差距，至少在磁盘方面，它们正在变得越来越大。我们有展示地方的节目。这三件事情，这些属性，存储技术和我们程序的属性，以这种美丽的方式相互补充，建议和指导我们的存储系统的设计。这个设计被称为记忆层次结构。</p>
<p>发言人   55:07<br>Here’s the idea of a memory hierarchy. You layer. Instead of a flat memory system, you now you create your memory system as a hierarchy of devices. And at the top of this hierarchy, you have your smaller, faster, and more expensive storage devices. At the very top, you have registers are, which can be accessed within one cycle, right? One instruction while that instruction is executing can access read and write into a register, so registers are at the top of the hierarchy. But because those are in custom silicon, they’re very expensive. The fabrication plants to make processors cost billions of dollars. So this is the most expensive, and because of that, it’s also the smallest.<br>这里有一个记忆层次结构的想法。你层。现在，您可以将内存系统创建为设备的层次结构，而不是平面内存系统。在这个层次结构的顶部，您有更小、更快、更昂贵的存储设备。在最顶部，您有寄存器，可以在一个周期内访问，对吗？一条指令在执行时可以读取和写入寄存器，因此寄存器位于层次结构的顶部。但由于这些是定制硅，它们非常昂贵。制造处理器的制造厂耗资数十亿美元。所以这是最贵的，也正因为如此，它也是最小的。</p>
<p>发言人   56:00<br>We’ve only got 16 registers at the top of the hierarchy. Now below that, put one or more SRAM memories. Remember SRAM is faster, it’s the fastest kind of memory. So we put one or more so-called caches, cache memories built out of SRAM in the processor chip itself. And then, and these caches, because they’re made out of SRAM, they’re on the order of megabytes in size. They’re much bigger than registers, but they’re megabytes, which if we look, and then beneath that is our main memory, which is built out of Drams. And those can be gigabytes, tens of gigabytes on modern systems. And then below that is our local disks.<br>我们在层次结构的顶部只有16个寄存器。现在在下面放置一个或多个SRAM记忆。请记住，SRAM更快，它是最快的内存类型。因此，我们在处理器芯片本身中放置了一个或多个所谓的缓存，即由SRAM构建的缓存内存。然后，这些缓存，因为它们是由SRAM组成的，它们的大小在兆字节量级上。它们比寄存器大得多，但它们是兆字节，如果我们看一下，下面是我们的主内存，它是用dram构建的。而这些可以是千兆字节，在现代系统上可以是数十千兆字节。下面是我们的本地磁盘。</p>
<p>发言人   56:54<br>And we can even have lower layers like web servers that are storing for storing stuff on Google that you can think of that as just part of our hierarchy.<br>我们甚至可以有更低层，比如网络服务器，它们在谷歌上存储东西，你可以把这看作是我们层次结构的一部分。</p>
<p>发言人   57:06<br>Now, here’s the key idea. In a memory hierarchy, each level in this hierarchy holds data that’s retrieved from the next lower. So cache registers hold data that’s stored in the L 1 cache. The L 1 cache holds data that’s retrieved from the L 2 cache. The L 3 cache holds data that’s restored, that’s retrieved from main memory. Main memory holds data retrieved from secondary disk, and so on.<br>现在，这是关键的想法。在内存层次结构中，此层次结构中的每个级别都保存从下一个较低级别检索的数据。所以缓存寄存器保存存储在L 1缓存中的数据。L 1缓存保存从L 2缓存检索的数据。L 3缓存保存已恢复的数据，这些数据是从主内存检索的。主内存保存从辅助磁盘等检索到的数据。</p>
<p>发言人   57:43<br>Now, as we’ll see, the reason memory systems are designed like this is that they when you have this kind of system. In general, you can access your data at the speed of the fastest item in the day and at the top of the hierarchy. So that’s the fastest. But with the cost of the storage at the lower part of the hierarchy. So this works all because of an idea called caching. So a cache to a.<br>现在，正如我们将看到的，记忆系统被设计成这样的原因是当你拥有这种系统时。通常，您可以以一天中最快的项目的速度和层次结构的顶部访问数据。所以这是最快的。但存储成本位于层次结构的较低部分。所以这之所以有效，完全是因为一种叫做缓存的想法。缓存到a。</p>
<p>发言人   58:25<br>Computer scientist is a it’s a smaller, faster storage device that acts as a staging area for the data in a larger, slower device. So just like here, you can think of your main memory is a cache for data that’s stored on disk. You read memory from disk, and then you store it in main memory. You can think of the main memory as a staging area. So once you get the data from the disk, you don’t access it again on the disk. You access it in memory, which is much faster. So this idea propagates all the way up the hierarchy.<br>计算机科学家是一种更小、更快的存储设备，充当大型、更慢的设备中数据的临时区域。就像这里一样，你可以把你的主内存想象成存储在磁盘上的数据的缓存。你从磁盘中读取内存，然后将其存储在主内存中。你可以把主存储器想象成一个临时区域。因此，一旦您从磁盘中获取数据，就不会再在磁盘上访问它。您可以在内存中访问它，这要快得多。所以这个想法一直在层次结构中传播。</p>
<p>发言人   59:03<br>So you can think of a cache. One way to think of a cache is imagine your backpack when you’re getting ready to come to school in the morning. So you’re in your apartment, which is kind of far away from school. So before you come into school, you take items from your house and you put them in your backpack because, and then, then you come to school and if you need those items, they’re in your backpack. If you didn’t do that every time you needed something, you’d have to walk back home and get it and walk back to school.<br>所以你可以想到一个缓存。一种思考缓存的方法是想象你的背包，当你准备早上上学的时候。所以你在你的公寓里，离学校有点远。所以在你来学校之前，你从家里拿物品放在你的背包里，因为，然后你来到学校，如果你需要这些物品，它们就在你的背包里。如果你每次需要什么东西的时候不这样做，你就必须步行回家去拿，然后步行回学校。</p>
<p>发言人   59:40<br>So the idea of caching is it’s a very familiar kind of simple notion, but it turns out to be quite powerful. And it shows up in all parts of of computer systems.<br>所以缓存的想法是它是一种非常熟悉的简单概念，但事实证明它非常强大。并且它出现在计算机系统的各个部分。</p>
<p>发言人   59:54<br>So what we say is for each level k in the hierarchy, the faster, smaller device at level k serves as a cache. For the larger, slower device at level k plus one. And remember, our levels go from, so L 0 is the highest. So the smallest, lowest level is actually the highest, the furthest up in the hierarchy. And as we increase the levels, we’re going down the hierarchy.<br>所以我们所说的是，对于层次结构中的每个级别k，级别k中更快、更小的设备充当缓存。对于级别k加一的较大、较慢的设备。请记住，我们的水平从，所以L 0是最高的。所以最小的、最低的层次实际上是层次结构中最高、最远的。随着我们增加级别，我们将沿着层次结构往下走。</p>
<p>发言人   01:00:24<br>Now, why do they work? So this is a really fundamental idea. They work because of locality. So because of locality, programs tend to access data that’s stored at level k more often than they access data at level k plus one. So if we access an item at level k plus one, we can move it up to level K, chances are, because of locality, we’re going to access it again. So now we’re accessing the data at level k multiple times at the rate at the speed of level k, not at the speed of level k plus one. So that’s the fundamental idea.<br>现在，他们为什么工作？所以这是一个非常基本的想法。他们工作是因为当地的原因。因此，由于局部性的原因，程序倾向于更频繁地访问存储在级别k的数据，而不是访问级别k加一的数据。因此，如果我们访问k加一级别的项目，我们可以将其移动到K级别，由于位置的原因，我们很可能会再次访问它。所以现在我们以级别k的速度多次访问数据，速度不是级别k加一。这就是基本思想。</p>
<p>发言人   01:01:11<br>And because we’re not accessing data at level k plus one as often, we can afford to use slower storage devices, which are cheaper. And thus, we can make them bigger and cheaper to bit. So what this does is the hierarchy creates a large pool of storage that’s roughly about the size of the lowest level that can be accessed at the speed at the highest level.<br>而且因为我们不经常在级别k加一访问数据，我们可以负担得起使用较慢的存储设备，这些设备更便宜。因此，我们可以把它们做得更大，更便宜。所以这样做的是层次结构创建了一个大型存储池，大小大约是最低级别的大小，可以以最高级别的速度访问。</p>
<p>发言人   01:01:45<br>All right, let’s look at how caching works in a general way. And then we’ll see on Thursday how these hardware cache memories work. But like I said, caching is a very general idea that can be applied at all levels in the hierarchy.<br>好的，让我们来看看缓存在一般情况下是如何工作的。然后我们将在周四看到这些硬件缓存存储器是如何工作的。但是就像我说的，缓存是一个非常普遍的想法，可以应用于层次结构中的所有级别。</p>
<p>发言人   01:02:03<br>Here we have a cache in all kinds of most caches. There’s some kind of transfer unit to go from one level to the next. At this upper level, we have what we’ll call the cache that can hold four blocks, so our memory. And then at the lower level, we have memory. And this memory is partitioned into blocks of some fixed size. That’s the way cache is near the upper part of hierarchy work.<br>在这里，我们在各种大多数缓存中都有一个缓存。有一种转移单元可以从一个级别转到下一个级别。在这个上层，我们拥有所谓的缓存，可以容纳四个块，即我们的记忆。然后在较低层次，我们有记忆。并且这个内存被划分成一些固定大小的块。这就是缓存靠近层次结构上部的工作方式。</p>
<p>发言人   01:02:41<br>Now, at the lower level, it’s like if you’re accessing data, say, from a web server, then the data is partitioned into files typically. But at upper levels, the data is partitioned into block. So just suppose this is main memory. And then above that we have that consists of a bunch of these blocks. So we just take the memory and partition into blocks where each block is the same number of bytes. And then data will be transferred between memory and the cache in block size transfer units. So if you need data from the memory, if the cache needs data from the memory, it’ll grab a whole block. And then at any point in time, the cache holds a subset of the blocks in main memory.<br>现在，在较低的级别上，就像如果您正在访问数据，例如从web服务器，那么数据通常会被分区为文件。但在较高的级别，数据被分区为块。所以假设这是主记忆。然后在上面我们有由一堆这些块组成的。所以我们只是将内存和分区分成几个块，每个块的字节数相同。然后数据将以块大小传输单元在内存和缓存之间传输。因此，如果您需要内存中的数据，如果缓存需要内存中的数据，它将占用整个块。然后在任何时间点，缓存都保存主内存中块的子集。</p>
<p>发言人   01:03:31<br>So this cache is much faster, but it’s also much slower. And because of that, and it’s much smaller. I’m sorry, it’s much faster, but it’s much more expensive because it’s faster. It’s more expensive. And because it’s more expensive, it’s smaller.<br>所以这个缓存速度要快得多，但速度也慢得多。正因为如此，它变得更小了。对不起，它更快，但是因为它更快，所以它更昂贵。它更昂贵。因为它更贵，所以更小。</p>
<p>发言人   01:03:56<br>Now suppose the cache wants to reference, say, that the CPU asks for data that’s contained in block 4. So it looks to see if the data is in the cache, it’s not. So the cache asks the memory to give it block 4. So that block is copied from memory into the cache, overriding the one of the existing, in this case, block 8. It’ll overwrite block 8. Now block 4 is in our cache now.<br>现在假设缓存想要引用，比如说，CPU请求的数据包含在第4块中。所以它会查看数据是否在缓存中，其实不是。所以缓存要求内存给它块4。以便将该块从内存复制到缓存中，覆盖现有的块之一，在本例中为块8。它会覆盖第8块。现在块4现在在我们的缓存中。</p>
<p>发言人   01:04:32<br>Now suppose the CPU for some data that’s in block 10, that gets copied up and we overwrite that block. Now the whole idea of storing it in the cache is that we’re hoping that the program that’s executing on the CPU, we’ll reuse one of those blocks we just spent all the time we went to all this trouble to copy from memory to this cache. And we know that’s slow.<br>现在假设块10中的某些数据的CPU被复制并覆盖该块。现在，将其存储在缓存中的整个想法是，我们希望在CPU上执行的程序能够重用其中的一个块，我们一直在费心地将其从内存复制到缓存中。我们知道这很慢。</p>
<p>发言人   01:05:02<br>So now suppose that the CPU needs some data in block B, in this case 14, okay? So it needs a memory word that’s stored that was originally stored in memory in block 14. Well, now this CA can just return, that’s what we call a hit. So the block that we access is in the cache. So that’s good. Hits are good because now we can return that block directly to the CPU. And this memory is much faster than if we had to go all the way to main memory to the DRAM. So the SRAM much faster than the DRAM. So the CPU gets that block 14 much faster than it would have if it had just gone all the way to memory.<br>现在假设CPU需要块B中的一些数据，在这种情况下是14，好吗？所以它需要一个存储在块14中的内存字。好的，现在这个CA可以返回了，这就是我们所说的打击。所以我们访问的块在缓存中。这很好。命中结果很好，因为现在我们可以直接将该块返回到CPU。这种内存比我们必须从主内存一直到DRAM要快得多。因此，SRAM比DRAM快得多。因此，CPU获取块14的速度比它刚刚完全进入内存的速度要快得多。</p>
<p>发言人   01:05:56<br>Sort of.<br>类似的。</p>
<p>发言人   01:05:59<br>The opposite of a hit is a miss. So suppose the Cpus for block 12, the cache looks for that block, can’t find it, That’s a miss. So the cache has to ask that the main memory of the DRAM for block 12, where it gets copied into the cache, and then it can return that. So that takes longer. So the CPU has to wait for that block X to be fetched from memory. And so misses are slow. So hits are good because they’re fast. Misses are bad because they’re slow.<br>命中的反面是错过。所以假设块12的CPU，缓存会寻找该块，但找不到，这是一个遗漏。所以缓存必须要求块12的DRAM的主内存复制到缓存中，然后它可以返回它。所以需要更长的时间。所以CPU必须等待从内存中获取那个块X。所以错过是缓慢的。所以点击数很好，因为它们很快。错过是不好的，因为它们很慢。</p>
<p>发言人   01:06:35<br>Now, we typically distinguish between several different kinds of caches. So the first kind of miss is a cold miss or a compulsory miss, which is caused because there’s just nothing in the cache. Initially, caches are empty, they have no blocks. And as we, as we fetch blocks from the lower level, from the next level and put them in the cache, the cash will slowly fill up with blocks and get, and that will increase the likelihood of hits. But when the cash is empty, we’re going to miss every time. So there’s just no way to avoid cold misses you. So this is called warming up your cache. So as you load data items into the cache initially it’s called, and as you add more items, you’re warming it up, meaning that you’re increasing the likelihood of a hit.<br>现在，我们通常区分几种不同类型的缓存。所以第一种失误是冷失误或强制性失误，这是因为缓存中没有任何东西引起的。最初，缓存是空的，它们没有块。当我们从较低的级别提取块，从下一个级别提取块并将它们放入缓存时，现金会慢慢填满块并获取，这将增加命中的可能性。但是当现金是空的时候，我们每次都会错过。所以没有办法避免感冒会让你想念。所以这叫做预热你的缓存。因此，当您将数据项加载到缓存中时，最初称为它，而当您添加更多项目时，您正在预热它，这意味着您正在增加命中的可能性。</p>
<p>发言人   01:07:26<br>Theres? Another sort of symmetric kind of miss, which is called a capacity miss. And these misses are due to the fact that the cache is just a certain size. In the example we looked at, we only had four blocks.<br>有吗？另一种对称类型的未命中，称为容量未命中。而这些失误是由于缓存只有一定的大小。在我们看的例子中，我们只有四个区块。</p>
<p>发言人   01:07:48<br>If our temporal locality involves 8 blocks, say if the loop that we’re accessing is, is accessing elements in array that consists of eight blocks, there’s just not enough room to store 8 blocks in that four block cache. So we’re going to get misses. We would need a bigger cache to be able to satisfy and store those eight blocks. And if we had a big enough cash, then we’d get good hit rate. If we could store all the blocks in our CA, then the cash could take advantage of the spatial and temporal locality within that program.<br>如果我们的时间局部性涉及8个块，比如我们正在访问的循环正在访问由8个块组成的数组中的元素，那么在这4个块缓存中就没有足够的空间来存储8个块。所以我们会错过。我们需要更大的缓存来满足和存储这八个块。如果我们有足够大的现金，那么我们就会获得良好的命中率。如果我们可以将所有块存储在我们的CA中，那么现金就可以利用该程序内的空间和时间局部性。</p>
<p>发言人   01:08:28<br>So in general, what we call the set of blocks at any point in time when a program is running, we call the set of blocks that are sort of being accessed over and over again, the working set. So your working set and the working set will change as you go from loop to loop, from function to function. But at any point in time in your program, when you have this idea of a working set, which is sort of the blocks that you need to have stored in your cache. And so when your working set size exceeds your cache size, then you get capacity misses.<br>因此，通常情况下，当程序运行时，我们在任何时间点称之为块集，我们将一遍又一遍地访问的块集称为工作集。因此，随着循环与函数的转换，您的工作集与工作集将发生变化。但是在程序中的任何时间点，当你有一个工作集的想法时，工作集是你需要存储在缓存中的块的一种。因此，当您的工作集大小超过高速缓存大小时，您会出现容量损失。</p>
<p>发言人   01:09:04<br>There’s this other kind of weird miss called a conflict miss, which has to do with the way that caches are often implemented. So the idea is that most caches, especially hardware caches, because they have to be simple. Have they limit where a block can be placed to some small set of positions in the cache?<br>还有另一种奇怪的错过，称为冲突错过，这与缓存的实现方式有关。所以这个想法是，大多数缓存，特别是硬件缓存，因为它们必须简单。他们是否限制了一个块可以放置在缓存中的一些小位置上？</p>
<p>发言人   01:09:32<br>So like one of the simplest models is to just take block. I can only be placed in block. I mod the cache size. So in that little cache we saw that had four blocks, we would take block I for memory, and we would stick it at block I mod 4. So block 0 would go at block 0 in our cache as would block 4, and as would block 8, block 9 would go into block 1 in the cache and that’s. When that happens, suppose, suppose we use that model. So we’re going to block I, and we’re going to put it. We can only place it in the cache at block I mod 4.<br>最简单的模型之一就是取块。我只能被放在区块中。我mod缓存大小。因此，在那个小缓存中，我们看到它有四个块，我们会将块I作为内存，并将其粘贴在块I mod 4。因此，块0将在我们的缓存中进入块0，就像块4一样，块8，块9将进入缓存中的块1，这就是。当这种情况发生时，假设我们使用那个模型。所以我们要阻止I，然后我们要放置它。我们只能将它放在块I mod 4的缓存中。</p>
<p>发言人   01:10:27<br>Now suppose, suppose our reference pattern involves from memory block 0, block 4, and block 8, it’s only three blocks, so we have enough room in the cache to store those three blocks. But because of the way we’ve decided to place blocks, each block will eviction. When we access block 4, it’ll go into block 0 in the cache When we access block 4 in the cache, it’ll overwrite that block, and it’ll go into block 0 in the cache. And so because of this, it’s really the access pattern conspiring with the algorithm that we’re using for placing blocks. So because of this, we have plenty of room in the cache. But because of this sort of the access pattern conspiring with the placement algorithm, we get misses every time we we’ll see how conflict verses work in detail when we study Cash is Tomorrow.<br>现在假设，假设我们的参考模式涉及到内存块0、块4和块8，它只有三个块，所以我们在缓存中有足够的空间来存储这三个块。但由于我们决定放置街区的方式，每个街区都会被驱逐。当我们访问块4时，它将进入缓存中的块0，当我们访问缓存中的块4时，它将覆盖该块，并进入缓存中的块0。正因为如此，访问模式与我们用于放置块的算法相结合。因此，我们在缓存中有足够的空间。但是由于这种与放置算法相关联的访问模式，当我们研究明天的现金时，每次我们看到冲突是如何详细工作的时候，我们都会错过。</p>
<p>发言人   01:11:32<br>So? So these caches exist everywhere in the memory hierarchy. And so all of them are caches of one form or another. So you can think of the registers as a type of cache.<br>所以呢？因此这些缓存存在于内存层次结构中的各个位置。所以它们都是某种形式的缓存。所以你可以把寄存器看作是一种缓存。</p>
<p>发言人   01:11:50<br>What are they CA 4 or 8 B words, where is it cached? It’s cached right on the CPU itself, what’s the latency? It’s instant, happens within an instruction. And then who manages the cache? Somebody has to manage the cache when there’s a request to load an item from the lower level in the hierarchy, something has to decide what to do with that, where to put it in the cache. That’s called managing the cache. Well, in this case, the compiler manages the cache When you compile your C code, the compiler figures out which register data items from memory are going to go into.<br>它们可能是4或8 B的单词，它们缓存在哪里？它缓存在CPU本身上，延迟是多少？它是瞬间的，发生在一个指令中。然后谁管理缓存？当有人请求从层次结构的较低层加载项目时，有人必须管理缓存，有些人必须决定如何处理它，将它放在缓存中的哪个位置。这称为管理缓存。好的，在这种情况下，当您编译C代码时，编译器管理缓存，编译器会计算出内存中的哪些寄存器数据项将进入。</p>
<p>发言人   01:12:33<br>TLB, this is something, this is a cache that’s used in virtual memory. Then there’s these hardware caches called L 1 and L 2 caches. So they store 64 B blocks on modern Intel systems, and they’re cached on the CPU chip itself in Srams that are built right into the CPU chip. And depending on whether L 1 cache on Core i7 S have a latency of four cycles and L 2 has a latency of 10 cycles. And both of these are managed by hardware. So when the CPU fetches an item from the L 1 cache, where are finds it? And if there’s a miss and a block is loaded from L 2, the hardware in the L 1 cache figures out where to put it. So all this is done without any intervention by hardware disks, contains operating systems, maintain buffer.<br>TLB，这是一种在虚拟内存中使用的缓存。然后有这些硬件缓存，称为L 1和L 2缓存。因此，它们在现代英特尔系统上存储64个B块，并将它们缓存在CPU芯片本身的Srams中，这些Srams直接内置于CPU芯片中。取决于核心i7上的L 1缓存的延迟是否为四个周期，而L 2的延迟是否为10个周期。这两个都由硬件管理。所以当CPU从L 1缓存中获取一个项目时，在哪里可以找到它？如果有未命中的情况，并且从L 2加载了一个块，则L 1缓存中的硬件会确定将其放置在哪里。所以所有这些都是在没有任何硬件磁盘干预的情况下完成的，包含操作系统，维护缓冲区。</p>
<p>发言人   01:13:32<br>Caches, So in this case, what’s cached is portions of files. And they’re cached in main memory. And latency to main memory, about 100 cycles or so. And these are managed by the operating system. So the operating system reserves a portion of memory to store files that you’ve loaded. So the operating system exploits locality if you read a file and then start reading referencing bytes from that file, it’ll actually be served from the file cache and it won’t go up to disk.<br>缓存，因此在这种情况下，缓存的是文件的部分。它们缓存在主内存中。和主存储器的延迟，大约100个周期左右。这些是由操作系统管理的。因此，操作系统会保留一部分内存来存储您加载的文件。因此，如果您读取一个文件，然后开始从该文件中读取引用字节，操作系统将利用局部性，它实际上将从文件缓存中提供，并且不会上传到磁盘。</p>
<p>发言人   01:14:13<br>Network networks maintain caches like things like NFS and Afs, maintain local caches on disk. Your browser has a cache, so when it fetches files from servers, it stores those files locally on disk. So if you reference those web pages, again, they’re served from your local disk rather than going all the way across the network. So the point is that these caches exist everywhere in the memory hierarchy, and they’re all based on the same principles. They’re just implemented in different ways.<br>网络网络维护像NFS和Afs这样的缓存，维护磁盘上的本地缓存。你的浏览器有一个缓存，所以当它从服务器获取文件时，它会将这些文件本地存储在磁盘上。因此，如果您引用这些网页，它们会从本地磁盘提供服务，而不是通过网络一直提供。所以重点是这些缓存存在于内存层次结构中的各个位置，并且它们都基于相同的原则。它们只是以不同的方式实现。</p>
<p>发言人   01:14:51<br>OK, so just to summarize what we’ve done today, we’ve seen that there’s a gap between the CPU and our storage devices that continues to increase. We’ve seen that well-written have this property called locality, and we’ve seen that caching. By taking, by using caching, we can build a memory hierarchy that takes advantage of locality in programs and allows us to build storage systems where we can access data at the rate of the fastest device, but at the cost and capacity of devices at the lowest level. So Thursday, we’re going to look at a very specific part of the hierarchy called cache memories.<br>好的，总结一下我们今天所做的，我们已经看到CPU和我们的存储设备之间存在着差距，并且这种差距还在继续扩大。我们已经看到，精心编写的具有称为 “位置” 的属性，并且我们已经看到了缓存。通过使用缓存，我们可以构建一个内存层次结构，利用程序中的局部性，并允许我们构建存储系统，在这个系统中，我们可以以最快的设备的速度访问数据，但以最低水平的设备的成本和容量访问数据。今天，我们将研究层次结构中一个非常具体的部分，称为缓存记忆。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>深入理解计算机系统 011-The Memory Hierarchy</div>
      <div>http://example.com/2025/10/12/15213-011/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月12日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/12/15213-012/" title="深入理解计算机系统 012-Cache Memories">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">深入理解计算机系统 012-Cache Memories</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/12/15213-010/" title="深入理解计算机系统 010-Program Optimization">
                        <span class="hidden-mobile">深入理解计算机系统 010-Program Optimization</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
