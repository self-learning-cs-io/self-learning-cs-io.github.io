

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="发言人   00:02All right, well, good afternoon, everybody, good to see you, welcome. Welcome to all those students watching on video as well. Before we start, we were talking about joinable and detached t">
<meta property="og:type" content="article">
<meta property="og:title" content="深入理解计算机系统 025-Synchronization, Basic">
<meta property="og:url" content="http://example.com/2025/10/12/15213-025/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="发言人   00:02All right, well, good afternoon, everybody, good to see you, welcome. Welcome to all those students watching on video as well. Before we start, we were talking about joinable and detached t">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-12T02:00:24.000Z">
<meta property="article:modified_time" content="2025-10-19T11:16:51.139Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>深入理解计算机系统 025-Synchronization, Basic - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="深入理解计算机系统 025-Synchronization, Basic"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-12 10:00" pubdate>
          2025年10月12日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          11k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          94 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">深入理解计算机系统 025-Synchronization, Basic</h1>
            
            
              <div class="markdown-body">
                
                <p>发言人   00:02<br>All right, well, good afternoon, everybody, good to see you, welcome. Welcome to all those students watching on video as well. Before we start, we were talking about joinable and detached threads. And you asked the question about why you ever want to threads running in non-starch mode, why you’d ever have them running enjoyable. And I didn’t give you a very good answer. So I want to try to answer that for you better. Turns out there’s an important class of. Parallel programming There’s an important parallel programming model called Fork and Join, where program consists of a series of phases. And in each phase, in each phase, you have a worker or a master, sorry. And it creates a bunch of worker threads.<br>好的，下午好，大家好，很高兴见到你们，欢迎。欢迎所有在视频中观看的学生。在我们开始之前，我们讨论了可连接和分离的线程。你问了一个问题，为什么你想要线程以非淀粉模式运行，为什么你让它们运行得愉快。我没有给你一个很好的答案。所以我想尝试为你更好地回答这个问题。结果发现有一个重要的类别。并行编程有一个重要的并行编程模型，称为Fork和Join，其中程序由一系列阶段组成。在每个阶段，每个阶段，你都有一个工人或主人，抱歉。它会创建一堆工作线程。</p>
<p>发言人   01:06<br>And then each of those worker threads solves some part of the problem for that phase. Like you take your data structure and you break it up into chunks. And then each thread updates its own chunk of that data structure. But for whatever reason, the master then has to wait for the worker threads to finish before it can go on to the next phase. So it does a join. So this is called the fork. And then it waits for all the threads to finish by doing a join. So this is called, this is called the fork, and this is called the join. And only when all of the threads have finished can it go and do the next do the next phase.<br>然后每个工作线程解决该阶段的某些问题。就像你把你的数据结构分解成块一样。然后每个线程最新进展自己的数据结构块。但无论出于何种原因，主服务器都必须等待工作线程完成，然后才能进入下一阶段。所以它做了一个连接。这被称为分叉。然后它通过执行join等待所有线程完成。所以这被称为fork，这被称为join。只有当所有线程都完成后，它才能继续下一个阶段。</p>
<p>发言人   01:56<br>So this model is really important in things like scientific computing, where you might, you’re simulating some domain, you’re simulating nature. So you represent that as some domain, like maybe you’re simulating how heat flows over a plate, a metal plate. And so you might have these workers, you might partition the domain amongst a set of those workers. And then each one of these phases is a time step. And then so once all the workers have finished a time step, then they can advance to the next time step.<br>所以这个模型在科学计算等领域非常重要，你可能在模拟某个领域，模拟自然。所以你可以将其表示为某个域，比如你正在模拟热量如何在金属板上流动。因此，您可能拥有这些工作程序，您可能会将域划分为一组这些工作程序。然后这些阶段中的每一个都是一个时间步骤。这样，一旦所有的工作人员完成了一个时间步骤，他们就可以进入下一个时间步骤。</p>
<p>发言人   02:36<br>So sorry, I don’t know why I didn’t think of that, but that’s an important reason why you’d want this.<br>很抱歉，我不知道为什么我没想到，但这是你想要这个的重要原因。</p>
<p>发言人   02:44<br>Okay, so. We’ve seen that the threaded programs are nice because they you can share all the global variables, but. The sharing can have unintended consequences. So somehow we need a mechanism where we can control how the flows of each individual thread are interleaved so that bad things don’t happen when we share data structures. This process of controlling the inner weaving is called synchronization. So we’re going to look at techniques that you can use to write correct threaded programs by properly synchronizing them.<br>好的，所以。我们已经看到线程化的程序很好，因为你可以共享所有的全局变量，但是。分享可能会产生意想不到的后果。因此，我们需要一种机制，可以控制每个线程的流程如何交错，以便在我们共享数据结构时不会发生不好的事情。这个控制内部编织的过程被称为同步。因此，我们将研究通过正确同步线程程序来编写正确线程程序的技术。</p>
<p>发言人   03:27<br>Now, first, though, we need to have a clear idea. So sharing is the issue. If we have threads that aren’t sharing any resources, then there’s no problem that we saw this when we looked at processes. There’s no shared data structures with processes, so processes just run independently, we don’t really care how they’re interleaved, no worries. But as soon as they introduce sharing, then we have to be careful.<br>现在，首先，我们需要有一个清晰的想法。所以分享是个问题。如果我们有不共享任何资源的线程，那么我们在查看进程时看到这一点就没有问题。没有与进程共享的数据结构，因此进程只是独立运行，我们并不关心它们是如何交错的，不用担心。但一旦他们引入共享，我们就必须小心。</p>
<p>发言人   03:56<br>So to understand how to synchronize threads, we first need to have a clear idea of what we mean by sharing in threaded C programs. So the answer is not as simple as global variables are shared and stacked variables are not shared, okay? With instead, a variable, x is shared if and only if multiple thread reference some instance of that variable x, so if only one thread is accessing a particular variable, then it’s not shared. So in order to know exactly what we mean by shared, we need to answer three questions.<br>因此，要理解如何同步线程，我们首先需要对在线程C程序中共享的含义有一个清晰的概念。所以答案并不像全局变量共享和堆叠变量不共享那么简单，好吗？当且仅当多个线程引用该变量的某个实例时，变量x才被共享，因此如果只有一个线程访问特定的变量，则它不会被共享。因此，为了确切地了解共享的含义，我们需要回答三个问题。</p>
<p>发言人   04:46<br>Okay? First, what is the memory model for threads? Second, how are instances of variables mapped to memory? And then third, how many threads might be referencing those the instances of the variables? So we’ll look at now, in turn, each of those three questions.<br>好吗？首先，线程的内存模型是什么？第二，变量的实例如何映射到内存？第三，有多少线程可能引用这些变量的实例？现在我们将依次来看这三个问题。</p>
<p>发言人   05:06<br>So first is the memory model. The conceptual model is a little bit different from the operational model, the way it really works. So conceptually, we have multiple threads that run in the context of a single process. And some of that context is shared and some of it’s not shared. So each thread has its own separate thread ID, stack, stack pointer, program counter condition codes, general purpose registers, and then they all share the remaining process context, which data structures that the kernel maintains for the threads, the virtual data structures to support the virtual memory system, open files, install signal handlers, and so forth. So that’s the conceptual model. And if that were really enforced, it would be nice, it would make things simpler for us. But unfortunately, in real life, this model is not strictly enforced.<br>首先是记忆模型。概念模型与操作模型略有不同，它的实际工作方式不同。因此，从概念上讲，我们有多个线程在单个进程的上下文中运行。其中一些上下文是共享的，一些不共享。因此每个线程都有自己单独的线程账号、堆栈指针、程序计数器条件代码、通用寄存器，然后它们都共享其余的进程上下文，内核为线程维护哪些数据结构，支持虚拟内存系统的虚拟数据结构，打开文件，安装信号处理程序等。这就是概念模型。如果这真的被强制执行，那就太好了，它会让我们的事情变得更简单。但不幸的是，在现实生活中，这种模式并没有严格执行。</p>
<p>发言人   06:07<br>Now, although register values are really separate, the kernel will maintain separate context for all the registers. So that part is good, but since the threads share the address space, a thread can access the memory Sta, 1 thread can access the stack of another thread. So although conceptually, these stacks are separate and distinct and private, they’re really not. And so this can create some problems. So here’s an example of that we’ll come back to later of how this one thread can access the stack of another thread.<br>现在，尽管寄存器的值确实是独立的，但内核将为所有寄存器维护独立的上下文。所以这部分很好，但是由于线程共享地址空间，一个线程可以访问内存Sta，一个线程可以访问另一个线程的堆栈。因此，尽管从概念上讲，这些堆栈是独立、独立和私有的，但它们实际上并不是。因此，这可能会产生一些问题。这里有一个例子，稍后我们会回到这个线程如何访问另一个线程的堆栈。</p>
<p>发言人   06:49<br>So here we’re defining a global variable called pointer, which is a char star star. And then in the main routine, we’re declaring a local variable called messages, which contains it’s a two element array, which contains a couple strings, which these will be printed out by the threads that we’re going to create. And then we assign the global pointer to the address of the array messages.<br>所以在这里，我们定义了一个名为指针的全局变量，它是一个char星形变量。然后在主例程中，我们声明了一个名为messages的局部变量，它包含了一个双元素数组，其中包含了几个字符串，这些字符串将由我们将要创建的线程打印出来。然后我们将全局指针分配给数组消息的地址。</p>
<p>发言人   07:18<br>Now pointer points to messages, and then we create in a loop, we create two threads. Each of which executes this routine called thread. And we’re passing an argument so. Pthreads we’ll assign a thread ID, but in this case, we’re going to assign our own local thread ID by passing this loop index. So this is an example we talked about this last time, that kind of this is perfectly OK. There’s no race, but it’s a little weird because we’re going to take this index I, and cast it to a generic pointer. And then after we create these threads, then we’ll exit the main thread.<br>现在指针指向消息，然后我们循环创建，我们创建两个线程。每个都执行这个称为线程的例程。我们正在提出一个论点。Pthreads我们将分配一个线程账号，但在这种情况下，我们将通过传递此循环索引来分配我们自己的本地线程账号。这是我们上次讨论过的一个例子，这种情况完全没问题。这里没有种族竞争，但这有点奇怪，因为我们要把这个索引I转换成一个通用的指针。然后在我们创建这些线程后，我们将退出主线程。</p>
<p>发言人   08:09<br>Now each the thread routine dereferences its argument to get the local thread ID, and then it declares a static variable count that we’re going to use to count how many times this thread routine is called inside of a thread. And then it just prints a simple message from identifying, giving the local thread ID, and then the message indexed by my ID. So pointer points to messages. Thread zero will print hello from foo, and thread one will print hello from bar. And then we pre increment the counter variable.<br>现在每个线程例程取消引用其参数以获取本地线程账号，然后它声明一个静态变量count，我们将使用该变量来计算此线程例程在线程内调用的次数。然后它只是打印一条简单的消息，通过识别、提供本地线程账号，然后根据我的账号索引该消息。所以指针指向消息。线程零将从foo打印hello，线程一将从bar打印hello。然后我们预先递增计数器变量。</p>
<p>发言人   09:02<br>Although it looks like we’re accessing this global variable pointer. But since that was assigned to be the address of the local variable on the main thread stack, we’ve got this, these pure threads accessing local variables on the main thread stack. This is not, you never want to do this. It’s a very bad practice, but it’s the kind of thing that can happen sometimes. By accident, if you forget, that pointer actually was assigned to some stack address.<br>尽管看起来我们正在访问这个全局变量指针。但由于这个被分配为主线程堆栈上局部变量的地址，我们得到了这些纯线程访问主线程堆栈上的局部变量。这不是，你永远不想这样做。这是一种非常糟糕的做法，但这种事情有时会发生。偶然间，如果你忘记了，那个指针实际上被分配到了某个堆栈地址。</p>
<p>发言人   09:41<br>So the second question then is, how do we map variable instances to memory? Now, we looked at this when we studied linking, but let’s just review this quickly again to make sure that it’s clear to you. So global variables are variable that are referenced outside of a function. And virtual memory, the linker, when it does a symbol resolution, makes sure that there’s exactly one instance of every global variable in virtual memory. Now local variables are declared on the stack inside of a function. Without the static attribute. And so in this case, the stack for each thread will contain one instance of that local variable.<br>那么第二个问题是，我们如何将变量实例映射到内存？现在，我们在研究链接时研究了这个，但让我们再次快速回顾一下，以确保你清楚明白。因此，全局变量是在函数外部引用的变量。和虚拟内存，链接器在进行符号解析时，确保虚拟内存中每个全局变量恰好有一个实例。现在局部变量在函数内部的堆栈上声明。没有静态属性。因此，在这种情况下，每个线程的堆栈将包含该局部变量的一个实例。</p>
<p>发言人   10:38<br>Now, if variables are declared inside of a function with the static attribute, then the scope of that variable is limited to that function, meaning no other function can access it. But that static variable is stored along with all the other local variables. Any static variable declared it inside of a function has exactly one instance in memory. And if you were to have, say, multiple functions that declared the same a static variable with the same name, the compiler would disambiguate those somehow. It would append some kind of unique. It would somehow make that name unique.<br>现在，如果变量在具有静态属性的函数内声明，则该变量的范围仅限于该函数，这意味着没有其他函数可以访问它。但是该静态变量与所有其他局部变量一起存储。在函数内声明的任何静态变量在内存中都只有一个实例。如果你有多个函数声明相同名称的静态变量，编译器会以某种方式消除它们的歧义。它会附加某种独特的东西。它会以某种方式使这个名字独一无二。</p>
<p>发言人   11:25<br>So recall how all these different types of variable instances are mapped into memory. Pointer is a global variable. So there’s one instance of pointer in the address space. And it’s stored in the data segment.<br>回想一下所有这些不同类型的变量实例是如何映射到内存的。指针是一个全局变量。所以在地址空间中有一个指针实例。并且它存储在数据段中。</p>
<p>发言人   11:51<br>I, and messages are examples of local variables to main. So there’s one instance of these stored on the stack of main stack, and we’ll denote those with this notation. We’ll say variable I do M means variable I is stored on main stack and messages is stored on the stack of main. Now my ID is a local variable defined in this thread routine. And so since there’s two of these threads, there are in memory, there’s two instances of my ID, one for each the stack. Associated with each thread. So my ID dop 0 is stored on pure thres zero stack and my ID dop one is stored on pure thread one stack.<br>I和消息是局部变量到main的示例。因此，这些实例存储在主堆栈的堆栈上，我们将用这种符号表示它们。我们会说变量I do M意味着变量I存储在主堆栈上，消息存储在主堆栈上。现在我的账号是在这个线程例程中定义的局部变量。因为有两个这样的线程，内存中有两个我的账号实例，每个堆栈一个。与每个线程相关联。所以我的账号dop0存储在纯thres零堆栈上，我的账号dopone存储在纯线程一堆栈上。</p>
<p>发言人   13:00<br>And now this counter variable, the static counter variable, has just exactly one instance in virtual memory. And it’s in the data segment along with other global variables like pointer. Okay, now, so the question is. Which of these variables are shared and which are not? So we can remember what we said is it’s shared.<br>现在这个计数器变量，静态计数器变量，在虚拟内存中只有一个实例。它与指针等其他全局变量一起在数据段中。好的，现在问题是。这些变量中哪些是共享的，哪些不是？所以我们可以记住我们所说的是共享的。</p>
<p>发言人   13:32<br>If more than one thread is accessing an instance of that variable. So let’s just list all the different variables. And then let’s look at each of these threads and see if it’s referenced by that thread. Okay, so what about pointer? It’s referenced by the main thread. And what about pure thread 0? Yeah, it’s referenced by pure thread 0 right here. Right here, and similarly for P thread one. So pointer is referenced by all three threads.<br>如果有多个线程正在访问该变量的实例。所以让我们列出所有不同的变量。然后让我们看看每个线程，看看它是否被该线程引用。好的，那么指针呢？它被主线程引用。那么纯线程0呢？是的，它在这里被纯线程0引用。就在这里，对于P线程1也是类似的。所以指针被所有三个线程引用。</p>
<p>发言人   14:25<br>Now, what about count? Counts not referenced by the main thread, but it is referenced by the two peer threads. Now, what about I in main, That’s referenced by main, of course, but not by, but not by either of the two threads. Now what about messages, the messages array? So that’s accessed by main and indirectly through pointer. It’s referenced by each of these two pure threads.<br>那么，伯爵呢？它不是由主线程引用的，而是由两个对等线程引用的。现在，我在main线程中怎么样，当然，它是由main线程引用的，但不是由两个线程中的任何一个线程引用的。那么，消息数组呢？以便由main访问并通过指针间接访问。它被这两个纯线程中的每一个引用。</p>
<p>发言人   15:08<br>Now what about my ID defined in thread 0? So that’s a local variable. So it’s only referenced by pure thread 0. It’s not referenced by either the other threads. And similarly. For my idea in pure thread one. So given that definition, then, which of these variables is shared? So it’s really straightforward. Yeah, it doesn’t count.<br>现在我的账号在线程0中定义了什么？所以这是一个局部变量。所以它只被纯线程0引用。它没有被其他任何一个线程引用。同样的。我的想法是在纯线程一。那么，根据这个定义，哪些变量是共享的？所以这真的很简单。是的，这不算数。</p>
<p>发言人   15:48<br>Count a shared variable. So the question is, does count count as the share variable? And the answer is yes, because it’s declared static. There’s one instance of it in virtual memory, and each of the thread references that instance. So it’s shared.<br>计算共享变量。所以问题是，count是否算作共享变量？答案是肯定的，因为它被声明为静态的。虚拟内存中有一个它的实例，每个线程都引用该实例。所以它是共享的。</p>
<p>发言人   16:12<br>It’s really like a global variable, it’s just the scope is limited to the. It’s stored the same way a global variable is, but its scope is limited to the function that it’s defined in. So to determine if each one, which of these variables is shared and which one’s not, we just look, go across. And for any variable that’s shared by more than one thread, then it’s shared. So pointer shared. So pointer is shared, count is not shared. Oh no, no count is shared because it’s referenced by pure thread 0 and pure thread one. I is not shared because it’s only referenced by main.<br>它真的像一个全局变量，只是范围被限制了。它的存储方式与全局变量相同，但其范围仅限于定义它的函数。因此，为了确定每个变量中哪些是共享的，哪些不是，我们只需查看并跨越。对于由多个线程共享的任何变量，则它是共享的。所以指针共享。所以指针是共享的，计数不共享。哦不，没有计数是共享的，因为它是由纯线程0和纯线程1引用的。I没有被共享，因为它只被main引用。</p>
<p>发言人   17:09<br>Messages is access referenced by all three threads, so it’s shared, but my ID is not shared because it’s only referenced by exactly one thread. So pointer count and messages are the shared variables in this program, and the others are unshared. Yes, so if you declared my idea static, would it would like a second process have overwritten? So if you declared my idea static with the second process of overwritten it, yeah, that would be a race. So it would just depend on which thread executed first. So you really wouldn’t want to do that.<br>消息是所有三个线程都引用的访问，因此它是共享的，但我的账号不共享，因为它只被一个线程引用。所以指针计数和消息是这个程序中的共享变量，其他的是不共享的。是的，所以如果你宣布我的想法是静态的，它会希望第二个进程被覆盖吗？所以如果你声明我的想法是静态的，用第二个覆盖它的过程，是的，那将是一场竞赛。所以它只取决于哪个线程首先执行。所以你真的不想这样做。</p>
<p>发言人   17:56<br>OK, so we have a very clear notion now of what we mean by sharing.<br>好的，现在我们对分享的含义有了非常清晰的概念。</p>
<p>发言人   18:09<br>So these being able to share variables like this in this way is very handy. But you can run into some really nasty problems that are very surprising.<br>因此，能够以这种方式共享变量非常方便。但是你可能会遇到一些非常棘手的问题，这些问题非常令人惊讶。</p>
<p>发言人   18:20<br>So let me show you an example. This is a program called Bad Count. So there’s something wrong with this. I’m giving you a little clue, but what we will do is we want to create, we want to create a bunch of threads, a number of threads, and each of those threads will increment a global variable called count some number of times, the same number of times. So we pass in the number of iterations as the first argument.<br>让我给你看一个例子。这是一个叫做坏计数的程序。所以这有点问题。我给你一点提示，但我们要做的是创建，我们想要创建一堆线程，许多线程，每个线程将增加一个名为count的全局变量的次数，相同的次数。所以我们将迭代次数作为第一个参数传入。</p>
<p>发言人   18:57<br>And here’s, well, here’s our globally shared variable. And do you remember what volatile means? Everybody remember what that means? So what does volatile, what does volatile tell the compiler? If the scope, and so we can’t trust that that value that the same between accesses. It actually, you’re in the right direction, actually tells. It tells the compiler never to put that variable in a register. So it will always read that value from memory or store it to memory.<br>这是我们的全局共享变量。你还记得volatile的意思吗？大家还记得那是什么意思吗？volatile告诉编译器什么？如果范围，那么我们不能相信该值在访问之间是相同的。实际上，你的方向是正确的，这说明了一切。它告诉编译器永远不要将该变量放入寄存器中。因此，它将始终从内存中读取该值或将其存储到内存中。</p>
<p>发言人   19:40<br>You do that because of exactly the kind of possibility that you mentioned. So in this case, have we create two threads with two distinct calls to P thread create? Each of these threads will run the thread routine called thread, and it will pass as an argument the address of the number of iterations that it should, that it should iterate.<br>你这样做，正是因为你提到的那种可能性。在这种情况下，我们是否创建了两个线程，并使用两个不同的P线程创建调用？每个线程都将运行名为 “线程” 的线程例程，并将它应该迭代的迭代次数的地址作为参数传递。</p>
<p>发言人   20:12<br>Now, you remember when we were looking, when we were passing connected file descriptors, if we pass an address that was a race, But in this case, there’s no race, this is fine. It’s fine just to pass the address of number of iterations. So why is it okay in this case, but it wasn’t okay when we were passing the connected file descriptor that we got from accept into our thread routine?<br>现在，你还记得当我们在查看时，当我们传递连接的文件描述符时，如果我们传递的地址是竞赛，但在这种情况下，没有竞赛，这没关系。只需传递迭代次数的地址就可以了。那么为什么在这种情况下它是可以的，但是当我们将从accept获得的连接文件描述符传递到我们的线程例程时却不可以呢？</p>
<p>发言人   20:50<br>Yes? Exactly, because the thread doesn’t modify the value. The problem we had before was that our main thread was modifying that connected descriptor on the next call to accept. But here it’s just a read only variable, so we’re OK.<br>是吗？确切地说，因为线程不会修改值。我们之前遇到的问题是，我们的主线程正在下一个调用accept时修改连接的描述符。但在这里它只是一个只读变量，所以我们没问题。</p>
<p>发言人   21:07<br>But you see how tricky the reasoning can get right there? You can’t do pattern matching to determine whether you’ve got races or not races. So you can’t just say, well, it’s always bad to pass the address of some variable to a thread routine because it’s not. It just depends on the context. So in this case, we’re passing the number of iterations to each. And then we’re waiting each of those threads to finish. So this is another example of why you need, why you might want to have a non detached thread because you can’t.<br>但是你看到推理有多么棘手吗？你无法进行模式匹配来确定你是否有种族。所以你不能只是说，嗯，把某个变量的地址传递给线程例程总是不好的，因为事实并非如此。这只取决于背景。所以在这种情况下，我们将迭代次数传递给每个。然后我们等待每个线程完成。所以这是另一个例子，说明为什么你需要，为什么你可能想要一个非分离线程，因为你不能。</p>
<p>发言人   21:47<br>When we when we check the value of count, we have to make sure that every thread is finished before we check whether we got the right value or not. So we wait for each thread to finish. And now since we’ve created two threads, each of which is incrementing count n enters time, we expect count to be equal to two times n enters. And if it’s not, we print my favorite error message with the value of count. Otherwise, we. Print OK also with the value of count. So now what’s going on in the thread routine?<br>当我们检查count的值时，我们必须确保在检查我们是否得到正确的值之前，每个线程都已完成。所以我们等待每个线程完成。现在，由于我们已经创建了两个线程，每个线程都在增加count n进入时间，我们期望count等于两倍于n进入时间。如果不是，我们打印我最喜欢的错误消息，其中包含count的值。否则，我们。打印OK也可以使用count的值。那么现在在线程例程中发生了什么？</p>
<p>发言人   22:25<br>Very simple. It dereferences the. Argument that was passed in and stores it in the local copy of NS, and then it loops and enters time and increments count each time and then returns. So this is very innocuous, what could go wrong? And since this is, since this is concurrent programming, and especially since it’s threaded programming, lots of subtle things can go wrong.<br>非常简单。它取消引用。传入的参数并将其存储在NS的本地副本中，然后它循环并输入时间和每次增量count，然后返回。所以这是非常无害的，什么会出错？由于这是并发编程，尤其是由于它是线程编程，很多微妙的事情都可能出错。</p>
<p>发言人   22:58<br>So it turns out this program has a really serious bug because when we run it. When we run it on a Linux box, sometimes if we call it with an argument of 10000, sometimes we get the correct answer two times 10000 or 20000. But then the next time we run it, we get some weird number, 13051 completely wrong. So what the heck is going on here? So to understand that, we have to look at the semi language for this counter loop.<br>所以事实证明这个程序有一个非常严重的错误，因为当我们运行它时。当我们在Linux系统上运行它时，有时如果我们用一个参数10000调用它，有时我们会得到两倍于10000或20000的正确答案。但是下次我们运行它时，我们得到一些奇怪的数字，13051完全错误。这里到底发生了什么？因此，要理解这一点，我们必须看一下这个计数器循环的半语言。</p>
<p>发言人   23:40<br>So that we need to look at the semilanuta for this counter loop in the thread routine. So we’ll break it up into three chunks. The first chunk is sort of getting ready for the loop, we’ll call that the head and we will, we’ll denote it as H of I for thread I. And then we’ll isolate on these three instructions that are directly related to incrementing count. So you see, the first instruction moves, it loads the value and global variable count into register RDX So we’ll denote that as l of I next, it increments RDX we’ll denote that U of I for update, so it updates RDX, and then it stores the value, the updated value of RDX into count, so into the location associated with the global variable count. And then the rest of this loop is getting ready for to do the next iteration.<br>因此，我们需要在线程例程中查看此计数器循环的semilanuta。所以我们将它分成三个部分。第一个块有点为循环做准备，我们将其称为头部，我们将其表示为I的H，代表线程I。然后我们将隔离这三条与增加计数直接相关的指令。所以你看，第一条指令移动了，它将值和全局变量计数加载到寄存器RDX中，所以我们将表示为I的l接下来，它增加RDX，我们将表示I的U为更新，所以它最新进展RDX，然后它存储值。将RDX的更新值放入count中，以便放入与全局变量count关联的位置。然后这个循环的其余部分正在准备进行下一次迭代。</p>
<p>发言人   25:01<br>It’s not directly related to incrementing count. So we’ll just sort of group this all together and refer to it as T of I for tail.<br>它与增加计数没有直接关系。所以我们只是将这些分组在一起，并将其称为I的T或tail。</p>
<p>发言人   25:15<br>Now let’s at, let’s look at how these two threads might be executed. In general, we can’t assume that there’s any specific interleaving. So any interleaving of these two threads is possible no matter how remote it might seem.<br>现在让我们来看一下这两个线程是如何执行的。一般来说，我们不能假设有任何特定的交错。因此，这两个线程的任何交错都是可能的，无论它看起来有多遥远。</p>
<p>发言人   25:36<br>So let’s look at one example. Let’s say we’re executing on a single course, so we’re only going to do one instruction at a time. And in this column, we’ll show which thread is executing. So either thread one or thread two. And then we’ll denote which instruction in that thread is executing either HL, US or t, and then this column shows the value of RDX for thread number one. And this column shows the value of RDX for thread number 2. And since the kernel keeps separate copies of all the general purpose registers for each thread, these can be different.<br>让我们来看一个例子。假设我们正在执行单个课程，因此我们一次只执行一个指令。在本专栏中，我们将展示哪个线程正在执行。所以要么线程1，要么线程2。然后我们将指示该线程中的哪条指令正在执行HL、US或t，然后此列显示第一个线程的RDX值。此列显示线程号2的RDX值。由于内核为每个线程保留了所有通用寄存器的单独副本，因此这些寄存器可以是不同的。</p>
<p>发言人   26:24<br>And then this last column shows the value of count in memory. So let’s start executing. So initially, count is equal to 0, and thread one gets the kernel schedules thread one, so it executes H1 that has no impact on count. Then thread one loads the value of count into its copy of RDX updates it. So now RDX is equal to one, and then stores that value in RDX to count. So now count is equal to one.<br>最后一列显示内存中count的值。所以让我们开始执行。所以最初，count等于0，而线程一获取内核调度线程一，因此它执行对count没有影响的H1。然后，线程1将count的值加载到它的RDX最新进展副本中。所以现在RDX等于1，然后将该值存储在RDX中以进行计数。所以现在count等于1。</p>
<p>发言人   27:02<br>Now at this point, the colonel decides to schedule a thread two, so thread two begins executing, and when it begins executing, value of count is one, so it executes h of I, then it loads count into thread two’s copy of RDX So now RDX equals 1, it updates it, now it’s equal to 2, and then stores that value back to count the kernel then decides, oh, and then it finishes executing the tail instruction, and let’s say we’re just doing one iteration of this, and then at this point, the kernel decides just thread one since thread 2 is finished, So thread one executes the remaining statement that it has to execute, and at this point, both threads have finished and count is equal to 2, which is the value we would expect, so this is OK, and notice how, so this is actually, this is an interleaving that works, we get the correct value, and notice how I. I’ve grouped the three instructions that are actually involved in updating count together. And we’ll call that, we’ll call those three instructions a critical section. And I’ve color coded them so you can easily keep track of them.<br>现在上校决定调度一个线程2，所以线程2开始执行，当它开始执行时，count的值是1，所以它执行I中的h，然后它将count加载到线程2的RDX副本中，所以现在RDX等于1，它最新进展它。现在它等于2，然后将该值存储回内核进行计数，然后决定，哦，然后它完成执行tail指令，假设我们只是进行一次迭代，然后在此时，由于线程2完成，内核决定只线程1，所以线程一执行它必须执行的剩余语句，此时，两个线程都完成了，count等于2，这是我们期望的值，所以这是可以的，请注意，这实际上是一个工作的交错。我们得到了正确的值，并注意到我是如何工作的。我已经将实际参与更新计数的三条指令分组在一起。我们称之为关键部分，我们将这三个指令称为关键部分。我对它们进行了颜色编码，这样你就可以很容易地跟踪它们。</p>
<p>发言人   28:35<br>All right, now let’s look at another interleaving, which is feasible, but in this case, it results in the wrong value. So here we start with thread one again. It loads the value of count into its copy of RDX updates it, But then before you can store it, the colonel decides to schedule thread 2. So thread two begins executing. It loads count into its copy of RDX 2, and notice count is still 0, it’s 1.<br>好的，现在让我们来看看另一个交错，这是可行的，但在这种情况下，它会导致错误的值。所以在这里，我们再次从线程开始。它将count的值加载到它最新进展的RDX副本中，但是在您存储它之前，上校决定调度线程2。所以线程二开始执行。它将count加载到它的RDX 2副本中，通知count仍然是0，它是1。</p>
<p>发言人   29:17<br>The value in thread one RDX, the copy of RDX in thread one, but it hasn’t been updated in memory. When thread two loads its value of count, now its copy in RDX is 0. Now, at this point, the kernel reschedules thread one to execute. So thread one does its store of its copy of RDX into count and then finishes executing the tail instruction.<br>线程1 RDX中的值，线程1中RDX的副本，但它尚未在内存中更新。当线程2加载它的count值时，现在它在RDX中的副本为0。现在，在这一点上，内核重新调度线程一执行。所以线程一将其RDX副本存储到count中，然后完成执行tail指令。</p>
<p>发言人   29:51<br>The kernel reschedules thread two, which picks up where it left off. It updates its copy of count. So now RDX goes from 0 to 1, and then it stores that value into count. So all we’ve done is we’ve overwritten count, had a value one, overwritten it with a value of one. So when we finish execution of these two threads, count has the wrong value.<br>内核重新调度了线程二，从它中断的地方开始拾取。它最新进展它的计数副本。现在RDX从0变为1，然后将该值存储到count中。所以我们所做的就是覆盖了计数，值为1，用值为1覆盖它。所以当我们完成这两个线程的执行时，count的值是错误的。</p>
<p>发言人   30:22<br>And the general thing to notice is you see how these critical sections have been interleaved. In this case, the first, the critical section for thread one executed before the critical section for thread 2. But in this case, the two critical sections interleaved. So let’s see another example of that. So here you can see that these are interleaves. Suggest there might be a problem, yes?<br>一般要注意的是，你会看到这些关键部分是如何交错的。在这种情况下，线程1的第一个临界区执行在线程2的临界区之前。但在这种情况下，两个关键部分交错。让我们再看看这方面的例子。所以在这里你可以看到这些是交错的叶子。这表明可能有问题，是吗？</p>
<p>发言人   31:13<br>Well, no, so the question is, would I or count count? If we it is defined as volatile, didn’t I. Yeah, so that’s why, I mean, there’s an actually, the compiler could have compiled this code in different ways. There is actually an increment instruction that will increment it variable in memory. So we could have done the compiler could have generated this three instruction sequences, 1 instruction, and then we wouldn’t have this problem. But the problem is that it’s loading into a register, then incrementing, and then saving so that the problem comes about. Because we can. This thread can be interrupted before it finishes this three step sequence. This load, modify store sequence, yes.<br>好的，没有，所以问题是，我或伯爵会数数吗？如果我们将其定义为易失性，不是吗？是的，所以这就是为什么，我的意思是，实际上，编译器可以以不同的方式编译这段代码。实际上有一个增量指令，它将在内存中递增变量。所以编译器可以生成这三个指令序列，一个指令，这样我们就不会有这个问题了。但问题是它正在加载到寄存器中，然后递增，然后保存，这样问题就出现了。因为我们可以。此线程可以在完成这三步序列之前被中断。这个加载，修改存储序列，是的。</p>
<p>发言人   32:23<br>Would put? Yeah, so that’s right. Yeah, I guess I wasn’t clear. It prevents it from being stored permanently in a register, right? It may have to be loaded into a register, but then it’ll be written back, whereas the compiler would have the option like we’ve seen it with local variables compiler, it never allocates stack space. It just keeps that local variable in a register all the time. So this prevent the volatile attribute, prevents the compiler from doing that.<br>会放吗？是的，没错。是的，我想我不太清楚。它可以防止它被永久存储在寄存器中，对吗？它可能必须被加载到寄存器中，但之后它会被写回，而编译器会有像我们在局部变量编译器中看到的那样的选项，它永远不会分配堆栈空间。它只是一直将该局部变量保持在寄存器中。这样可以防止volatile属性，防止编译器这样做。</p>
<p>发言人   32:57<br>Okay, so let’s look at another example. So here, thread one starts, it loads count into RDX, then thread two starts, and it loads count, which is still 0 into RDX 2, updates it, and then stores it. So now count equal to one. When thread one resumes, it updates its value of count and RDX and stores that back to count. And so again, we have the same problem. So the problem here is that we’re interleaving these critical sections.<br>好的，让我们再看一个例子。所以在这里，线程一开始，它将count加载到RDX中，然后线程二开始，它将仍然为0的count加载到RDX 2中，最新进展它，然后存储它。所以现在数等于一。当线程一恢复时，它会最新进展count和RDX的值，并将其存储回count。所以，我们又面临着同样的问题。所以这里的问题是我们将这些关键部分交错在一起。</p>
<p>发言人   33:38<br>And you can understand why this is bad with a nice sort of graphical technique called a progress graph.<br>你可以理解为什么这很糟糕，用一种叫做进度图的漂亮的图形技术。</p>
<p>发言人   33:50<br>So in a progress graph, if we have for n threads, it’s an n dimensional Cartesian grid that characterizes the execution state space of a concurrent threaded program. So in this case, each here, we have two threads, So it’s a 2D coordinate system. So each axis represents the progress, the execution progress of some thread. The x axis here is thread one, and the y axis corresponds to thread 2. And then each one of these edges corresponds to the execution of an instruction.<br>因此，在进度图中，如果我们有n个线程，它是一个n维笛卡尔网格，用来表征并发线程程序的执行状态空间。因此，在这种情况下，每个线程都有两个线程，因此它是一个2D坐标系。所以每个轴代表进度，一些线程的执行进度。这里的x轴是线程1，y轴对应于线程2。然后这些边中的每一条都对应于指令的执行。</p>
<p>发言人   34:35<br>So we start out in an initial state, and then the first thing we execute is H1. So that’s represented by this arc here. So this position, this point right here, represents the state where we’ve executed. We finished executing H1 in thread one, but we haven’t yet executed any instructions in thread 2. So in general, each one of these points represents sort of the current progress of the program or the execution state.<br>所以我们从初始状态开始，然后我们执行的第一件事是h1。所以这里用这个弧线表示。所以这个位置，就在这里，代表我们执行的状态。我们在线程1中完成了H1的执行，但在线程2中还没有执行任何指令。因此，一般来说，这些点中的每一个都代表了程序或执行状态的当前进度。</p>
<p>发言人   35:08<br>So for example, this state right here represents the state where thread one has completed L 1 and thread two is completed S 2. And now the execution of a program is modeled as a transition from one state to the other. And so from this, and there’s constraints on how, on how these states can advance. So from this state, l 1 s 2, yeah, obviously time can’t go backwards. So we can’t go backwards in this direction to the left, and we can’t go down. So we can only go to the right and up. And since we’re assuming that each instruction executes, there’s only one instruction executing at a time, we can’t go diagonally. That would be two instructions from L 1 s 2.<br>例如，这里的状态代表线程一已完成L 1，线程二已完成S 2的状态。现在程序的执行被建模为从一个状态到另一个状态的转换。因此，从这个角度来看，这些状态如何发展受到限制。所以从这个状态开始，l 1 s 2，是的，显然时间不能倒退。所以我们不能朝这个方向向左倒退，也不能往下走。所以我们只能向右和向上走。由于我们假设每个指令都会执行，因此一次只执行一条指令，我们不能沿对角线前进。这将是来自L 1 s 2的两个指令。</p>
<p>发言人   36:08<br>The next execution state is either here if thread one executes or here if thread two executes. So you can put all these together to form a trajectory which characterizes one execution of the program and any feasible set of transitions from one state to the next corresponds to a feasible trajectory.<br>下一个执行状态要么在这里，如果线程1执行，要么在这里，如果线程2执行。因此，您可以将所有这些组合在一起形成一个轨迹，其表征程序的一次执行，并且从一个状态到下一个状态的任何可行过渡集都对应于一个可行轨迹。</p>
<p>发言人   36:36<br>So for example, H1, l 1, u 1, H2, l 2, s 1, t 1, u 2, whoops, u 2 s 2, and T 2. That’s a feasible. That’s a feasible trajectory. And it’s one possible, it represents one possible execution or one set of interleavings for this program.<br>例如，H1，l 1，u 1，H2，l 2，s 1，t 1，u 2，哎呀，u 2，s2和T 2。这是可行的。这是一个可行的轨迹。这是一种可能，它代表了这个程序的一种可能的执行或一组交织。</p>
<p>发言人   37:12<br>Now these three instructions Lu and S that operate, that manipulate count form what we call a critical section with respect to count. And the idea is that instructions inside these critical sections with respect to the same global variables shouldn’t be interleaved. So we can capture this geometrically by taking the intersection of these critical sections to form what we call an unsafe region.<br>现在这三个操作的指令Lu和S，它们操作计数形成我们所说的关于计数的临界区。这个想法是这些关键部分内关于相同全局变量的指令不应该交错。因此，我们可以通过将这些关键部分的交点形成所谓的不安全区域来几何地捕捉这个区域。</p>
<p>发言人   37:51<br>So insafe region is the points within an unsafe region are those points in an execution where the critical sections are interleaved. So for this particular example, there’s four points within the unsafe region. And if a trajectory ever touches one of those points, then we’ve interleaved critical section, and we’re going to get the wrong answer. So the idea is to try to stay out of these unsafe regions. And if we do, we say that that trajectory is safe.<br>因此，不安全区域内的点是执行中关键点交错的点。因此，对于这个特定的示例，在不安全区域内有四个点。如果轨迹触及其中一个点，那么我们就交错了临界区，我们将得到错误的答案。所以我们的想法是尽量远离这些不安全的地区。如果我们这样做了，我们说这个轨迹是安全的。</p>
<p>发言人   38:30<br>So here’s an example of a trajectory that’s safe. Now, this is okay, right? This point right here is not in the unsafe region because we haven’t executed, we’ve only executed H1 here. Remember, a point corresponds to the instruction that we’ve completed, that instruction. So here we’re skirting the unsafe region, but it’s still OK. So this is a safe trajectory.<br>所以这是一个安全轨迹的例子。现在没事了，对吧？这里的这个点不在不安全的区域，因为我们还没有执行，我们只在这里执行了H1。记住，点对应于我们完成的指令，即该指令。所以我们在这里绕过不安全的地区，但它仍然没问题。所以这是一个安全的轨迹。</p>
<p>发言人   38:59<br>We’ll get the right answer for this one. This trajectory is unsafe because. It enters the unsafe region at this point here. And even though it quickly exits, there’s an interleaving there that creates a potential for the correct answer.<br>我们会得到正确答案的。这个轨迹是不安全的，因为。它此时进入了不安全的区域。即使它很快就会退出，但那里有一个交错，为正确答案创造了可能性。</p>
<p>发言人   39:30<br>Okay, so the question is, how do we guarantee a safe trajectory? And this is what we call synchronization.<br>好的，问题是，我们如何保证安全的轨道？这就是我们所说的同步。</p>
<p>发言人   39:36<br>Somehow want, we want to sort of configure the kernel so that it’ll never schedule an unsafe trajectory. So how do we do that? So somehow we have to synchronize the execution of those threads. And another way to think of this is that we need to guarantee mutually exclusive access to the critical sections. Once the kernel begins, once the tred starts executing, the first instruction is critical section. We don’t want it to be interrupted by another thread that has a similar critical section. We don’t want it to be interrupted. We don’t want one critical section with respect to a certain global variable to be interrupted by another thread that has that’s currently within that same critical section.<br>我们希望以某种方式配置内核，使其永远不会安排不安全的轨迹。那么我们该怎么做呢？因此，我们必须以某种方式同步这些线程的执行。另一种思考方式是，我们需要保证对临界区的互斥访问。一旦内核开始，一旦tred开始执行，第一个指令就是关键部分。我们不希望它被另一个具有类似临界区的线程中断。我们不希望它被打断。我们不希望关于某个全局变量的一个临界区被当前在同一临界区中的另一个线程中断。</p>
<p>发言人   40:33<br>Sorry, yes, question? How frequently does that bulk of color see? Somebody might believe to me that the correct of 20000 or whatever you. OK, so the question is, how likely is it that you get a correct trajectory? And it happens? You can run it. Sometimes you do, it just depends. Usually it’s wrong, sometimes it’s right. And it just depends on how the kernel scheduled it. And you can’t assume any particular scheduling. So say if you want to claim that you would never get the right answer, then you’re assuming that the kernel is always going to schedule the unsafe trajectory. But you can’t assume that, and in fact, it doesn’t. Sometimes you just get lucky.<br>抱歉，是的，问题？那么大部分的颜色多久会看到？有人可能会相信20000的正确答案或者其他任何答案。好的，那么问题是，你得到正确轨迹的可能性有多大？它会发生吗？你可以运行它。有时你会这样做，这取决于情况。通常是错的，有时是对的。这取决于内核如何调度它。你不能假设任何特定的日程安排。因此，如果你想声称你永远不会得到正确的答案，那么你就假设内核总是会安排不安全的轨迹。但你不能假设，事实上，它并不是这样的。有时候你只是走运而已。</p>
<p>发言人   41:26<br>It turns out you have to call this function with a pretty big number in order to trip it up. So, and it makes sense, right?<br>事实证明，你必须用一个相当大的数字调用这个函数才能使其绊倒。所以，这很感知，对吧？</p>
<p>发言人   41:37<br>Usually what the kernel does is that. We can only schedule. We can only reschedule a thread, swap it out, and schedule another threat in when there’s some exception. So that passes control back to the kernel. So these exceptions are in two forms, either calling system, making system calls. So that’ll trap into the kernel, so that’s a form of exception, or the timer interrupt goes off, which transfers control back to the kernel.<br>通常内核所做的就是这样。我们只能安排。我们只能重新安排一个线程，将其交换出去，并在出现异常时安排另一个威胁。以便将控制权传递回内核。所以这些异常有两种形式，要么调用系统，要么进行系统调用。这样就会陷入内核，这是一种异常形式，或者计时器中断停止，这会将控制权转移回内核。</p>
<p>发言人   42:12<br>So the timer is going off on intervals of like milliseconds. So if we’re just doing one iteration in each thread, when a thread gets executed, the chances are very low that the timer is going to go off while that thread is executing. It’s a little loop, but, and we’re not making any system calls, so there’s nothing that will, we’re not passing control back into the kernel ourselves. So the only way the kernel is going to get access is if the timer interrupt goes up. So if we’re doing a very small number of iterations, the probability that, so here’s the timer interval, it’s going off at intervals like this here, the probability we’d have to that thread would have to have been scheduled right before a timer interrupt would go off or to interrupt that one or two iterations. So it turns out we have to call this function a lot of with editors being fairly large. So the probability of the timer interrupt going off during that during that loop, it gets increasingly large, that makes sense?<br>所以计时器的时间间隔为毫秒。因此，如果我们在每个线程中只进行一次迭代，当一个线程被执行时，计时器在该线程执行时停止的可能性非常低。这是一个小循环，但是，我们没有进行任何系统调用，所以没有什么可以的，我们不会自己将控制权传递回内核。所以内核获取访问的唯一方法是如果计时器中断上升。因此，如果我们进行非常少的迭代次数，那么这是计时器间隔的概率，它以这样的间隔进行，我们必须在计时器中断或中断一两次迭代之前安排该线程的概率。所以事实证明，我们必须在编辑器相当大的情况下调用这个函数。所以在那个循环期间计时器中断的概率会变得越来越大，这就使得感知？</p>
<p>发言人   43:38<br>So the classic solution from this comes from the early 1960s. One of the most famous computer scientists, a Dutchman named or Edgar dystra, and he came up with the classical first solution to this problem, which is what we’re going to look at. And it’s still the first. It’s fundamental and very general purpose, and there’s been many iterations and variations on this idea. But semaphores were the first in classic solution, which we’ll look at. So a semaphore is a non-snow of global integer that’s used as a synchronization variable by 2, 2 kernel functions called p and v.<br>所以这个经典的解决方案来自20世纪60年代初。最著名的计算机科学家之一，荷兰人Edgar dystra，他提出了这个问题的经典的第一个解决方案，这就是我们将要研究的。这仍然是第一个。这是一个基本且非常普遍的目的，这个想法已经进行了许多迭代和变化。但信号量是经典解决方案中的第一个，我们将会研究。所以信号量是一个非雪的全局整数，被称为p和v的2，2个内核函数用作同步变量。</p>
<p>发言人   44:29<br>Are two system calls called P and V? These P and V correspond to the Dutch words. But we just call them P and V, you just have to learn what they do. So each of these takes as an argument, a semaphore.<br>两个系统调用叫做P和V吗？这些P和V对应于荷兰语单词。但我们只叫它们P和V，你只需要学习它们做什么。所以每个都作为一个参数，一个信号量。</p>
<p>发言人   44:55<br>And the p operation has the following semantics. If s is non-zero, then decrement it by one and return immediately. And this test that it’s nonzero and the decrement occur atomically, so they’ll never be interrupted. However, if S is 0, then suspend this thread until S becomes nonzero, and that thread then is restarted by a V operation. So if, if the semaphore is 0, p just blocks, it just gets suspended until it gets restarted by a V operation. And then after it restarts, the P operation now can decrement S by one and return control to the call.<br>并且p操作具有以下语义。如果s不为零，则将其减一并立即返回。这个测试表明它是非零的，并且减少是原子性的，所以它们永远不会被中断。但是，如果S为0，则暂停此线程，直到S变为非零，然后通过V操作重新启动该线程。因此，如果信号量为0，则p会阻塞，它将被暂停，直到通过V操作重新启动。然后在重新启动后，P操作现在可以将S递减一，并将控制返回给调用。</p>
<p>发言人   46:06<br>OK, the V operation just increments s by one. And this increment, unlike that count plus plus that we looked at, just looked at that increment occurs atomically. So it can never be interrupted.<br>好的，V操作只是将s增加一。而这种增量，与我们所看到的计数加号不同，它只是在原子上发生的增量。所以它永远不会被打断。</p>
<p>发言人   46:20<br>And then after it increments S, it checks to see if there’s any threads that are blocked in AP operation. So you can think of the kernel just keeps a Q of of threads that are blocked in AP operation, and the V operation, after it increments S, it checks that Q for any threads that were blocked. Because when they did the P operation, the semaphore was 0. And then it restarts exactly one of those threads in some indeterminate order, in some order that you can’t. You can’t assume. It just picks one using some selection algorithm. And then it unblocks the suspended, the suspended process. Which then completes its P operation by decrementing S?<br>然后在它递增S之后，它会检查是否有线程在AP操作中被阻塞。因此，您可以认为内核仅保留AP操作中阻塞的线程Q，而V操作在增加S后，会检查该Q中是否有任何被阻塞的线程。因为当他们进行P操作时，信号量为0。然后它以不确定的顺序重新启动其中一个线程，以您无法确定的顺序重新启动。你不能假设。它只是使用一些选择算法来选择一个。然后它解除阻止被暂停的进程。然后，哪个通过递减S来完成其P操作？</p>
<p>发言人   47:20<br>This seems like really simple, but it can be kind of hard to get your head around the first time you see it. So are there any questions about P and V?<br>这似乎非常简单，但第一次看到它时可能会有点难以理解。那么对于P和V有什么问题吗？</p>
<p>发言人   47:37<br>So that the key idea, these definitions of p and V, is that it imposes an invariant on the semaphores called the semaphore variant, which, which is that for a semaphore S being operated on by P and V, operations s is always greater than or equal to 0. And that doesn’t seem very exciting, but it turns out this is a very useful property that will allow us to enforce mutual exclusion on these critical sections. So the P and V operations are provided by P threads in the form of three functions. There’s a seminate functions, which initializes the semaphore to some value. So semaphores can be initialized to any value greater than or equal to 0. Se weight is the P operation and Se post is the V operation. And because I’m old school, I provide wrapper functions for those in the in your CSP Doh file called P and V, it’s also more compact 2.<br>因此，p和V的这些定义的关键思想是，它对信号量施加了一个称为信号量变体的不变性，即对于由P和V操作的信号量，操作S始终大于或等于0。这似乎并不是很令人兴奋，但事实证明这是一个非常有用的属性，它将允许我们在这些关键部分上实施互斥。因此，P和V操作由P线程以三个函数的形式提供。有一个半函数，它将信号量初始化为某个值。因此，信号量可以初始化为任何大于或等于0的值。Se权重是P操作，Se post是V操作。而且因为我是老派，我为您的CSP Doh文件中的P和V提供了包装函数，它也更紧凑2。</p>
<p>发言人   49:03<br>Okay, so recall our buggy program called Bad Count DOC, which was giving us the wrong answers for count. So how do we use semaphores to fix this program?<br>好的，回想一下我们的错误程序Bad Count DOC，它给了我们错误的count答案。那么我们如何使用信号量来修复这个程序呢？</p>
<p>发言人   49:21<br>So the basic idea is to create a semaphore which is initialized to one. And so by definition, we’ll call any semaphore which is initialized to one that’s used to provide mutual exclusion. We’ll call that a mutex. And this goes back to the early Dykstra papers. So we’ll associate a unique mutex initialized to one for each shared variable in our program. So in this case, count, we have count. So we have one shared variable that we’re concerned about. So we’ll create one mutex that we’ll call mutex. And then you surround the critical section with respect to count with AP, you call p, then you execute the critical section, and then you call v.<br>所以基本的想法是创建一个初始化为1的信号量。因此，根据定义，我们将调用任何初始化为用于提供互斥的信号量。我们称它为互斥锁。这可以追溯到早期的Dykstra文件。因此，我们将为程序中的每个共享变量关联一个唯一的互斥锁。所以在这种情况下，伯爵，我们有伯爵。所以我们有一个我们关心的共享变量。所以我们将创建一个我们称之为互斥锁的互斥锁。然后你用关于计数的AP包围临界区，你调用p，然后执行临界区，然后调用v。</p>
<p>发言人   50:18<br>Now, there’s some terminology we’ll use when we talk about semaphores. So a binary semaphore is is a semaphore whose value is always 0, 1. And then a mutex is a binary semaphore that’s being used for mutual exclusion. The P operation is called locking the mutex. We’ll refer to a V as sometimes unlocking or releasing the mutex. And if a process is holding a mutex, then that means it’s been locked, but not not released. So mutexes and binary semaphores are always initialized to one accounting semaphore, and the mutex is used for mutual exclusion.<br>现在，当我们谈论信号量时，我们将使用一些术语。因此二进制信号量是一个值始终为0，1的信号量。然后一个互斥锁是一个二进制信号量，用于互斥。这个P操作叫做锁定互斥锁。我们将V称为有时解锁或释放互斥锁。如果一个进程持有互斥锁，那么这意味着它已经被锁定，但没有被释放。因此互斥锁和二进制信号量总是被初始化为一个记帐信号量，互斥锁用于互斥。</p>
<p>发言人   51:06<br>But you can also use semaphores to count sort of events in the system. And oftentimes, for those counting semaphores have sort of non values that are greater than one. So for mutual exclusion.<br>但您也可以使用信号量来计算系统中的事件排序。而且通常情况下，对于那些计数信号量的人来说，它们的非值大于一。所以为了相互排斥。</p>
<p>发言人   51:27<br>To fix our program, we create a new program called Good Count DOC. And here we initialize a mutex, or we create a mutex and initialize it to one. And then we surround the critical section, which is the three assembly language instructions embodied that implement this count plus plus instruction. We surround it with AP followed by a v? And if we do that, we always the right answer. But P and V are system calls. So there’s overhead associated with these. So they’re not free. In fact, there are orders of magnitude. This program runs orders of magnitude slower then the incorrect buggy version all. So why do these mutexes work?<br>为了修复我们的程序，我们创建了一个名为 “Count DOC” 的新程序。这里我们初始化一个互斥锁，或者我们创建一个互斥锁并将其初始化为一个。然后我们围绕着临界区，它是实现这个计数加号指令的三个汇编语言指令。我们用AP包围它，后面跟着一个v？如果我们这样做，我们总是能得到正确的答案。但P和V是系统调用。因此，这些与开销相关。所以他们不自由。事实上，有几个数量级。这个程序的运行速度比错误版本慢几个数量级。那么，为什么这些互斥锁会工作呢？</p>
<p>发言人   52:22<br>So here we’ve got a progress graph now where we’ve decorated our program with P and V operation. So we put the P before the critical section, we execute the critical section, and then we call V, and now if you were to look, you remember P and VP increments the p decrements the semaphore, v increments the semaphore. So if you were just to look at the value of that semaphore for every point in the execution state space, you’d get these, you’d get these values.<br>所以现在我们有一个进度图，我们用P和V操作装饰了我们的程序。所以我们把P放在临界区之前，我们执行临界区，然后我们调用V，现在如果你看，你记得P，VP增加p减少信号量，v增加信号量。因此，如果您只查看执行状态空间中每个点的信号量值，您将得到这些值。</p>
<p>发言人   53:01<br>So here we initialize the semaphore at the origin, we initialized it to one, the value of our semaphore at the origin is one, and let’s say we just move along, so we’re just executing thread one. So after H1, the semaphore is one, we do the p, the semaphore is one, so P just decrements it and proceeds, so now the semaphore value becomes 0, and it remains 0 until we execute the v, and when we finished executing the v, the semaphore is one again, so if we go through a similar reasoning, if we look at the trajectory to get to any point in this state space, so.<br>在这里，我们初始化原点处的信号量，并将其初始化为1，我们在原点处的信号量的值为1，假设我们只是继续前进，所以我们只是执行线程1。所以在H1之后，信号量是一，我们执行p，信号量是一，所以P只是递减并继续，所以现在信号量值变为0，并且在我们执行v之前它仍然是0，当我们完成执行v时，信号量再次是一。因此，如果我们进行类似的推理，如果我们查看到达该状态空间中任一点的轨迹，那么。</p>
<p>发言人   53:54<br>Let’s say this point right here. So to get there, we could execute thread one up to this point, finish the L 1, and then execute H2, and then do at this point, the semaphore is 0, and then p decrements the semaphore. So now it’s -1.<br>我们就在这里说这一点。因此，为了到达那里，我们可以执行线程一到这一点，完成L 1，然后执行H2，然后在这一点上，信号量为0，然后p递减信号量。现在是-1。</p>
<p>发言人   54:21<br>But that’s impossible. That can’t happen because p blocks. Remember, if the semaphore is 0 p blocks, it doesn’t decrement it. So the semantics of the p operation prohibits this, this transition. It prohibits this transition to the state where the semaphore is 0 to a state where it would be -1. And so it creates what we call a forbidden region. So these points in the state space where the semaphore would have a value of -1 are infeasible. That can never be reached by the definition of of p and v, so this forms a forbidden region around the unsafe region, and in doing so provides mutually exclusive access to the to the critical sections in each thread.<br>但这是不可能的。这不可能发生，因为p块。记住，如果信号量是0 p块，它不会减少它。因此，p操作的语义禁止这种转换。它禁止转换到信号量为0的状态到-1的状态。因此，它创造了我们所谓的禁区。因此，在状态空间中信号量的值为-1的这些点是不可行的。这永远无法通过p和v的定义达到，因此这在不安全区域周围形成了一个禁区，并且这样做提供了对每个线程中临界区的互斥访问。</p>
<p>发言人   55:28<br>So this is the fundamental reason why P’s and v’s can be used to provide mutually exclusive access. Any questions on this? I explained it so clearly that there’s no questions.<br>这就是为什么P和v可以用来提供互斥访问的根本原因。对此有什么问题吗？我解释得很清楚，没有问题。</p>
<p>发言人   55:52<br>All right, good. Well, you get to go. You get to leave early, then work on your Malik lab so. All right, so we’ll see you Monday. We’re going to look at sort of some advanced topics. This was like our first introduction to synchronization. On Tuesday, we’ll look at more advanced topics and synchronization and ways that you can use semaphores for to provide more other interesting kinds of synchronization for your programs.<br>好的，好的。好吧，你可以走了。你可以提前离开，然后在你的Malik实验室工作。好的，我们将在每个工作日见。我们将会看一些高级话题。这就像我们对同步的第一次介绍。在周二，我们将探讨更高级的主题和同步方式，以及如何使用信号量为您的程序提供更多其他有趣的同步方式。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>深入理解计算机系统 025-Synchronization, Basic</div>
      <div>http://example.com/2025/10/12/15213-025/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月12日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/12/15213-026/" title="深入理解计算机系统 026-Synchronization, Advanced">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">深入理解计算机系统 026-Synchronization, Advanced</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/12/15213-024/" title="深入理解计算机系统 024-Concurrent Programming">
                        <span class="hidden-mobile">深入理解计算机系统 024-Concurrent Programming</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
