

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:26,640Good morning. 200:00:26,640 –&gt; 00:00:33,039I’m Jignesh Patel and I am going to be teaching this class for the month of October. 300:00:33,039 –&gt; 00:00:39,679Andy">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU15445 P11F202310 SortingAggregationAlgorithms">
<meta property="og:url" content="http://example.com/2025/10/24/CMU15445%20P11F202310-SortingAggregationAlgorithms/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:26,640Good morning. 200:00:26,640 –&gt; 00:00:33,039I’m Jignesh Patel and I am going to be teaching this class for the month of October. 300:00:33,039 –&gt; 00:00:39,679Andy">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-24T12:00:44.465Z">
<meta property="article:modified_time" content="2025-10-24T12:06:28.540Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>CMU15445 P11F202310 SortingAggregationAlgorithms - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CMU15445 P11F202310 SortingAggregationAlgorithms"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-24 20:00" pubdate>
          2025年10月24日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.8k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          48 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CMU15445 P11F202310 SortingAggregationAlgorithms</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:26,640<br>Good morning.</p>
<p>2<br>00:00:26,640 –&gt; 00:00:33,039<br>I’m Jignesh Patel and I am going to be teaching this class for the month of October.</p>
<p>3<br>00:00:33,039 –&gt; 00:00:39,679<br>Andy will be back in November. In additional changes that on Wednesday, both Andy and I are</p>
<p>4<br>00:00:39,679 –&gt; 00:00:45,359<br>traveling. So Matt is going to run the class on Wednesday. Matt is Andy’s student.</p>
<p>5<br>00:00:46,159 –&gt; 00:00:51,840<br>This is a re-recording of the class that happened on Monday. So those of you who worry class on Monday</p>
<p>6<br>00:00:51,840 –&gt; 00:00:56,240<br>and see a different background, see a few different set of notes, it’s because they’re</p>
<p>7<br>00:00:56,240 –&gt; 00:01:00,560<br>recording on Monday didn’t work. So let’s get started with the few announcements first.</p>
<p>8<br>00:01:01,760 –&gt; 00:01:08,080<br>We have the database seminar series as many of you know and there are two lectures,</p>
<p>9<br>00:01:08,080 –&gt; 00:01:12,879<br>VBate, which just happened yesterday. There’s a recording for that. You can find that from the CMU</p>
<p>10<br>00:01:12,879 –&gt; 00:01:20,960<br>database page. There’s feature form. That’s a feature store that works with machine learning models</p>
<p>11<br>00:01:21,039 –&gt; 00:01:25,839<br>and stores those features helps you manage the entire retraining pipeline. Their</p>
<p>12<br>00:01:26,719 –&gt; 00:01:31,919<br>presentation is on the coming Monday. So if you’re interested in data-related things,</p>
<p>13<br>00:01:31,919 –&gt; 00:01:36,239<br>outside traditional relational databases, but where databases meet machine learning,</p>
<p>14<br>00:01:36,239 –&gt; 00:01:39,839<br>the seminar series is a great event and hope you can come to it.</p>
<p>15<br>00:01:41,519 –&gt; 00:01:48,639<br>Few announcements. Homebook 3 is due on Sunday at midnight and the midterms coming up on Wednesday,</p>
<p>16<br>00:01:48,640 –&gt; 00:01:53,519<br>October 13. So start brushing up on the material that we’ve been discussing in class since the</p>
<p>17<br>00:01:53,519 –&gt; 00:01:58,400<br>start of the semester. And of course come to our office hours and ask questions if some things are</p>
<p>18<br>00:01:58,400 –&gt; 00:02:05,200<br>not clear. So with that, let’s get started. Today we are going to talk about executing queries inside</p>
<p>19<br>00:02:05,200 –&gt; 00:02:10,879<br>a database engine. And you see the structure of the database engine on the right side. You’ve seen</p>
<p>20<br>00:02:10,879 –&gt; 00:02:17,199<br>this before. And the part that we’re going to focus on today is that operator execution engine.</p>
<p>21<br>00:02:17,199 –&gt; 00:02:23,280<br>So at this point in the lifecycle of a query, the query has started. The query has been planned,</p>
<p>22<br>00:02:23,280 –&gt; 00:02:30,479<br>basically optimized. And you end up with this situation now where you have to go and execute</p>
<p>23<br>00:02:30,479 –&gt; 00:02:35,439<br>the operators in that query. There’s a sequence of four lectures starting today where we look at</p>
<p>24<br>00:02:35,439 –&gt; 00:02:40,799<br>algorithms that are used for executing these operators. And they will end up using the access</p>
<p>25<br>00:02:40,800 –&gt; 00:02:47,280<br>methods, might scan a file, it might end up using a B3. Stuff that you know from before. Though</p>
<p>26<br>00:02:47,280 –&gt; 00:02:52,560<br>the data that gets fetched from disk gets pulled into the buffer manager. And you know how buffer</p>
<p>27<br>00:02:52,560 –&gt; 00:03:01,520<br>managers work. That was your first project assignment. And essentially the goal is to fetch data from</p>
<p>28<br>00:03:01,520 –&gt; 00:03:07,040<br>the disk. Keep all the hot stuff in the buffer pool for as long as possible so that you can</p>
<p>29<br>00:03:07,039 –&gt; 00:03:13,120<br>re-access any data pages that you need to re-access from memory, which is far cheaper than going to</p>
<p>30<br>00:03:13,120 –&gt; 00:03:22,239<br>the disk. All right, so let’s jump into it and look at what happens to the query after it’s been</p>
<p>31<br>00:03:22,239 –&gt; 00:03:30,479<br>passed. So here’s a SQL query, which does a joint between two tables. There’s a selection on one</p>
<p>32<br>00:03:30,479 –&gt; 00:03:36,799<br>of the tables S and projects out a column from each of the tables. After this query is presented</p>
<p>33<br>00:03:36,800 –&gt; 00:03:41,840<br>to the database engine, it’s going to get checked through a syntactical parser. And then it’s going to</p>
<p>34<br>00:03:41,840 –&gt; 00:03:47,920<br>get converted into a relational algebraic representation. And that representation is what gets optimized. We’ll</p>
<p>35<br>00:03:47,920 –&gt; 00:03:54,560<br>talk about optimization later on in the class. But for today, we just assume that we’ve got some</p>
<p>36<br>00:03:54,560 –&gt; 00:04:02,080<br>tree-like representation for the query. And in the tree are nodes that are operators. So here you’ve</p>
<p>37<br>00:04:02,080 –&gt; 00:04:08,000<br>got the relation R that’s feeding into a joint operator where the condition for the joint is looking</p>
<p>38<br>00:04:08,000 –&gt; 00:04:19,199<br>for equality between the ID fields on the R and the S tables records. The S table is being scanned</p>
<p>39<br>00:04:19,199 –&gt; 00:04:24,960<br>and only the records that have value greater than 10 are sent to this joint operator. Now here,</p>
<p>40<br>00:04:24,960 –&gt; 00:04:29,520<br>if there’s an index built on the value that will get used and you know how those indices work from</p>
<p>41<br>00:04:29,519 –&gt; 00:04:34,799<br>the last lecture. The output of the joint goes into a projection operator where these two columns</p>
<p>42<br>00:04:34,799 –&gt; 00:04:40,560<br>are projected, producing the output of the result. And so that’s really what the query tree looks like.</p>
<p>43<br>00:04:40,560 –&gt; 00:04:45,359<br>And a tables are flowing through it and you can think of a query tree as a data flow graph where the</p>
<p>44<br>00:04:45,359 –&gt; 00:04:51,120<br>records flowing from the bottom, they go through the operators where they get processed based upon</p>
<p>45<br>00:04:51,120 –&gt; 00:04:56,240<br>the semantics of each of those operators, a selection, a joint, a projection in this case,</p>
<p>46<br>00:04:56,319 –&gt; 00:05:02,720<br>and eventually you produce the output over here that satisfies all the conditions that are in the</p>
<p>47<br>00:05:02,720 –&gt; 00:05:10,639<br>query. Okay. What we are seeing over here is a tree form for this query, but in general, this can be</p>
<p>48<br>00:05:10,639 –&gt; 00:05:15,519<br>a DAC where it may be that there’s a portion of the query where the output of this joint gets fed into</p>
<p>49<br>00:05:15,519 –&gt; 00:05:20,879<br>another tree and all of those come together before you produce the final output. When you have nested</p>
<p>50<br>00:05:20,959 –&gt; 00:05:28,959<br>queries, you have CTEs, often you’ll end up with a structure that looks like a DAC and not a regular tree</p>
<p>51<br>00:05:28,959 –&gt; 00:05:36,159<br>like you see over here, which never a graph is the complexity in the worst case is going to be a DAC.</p>
<p>52<br>00:05:36,159 –&gt; 00:05:41,120<br>Things are going to flow in and come out with one node at the top, which is going to be the output</p>
<p>53<br>00:05:41,120 –&gt; 00:05:49,839<br>of that query. Okay. All right. Now let’s jump into what I’ll be trying to do with the algorithms</p>
<p>54<br>00:05:49,839 –&gt; 00:05:56,079<br>for these operators. So the first thing is databases need to work with large amounts of data. So</p>
<p>55<br>00:05:57,119 –&gt; 00:06:04,719<br>we want our operator algorithms to work on data that cannot fit in memory. So we want to be able to</p>
<p>56<br>00:06:04,719 –&gt; 00:06:11,439<br>deal with data that is far bigger than the memory that we have available. Second, we want to use the</p>
<p>57<br>00:06:11,439 –&gt; 00:06:16,479<br>memory that is available and that’s in the form of the buffer pool. We want that memory to be used</p>
<p>58<br>00:06:16,480 –&gt; 00:06:22,480<br>as efficiently as possible. And this is where we will bring pages into the buffer pool. We’ll apply</p>
<p>59<br>00:06:22,480 –&gt; 00:06:30,560<br>some sort of a buffer replacement policy. You’ve implemented LREA2 in the last assignment. And so</p>
<p>60<br>00:06:30,560 –&gt; 00:06:35,360<br>you know how those things work. And that’s what we are trying to do. We are trying to avoid going to</p>
<p>61<br>00:06:35,360 –&gt; 00:06:42,160<br>the disk as much as possible because accessing a page in the buffer pool in memory is orders of</p>
<p>62<br>00:06:42,160 –&gt; 00:06:47,120<br>magnitude cheaper than going to the disk. Okay. And now things get even more complicated and cloud</p>
<p>63<br>00:06:47,120 –&gt; 00:06:52,000<br>settings. We both delve into that in this class. But the advanced database class goes into that in</p>
<p>64<br>00:06:52,000 –&gt; 00:06:56,800<br>much more detail. Sometimes the data is not coming from this that is local. It may come from cloud</p>
<p>65<br>00:06:56,800 –&gt; 00:07:01,680<br>storage that is remote, which could be even more expensive. Sometimes there are configurations where</p>
<p>66<br>00:07:01,680 –&gt; 00:07:06,800<br>the data is coming from memory from a different node in which case it’s not as expensive as going</p>
<p>67<br>00:07:06,879 –&gt; 00:07:12,639<br>to a disk, but it’s still more expensive than accessing data in local memory. So regardless of where</p>
<p>68<br>00:07:12,639 –&gt; 00:07:17,600<br>the data is coming from, there’s a hierarchy for where the data lives. And you want to use the buffer</p>
<p>69<br>00:07:17,600 –&gt; 00:07:22,080<br>pool, which is sitting in DRAM that is closest to where things are getting processed as efficiently</p>
<p>70<br>00:07:22,080 –&gt; 00:07:28,080<br>as possible. But we also want our algorithms to work on large amounts of data. And generally,</p>
<p>71<br>00:07:28,080 –&gt; 00:07:35,840<br>when we have to go and fetch something from the disk, we want the IO access pattern to be sequential</p>
<p>72<br>00:07:35,839 –&gt; 00:07:43,919<br>because generally disks are better if you ask them for a bunch of pages sequentially than random</p>
<p>73<br>00:07:43,919 –&gt; 00:07:50,479<br>me. So if you need to go to the disk and fetch 10 pages, and if your access pattern, your operator</p>
<p>74<br>00:07:50,479 –&gt; 00:07:57,039<br>is asking for those 10 pages at random locations on the disk compared to asking for 10 pages that are</p>
<p>75<br>00:07:57,039 –&gt; 00:08:02,479<br>contiguous or sequential together on disk, the latter is nearly always going to be faster. So we want</p>
<p>76<br>00:08:03,040 –&gt; 00:08:09,200<br>our algorithms to use the buffer pool efficiently. And when we have to go to disk, do that in a way</p>
<p>77<br>00:08:09,200 –&gt; 00:08:16,480<br>that minimizes the time that might need to go fetch those pages from disk. So how do we do that?</p>
<p>78<br>00:08:16,480 –&gt; 00:08:22,160<br>We’ll go through SOR and aggregation operations in today’s lecture and we’ll continue with</p>
<p>79<br>00:08:22,160 –&gt; 00:08:28,560<br>joins and other operations in the subsequent lectures. So starting with SOR, the first question that</p>
<p>80<br>00:08:28,560 –&gt; 00:08:34,639<br>might come to mind is the relational model, which is based on relational algebra, is based on set theory</p>
<p>81<br>00:08:35,200 –&gt; 00:08:41,840<br>and sets are not sorted. So why do we need SOR? Now SQL has that, so we need sorting for a number of</p>
<p>82<br>00:08:41,840 –&gt; 00:08:49,039<br>reasons. One is SQL has an order by clause and that order by clause requires that the data be produced,</p>
<p>83<br>00:08:49,039 –&gt; 00:08:54,879<br>the final result be produced sorted by the column set is specified in the order by clause.</p>
<p>84<br>00:08:55,519 –&gt; 00:09:00,639<br>And sometimes you need SQL, you need sorting to be able to apply operations like distinct and we’ll</p>
<p>85<br>00:09:00,639 –&gt; 00:09:06,080<br>see that aggregations can also be done using sorting. And as we get into aggregations in the</p>
<p>86<br>00:09:06,080 –&gt; 00:09:12,000<br>second half of this lecture today, we’ll see that there are SOR based methods to evaluate the</p>
<p>87<br>00:09:12,000 –&gt; 00:09:17,360<br>aggregate operator, but they also hash based methods to do that. And we’ll see that duality</p>
<p>88<br>00:09:17,360 –&gt; 00:09:23,440<br>between sorting and hashing, they’re like siblings that are rivaling with each other in terms of</p>
<p>89<br>00:09:23,440 –&gt; 00:09:29,040<br>when is sorting better for evaluating a specific operations versus hashing. Generally hashing is</p>
<p>90<br>00:09:29,040 –&gt; 00:09:33,200<br>going to be better and that’s well known now, but there was a time in the community where that was</p>
<p>91<br>00:09:33,200 –&gt; 00:09:38,400<br>an active debate. SORting still helps in many cases and we’ll talk about that. Those cases are</p>
<p>92<br>00:09:38,400 –&gt; 00:09:43,840<br>largely going to be centered around when data is already pre-sorted, then you can, the SOR based</p>
<p>93<br>00:09:43,840 –&gt; 00:09:48,640<br>methods will likely win over the hash based methods. And of course, if you have to produce records</p>
<p>94<br>00:09:48,639 –&gt; 00:09:53,519<br>because there’s an order by you will have to do a sorting for that final result. Okay, but</p>
<p>95<br>00:09:54,399 –&gt; 00:09:59,840<br>many of these algorithms we’re going to look at aggregation, joins in later classes, they’ll have</p>
<p>96<br>00:09:59,840 –&gt; 00:10:04,639<br>a SOR based approach and a hash based approach and they’re constantly dwelling with each other for</p>
<p>97<br>00:10:04,639 –&gt; 00:10:12,639<br>higher performance. So let’s start with very basic in-memory sorting. If the data fits in memory,</p>
<p>98<br>00:10:12,639 –&gt; 00:10:18,000<br>then we can use a standard algorithm like quicksort. And all of you guys have looked at a number of</p>
<p>99<br>00:10:18,000 –&gt; 00:10:23,440<br>in-memory sorting algorithms and yesterday in class many of you volunteered the different types</p>
<p>100<br>00:10:23,440 –&gt; 00:10:30,240<br>of algorithms, some of the other algorithms that you looked at including bubble SOR and insertion SOR.</p>
<p>101<br>00:10:31,759 –&gt; 00:10:36,480<br>Most database systems when they have to do an in-memory SOR, remember we are also going to figure out</p>
<p>102<br>00:10:36,480 –&gt; 00:10:41,519<br>how to sort things that are much larger than memory so that we can sort extremely large data</p>
<p>103<br>00:10:42,000 –&gt; 00:10:46,799<br>requiring all of that fit in memory. But there will be a portion of that master</p>
<p>104<br>00:10:47,439 –&gt; 00:10:52,879<br>external SOR algorithm for which you need to sort in memory. And so you need an in-memory SOR</p>
<p>105<br>00:10:52,879 –&gt; 00:10:57,519<br>algorithm and most database systems are going to use quicksort for this in-memory SOR algorithm.</p>
<p>106<br>00:10:58,159 –&gt; 00:11:04,000<br>It’s not quite true. Most database systems will use quicksort for that in-memory SOR algorithm,</p>
<p>107<br>00:11:04,000 –&gt; 00:11:09,759<br>but in quicksort you find a pivot point and you sort on both sides. But if one of the sides becomes</p>
<p>108<br>00:11:09,759 –&gt; 00:11:14,240<br>really small then they might end up using something like insertion SOR because it’s just much</p>
<p>109<br>00:11:14,240 –&gt; 00:11:20,720<br>faster when you have really small number of records like maybe 10 or 20 and that number really</p>
<p>110<br>00:11:20,720 –&gt; 00:11:26,559<br>depends also on the hardware and which you’re running on. In data platform, most notably Python,</p>
<p>111<br>00:11:26,559 –&gt; 00:11:30,799<br>which is very popular in the data science world, then many of those data science notebooks that you</p>
<p>112<br>00:11:30,799 –&gt; 00:11:36,639<br>see often get connected to a relational database to go pull stuff. So it’s like the extension in many</p>
<p>113<br>00:11:36,639 –&gt; 00:11:41,439<br>cases of the database platform for doing data science work and Python’s the language in which a lot</p>
<p>114<br>00:11:41,439 –&gt; 00:11:47,679<br>of these things get done. Python, you can pull data into Python data structures and there’s a</p>
<p>115<br>00:11:47,679 –&gt; 00:11:54,319<br>default SOR mechanism in Python and that uses something called TimSOR, which is a combination of</p>
<p>116<br>00:11:54,319 –&gt; 00:12:00,960<br>insertion SOR and binary SOR. So there’s a lot of in-memory SORting algorithms and it’s really fun</p>
<p>117<br>00:12:00,960 –&gt; 00:12:05,759<br>to go and look at them and think about that and what combination of algorithms works best</p>
<p>118<br>00:12:06,240 –&gt; 00:12:11,840<br>is changing even today because the hardware is changing some of the considerations change and</p>
<p>119<br>00:12:11,840 –&gt; 00:12:16,159<br>sometimes depending upon the data distribution which algorithm is going to do better for this in-memory</p>
<p>120<br>00:12:16,159 –&gt; 00:12:23,360<br>SOR component also changes. So let’s go and take a quick look at a couple SORT algorithms and visualize</p>
<p>121<br>00:12:23,360 –&gt; 00:12:28,399<br>them. I’m not going to go into the details of all the SORT algorithms but let me just pull up this</p>
<p>122<br>00:12:28,399 –&gt; 00:12:33,600<br>web page and bear with me as I try to bring that window back into focus in zoom here.</p>
<p>123<br>00:12:34,320 –&gt; 00:12:40,320<br>And so as you can see here this is a page in which we can look at a number of different SORT algorithms.</p>
<p>124<br>00:12:41,600 –&gt; 00:12:48,320<br>Again we are focusing just on in-memory SORT methods here and the key point over here is that</p>
<p>125<br>00:12:48,320 –&gt; 00:12:54,159<br>which algorithm wins is going to depend upon things like the data distribution and also the inherent</p>
<p>126<br>00:12:54,159 –&gt; 00:13:00,160<br>properties of the algorithm. So let’s take a look at random and let’s go and bump this up so that</p>
<p>127<br>00:13:00,159 –&gt; 00:13:03,839<br>we have 50 data points so that we can see the simulation happen for a little bit longer.</p>
<p>128<br>00:13:04,399 –&gt; 00:13:10,639<br>I’m going to run random and just watch this. This is in-s ocean SORT here. This is a merge SORT. We’ll use</p>
<p>129<br>00:13:10,639 –&gt; 00:13:16,240<br>something quite that later on as a primitive for building the external SORT method. We are going to</p>
<p>130<br>00:13:16,240 –&gt; 00:13:21,039<br>talk about it in a second and then here is quick SORT and this is quick SORT that spits it up into</p>
<p>131<br>00:13:21,039 –&gt; 00:13:27,360<br>three parts. Let’s just go run that and you can see things are getting sorted and this is random</p>
<p>132<br>00:13:27,360 –&gt; 00:13:32,000<br>data so these algorithms here on this right side which are more complex are going to do a lot better.</p>
<p>133<br>00:13:32,000 –&gt; 00:13:38,240<br>You can see heap SORT is nearly done there, quick SORT is getting there, shell SORT is done and all</p>
<p>134<br>00:13:38,240 –&gt; 00:13:43,279<br>these five algorithms here on the right are done and these most simpler algorithms insert</p>
<p>135<br>00:13:43,279 –&gt; 00:13:48,399<br>shouldn’t selection and bubble SORT are still working on it. Now let’s change the scenario a little</p>
<p>136<br>00:13:48,399 –&gt; 00:13:54,000<br>bit. We let that complete on the top over there. Let’s go to the scenario where the data is nearly</p>
<p>137<br>00:13:54,799 –&gt; 00:13:59,679<br>sorted and let’s now go and play through that and watch how quickly the simpler algorithms finish up</p>
<p>138<br>00:14:00,399 –&gt; 00:14:04,399<br>and as you can see the more complex algorithms on the right they’re still working on it but the</p>
<p>139<br>00:14:04,399 –&gt; 00:14:10,480<br>first column insertion SORT is already done. Hopefully that illustrates how these sorting algorithms work</p>
<p>140<br>00:14:10,480 –&gt; 00:14:15,440<br>and why there is this constant interest even in database systems is to find the right in memory</p>
<p>141<br>00:14:15,440 –&gt; 00:14:22,159<br>SORT algorithms and people are constantly re-evaluating that. I’m also very briefly going to go into</p>
<p>142<br>00:14:22,159 –&gt; 00:14:31,039<br>this other site which is the link is in the slide deck and let’s go to that site and also take a</p>
<p>143<br>00:14:31,039 –&gt; 00:14:38,559<br>look at a different way of looking at sorting. So let’s see I might just type that in.</p>
<p>144<br>00:14:38,799 –&gt; 00:14:53,519<br>There we go. Okay and I’m going to switch this over to exploration mode and this is really a</p>
<p>145<br>00:14:54,639 –&gt; 00:15:01,759<br>cute way of looking at algorithms where effectively it’s like a debugger and as you can see we’ll</p>
<p>146<br>00:15:01,759 –&gt; 00:15:07,839<br>start with quickSORT which has this you pick a pivot and then sort on both sides right it’s</p>
<p>147<br>00:15:07,840 –&gt; 00:15:12,399<br>a divide and conquer algorithm and let’s go ahead and sort that and the nice thing about this is</p>
<p>148<br>00:15:12,399 –&gt; 00:15:18,240<br>you can see what that code for quickSORT looks like and it’s walking through the elements and it’s</p>
<p>149<br>00:15:18,240 –&gt; 00:15:24,480<br>a very nice way to connect the algorithm in that code centric way with what’s happening visually.</p>
<p>150<br>00:15:24,480 –&gt; 00:15:29,440<br>So I encourage you to play around with this if you have forgotten in memory SORT algorithms you should</p>
<p>151<br>00:15:29,440 –&gt; 00:15:35,120<br>at least know the basic algorithms like quickSORT and insertion SORT and just go and refresh that</p>
<p>152<br>00:15:35,919 –&gt; 00:15:40,799<br>you’re probably going to need it if you’re going to interview it’s a fundamental question that gets</p>
<p>153<br>00:15:40,799 –&gt; 00:15:47,759<br>asked many times. Alright let’s get back to a slide so I’m going to close this and let you play</p>
<p>154<br>00:15:47,759 –&gt; 00:15:55,200<br>with the algorithms on this site by yourself. So moving along we’re going to start into the</p>
<p>155<br>00:15:55,200 –&gt; 00:16:01,360<br>SORT operation start with something simple called the top-end top-end heapSORT and that shows up</p>
<p>156<br>00:16:01,440 –&gt; 00:16:07,440<br>when you have an order by as we just discussed SQL has an order by clause and when that’s present</p>
<p>157<br>00:16:07,440 –&gt; 00:16:12,879<br>in the SQL query you have to present the results sorted by the columns in that order by here you have</p>
<p>158<br>00:16:12,879 –&gt; 00:16:19,600<br>to output the records from the enroll table ordered by the student ID. There’s a few additional</p>
<p>159<br>00:16:19,600 –&gt; 00:16:27,440<br>components that SQL allows you to do so here we are asking the system to send us only the first four</p>
<p>160<br>00:16:27,440 –&gt; 00:16:33,680<br>rows sorted by student ID of course so the first four in that sorted order and this is extra</p>
<p>161<br>00:16:33,680 –&gt; 00:16:40,400<br>optional clause that says which ties so if there are any ties in the top four give me all the ties</p>
<p>162<br>00:16:40,960 –&gt; 00:16:48,560<br>so in this case if this table has more than four records the output of this will be at least</p>
<p>163<br>00:16:48,560 –&gt; 00:16:55,280<br>forward but it could be more so if one of those top four student IDs is repeated that repeated</p>
<p>164<br>00:16:55,279 –&gt; 00:17:01,839<br>value will be shown back to us. Okay so let’s see how that works we will use a version of heap</p>
<p>165<br>00:17:01,839 –&gt; 00:17:09,920<br>SORT called the top-end heapSORT and here’s how it works here we are going to go and look at the</p>
<p>166<br>00:17:09,920 –&gt; 00:17:15,519<br>records so assume the student IDs these values we’re going to start by fetching the first student ID</p>
<p>167<br>00:17:15,519 –&gt; 00:17:22,160<br>which is three and we’re going to build in memory a heap and we’ll start by allocating a heap of</p>
<p>168<br>00:17:22,160 –&gt; 00:17:27,600<br>size four and obviously a heap is a sorted data structure its code implementation is that of an array</p>
<p>169<br>00:17:27,600 –&gt; 00:17:32,480<br>and so I’m just going to show that array representation I’m going to assume you know how our heap works</p>
<p>170<br>00:17:32,480 –&gt; 00:17:37,360<br>and if you’ve forgotten then you can quickly go look that up so I’m just going to show that array</p>
<p>171<br>00:17:37,360 –&gt; 00:17:42,160<br>in a sorted order as we insert elements because ultimately that’s what a heap does so we’ll fetch three</p>
<p>172<br>00:17:42,720 –&gt; 00:17:47,759<br>insert that into the heap then we’ll fetch four insert that into the heap in sorted order</p>
<p>173<br>00:17:47,759 –&gt; 00:17:53,920<br>this heap I’m going to show sorted from right to left so three is smaller than four and so the</p>
<p>174<br>00:17:53,920 –&gt; 00:18:01,920<br>heap’s growing in this direction then go to six that’s added to the heap so three four six now add two</p>
<p>175<br>00:18:01,920 –&gt; 00:18:08,960<br>and we have a heap that is four now we come to this value nine and we have to decide what we want to</p>
<p>176<br>00:18:08,960 –&gt; 00:18:13,759<br>do with it so yesterday in class I paused the lecture and asked like what would you do with nine</p>
<p>177<br>00:18:13,759 –&gt; 00:18:18,160<br>there were a bunch of answers that were given out in terms of what you could do the simple answer was</p>
<p>178<br>00:18:18,160 –&gt; 00:18:24,400<br>add nine to the heap and grow the heap which is correct but there’s a better way to do it when you</p>
<p>179<br>00:18:24,400 –&gt; 00:18:33,599<br>are doing this top four evaluation and the insight is the following I’ve already seen that there are</p>
<p>180<br>00:18:33,599 –&gt; 00:18:41,839<br>phone numbers in the data have scanned so far that are all less than nine if I only have to retrieve</p>
<p>181<br>00:18:41,839 –&gt; 00:18:47,759<br>the first four rows the first four smallest values because it’s ordered by the student ID</p>
<p>182<br>00:18:49,119 –&gt; 00:18:55,279<br>there is no way I would ever output nine because I already have four values that are smaller than nine</p>
<p>183<br>00:18:55,279 –&gt; 00:19:00,879<br>so nine does not even need to be processed because I have four values each of which are smaller than</p>
<p>184<br>00:19:00,879 –&gt; 00:19:09,519<br>nine so anytime in my heap I’ve got enough values for in this case and I see a value that is greater</p>
<p>185<br>00:19:09,519 –&gt; 00:19:15,839<br>than the largest value in the heap six in this case I can simply toss it so now you can start to see</p>
<p>186<br>00:19:15,839 –&gt; 00:19:21,200<br>how when you implement things like in memory sorting in the database context where you have these</p>
<p>187<br>00:19:21,200 –&gt; 00:19:27,519<br>semantics you can do very interesting things you can modify those algorithms to make it more efficient</p>
<p>188<br>00:19:27,519 –&gt; 00:19:33,200<br>and we’ll see that with external merge sort is the algorithms that you know and you love for sorting</p>
<p>189<br>00:19:33,200 –&gt; 00:19:38,000<br>hashing other kinds of things when you start to make that in databases in in memory case like this</p>
<p>190<br>00:19:38,000 –&gt; 00:19:43,279<br>with top and semantics or external memory you make these subtle changes and make that magic work so</p>
<p>191<br>00:19:43,279 –&gt; 00:19:50,079<br>you can do things in a more efficient way and do these operations on much larger data sets much</p>
<p>192<br>00:19:50,079 –&gt; 00:19:55,039<br>larger than the amount of memory that you have okay so let me just pause let you take that in</p>
<p>193<br>00:19:55,039 –&gt; 00:20:00,960<br>make sure you understand why we can skip nine okay it is greater than six and we are guaranteed</p>
<p>194<br>00:20:00,960 –&gt; 00:20:08,160<br>we are not going to need it in the final answer then we come to one which is interesting we have to</p>
<p>195<br>00:20:08,160 –&gt; 00:20:15,279<br>put that in the heap but as you might notice there was previously two three four six as I put one I no</p>
<p>196<br>00:20:15,279 –&gt; 00:20:20,319<br>longer need to keep six around and I can toss that out again that same reasoning that I’ve got four</p>
<p>197<br>00:20:20,319 –&gt; 00:20:27,200<br>numbers that are the smallest I’ve seen so far I only need to output four I can now toss away six</p>
<p>198<br>00:20:27,200 –&gt; 00:20:33,440<br>which had scanned a few records ago okay so again we are making these optimizations to the algorithm</p>
<p>199<br>00:20:34,480 –&gt; 00:20:39,840<br>now because we have these width ties we’re going to come to this number four and we have to decide</p>
<p>200<br>00:20:39,840 –&gt; 00:20:44,640<br>what we do we can’t throw it away because four is one of the smallest number and we have width ties</p>
<p>201<br>00:20:44,640 –&gt; 00:20:49,039<br>if we didn’t have width ties we could toss it away but in this case we need to keep it we have no</p>
<p>202<br>00:20:49,039 –&gt; 00:20:53,840<br>choice but to grow the heap and you can grow the heap in multiple ways it’s often an array data</p>
<p>203<br>00:20:53,839 –&gt; 00:21:00,879<br>structure that is used to write the heap data structure and so we would generally double that so</p>
<p>204<br>00:21:00,879 –&gt; 00:21:06,159<br>that’s what we’re going to do to here double the size of the heap add four to the sorted heap go to</p>
<p>205<br>00:21:06,159 –&gt; 00:21:12,079<br>the next element which is also four then we come to this last element which is eight and as we</p>
<p>206<br>00:21:12,079 –&gt; 00:21:17,199<br>discussed in class ask for questions as to what you would do with eight at that point when you</p>
<p>207<br>00:21:17,199 –&gt; 00:21:22,559<br>of you volunteered and knew that you would skip eight and that totally makes sense because just like</p>
<p>208<br>00:21:22,559 –&gt; 00:21:27,599<br>nine we are guaranteed we don’t need eight four is the smallest number in the heap right now</p>
<p>209<br>00:21:27,599 –&gt; 00:21:33,440<br>we have four distinct values here we can skip and we can simply output the sorted heap</p>
<p>210<br>00:21:34,240 –&gt; 00:21:40,639<br>okay so a modified version of heap sort far more efficient in memory but allows you to go</p>
<p>211<br>00:21:40,639 –&gt; 00:21:46,960<br>to the fetching of the first end rows of width ties and the different variants of this in C</p>
<p>212<br>00:21:46,960 –&gt; 00:21:53,039<br>colon terms of how you can specify which rows to fetch and this type of a structure works for</p>
<p>213<br>00:21:53,039 –&gt; 00:22:00,799<br>with some modification but that’s the overall idea all right now we’re going to get into the more</p>
<p>214<br>00:22:00,799 –&gt; 00:22:06,400<br>interesting part of today’s lecture and probably something you haven’t seen before which is</p>
<p>215<br>00:22:06,400 –&gt; 00:22:14,640<br>how do you sort a table of records when the table is much larger than the amount of memory that you have</p>
<p>216<br>00:22:15,600 –&gt; 00:22:22,160<br>as you’ll see a theme for many of the algorithms they’re called external the memory algorithms</p>
<p>217<br>00:22:22,880 –&gt; 00:22:28,800<br>they are based on the idea of divide and conquer you’re going to take that big problem that we have</p>
<p>218<br>00:22:28,800 –&gt; 00:22:34,560<br>did is too large to fit into memory split it up into smaller chunks in such a way that processing</p>
<p>219<br>00:22:34,560 –&gt; 00:22:40,320<br>each chunk individually guarantees that we can produce the final output in aggregate okay so let’s</p>
<p>220<br>00:22:40,319 –&gt; 00:22:49,599<br>see how this works before we go as we do sorting we are going to take multiple passes on the data that</p>
<p>221<br>00:22:49,599 –&gt; 00:22:56,720<br>we are sorting and we will have to write records out in intermediate files and the question is what</p>
<p>222<br>00:22:56,720 –&gt; 00:23:02,720<br>do we write in those intermediate files so we are sorting on some key so that’s the k value shown here</p>
<p>223<br>00:23:02,720 –&gt; 00:23:09,519<br>k1k2 or two distinct key values here and we could either take the entire record along with the key</p>
<p>224<br>00:23:09,519 –&gt; 00:23:14,480<br>and store that in these intermediate form that’s called only materialization or we could do something</p>
<p>225<br>00:23:14,480 –&gt; 00:23:20,400<br>called late materialization where we just take the key and store a pointer to the record obviously</p>
<p>226<br>00:23:20,400 –&gt; 00:23:27,039<br>if I’m sorting a table in which each record is a thousand bytes long and I’m just sorting on an</p>
<p>227<br>00:23:27,039 –&gt; 00:23:33,200<br>int for key you will this payload here this key if you think of everything here as a key value pair</p>
<p>228<br>00:23:33,200 –&gt; 00:23:38,639<br>the value portion is going to be a thousand bytes and if this record ID is let’s say eight bytes</p>
<p>229<br>00:23:38,640 –&gt; 00:23:44,320<br>that’s the space that’s this number of bytes that you need to represent the pointer on disk and</p>
<p>230<br>00:23:44,320 –&gt; 00:23:48,000<br>you saw what those pointers look like right they’re the same type of pointers that read the leaf node</p>
<p>231<br>00:23:48,000 –&gt; 00:23:55,680<br>of a B tree eight bytes here for the pointer to the record versus storing the actual record</p>
<p>232<br>00:23:55,680 –&gt; 00:24:01,040<br>obviously this is going to be far more efficient space-wise so if we are writing stuff this will take</p>
<p>233<br>00:24:01,040 –&gt; 00:24:07,520<br>fewer number of bytes that we need to write to the disk as we are doing multiple passes on the file</p>
<p>234<br>00:24:08,079 –&gt; 00:24:12,400<br>but at the end when we are done sorting we have to go retrieve all these records and there may be a</p>
<p>235<br>00:24:12,400 –&gt; 00:24:19,759<br>whole bunch of random miles generally what happens is uh roasters will use this format column</p>
<p>236<br>00:24:19,759 –&gt; 00:24:23,920<br>stores are naturally in the format where the keys have not been brought together and they ultimately</p>
<p>237<br>00:24:23,920 –&gt; 00:24:29,680<br>need to be pulled in and so might as well keep the record IDs or some logical version of that around</p>
<p>238<br>00:24:29,680 –&gt; 00:24:34,319<br>because you know this records haven’t been stitched together to begin with might as well delay</p>
<p>239<br>00:24:34,319 –&gt; 00:24:39,359<br>that stitching till later on so roasters often will use this format column stores will often use</p>
<p>240<br>00:24:39,359 –&gt; 00:24:44,399<br>this format for how they represent the internal sort stuff obviously this is way more space-efficient</p>
<p>241<br>00:24:47,119 –&gt; 00:24:54,879<br>all right so let’s go into the setup for the moodsot we have a data that is end pages</p>
<p>242<br>00:24:56,000 –&gt; 00:25:02,000<br>and we have a buffer point that is B pages and is much larger than B and we’ll start with a very</p>
<p>243<br>00:25:02,000 –&gt; 00:25:07,759<br>simple version of the external moodsot in which we are going to merge things two ways and then we’ll</p>
<p>244<br>00:25:07,759 –&gt; 00:25:14,079<br>see how we can generalize that so the two is the degree of the merge tree and I’ll show you that next</p>
<p>245<br>00:25:14,880 –&gt; 00:25:19,279<br>I’ll come back to this in a little bit but let me just go to the diagram and show you how it works</p>
<p>246<br>00:25:20,079 –&gt; 00:25:27,920<br>so here’s a pictorial way of looking at moodsot imagine we are starting with a file in which there are</p>
<p>247<br>00:25:27,920 –&gt; 00:25:34,240<br>eight pages the first page has two records just to keep the diagram manageable obviously a page</p>
<p>248<br>00:25:34,240 –&gt; 00:25:39,680<br>will have a lot more than two records often hundreds or if you’re using bigger block sizes maybe even</p>
<p>249<br>00:25:39,680 –&gt; 00:25:45,600<br>many thousands but in this case just to keep things simple here is a page which has only two records</p>
<p>250<br>00:25:45,600 –&gt; 00:25:50,080<br>three and four and three and four is really the key only chance sorting and not showing all the</p>
<p>251<br>00:25:50,080 –&gt; 00:25:55,440<br>payload of all the entire record or the key point repairs that we might keep around this is just the</p>
<p>252<br>00:25:55,440 –&gt; 00:26:01,039<br>key values and then the second page has six and two and so on we want to sort all of this of course</p>
<p>253<br>00:26:01,039 –&gt; 00:26:07,200<br>when we sorted the in the final output file the first record will be one dead two and so on but we</p>
<p>254<br>00:26:07,200 –&gt; 00:26:13,360<br>want to get to that and we’ll do this by using only three pages right just to show how you can do</p>
<p>255<br>00:26:13,920 –&gt; 00:26:17,840<br>sorting of files that are much bigger than the amount of memory that you have so assume you have</p>
<p>256<br>00:26:17,840 –&gt; 00:26:23,920<br>only three pages right pretty small and we’ve got seven pages in this file there’s an extra dummy</p>
<p>257<br>00:26:23,920 –&gt; 00:26:28,800<br>page put over here to just indicate the end of file that’s just for convenience and also in this</p>
<p>258<br>00:26:28,800 –&gt; 00:26:33,360<br>case makes it a power of two you don’t need to actually allocate a page you could just remember that</p>
<p>259<br>00:26:33,360 –&gt; 00:26:39,039<br>this is the last page but this is just shown for visual clarity over here okay so let’s see what</p>
<p>260<br>00:26:39,039 –&gt; 00:26:45,440<br>happens in the first pass we’re going to make multiple passes on the data and at in each pass we</p>
<p>261<br>00:26:45,440 –&gt; 00:26:51,360<br>will read what we had in the previous pass and then write new data and when we write that data we’ll</p>
<p>262<br>00:26:51,359 –&gt; 00:26:57,919<br>either use that materialized format or that key and record ID format so in the first pass the input</p>
<p>263<br>00:26:57,919 –&gt; 00:27:03,759<br>data is the original file so we start there and that’s the eUF marker as we talked about and then</p>
<p>264<br>00:27:03,759 –&gt; 00:27:11,439<br>we’ll bring one page into memory this page sorted and write that back to a new file as the first</p>
<p>265<br>00:27:11,439 –&gt; 00:27:16,000<br>page and in this case three four was already sorted that’s okay we’ll write that back so this is a</p>
<p>266<br>00:27:16,000 –&gt; 00:27:24,079<br>new page a copy of that page made in a new file okay we’ll take the second page which is six two</p>
<p>267<br>00:27:24,720 –&gt; 00:27:30,079<br>and then sort that in memory and we’ll use quicksort or any of your favorite in memory sort</p>
<p>268<br>00:27:30,079 –&gt; 00:27:38,400<br>method to do that and then write that two six on to the second page of this new file we are creating</p>
<p>269<br>00:27:38,400 –&gt; 00:27:44,640<br>and then we keep going on so you have four nine then seven eight basically each page is getting</p>
<p>270<br>00:27:44,640 –&gt; 00:27:51,440<br>sorted and you finally end up having this file in which you have what we call as one page runs</p>
<p>271<br>00:27:52,080 –&gt; 00:27:56,240<br>basically in this file there are as many pages as there are in the input file</p>
<p>272<br>00:27:58,240 –&gt; 00:28:05,280<br>and each page in this file each one page is sorted and this one page seems all right now but just</p>
<p>273<br>00:28:05,280 –&gt; 00:28:11,040<br>hold on till what happens in the second pass in the second pass here’s what we’ll do we will start</p>
<p>274<br>00:28:11,039 –&gt; 00:28:15,839<br>merging and this is where the two way merge comes in we’re going to merge two pages at the records</p>
<p>275<br>00:28:15,839 –&gt; 00:28:21,519<br>in each page are sorted so we’ll bring this page into the buffer pool so now we’ve used one page in our</p>
<p>276<br>00:28:21,519 –&gt; 00:28:27,200<br>three page buffer manager we’ll bring the second page into the buffer pool second page is gone</p>
<p>277<br>00:28:27,200 –&gt; 00:28:31,920<br>we’ll reserve the third page for the output and I don’t know why those bubbles came up I think</p>
<p>278<br>00:28:31,920 –&gt; 00:28:36,879<br>zoom is trying to get too smart and did that automatically hopefully you enjoyed that</p>
<p>279<br>00:28:37,840 –&gt; 00:28:43,920<br>so we bring the first page and the second page into memory and then we’ll hold a cursor on</p>
<p>280<br>00:28:43,920 –&gt; 00:28:49,920<br>the smallest value in the first page hold a pointer and that points to three we’ll hold a</p>
<p>281<br>00:28:49,920 –&gt; 00:28:55,840<br>pointer to two which is the smallest record on the second page and then compare those two</p>
<p>282<br>00:28:56,400 –&gt; 00:29:01,280<br>and then output the smaller of those two which is two and as we do that we will move</p>
<p>283<br>00:29:02,240 –&gt; 00:29:07,039<br>the cursor on the second page to six so in the next step we’ll compare three and six</p>
<p>284<br>00:29:07,039 –&gt; 00:29:13,359<br>output three and so on and so effectively we’ll start producing these output as soon as that</p>
<p>285<br>00:29:13,359 –&gt; 00:29:18,000<br>output buffer page which was a third page becomes full we’ll write it to disk so not that output</p>
<p>286<br>00:29:18,000 –&gt; 00:29:23,200<br>buffer page is free so we can fill it up again with the next page so as you can see as I do this</p>
<p>287<br>00:29:23,200 –&gt; 00:29:30,639<br>merge step in this second pass which is called pass number one because we started the first pass</p>
<p>288<br>00:29:30,640 –&gt; 00:29:39,759<br>was label zero in pass number one we will have created a sequence of two pages and the records across</p>
<p>289<br>00:29:39,759 –&gt; 00:29:45,440<br>those two pages are fully sorted and so that’s called a two page run you can take a sequence of two</p>
<p>290<br>00:29:45,440 –&gt; 00:29:50,560<br>pages and across that the records are sorted and so the two three gets written out to disk then four</p>
<p>291<br>00:29:50,560 –&gt; 00:29:54,880<br>six and I’m just gonna draw it in a slightly different way this file created at the end of pass one</p>
<p>292<br>00:29:54,880 –&gt; 00:30:00,320<br>still has seven pages as before eight if you add that dummy page but now I’m just gonna draw the</p>
<p>293<br>00:30:00,320 –&gt; 00:30:05,360<br>sequence of two pages each pair vertically like that just to show that they’re sorted right it’s a</p>
<p>294<br>00:30:05,360 –&gt; 00:30:12,480<br>two page run the first two pages in this file have what you see here the second two pages will also</p>
<p>295<br>00:30:12,480 –&gt; 00:30:20,880<br>be merged and there’ll be a second two page run for the second for the 49 and 78 page that we had</p>
<p>296<br>00:30:20,880 –&gt; 00:30:27,280<br>written out at the end of pass zero okay so now you can start to see first we started with data</p>
<p>297<br>00:30:27,280 –&gt; 00:30:32,720<br>was completely unsorted then we said everything on a single page is sorted now we are seeing in this</p>
<p>298<br>00:30:32,720 –&gt; 00:30:40,000<br>new file that is produced every pair of pages the records across data are sorted now we’ll repeat</p>
<p>299<br>00:30:40,000 –&gt; 00:30:46,160<br>this process again using three buffer pool pages and what we’ll do is we’ll create this four page run</p>
<p>300<br>00:30:46,480 –&gt; 00:30:51,200<br>file we’ll do that by doing the following we’ll bring page two three into memory again now we use</p>
<p>301<br>00:30:51,759 –&gt; 00:30:57,360<br>one buffer pool page for that we’ll bring the page four seven into memory second page is gone</p>
<p>302<br>00:30:57,360 –&gt; 00:31:03,040<br>that’s used for the smallest page on the two runs we are trying to run merge and then the output</p>
<p>303<br>00:31:03,040 –&gt; 00:31:07,840<br>pages before it’s the same algorithm that we did before we’ll find the smallest between what’s in</p>
<p>304<br>00:31:07,840 –&gt; 00:31:14,000<br>memory we’ll compare two and four output two move the cursor to three compare three and four</p>
<p>305<br>00:31:14,000 –&gt; 00:31:20,640<br>output three fill up that page in the output buffer keep going at any point in time we just need one</p>
<p>306<br>00:31:20,640 –&gt; 00:31:27,839<br>input page from either side from these one input page from the two runs that we are merging and one</p>
<p>307<br>00:31:27,839 –&gt; 00:31:34,160<br>output page and we effectively create this new file at the end of pass two surprise surprise now</p>
<p>308<br>00:31:34,160 –&gt; 00:31:40,400<br>this is called a four page run because in this file there are again seven plus one dummy eight page</p>
<p>309<br>00:31:40,400 –&gt; 00:31:45,440<br>but the first four pages now are fully sorted the first the records across the first four page you</p>
<p>310<br>00:31:45,440 –&gt; 00:31:51,519<br>start from the first to the last and it’s in the right sort of order do the last thing which is</p>
<p>311<br>00:31:52,640 –&gt; 00:31:59,519<br>do one more merge and you’re basically done so as you can see if you think about what’s the cost</p>
<p>312<br>00:32:00,000 –&gt; 00:32:07,920<br>of doing this operation the cost is going to be two times the number of pages and is the number of</p>
<p>313<br>00:32:07,920 –&gt; 00:32:14,720<br>pages in each pass because in each pass we are reading it and writing it so hence this two n and how</p>
<p>314<br>00:32:14,720 –&gt; 00:32:20,560<br>many passes to be half that’s the depth of this tree this is effectively a binary tree and so the</p>
<p>315<br>00:32:20,560 –&gt; 00:32:26,000<br>depth is going to be log off into the base two and the ceiling stuff is just to take care of the</p>
<p>316<br>00:32:26,000 –&gt; 00:32:30,960<br>fact that the number of pages may not be exact power of two but he can’t take half a pass we have to</p>
<p>317<br>00:32:30,960 –&gt; 00:32:37,200<br>take a full pass and that’s what we do there’s an excellent question that was asked in class yesterday</p>
<p>318<br>00:32:37,200 –&gt; 00:32:45,680<br>about why do we go about merging this way could we have in pass one done this merge then done this</p>
<p>319<br>00:32:45,680 –&gt; 00:32:53,120<br>merge and before doing the merge of the five six and one three to create the this two page run</p>
<p>320<br>00:32:53,120 –&gt; 00:32:59,920<br>could we have merged these two to create this in the first place so instead of doing the</p>
<p>321<br>00:33:00,400 –&gt; 00:33:08,400<br>processing effectively level by level could we go go down the depth of the tree as much as we can</p>
<p>322<br>00:33:08,400 –&gt; 00:33:14,400<br>and then keep coming back so effectively what you could do is produce this in pass one pause the rest</p>
<p>323<br>00:33:14,400 –&gt; 00:33:20,720<br>of the processing of pass one go to pass two and so on that was an excellent question the answer is yes</p>
<p>324<br>00:33:20,799 –&gt; 00:33:29,279<br>you can do that and there’s an advantage to that is you could you process this you process these two</p>
<p>325<br>00:33:30,160 –&gt; 00:33:37,200<br>page runs and do that you can delete this page this set of four pages from disk and you basically</p>
<p>326<br>00:33:37,200 –&gt; 00:33:43,440<br>just have this portion here but so you’re not allocating as much space on this because at that point</p>
<p>327<br>00:33:43,440 –&gt; 00:33:48,720<br>you could be tossing this away in the other case you will have twice as many pages allocated on this</p>
<p>328<br>00:33:48,720 –&gt; 00:33:53,839<br>so if your disk is getting full then that might help generally disks these days have plenty of space</p>
<p>329<br>00:33:53,839 –&gt; 00:33:58,160<br>so it’s not a problem but that’s definitely a way to think about it and those are the ways in which</p>
<p>330<br>00:33:58,160 –&gt; 00:34:03,200<br>people are still constantly improving external sort it’s still a blood sport people compete very</p>
<p>331<br>00:34:03,200 –&gt; 00:34:10,079<br>heavily on how fast they can sort and ideas like that and ideas like trying to improve the in-memory</p>
<p>332<br>00:34:10,079 –&gt; 00:34:14,720<br>sort for specific hardware trying to make this work in an environment where your data is coming from</p>
<p>333<br>00:34:14,719 –&gt; 00:34:20,079<br>a cloud storage device and can you do things faster all of this is still interesting topic in</p>
<p>334<br>00:34:20,079 –&gt; 00:34:28,559<br>other words external mood sort is still a research topic that is work for sewing okay now let’s go</p>
<p>335<br>00:34:28,559 –&gt; 00:34:34,319<br>and see how we can make what we have better so I’ll go back now to the macro perspective of what</p>
<p>336<br>00:34:34,319 –&gt; 00:34:40,159<br>the algorithm does right we have pass zero where we were reading one page into memory sought that into</p>
<p>337<br>00:34:40,159 –&gt; 00:34:45,519<br>a one page run then in pass one two three onwards recursively merge all of these pairs still be a</p>
<p>338<br>00:34:45,519 –&gt; 00:34:52,239<br>finally done right pretty standard divide and conquer and the everything is great so far we are now</p>
<p>339<br>00:34:52,239 –&gt; 00:34:59,119<br>able to sort stuff that’s extremely fast but if you had a petabyte file and you just had a hundred</p>
<p>340<br>00:34:59,119 –&gt; 00:35:04,000<br>pages in the buffer pool or three or just three pages in the buffer pool like we were doing here</p>
<p>341<br>00:35:04,000 –&gt; 00:35:09,679<br>you will eventually finish sorting that file but it will take a very very long time it may take</p>
<p>342<br>00:35:09,679 –&gt; 00:35:14,399<br>decades or a century depending on the hardware you have before you are done so can we do better</p>
<p>343<br>00:35:14,399 –&gt; 00:35:20,079<br>can we do better especially if we have larger amounts of buffer pool so imagine you know today</p>
<p>344<br>00:35:20,079 –&gt; 00:35:26,000<br>gigabyte memory is very feasible in fact many database servers high end servers run with terabytes of</p>
<p>345<br>00:35:26,000 –&gt; 00:35:31,679<br>main memory so imagine I give you a lot more than three buffer pool pages can we make this go a lot</p>
<p>346<br>00:35:31,679 –&gt; 00:35:37,599<br>faster so what can we do to make this go faster we can change this to end right in each pass we</p>
<p>347<br>00:35:37,599 –&gt; 00:35:44,000<br>are going to have to do that that many ios what we can do is try and reduce this cost which is</p>
<p>348<br>00:35:44,000 –&gt; 00:35:49,279<br>basically this okay and effectively you can’t do something with this number one you really have to</p>
<p>349<br>00:35:49,279 –&gt; 00:35:56,000<br>focus on what you can do here this is basically determine that log of n to the base two is determined</p>
<p>350<br>00:35:56,000 –&gt; 00:36:01,039<br>by the shape of the tree so you can do two things if I told you in this case I’m going to give you</p>
<p>351<br>00:36:01,039 –&gt; 00:36:08,880<br>five pages what could you do you could drop this tree so instead of starting with a one page run</p>
<p>352<br>00:36:08,880 –&gt; 00:36:13,440<br>you could immediately go to something like a four page or a five page run you know if I give you</p>
<p>353<br>00:36:13,440 –&gt; 00:36:18,800<br>five pages or let’s just start with four pages bring all the four pages in memory</p>
<p>354<br>00:36:19,519 –&gt; 00:36:25,039<br>sort them and immediately you get this right right so effectively what you can do is take this</p>
<p>355<br>00:36:25,039 –&gt; 00:36:31,279<br>tree and you can chalk the base of the tree so that you can reduce the number of passes by jumping</p>
<p>356<br>00:36:31,279 –&gt; 00:36:35,920<br>from here to there right but because you have a lot more memory so if I’ve got four pages I can just</p>
<p>357<br>00:36:35,920 –&gt; 00:36:41,440<br>bring those four goes straight here didn’t have to do these two passes save two passes second</p>
<p>358<br>00:36:41,440 –&gt; 00:36:45,360<br>thing you can do if you have more pages there’s no reason to do a two way merge I could do a three</p>
<p>359<br>00:36:45,360 –&gt; 00:36:51,360<br>way merge or a four way merge or you know how many ever pages that I have if I’ve got three buffer</p>
<p>360<br>00:36:51,360 –&gt; 00:36:56,880<br>pages I always need one page for the output and I could do a three minus one way merge and that</p>
<p>361<br>00:36:56,880 –&gt; 00:37:02,960<br>basically widens the tree so we’re going to chop the tree and widen the tree that dramatically reduces</p>
<p>362<br>00:37:02,960 –&gt; 00:37:10,400<br>the number of passes and in practice you rarely see even on very large data sets because if you have</p>
<p>363<br>00:37:10,400 –&gt; 00:37:15,599<br>a petabyte data set you’re probably going to get terabytes of main memory to sort that you rarely</p>
<p>364<br>00:37:15,599 –&gt; 00:37:21,120<br>need more than two passes to sort data maybe three if you’re doing something crazy crazy big and</p>
<p>365<br>00:37:21,119 –&gt; 00:37:26,400<br>don’t have a lot of memory but the number of passes are not going to be a lot more than two or three</p>
<p>366<br>00:37:26,400 –&gt; 00:37:34,480<br>in practice and it’s because of this technique so how does this work we are that idea is essentially</p>
<p>367<br>00:37:34,480 –&gt; 00:37:39,119<br>what I told you captured over here in a little bit more detail start by using all the buffer pool pages</p>
<p>368<br>00:37:39,119 –&gt; 00:37:44,319<br>all the b pages don’t have to leave one for the output bring everything into those b pages sorted</p>
<p>369<br>00:37:44,319 –&gt; 00:37:50,880<br>and write these sorted runs so that will produce and divided by b take the ceiling function to get</p>
<p>370<br>00:37:50,880 –&gt; 00:37:58,800<br>that nice integer number sorted runs and each of them is b pages long then merge in a b minus</p>
<p>371<br>00:37:58,800 –&gt; 00:38:05,200<br>way the final equation becomes log to the base of b minus one right massive reduction in the number</p>
<p>372<br>00:38:05,200 –&gt; 00:38:11,599<br>of passes because of that or another big reduction because you’re starting with a much smaller number</p>
<p>373<br>00:38:11,599 –&gt; 00:38:16,640<br>of nodes in that tree that you have right so this is a b minus way fan out tree where the number of</p>
<p>374<br>00:38:16,639 –&gt; 00:38:25,440<br>leaves in that tree is n divided by b with the ceiling function okay all right just to put that</p>
<p>375<br>00:38:25,440 –&gt; 00:38:31,920<br>in perspective imagine we want to sort a file with 108 pages and have five buffer pool pages</p>
<p>376<br>00:38:32,480 –&gt; 00:38:39,440<br>bring five pages at a time into memory sort that so you get a five page run file and the number</p>
<p>377<br>00:38:39,440 –&gt; 00:38:47,519<br>of a sorted runs in that is going to be 108 divided by five rounded up 22 and that’s how many</p>
<p>378<br>00:38:47,519 –&gt; 00:38:53,119<br>runs you have now each of these 22 runs have to be merged but you have b pages so you can do a</p>
<p>379<br>00:38:53,119 –&gt; 00:38:59,440<br>four way merge remember we still need one page for the output and so the output of that is going</p>
<p>380<br>00:38:59,440 –&gt; 00:39:06,960<br>to be a file that is five times four which should have 20 pages in each run so it’s a 20 page run</p>
<p>381<br>00:39:06,960 –&gt; 00:39:13,679<br>file and the number of runs in that is going to be six which you merge one more time and basically</p>
<p>382<br>00:39:13,679 –&gt; 00:39:19,119<br>you’re done as an exercise try to look at different values try to see what happens when b is equal to</p>
<p>383<br>00:39:19,119 –&gt; 00:39:24,880<br>three try to make n equal to a million which is not very unusual to find in databases to have a</p>
<p>384<br>00:39:24,880 –&gt; 00:39:30,159<br>a million page file in the large databases and you’ll see why everything we are doing with the</p>
<p>385<br>00:39:30,159 –&gt; 00:39:39,519<br>larger fan out and this merge can happen okay and happens fast all right okay now there’s an</p>
<p>386<br>00:39:39,519 –&gt; 00:39:46,319<br>optimization that you can do with external merge where you play on this idea that if you plot this</p>
<p>387<br>00:39:46,319 –&gt; 00:39:54,159<br>log function you’ll see that for large values of n if I increase n the number of passes is not going</p>
<p>388<br>00:39:54,159 –&gt; 00:40:00,719<br>to change significantly right it’s going to jump in in a step function and if that is the case</p>
<p>389<br>00:40:00,719 –&gt; 00:40:06,319<br>effectively even if I give you p pages or give you half of those pages the number of passes might</p>
<p>390<br>00:40:06,319 –&gt; 00:40:13,359<br>remain the same for a whole range of n values so in many of those cases it makes sense to do this</p>
<p>391<br>00:40:13,359 –&gt; 00:40:21,039<br>optimization call double buffering and double buffering does the following it’s going to try and</p>
<p>392<br>00:40:21,039 –&gt; 00:40:26,880<br>use the buffer pool and instead of using all the pages it has only used part of it to do one</p>
<p>393<br>00:40:27,679 –&gt; 00:40:32,880<br>pass while the other stuff is getting ready let me explain what I mean so assume we have</p>
<p>394<br>00:40:33,440 –&gt; 00:40:38,320<br>the table that we want to be sorted is sitting on disk and there’s a bunch of pages I’ve</p>
<p>395<br>00:40:38,320 –&gt; 00:40:43,440<br>all pages are equal I’ve just colored it into light and dark to make this animation work and so far</p>
<p>396<br>00:40:43,440 –&gt; 00:40:47,840<br>everything we’ve talked about what are we going to do if I’ve got four buffer pool pages bring three</p>
<p>397<br>00:40:47,840 –&gt; 00:40:54,720<br>pages in do a three-day merge and write those output into the into this sorted run that we are</p>
<p>398<br>00:40:54,720 –&gt; 00:41:00,880<br>creating on disk okay so now with double buffering assume we have a lot more pages we have</p>
<p>399<br>00:41:01,680 –&gt; 00:41:05,840<br>eight pages and the number of passes remains the same because there’s going to be a whole range of</p>
<p>400<br>00:41:05,840 –&gt; 00:41:11,760<br>n values for which that’s going to happen now what’s happening right now with the way we are doing</p>
<p>401<br>00:41:11,760 –&gt; 00:41:16,880<br>things is we could have gone to an eight way merge and that will certainly help and we can we</p>
<p>402<br>00:41:16,880 –&gt; 00:41:20,960<br>should obviously consider that when we try to optimize this operation but another thing we can</p>
<p>403<br>00:41:20,960 –&gt; 00:41:28,400<br>consider is to try and play with the observation here that right now the sequential nature of this</p>
<p>404<br>00:41:28,400 –&gt; 00:41:35,200<br>processing is that if I look at the CPU and the disk when I’m bringing the pages into the buffer pool</p>
<p>405<br>00:41:35,200 –&gt; 00:41:41,360<br>the CPU is doing nothing it’s just idle my IO bus is busy and then when I start processing the</p>
<p>406<br>00:41:41,360 –&gt; 00:41:47,120<br>disk buses and is not doing anything and it’s only the CPU that’s doing so at any point in time if I</p>
<p>407<br>00:41:47,120 –&gt; 00:41:52,320<br>look at the CPU resource and the disk resource one of them is basically idling so what if you wanted</p>
<p>408<br>00:41:52,320 –&gt; 00:41:58,480<br>to use all of that and we had this extra buffer space and the way you could deal with that is the</p>
<p>409<br>00:41:58,480 –&gt; 00:42:03,360<br>following you do double buffering so we’ll start the same thing except we’ll create a shadow buffer</p>
<p>410<br>00:42:03,360 –&gt; 00:42:07,680<br>page for each actual buffer page that we’re doing so we’re still going to do a three-day merge</p>
<p>411<br>00:42:07,679 –&gt; 00:42:13,919<br>but as this data is brought in same as before and it’s getting merged I’m going to start fetching</p>
<p>412<br>00:42:13,919 –&gt; 00:42:21,279<br>the other pages to get it ready for the next merge phase okay or the next creation of the sorted</p>
<p>413<br>00:42:21,279 –&gt; 00:42:28,480<br>run phase and so now when I’m done with merging together these three pages that I have into the</p>
<p>414<br>00:42:28,480 –&gt; 00:42:34,719<br>red runs the CPU was really busy but the disk was also busy because it was fetching the next set of</p>
<p>415<br>00:42:34,719 –&gt; 00:42:40,000<br>pages that needs to be processed we finished writing this red run and then we start working on the</p>
<p>416<br>00:42:40,000 –&gt; 00:42:45,439<br>darker pages that we brought in here to create that blue run and we’ll keep toggling between those</p>
<p>417<br>00:42:45,439 –&gt; 00:42:49,919<br>buffer pages is effectively like you’ve got the buffer pool you’ve divided into two there’s a shadow</p>
<p>418<br>00:42:49,919 –&gt; 00:42:55,039<br>version of the pool and one is operating and the shadow is fetching data from disk and you keep</p>
<p>419<br>00:42:55,039 –&gt; 00:43:00,559<br>flipping which one is active and which is the shadow version okay and obviously with this we’ll get</p>
<p>420<br>00:43:00,559 –&gt; 00:43:07,119<br>far better resource utilization for the disk and IO and you can overlap the computation you’ll get</p>
<p>421<br>00:43:07,119 –&gt; 00:43:14,000<br>a reduction in the response time and the other the downside of that is the effective being the</p>
<p>422<br>00:43:14,000 –&gt; 00:43:19,039<br>equations we had before is half of what we had but as I said there’s a log function and a ceiling</p>
<p>423<br>00:43:19,039 –&gt; 00:43:23,920<br>function so in many cases it won’t matter won’t increase the number of passes so this this could</p>
<p>424<br>00:43:23,920 –&gt; 00:43:28,799<br>certainly help reduce that response time because you are using both the disk and CPU in parallel</p>
<p>425<br>00:43:30,639 –&gt; 00:43:35,119<br>it may not change the throughput you could get a response time reduction but you’ve got a lot of</p>
<p>426<br>00:43:35,119 –&gt; 00:43:39,679<br>sort operations happening in parallel obviously the throughput may not change right so it’s a trade-off</p>
<p>427<br>00:43:39,679 –&gt; 00:43:43,679<br>that you make but it’s a cool technique especially if you want to get the latency of that sort</p>
<p>428<br>00:43:43,679 –&gt; 00:43:53,119<br>operation down you can play around with techniques like that all right one little tidbit of information</p>
<p>429<br>00:43:53,119 –&gt; 00:44:00,239<br>deep down in the sort core we are doing a comparison between two values and often it helps</p>
<p>430<br>00:44:00,239 –&gt; 00:44:05,279<br>to write specialized codes so that that comparison can be fast you know especially for</p>
<p>431<br>00:44:06,079 –&gt; 00:44:13,519<br>types that might be complex types like date time or even for integer types if I can write the code</p>
<p>432<br>00:44:13,519 –&gt; 00:44:19,599<br>if I can write a sort function where the type of the keys is predefined as opposed to have to</p>
<p>433<br>00:44:19,599 –&gt; 00:44:24,959<br>infer the type on the fly if I have to infer the type on the fly I have to pass into the sort function</p>
<p>434<br>00:44:24,960 –&gt; 00:44:31,519<br>of a pointer to a function to compare the value and in equal it’d be better if I could just use</p>
<p>435<br>00:44:31,519 –&gt; 00:44:39,519<br>native in equal and so often what systems do is they will write the sort code in a generic way</p>
<p>436<br>00:44:39,519 –&gt; 00:44:44,639<br>and if you’re in C++ you can write that using template programming and then instantiate the</p>
<p>437<br>00:44:44,639 –&gt; 00:44:51,440<br>template when you’re compiling the code for all the data types that you care about that you need to</p>
<p>438<br>00:44:51,440 –&gt; 00:44:59,119<br>go fast and usually those data types have to be fixed data types like ints int2 int4 int8 and so on</p>
<p>439<br>00:44:59,119 –&gt; 00:45:02,960<br>you can do a few more things with strings but this code specialization we’re going to say I have a</p>
<p>440<br>00:45:02,960 –&gt; 00:45:08,000<br>generic sort function maybe I’m looking at the quicksort component written quicksort once I don’t</p>
<p>441<br>00:45:08,000 –&gt; 00:45:13,360<br>want to write quicksort for int2 quicksort for int4 quicksort for int8 and so on I write it once using</p>
<p>442<br>00:45:13,360 –&gt; 00:45:18,480<br>template meta programming compiled it so now I have a specialized version of int2 and that inner loop</p>
<p>443<br>00:45:18,480 –&gt; 00:45:24,320<br>might be optimized the comparison predicate is optimized to make int2 or int4 get go really fast</p>
<p>444<br>00:45:24,320 –&gt; 00:45:28,320<br>but it might be that even some parts of that inner loop with as a loop the compiler may be</p>
<p>445<br>00:45:28,320 –&gt; 00:45:34,719<br>able to unroll at compilation time because it has perfect type information so that code specialization</p>
<p>446<br>00:45:34,719 –&gt; 00:45:39,679<br>is applied in a bunch of database systems through a variety of methods in C++ written databases it’s</p>
<p>447<br>00:45:39,679 –&gt; 00:45:45,440<br>often done through template mechanism and compilation of those templates that are instantiated</p>
<p>448<br>00:45:45,440 –&gt; 00:45:53,039<br>explicitly to make that that code go fast if I’m doing sorting on</p>
<p>449<br>00:45:54,480 –&gt; 00:46:00,000<br>their car keys basically string keys then I could do a simple thing and just do a comparison on</p>
<p>450<br>00:46:00,000 –&gt; 00:46:04,639<br>the entire string but if the strings are long they might be 100 characters long I’m going to need a</p>
<p>451<br>00:46:04,639 –&gt; 00:46:09,679<br>lot of cycles to just do individual key comparison and we’re doing a lot of these key comparisons as we do</p>
<p>452<br>00:46:09,679 –&gt; 00:46:17,279<br>this sort so one alternative popular technique that gets used is to get a representation of the key</p>
<p>453<br>00:46:17,279 –&gt; 00:46:24,159<br>in some encoded fixed-length form usually something like a 64 bit encoded version of that string</p>
<p>454<br>00:46:24,559 –&gt; 00:46:29,119<br>and which has a property such that it could be basically just the prefix of the string so if I</p>
<p>455<br>00:46:29,119 –&gt; 00:46:35,679<br>compare that bit encoded 64 bit version that I can just read like a 64 bit int and use int comparison</p>
<p>456<br>00:46:35,679 –&gt; 00:46:40,480<br>which is faster than doing string comparison I can tell whether something is less than</p>
<p>457<br>00:46:41,359 –&gt; 00:46:47,440<br>another string and it’s only when the that prefix is equal to have to go into a full string comparison</p>
<p>458<br>00:46:47,440 –&gt; 00:46:52,960<br>and so I don’t need to do a full string comparison for many of these operations and these comparison</p>
<p>459<br>00:46:52,960 –&gt; 00:46:59,599<br>operations are getting used a lot so when you’re sorting on strings you should very rarely be sorting</p>
<p>460<br>00:46:59,599 –&gt; 00:47:04,399<br>using a equality function or comparison function on the native strings you could use that if the</p>
<p>461<br>00:47:04,400 –&gt; 00:47:08,639<br>strings are really small and you know that but if it’s variable character strings then you generally</p>
<p>462<br>00:47:08,639 –&gt; 00:47:14,079<br>want to go use a technique that looks like that and this type of idea of taking keys and using a</p>
<p>463<br>00:47:14,079 –&gt; 00:47:19,360<br>suffix of it as a surrogate for getting correct comparison and only having to look at the full string</p>
<p>464<br>00:47:20,240 –&gt; 00:47:26,720<br>if you need to is used all over the place Beatrice that have string keys often in the inner nodes are</p>
<p>465<br>00:47:26,720 –&gt; 00:47:31,280<br>going to have that suffix representation in the case because they’re smaller and they’re all kinds</p>
<p>466<br>00:47:31,280 –&gt; 00:47:36,960<br>of interesting things that you can play around with string Beatrice so this suffix idea is used</p>
<p>467<br>00:47:36,960 –&gt; 00:47:43,519<br>shows up all over now some of you might be thinking as we’ve been talking about sorting that there’s</p>
<p>468<br>00:47:43,519 –&gt; 00:47:49,280<br>a lot of connection between sorting and what you guys learned for Beatrice and could we use the Beatrice</p>
<p>469<br>00:47:49,280 –&gt; 00:47:53,920<br>for sorting and there are two cases to consider and the answer is yes you can use Beatrice for sorting</p>
<p>470<br>00:47:53,920 –&gt; 00:47:59,519<br>but you have to be careful about what type of Beatrice it is so Beatrice come in two form clustered</p>
<p>471<br>00:47:59,519 –&gt; 00:48:05,280<br>and unclustered clustered means the record IDs in the leaf level of the Beatrice shown by this gray</p>
<p>472<br>00:48:05,280 –&gt; 00:48:11,360<br>area over here they will generally follow the record ID of the pages that are stored in the disc</p>
<p>473<br>00:48:11,360 –&gt; 00:48:19,280<br>so if I have a clustered Beatrice then I could just sort the keys so if a Beatrice is built on student</p>
<p>474<br>00:48:19,280 –&gt; 00:48:25,360<br>ID the example we’ve been using before and someone and the query says order by student ID don’t need to</p>
<p>475<br>00:48:25,360 –&gt; 00:48:31,039<br>sort you could just go look at start with the leftmost leaf node go chase the</p>
<p>476<br>00:48:32,960 –&gt; 00:48:38,079<br>records in that leaf node from left to right pull up the pointer and effectively you’re going to get</p>
<p>477<br>00:48:38,079 –&gt; 00:48:42,800<br>I sort it out but right because the keys already sorted at the lowest level of the Beatrice just</p>
<p>478<br>00:48:42,800 –&gt; 00:48:48,800<br>fritchy the records the records are clustered so the first three keys over here all belong to page</p>
<p>479<br>00:48:49,600 –&gt; 00:48:55,360<br>page 101 and so you’re only accessing each page once basically in a single scan of the file</p>
<p>480<br>00:48:55,360 –&gt; 00:48:59,920<br>and a scan of the lowest level of the Beatrice you’re going to get sorted which is going to be</p>
<p>481<br>00:48:59,920 –&gt; 00:49:05,120<br>faster than the external sort merge however if it’s an unclustered Beatrice probably a bad</p>
<p>482<br>00:49:05,120 –&gt; 00:49:11,200<br>idea to use it unless you’ve got a range selection predicate also on the Beatrice or zoom we’re just</p>
<p>483<br>00:49:11,200 –&gt; 00:49:17,039<br>saying order by student ID the Beatrice is built on student ID and it’s the leaf level then it’s a</p>
<p>484<br>00:49:17,039 –&gt; 00:49:21,360<br>bad idea to use an unclustered Beatrice because as you can see here you’re going to chase the key</p>
<p>485<br>00:49:21,360 –&gt; 00:49:26,159<br>down you’re going to fetch this page the second key here goes to a second page and later on you’re</p>
<p>486<br>00:49:26,159 –&gt; 00:49:31,679<br>going to refetch this page so it’s at random IOs and in this case not just random IOs but also</p>
<p>487<br>00:49:31,679 –&gt; 00:49:37,199<br>re-accessing the same page multiple times this is going to be pretty expensive you are going to be</p>
<p>488<br>00:49:37,199 –&gt; 00:49:42,880<br>better off having done that external merge on so if you have to sort you have a clustered Beatrice</p>
<p>489<br>00:49:42,960 –&gt; 00:49:48,160<br>on the sort key you can use that otherwise if it’s an unclustered Beatrice you can avoid that and</p>
<p>490<br>00:49:48,160 –&gt; 00:49:52,800<br>these are the types of decisions that an optimizer can make as they’re picking the right algorithm</p>
<p>491<br>00:49:52,800 –&gt; 00:50:01,280<br>or the access tab all right switching gears from the sort operator to the aggregation operator</p>
<p>492<br>00:50:02,559 –&gt; 00:50:07,519<br>we can start to now look at different algorithms for it and also start to think about hashing</p>
<p>493<br>00:50:08,400 –&gt; 00:50:14,000<br>so aggregation basically involves you’ve seen aggregation before so let’s just go look at it with</p>
<p>494<br>00:50:14,000 –&gt; 00:50:20,239<br>an example so here’s a query in which on this en-roll table which has student ID column ID and great</p>
<p>495<br>00:50:20,880 –&gt; 00:50:27,119<br>we are looking for only those students that are that have a grade of B and C and as I joked about</p>
<p>496<br>00:50:27,119 –&gt; 00:50:32,480<br>this in class yesterday obviously this is not a query you would run in CMU because probably it</p>
<p>497<br>00:50:32,480 –&gt; 00:50:38,719<br>comes out empty everyone gets an aid I’m just kidding but here we are selecting records that</p>
<p>498<br>00:50:38,719 –&gt; 00:50:46,159<br>fit this criteria ordering it by the column ID and then selecting this distinct so it’s a very simple</p>
<p>499<br>00:50:46,159 –&gt; 00:50:52,079<br>aggregate we will bring group buys in in a little bit distinct count IDs is an aggregate and we’ll</p>
<p>500<br>00:50:52,079 –&gt; 00:50:56,559<br>see how we can do that with a sort based method and we’ll also see the hash based version after that</p>
<p>501<br>00:50:57,440 –&gt; 00:51:01,920<br>so first thing we’ll do in the square E3 I’m not going to draw that tree as you saw before but this</p>
<p>502<br>00:51:01,920 –&gt; 00:51:06,880<br>is the bottom level of the tree you apply the selection on this table and you keep just the records</p>
<p>503<br>00:51:06,880 –&gt; 00:51:12,800<br>that have B’s and C’s now you go to that second operator in that tree which is to project and remove</p>
<p>504<br>00:51:12,800 –&gt; 00:51:17,039<br>the columns keeping just the column ID so just this column that’s what you produce at that second</p>
<p>505<br>00:51:17,039 –&gt; 00:51:22,960<br>operator in that query tree and then we sort it and you can use external sort merge if this file</p>
<p>506<br>00:51:22,960 –&gt; 00:51:27,360<br>were really large I know it’s a small example here four records but imagine it were four million</p>
<p>507<br>00:51:27,440 –&gt; 00:51:31,840<br>you would sort that using external memory if you didn’t have enough space in the buffer pool</p>
<p>508<br>00:51:31,840 –&gt; 00:51:37,120<br>it’s a small file you’ll sort it using an memory sort regardless you get a sorted output and now what</p>
<p>509<br>00:51:37,120 –&gt; 00:51:43,120<br>you can do is to eliminate the duplicates just scan over this file from top to bottom and only</p>
<p>510<br>00:51:43,120 –&gt; 00:51:48,960<br>output the values ones that you see so here we’ll output four four five the first record skip over</p>
<p>511<br>00:51:48,960 –&gt; 00:51:53,599<br>the second one because it’s duplicate the duplicates will always be next to each other so at any point</p>
<p>512<br>00:51:53,599 –&gt; 00:51:58,400<br>in time you just remember output this value remember that value go to the next record if it’s</p>
<p>513<br>00:51:58,400 –&gt; 00:52:05,119<br>the same value skip over okay this is a little optimization you can do this idea of skipping stuff</p>
<p>514<br>00:52:06,000 –&gt; 00:52:11,920<br>of having dropped this if you go back to where we were many slides ago with that merge tree up</p>
<p>515<br>00:52:11,920 –&gt; 00:52:17,679<br>over here you could imagine that you could fold in some of that optimization to this level imagine</p>
<p>516<br>00:52:17,679 –&gt; 00:52:23,119<br>you had to do a distinct on the keys here and imagine instead of this two there was a three here</p>
<p>517<br>00:52:24,079 –&gt; 00:52:27,920<br>and there was another and what you could do at that point when you’re doing this merge you could</p>
<p>518<br>00:52:27,920 –&gt; 00:52:31,599<br>have written the three only ones you can have dropped that tree earlier because you’re just looking</p>
<p>519<br>00:52:31,599 –&gt; 00:52:37,279<br>for distinct so if new you were doing sorting to do distinct you can actually go change the core</p>
<p>520<br>00:52:37,279 –&gt; 00:52:42,480<br>sort algorithm to do that distinct earlier using essentially that same ideas that when you have</p>
<p>521<br>00:52:42,480 –&gt; 00:52:49,360<br>distinct you just need to keep one copy of that record and you could push that optimization that</p>
<p>522<br>00:52:49,360 –&gt; 00:52:56,079<br>we just saw here on this slide where we skipped over that second duplicate value up ahead in that</p>
<p>523<br>00:52:56,079 –&gt; 00:53:02,320<br>operator tree so now you can see if I can unpack the full semantics of the SQL query in the operator</p>
<p>524<br>00:53:02,320 –&gt; 00:53:07,760<br>that same external sort merge operator that we are looking at I can actually modify that operator</p>
<p>525<br>00:53:07,760 –&gt; 00:53:15,680<br>within the context of the rest of the query and do even better okay now as I started earlier on</p>
<p>526<br>00:53:15,679 –&gt; 00:53:20,879<br>and told you that you’ll see this duality between sort based methods and hash based methods and</p>
<p>527<br>00:53:20,879 –&gt; 00:53:27,919<br>it’s like the sibling library that happens we now can start to unpack that and look at aggregation</p>
<p>528<br>00:53:28,480 –&gt; 00:53:34,000<br>and look at the hash based aggregation so imagine we don’t need the data to be ordered because</p>
<p>529<br>00:53:34,000 –&gt; 00:53:39,519<br>we have a group by order distinct right so that opens up the chance to go use a hash based aggregation</p>
<p>530<br>00:53:40,079 –&gt; 00:53:45,440<br>and hashing is nearly always going to be a better alternative in this scenario okay</p>
<p>531<br>00:53:45,440 –&gt; 00:53:49,760<br>when it may not be a better option is that if I have a B3 that is built on the group by column</p>
<p>532<br>00:53:49,760 –&gt; 00:53:55,039<br>because I could and it’s a clustered B3 I could potentially use that and get a faster operation</p>
<p>533<br>00:53:55,039 –&gt; 00:54:00,079<br>and again and optimize if we consider that so in a hash based aggregate I’m just going to go</p>
<p>534<br>00:54:00,079 –&gt; 00:54:04,639<br>through this with an example it’s going to be two phases divide and conquer in the divide phase we</p>
<p>535<br>00:54:04,639 –&gt; 00:54:10,639<br>are going to break up the file partition it into two two more pieces and then we want each piece to be</p>
<p>536<br>00:54:10,639 –&gt; 00:54:14,960<br>processed individually to get the final answer and we want each of those partitions to be small enough</p>
<p>537<br>00:54:15,039 –&gt; 00:54:20,000<br>that we can do things with it in memory right files too big to fit in memory break it up into small</p>
<p>538<br>00:54:20,000 –&gt; 00:54:25,679<br>parts so that each small part can be worked on in memory so breaking up is the first phase rehashing</p>
<p>539<br>00:54:25,679 –&gt; 00:54:30,000<br>which is working on each of those partition in this case is going to be that second phase that you</p>
<p>540<br>00:54:30,000 –&gt; 00:54:38,400<br>work in memory okay so we’ll use the two hash functions h1 and h2 we’ll assume we’ve got B buffer pages</p>
<p>541<br>00:54:39,039 –&gt; 00:54:42,559<br>and now for this hash based aggregation we’ll have to keep one page for the output</p>
<p>542<br>00:54:43,279 –&gt; 00:54:48,239<br>and we’ll start in the following way so assume this query where we have to do this distinct core</p>
<p>543<br>00:54:48,239 –&gt; 00:54:54,079<br>side I don’t have a group byte but just hold on to that this example is simplified and there are</p>
<p>544<br>00:54:54,079 –&gt; 00:55:00,079<br>again optimizations you could do here to fold in some early elimination of distinct values but</p>
<p>545<br>00:55:01,119 –&gt; 00:55:05,679<br>don’t worry about it in this example it’s an inefficient example but just to show you how</p>
<p>546<br>00:55:05,679 –&gt; 00:55:09,679<br>hashing works okay after you look at it this side multiple times you’ll say I could have done this</p>
<p>547<br>00:55:09,679 –&gt; 00:55:15,359<br>hashing earlier but just to show a partition phase while keeping the same type of example we had</p>
<p>548<br>00:55:15,359 –&gt; 00:55:20,480<br>before for the sort based stuff so now we have a whole bunch of records here assume that there are</p>
<p>549<br>00:55:20,480 –&gt; 00:55:26,879<br>lots of lots more data in here and we’ll apply the filter we get a file it has these four records but</p>
<p>550<br>00:55:26,879 –&gt; 00:55:32,559<br>also a lot more here because now a data is much larger and we’ll remove the columns we get a long</p>
<p>551<br>00:55:32,559 –&gt; 00:55:39,119<br>list of column IDs again assume that’s really big and it can’t fit in memory now we’ll apply</p>
<p>552<br>00:55:39,119 –&gt; 00:55:45,759<br>a hash function to create different partition files we’ll create b-1 partition files so we’ll</p>
<p>553<br>00:55:45,759 –&gt; 00:55:52,719<br>bring in a record we’ll use one buffer page for the input we’ll allocate b-1 pages for the</p>
<p>554<br>00:55:52,719 –&gt; 00:55:59,199<br>b-1 output partition files as we read a record we’ll apply the hash function put it into the</p>
<p>555<br>00:55:59,199 –&gt; 00:56:03,839<br>output buffer page for that partition as that fills up we will write it to disk we just need</p>
<p>556<br>00:56:03,840 –&gt; 00:56:09,920<br>one output page for each partition but the end of it what we end up having is we’ll have a whole</p>
<p>557<br>00:56:09,920 –&gt; 00:56:14,800<br>bunch of pages in the first partition I’m just showing one here but there could be a whole bunch as</p>
<p>558<br>00:56:14,800 –&gt; 00:56:24,160<br>that spills over and we’ll break up the input file in this case column IDs into b-1 chunks</p>
<p>559<br>00:56:24,160 –&gt; 00:56:32,160<br>partitions where in each partition all the keys have the property that if they they hashed the same</p>
<p>560<br>00:56:32,159 –&gt; 00:56:37,440<br>value using this h1 function and why is that important because if I’ve got two duplicates like</p>
<p>561<br>00:56:37,440 –&gt; 00:56:42,719<br>here I’ve got a duplicate here and a duplicate here a duplicate if I apply the same hash function</p>
<p>562<br>00:56:42,719 –&gt; 00:56:49,119<br>will hash to the same position always will hash to bucket 0 the partition 0 here and hence I</p>
<p>563<br>00:56:49,119 –&gt; 00:56:54,799<br>will bring all the duplicates together so that’s my divide strategy and the second part all I do</p>
<p>564<br>00:56:54,799 –&gt; 00:57:00,000<br>is process each partition to eliminate duplicates I’m guaranteed because I’ve applied h1 here for</p>
<p>565<br>00:57:00,000 –&gt; 00:57:07,039<br>partitioning that if two records are the same they will be in the same partition so by dividing</p>
<p>566<br>00:57:07,039 –&gt; 00:57:12,639<br>the file into smaller pieces these partitions and then processing each partition individually for</p>
<p>567<br>00:57:12,639 –&gt; 00:57:18,719<br>that piece we use an in-memory algorithm we are guaranteed we’ve done the entire operation efficiently</p>
<p>568<br>00:57:19,440 –&gt; 00:57:26,400<br>in this two passes partition pass and then in merge pass and then a rehash pass okay so that’s</p>
<p>569<br>00:57:26,400 –&gt; 00:57:30,320<br>the second page in that partition as we are scanning through it just showing that partition can have</p>
<p>570<br>00:57:30,320 –&gt; 00:57:35,840<br>multiple pages so now in this rehash will apply a second hash function let’s go and see visually what</p>
<p>571<br>00:57:35,840 –&gt; 00:57:44,000<br>that looks like so imagine these are pages that we’ve got across all these partitions so that first</p>
<p>572<br>00:57:44,000 –&gt; 00:57:49,519<br>partition has two pages and then we’ve got a bunch of other partitions that are in here as we pull</p>
<p>573<br>00:57:49,519 –&gt; 00:57:56,320<br>that in we will apply the hash function and so we will take the first record put that into that</p>
<p>574<br>00:57:56,320 –&gt; 00:58:01,599<br>in-memory hash table then when we take the second record and apply a hash function to a disordered</p>
<p>575<br>00:58:01,599 –&gt; 00:58:05,679<br>there so we’ll just toss it out that’s how we’re eliminating duplicates because it’s hashing to</p>
<p>576<br>00:58:05,679 –&gt; 00:58:13,119<br>the same value at the end when we are done sorry in this example this is the second page in that</p>
<p>577<br>00:58:13,119 –&gt; 00:58:20,079<br>same partition so we’ll hash that here so we are still in the first partition and you put that</p>
<p>578<br>00:58:20,079 –&gt; 00:58:24,799<br>into the hash table and at the end of it when you’re done processing all the records in that partition</p>
<p>579<br>00:58:24,799 –&gt; 00:58:29,359<br>we will output the results look through the hash table anything that is a value will fill that up</p>
<p>580<br>00:58:29,920 –&gt; 00:58:35,119<br>so we’re done with processing all the records in this partition now we’ll clear up the hash table</p>
<p>581<br>00:58:35,839 –&gt; 00:58:40,000<br>then do the same thing again for records in the other partition and output those keep upending</p>
<p>582<br>00:58:40,079 –&gt; 00:58:45,679<br>to this final result so second partition that we are starting to process clear up the hash table</p>
<p>583<br>00:58:46,559 –&gt; 00:58:52,480<br>use that space now to do the same thing as we did before that rehash function and keep doing that</p>
<p>584<br>00:58:52,480 –&gt; 00:58:58,960<br>till you’ve done with all the partitions okay so very simple divide and conquer where you first</p>
<p>585<br>00:58:58,960 –&gt; 00:59:02,960<br>break it up into partitions so this is the first partition this is the second partition and</p>
<p>586<br>00:59:02,960 –&gt; 00:59:09,760<br>they’d be many more because when you apply h1 all the records that have duplicates will hash to</p>
<p>587<br>00:59:09,760 –&gt; 00:59:15,840<br>the same bucket because of that in this case four for five records and that way your guaranteed</p>
<p>588<br>00:59:15,840 –&gt; 00:59:23,040<br>you can eliminate duplicates okay and in this case if you’ve gotten the partition right so one question</p>
<p>589<br>00:59:23,040 –&gt; 00:59:28,560<br>might arise is hey what happens if let’s say this partition had a lot of duplicate values and</p>
<p>590<br>00:59:28,560 –&gt; 00:59:33,600<br>this hash table doesn’t fit in memory what would you do at that point you could do one of several things</p>
<p>591<br>00:59:33,679 –&gt; 00:59:39,519<br>you could take this partition and re partition it or what you could do as you could say</p>
<p>592<br>00:59:40,400 –&gt; 00:59:48,000<br>there are too many records over here if I haven’t output any records already I can take this partition</p>
<p>593<br>00:59:48,880 –&gt; 00:59:53,679<br>and I can use a sort based algorithm for this partition so you can mix and match some you</p>
<p>594<br>00:59:53,679 –&gt; 00:59:58,400<br>apply the first space of partition everything using a hash function but each individual partition</p>
<p>595<br>00:59:58,400 –&gt; 01:00:03,039<br>you could decide whether they’re going to use a hash based approach for eliminating duplicates or you</p>
<p>596<br>01:00:03,039 –&gt; 01:00:08,239<br>could use a sort based approach and many times when you’ve created the partition you know how many</p>
<p>597<br>01:00:08,239 –&gt; 01:00:12,719<br>keys there are in each of the partition files so you could decide how to choose but they also adaptive</p>
<p>598<br>01:00:12,719 –&gt; 01:00:17,119<br>techniques that can adapt on the fly the advanced database course talks about that but just want you</p>
<p>599<br>01:00:17,119 –&gt; 01:00:23,360<br>to be aware that sometimes you may need to deal with overflows of the data structure because</p>
<p>600<br>01:00:23,360 –&gt; 01:00:30,559<br>hashing is not perfect and it may be that when we were doing h1 or the data is such that a lot of</p>
<p>601<br>01:00:30,639 –&gt; 01:00:35,599<br>duplicates are there a lot of values that map to the first partition you go first partition here</p>
<p>602<br>01:00:35,599 –&gt; 01:00:40,400<br>that you might have to do something else when you start to do the rehash the rehash table</p>
<p>603<br>01:00:40,400 –&gt; 01:00:45,519<br>hash table doesn’t fit in memory but there are details just want to be aware that you may need to do</p>
<p>604<br>01:00:45,519 –&gt; 01:00:54,719<br>something else and you can look things up if you need to if you hit that case all right so essentially</p>
<p>605<br>01:00:55,439 –&gt; 01:01:01,679<br>we’ve looked at how we can do hashing using sort based and hash based methods now let’s cover this</p>
<p>606<br>01:01:01,679 –&gt; 01:01:06,879<br>last scenario and aggregation but the aggregation is a little bit more complex you know instead of</p>
<p>607<br>01:01:06,879 –&gt; 01:01:11,279<br>the distinct count which is the simplest aggregate you can think of you’ve got a group by</p>
<p>608<br>01:01:11,279 –&gt; 01:01:17,839<br>this is a join and then we are computing the average so now in this case imagine we are creating</p>
<p>609<br>01:01:17,839 –&gt; 01:01:24,000<br>the buckets as we did before we applying the hash function as we did before you know ignore how we</p>
<p>610<br>01:01:24,000 –&gt; 01:01:29,199<br>did the h1 stuff before the first phase that’s exactly the same as before what matters is in that</p>
<p>611<br>01:01:29,199 –&gt; 01:01:35,760<br>rehash phase when we are processing each individual partition we will store now in the hash table</p>
<p>612<br>01:01:35,760 –&gt; 01:01:42,559<br>not just the key but also a value in this case if I’ve got two records in that first partition</p>
<p>613<br>01:01:43,119 –&gt; 01:01:49,280<br>and they have two different GPAs right what I store in the value is the running count of how many</p>
<p>614<br>01:01:49,280 –&gt; 01:01:56,560<br>records have hashed to this value how many 445 records I’ve seen too what’s the running sum of those</p>
<p>615<br>01:01:56,560 –&gt; 01:02:03,920<br>GPAs 7.2 because I’m computing an average if instead I just stored the average here I would be</p>
<p>616<br>01:02:03,920 –&gt; 01:02:08,800<br>averaging the averages in a continuous form and that’s not precise average of averages is not the</p>
<p>617<br>01:02:08,800 –&gt; 01:02:14,320<br>true average and so here we’ll do the sum and the count as two different things we keep around and</p>
<p>618<br>01:02:14,320 –&gt; 01:02:18,400<br>when we are done with scanning all the records in that partition we’ll output the aggregate by</p>
<p>619<br>01:02:18,400 –&gt; 01:02:24,559<br>dividing this value 7.32 by the count which is two and after the correct average so two things</p>
<p>620<br>01:02:24,559 –&gt; 01:02:30,639<br>are happening a hash table now has the key and a value the second is the value may not be the final</p>
<p>621<br>01:02:30,639 –&gt; 01:02:36,400<br>value but maybe some intermediate running data structure that allows us to calculate the final value</p>
<p>622<br>01:02:36,400 –&gt; 01:02:43,840<br>as you can see with average okay now of course if the aggregate is of average it will min then what</p>
<p>623<br>01:02:43,840 –&gt; 01:02:47,680<br>we put in the value space would just be min because min of min is guaranteed to be min</p>
<p>624<br>01:02:47,759 –&gt; 01:02:54,159<br>same thing with maximum count averages different databases often also support statistical aggregates</p>
<p>625<br>01:02:54,159 –&gt; 01:02:59,759<br>like median and mode and the different ways of dealing with that here take the advanced database class</p>
<p>626<br>01:03:00,399 –&gt; 01:03:05,199<br>we talk about how do you deal with most sophisticated statistical aggregation and what are their</p>
<p>627<br>01:03:05,199 –&gt; 01:03:09,679<br>properties when is something easy when is something hard and in some cases you have to keep all the</p>
<p>628<br>01:03:09,679 –&gt; 01:03:14,319<br>values around and that is complicated but the ways of trying to work around that or to at least</p>
<p>629<br>01:03:14,320 –&gt; 01:03:20,880<br>reduce the effect of that statistical aggregates are present in database systems you can ask for</p>
<p>630<br>01:03:20,880 –&gt; 01:03:25,680<br>those in SQL and they will require some additional modification and that’s the main thing we want you</p>
<p>631<br>01:03:25,680 –&gt; 01:03:32,800<br>to know in this material all right so in this case final result is being outputted for that average</p>
<p>632<br>01:03:32,800 –&gt; 01:03:38,800<br>pretty straightforward and so with that we conclude today’s lecture hopefully you’ve seen that</p>
<p>633<br>01:03:39,760 –&gt; 01:03:44,560<br>there’s a huge emphasis database systems on these operator algorithms that work with large amounts</p>
<p>634<br>01:03:44,560 –&gt; 01:03:49,519<br>of data even when it doesn’t fit in memory they require a rethinking of basic algorithms that you</p>
<p>635<br>01:03:49,519 –&gt; 01:03:53,519<br>might think you already know and there are all kinds of interesting optimizations that you can bring</p>
<p>636<br>01:03:53,519 –&gt; 01:03:58,560<br>to the table and the jury is not yet completely done on can you optimize it more the answer is yes</p>
<p>637<br>01:03:58,560 –&gt; 01:04:03,200<br>people are constantly making all kinds of supple and interesting changes especially as you start</p>
<p>638<br>01:04:03,200 –&gt; 01:04:07,920<br>moving things to the cloud you have new hardware that changes a lot of the trade-offs and opens up</p>
<p>639<br>01:04:07,920 –&gt; 01:04:15,440<br>opportunities for new algorithmic innovations we saw that there are hash and sort-based methods</p>
<p>640<br>01:04:15,440 –&gt; 01:04:21,200<br>that duality between these two methods will continue as we go into the next lecture and we start</p>
<p>641<br>01:04:21,199 –&gt; 01:04:23,199<br>talking about joins and other algorithms</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CMU15445 P11F202310 SortingAggregationAlgorithms</div>
      <div>http://example.com/2025/10/24/CMU15445 P11F202310-SortingAggregationAlgorithms/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月24日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/24/CMU15445%20P12F202311-JoinAlgorithms/" title="CMU15445 P12F202311 JoinAlgorithms">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CMU15445 P12F202311 JoinAlgorithms</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/24/CMU15445%20P10F202309-IndexConcurrencyControl/" title="CMU15445 P10F202309 IndexConcurrencyControl">
                        <span class="hidden-mobile">CMU15445 P10F202309 IndexConcurrencyControl</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
