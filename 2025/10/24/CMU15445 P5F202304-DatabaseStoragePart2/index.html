

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:27,280Let’s get started. 200:00:27,280 –&gt; 00:00:34,280So you got to show this weekend, right? 300:00:34,280 –&gt; 00:00:35,280Yeah. 400:00:35,280 –&gt; 00:00:36,280You don">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU15445 P5F202304 DatabaseStoragePart2">
<meta property="og:url" content="http://example.com/2025/10/24/CMU15445%20P5F202304-DatabaseStoragePart2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:27,280Let’s get started. 200:00:27,280 –&gt; 00:00:34,280So you got to show this weekend, right? 300:00:34,280 –&gt; 00:00:35,280Yeah. 400:00:35,280 –&gt; 00:00:36,280You don">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-24T12:00:44.479Z">
<meta property="article:modified_time" content="2025-10-24T12:06:28.543Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>CMU15445 P5F202304 DatabaseStoragePart2 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CMU15445 P5F202304 DatabaseStoragePart2"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-24 20:00" pubdate>
          2025年10月24日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          10k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          85 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CMU15445 P5F202304 DatabaseStoragePart2</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:27,280<br>Let’s get started.</p>
<p>2<br>00:00:27,280 –&gt; 00:00:34,280<br>So you got to show this weekend, right?</p>
<p>3<br>00:00:34,280 –&gt; 00:00:35,280<br>Yeah.</p>
<p>4<br>00:00:35,280 –&gt; 00:00:36,280<br>You don’t know where it is.</p>
<p>5<br>00:00:36,280 –&gt; 00:00:37,280<br>No.</p>
<p>6<br>00:00:37,280 –&gt; 00:00:38,280<br>You don’t know when it is.</p>
<p>7<br>00:00:38,280 –&gt; 00:00:39,280<br>When it is.</p>
<p>8<br>00:00:39,280 –&gt; 00:00:40,280<br>When it is.</p>
<p>9<br>00:00:40,280 –&gt; 00:00:41,280<br>When it is.</p>
<p>10<br>00:00:41,280 –&gt; 00:00:42,280<br>When it is.</p>
<p>11<br>00:00:42,280 –&gt; 00:00:43,280<br>When it is.</p>
<p>12<br>00:00:43,280 –&gt; 00:00:44,280<br>When it is.</p>
<p>13<br>00:00:44,280 –&gt; 00:00:45,280<br>When it is.</p>
<p>14<br>00:00:45,280 –&gt; 00:00:46,280<br>When it is.</p>
<p>15<br>00:00:46,280 –&gt; 00:00:47,280<br>When it is.</p>
<p>16<br>00:00:47,280 –&gt; 00:00:48,280<br>When it is.</p>
<p>17<br>00:00:48,280 –&gt; 00:00:49,280<br>When it is.</p>
<p>18<br>00:00:49,280 –&gt; 00:00:50,280<br>When it is.</p>
<p>19<br>00:00:50,280 –&gt; 00:00:51,280<br>When it is.</p>
<p>20<br>00:00:51,280 –&gt; 00:00:52,280<br>When it is.</p>
<p>21<br>00:00:52,280 –&gt; 00:00:53,280<br>When it is.</p>
<p>22<br>00:00:53,280 –&gt; 00:00:54,280<br>When it is.</p>
<p>23<br>00:00:54,280 –&gt; 00:00:55,280<br>When it is.</p>
<p>24<br>00:00:55,280 –&gt; 00:00:56,280<br>When it is.</p>
<p>25<br>00:00:56,280 –&gt; 00:00:57,280<br>When it is.</p>
<p>26<br>00:00:57,280 –&gt; 00:01:03,600<br>So, on the dock of you guys, obviously Project Zero was due last night.</p>
<p>27<br>00:01:03,600 –&gt; 00:01:06,359<br>We haven’t gone through yet and looked at results for everyone.</p>
<p>28<br>00:01:06,359 –&gt; 00:01:09,000<br>I think we had about 150 something people completed.</p>
<p>29<br>00:01:09,000 –&gt; 00:01:11,200<br>That’s good.</p>
<p>30<br>00:01:11,200 –&gt; 00:01:16,359<br>Project One is out and that will be due on, sorry, homework One has been out for a while,</p>
<p>31<br>00:01:16,359 –&gt; 00:01:21,319<br>but we bumped the deadline up to this, like, 15, four days from now.</p>
<p>32<br>00:01:21,319 –&gt; 00:01:23,560<br>So that should be reflected in grade scope.</p>
<p>33<br>00:01:23,560 –&gt; 00:01:27,640<br>And then Project One is out and that will be due on October 1st.</p>
<p>34<br>00:01:27,640 –&gt; 00:01:29,640<br>Any questions about homework One?</p>
<p>35<br>00:01:29,640 –&gt; 00:01:34,320<br>I know there’s so many posts on Piazza about Project One, the leaderboard assignment doesn’t</p>
<p>36<br>00:01:34,320 –&gt; 00:01:35,320<br>work yet.</p>
<p>37<br>00:01:35,320 –&gt; 00:01:41,760<br>We’re fixing that and we’ll push that on GitHub later this week.</p>
<p>38<br>00:01:41,760 –&gt; 00:01:47,000<br>Then I’ll announce on Wednesday what the leaderboard is, what the implications of it are, and</p>
<p>39<br>00:01:47,000 –&gt; 00:01:48,000<br>why it matters.</p>
<p>40<br>00:01:48,000 –&gt; 00:01:49,000<br>Okay?</p>
<p>41<br>00:01:49,000 –&gt; 00:01:51,040<br>All right.</p>
<p>42<br>00:01:51,040 –&gt; 00:01:53,720<br>The other thing is going on for additional things.</p>
<p>43<br>00:01:53,720 –&gt; 00:01:57,160<br>If you want to learn beyond the stuff we’re talking about in the course, there’s a couple</p>
<p>44<br>00:01:57,160 –&gt; 00:02:00,440<br>of database talks that are coming up.</p>
<p>45<br>00:02:00,440 –&gt; 00:02:05,040<br>So today, after class at 430, we’re having the quadrant guys at a Germany.</p>
<p>46<br>00:02:05,040 –&gt; 00:02:10,960<br>They’re one of these vector databases that target LLMs or chat TVT kind of setups.</p>
<p>47<br>00:02:10,960 –&gt; 00:02:15,640<br>They’ll be talking about the internals of their system and that’ll be again 430 over Zoom.</p>
<p>48<br>00:02:15,640 –&gt; 00:02:19,759<br>Tomorrow at 6pm, the Databricks people are giving talks somewhere.</p>
<p>49<br>00:02:19,759 –&gt; 00:02:24,639<br>It’s a recording talk, but that means they’re probably going to feed you.</p>
<p>50<br>00:02:24,639 –&gt; 00:02:27,879<br>And then you can talk to them about getting jobs there.</p>
<p>51<br>00:02:27,879 –&gt; 00:02:31,919<br>Databricks has hired pretty much almost all my best students in the last two or three</p>
<p>52<br>00:02:31,919 –&gt; 00:02:32,919<br>years.</p>
<p>53<br>00:02:32,919 –&gt; 00:02:37,959<br>They’ve all gone to Databricks and I was there in July and they’re all doing great.</p>
<p>54<br>00:02:37,959 –&gt; 00:02:40,319<br>They have a lot of money and they don’t give us any.</p>
<p>55<br>00:02:40,319 –&gt; 00:02:42,199<br>It’s a little problem.</p>
<p>56<br>00:02:42,199 –&gt; 00:02:47,199<br>And then Auditron is actually my startup, but my former PhD student who’s a co-founder</p>
<p>57<br>00:02:47,199 –&gt; 00:02:52,199<br>with the Dan of Anakon, she’ll be giving a talk about what we’re doing using machine</p>
<p>58<br>00:02:52,199 –&gt; 00:02:53,519<br>learning optimized database systems.</p>
<p>59<br>00:02:53,519 –&gt; 00:02:55,519<br>I’ve posted this my sequel next week.</p>
<p>60<br>00:02:55,519 –&gt; 00:02:56,519<br>Yes.</p>
<p>61<br>00:02:56,519 –&gt; 00:02:59,280<br>We’re going to have an information about the location of these.</p>
<p>62<br>00:02:59,280 –&gt; 00:03:02,919<br>So my talks, the Quadrant one, the Q-Outer-2 one, that’s on Zoom.</p>
<p>63<br>00:03:02,919 –&gt; 00:03:07,039<br>And then if you go on the slides, the link here will take you to whatever it is on the calendar.</p>
<p>64<br>00:03:07,039 –&gt; 00:03:08,560<br>It’s somewhere in Gates.</p>
<p>65<br>00:03:08,560 –&gt; 00:03:09,560<br>Okay.</p>
<p>66<br>00:03:09,560 –&gt; 00:03:10,560<br>For the Databricks one.</p>
<p>67<br>00:03:10,560 –&gt; 00:03:11,560<br>Okay, it’s all over the slide.</p>
<p>68<br>00:03:11,560 –&gt; 00:03:12,560<br>Yeah.</p>
<p>69<br>00:03:12,560 –&gt; 00:03:13,560<br>Other questions?</p>
<p>70<br>00:03:13,560 –&gt; 00:03:14,560<br>Again, these are optional.</p>
<p>71<br>00:03:14,560 –&gt; 00:03:17,000<br>These are like, if you want to go beyond the stuff, the document, the course.</p>
<p>72<br>00:03:17,000 –&gt; 00:03:20,439<br>What I like about these kind of talks is, even if you don’t understand anything right</p>
<p>73<br>00:03:20,439 –&gt; 00:03:24,080<br>away, we’ll hit these, a lot of these topics throughout the semester.</p>
<p>74<br>00:03:24,080 –&gt; 00:03:28,240<br>And then you realize, I’m not crazy, well, I’m crazy, but not that crazy, but I’m not</p>
<p>75<br>00:03:28,240 –&gt; 00:03:29,240<br>making stuff up.</p>
<p>76<br>00:03:29,240 –&gt; 00:03:33,039<br>These are the things we’re talking about in the semester, you need to know or clickable</p>
<p>77<br>00:03:33,039 –&gt; 00:03:35,039<br>to building real systems.</p>
<p>78<br>00:03:35,039 –&gt; 00:03:36,039<br>Okay.</p>
<p>79<br>00:03:36,039 –&gt; 00:03:37,039<br>All right.</p>
<p>80<br>00:03:37,039 –&gt; 00:03:43,560<br>So last class, we talked about the initial setup from what the framework you’re going</p>
<p>81<br>00:03:43,560 –&gt; 00:03:47,400<br>to have in our minds for describing how we’re going to build a data management system.</p>
<p>82<br>00:03:47,400 –&gt; 00:03:54,560<br>And we discussed how it was a disk oriented architecture where all the components in the</p>
<p>83<br>00:03:54,560 –&gt; 00:04:01,120<br>system are really going to be based around this key premise that the primary search location</p>
<p>84<br>00:04:01,120 –&gt; 00:04:06,640<br>of the database, when it is at rest, will be on some non-volatile disk.</p>
<p>85<br>00:04:06,640 –&gt; 00:04:07,640<br>Right?</p>
<p>86<br>00:04:07,640 –&gt; 00:04:09,800<br>An SSD spinning disk hard drive doesn’t matter.</p>
<p>87<br>00:04:09,800 –&gt; 00:04:14,200<br>And that the components of the system are really about moving the data back and forth</p>
<p>88<br>00:04:14,200 –&gt; 00:04:17,120<br>between disk and memory because it’s a Von Nomen architecture.</p>
<p>89<br>00:04:17,120 –&gt; 00:04:19,879<br>You can’t operate on it while it’s at rest.</p>
<p>90<br>00:04:19,879 –&gt; 00:04:20,879<br>Right?</p>
<p>91<br>00:04:20,879 –&gt; 00:04:24,800<br>So that’s really what the big picture of what we’re trying to achieve.</p>
<p>92<br>00:04:24,800 –&gt; 00:04:28,720<br>And of course, now since disk is slow, we need to do a bunch of tricks and a bunch of</p>
<p>93<br>00:04:28,720 –&gt; 00:04:33,600<br>other techniques to hide the stalls of going to disk.</p>
<p>94<br>00:04:33,600 –&gt; 00:04:36,000<br>They’re maximizing the amount of squint or IO.</p>
<p>95<br>00:04:36,600 –&gt; 00:04:40,439<br>And we’ll see in the beginning right away today, we’ll talk about a different method alternative</p>
<p>96<br>00:04:40,439 –&gt; 00:04:43,680<br>to what we talked about last class that tries to maximize the squint or IO.</p>
<p>97<br>00:04:43,680 –&gt; 00:04:47,639<br>And then again, there’ll be other things like filters and indexes the way to reduce the</p>
<p>98<br>00:04:47,639 –&gt; 00:04:50,800<br>amount of data we have to actually look at when we run queries.</p>
<p>99<br>00:04:50,800 –&gt; 00:04:54,680<br>Then we also talked about a page oriented storage scheme.</p>
<p>100<br>00:04:54,680 –&gt; 00:04:59,759<br>There’s a lot of page architecture where it was allowed to store tuples of arbitrary length,</p>
<p>101<br>00:04:59,759 –&gt; 00:05:02,839<br>variable length sizes across these heap files.</p>
<p>102<br>00:05:02,839 –&gt; 00:05:08,959<br>And then we could expand the size of the tuple as needed, according to whether it fit in</p>
<p>103<br>00:05:08,959 –&gt; 00:05:12,439<br>the page or not.</p>
<p>104<br>00:05:12,439 –&gt; 00:05:17,519<br>So I would say what we were describing last time is what I’ll loosely turn to as a tuple</p>
<p>105<br>00:05:17,519 –&gt; 00:05:19,599<br>oriented storage scheme.</p>
<p>106<br>00:05:19,599 –&gt; 00:05:23,159<br>What that really means is that the system is really about, I got a tuple, I got to put</p>
<p>107<br>00:05:23,159 –&gt; 00:05:24,159<br>it somewhere.</p>
<p>108<br>00:05:24,159 –&gt; 00:05:29,079<br>And the pages of the layout, the layouts of the pages are really based around this like,</p>
<p>109<br>00:05:29,079 –&gt; 00:05:32,079<br>I got a tuple, let me store it.</p>
<p>110<br>00:05:32,079 –&gt; 00:05:36,680<br>And so in this architecture, if we wanted to insert a new tuple, the way we do it is you</p>
<p>111<br>00:05:36,680 –&gt; 00:05:42,519<br>go look in the page directory and find somewhere in your heap files a page of the free slot.</p>
<p>112<br>00:05:42,519 –&gt; 00:05:46,079<br>Or if you said that the page directory would maintain metadata about what’s what space</p>
<p>113<br>00:05:46,079 –&gt; 00:05:48,120<br>is available.</p>
<p>114<br>00:05:48,120 –&gt; 00:05:53,000<br>And then once we have our page, we want to insert the tuple into if it’s not memory, sorry,</p>
<p>115<br>00:05:53,000 –&gt; 00:05:56,039<br>if it’s not memory, they’ve got to go to disk, disk and fetch it in, which we’ll talk</p>
<p>116<br>00:05:56,039 –&gt; 00:05:57,279<br>about next week, how we do that.</p>
<p>117<br>00:05:57,279 –&gt; 00:06:00,240<br>But you know, think of like reading a file, bringing the memory.</p>
<p>118<br>00:06:00,240 –&gt; 00:06:04,360<br>And then once we have that page, we go look in that slot array and we say, you know, what’s</p>
<p>119<br>00:06:04,360 –&gt; 00:06:08,879<br>the next free slot where we can store this tuple, update the slot array, put the tuple inside</p>
<p>120<br>00:06:08,879 –&gt; 00:06:13,160<br>the page and then we’re done.</p>
<p>121<br>00:06:13,160 –&gt; 00:06:18,079<br>The updated tuple in this environment is basically the same thing where we’re going to have some</p>
<p>122<br>00:06:18,079 –&gt; 00:06:20,199<br>way to get the record ID of a tuple.</p>
<p>123<br>00:06:20,199 –&gt; 00:06:25,040<br>We said this is typically the page ID and the offset or the slot number.</p>
<p>124<br>00:06:25,040 –&gt; 00:06:30,080<br>Ignoring how we got that, which is what index will do for us, ignoring that, assuming we</p>
<p>125<br>00:06:30,080 –&gt; 00:06:34,120<br>could do that, we go go in the page directory again, find the location of this page.</p>
<p>126<br>00:06:34,120 –&gt; 00:06:35,920<br>If it’s in memory, we’re good.</p>
<p>127<br>00:06:35,920 –&gt; 00:06:37,800<br>If not, we got to go disk and get it.</p>
<p>128<br>00:06:37,800 –&gt; 00:06:40,320<br>Then look in the page in the slot array, find the offset.</p>
<p>129<br>00:06:40,320 –&gt; 00:06:44,840<br>And then if the new tuple we’re trying to, the updated tuple we’re trying to install, if</p>
<p>130<br>00:06:44,840 –&gt; 00:06:49,720<br>that’s the same size of the original tuple, the existing tuple, then we just overwrite it.</p>
<p>131<br>00:06:49,720 –&gt; 00:06:52,720<br>If not, then maybe you got to find another page that could accommodate it.</p>
<p>132<br>00:06:52,720 –&gt; 00:06:56,440<br>There’s no space in the page we’re looking at.</p>
<p>133<br>00:06:56,440 –&gt; 00:07:04,080<br>This is the core idea of what the heat files with the page or architecture and it’s based</p>
<p>134<br>00:07:04,080 –&gt; 00:07:05,080<br>on tuples.</p>
<p>135<br>00:07:05,080 –&gt; 00:07:09,440<br>This is basically how any system would actually work.</p>
<p>136<br>00:07:09,440 –&gt; 00:07:11,280<br>What are some problems with this?</p>
<p>137<br>00:07:11,280 –&gt; 00:07:18,880<br>We touched on some of these last class.</p>
<p>138<br>00:07:18,879 –&gt; 00:07:22,839<br>Is it efficient?</p>
<p>139<br>00:07:22,839 –&gt; 00:07:24,319<br>For reads maybe, right?</p>
<p>140<br>00:07:24,319 –&gt; 00:07:28,360<br>If I need the entire tuple, I go to one page and get it.</p>
<p>141<br>00:07:28,360 –&gt; 00:07:29,680<br>That’s okay.</p>
<p>142<br>00:07:29,680 –&gt; 00:07:33,560<br>But if I start updating things, I’m starting making rights, doing inserts, updates, deletes,</p>
<p>143<br>00:07:33,560 –&gt; 00:07:36,719<br>I could end up with fragmentation in my pages.</p>
<p>144<br>00:07:36,719 –&gt; 00:07:42,279<br>I could have pages that are not fully utilized, meaning I have a little empty space where I</p>
<p>145<br>00:07:42,279 –&gt; 00:07:43,759<br>can’t fit any new tuple.</p>
<p>146<br>00:07:43,759 –&gt; 00:07:47,800<br>It’s not big enough for a new tuple, but I can’t use it, but it’s just wasted.</p>
<p>147<br>00:07:47,800 –&gt; 00:07:51,840<br>It’s just there.</p>
<p>148<br>00:07:51,840 –&gt; 00:07:57,040<br>Or even before if I don’t run that space, if I have to insert into a tuple, I got to allocate</p>
<p>149<br>00:07:57,040 –&gt; 00:07:58,040<br>it.</p>
<p>150<br>00:07:58,040 –&gt; 00:07:59,040<br>It’s assuming I have nothing on my table.</p>
<p>151<br>00:07:59,040 –&gt; 00:08:00,040<br>I inserted into a tuple.</p>
<p>152<br>00:08:00,040 –&gt; 00:08:01,040<br>I allocated a page.</p>
<p>153<br>00:08:01,040 –&gt; 00:08:02,759<br>I insert one tuple in that page.</p>
<p>154<br>00:08:02,759 –&gt; 00:08:04,840<br>There’s nothing else in that page.</p>
<p>155<br>00:08:04,840 –&gt; 00:08:10,120<br>Depending on the size of my pages, which could be different per systems, there’s a bunch</p>
<p>156<br>00:08:10,120 –&gt; 00:08:14,319<br>of these spaces that’s not being used.</p>
<p>157<br>00:08:14,319 –&gt; 00:08:16,960<br>Next challenge you face is much useless disk IO.</p>
<p>158<br>00:08:16,959 –&gt; 00:08:20,599<br>If I got update one tuple, if it’s not in memory, I got to go disk and fetch it.</p>
<p>159<br>00:08:20,599 –&gt; 00:08:23,439<br>But if it’s in that side, that page, what am I getting?</p>
<p>160<br>00:08:23,439 –&gt; 00:08:27,039<br>We’re not storing one tuple per page.</p>
<p>161<br>00:08:27,039 –&gt; 00:08:31,439<br>You typically don’t want to do that.</p>
<p>162<br>00:08:31,439 –&gt; 00:08:34,919<br>So now if I got to go update one page, or sorry, on one tuple, I got to fetch that entire</p>
<p>163<br>00:08:34,919 –&gt; 00:08:38,199<br>page and bring in a bunch of data that may not even be what I need.</p>
<p>164<br>00:08:38,199 –&gt; 00:08:41,919<br>There’s a bunch of other tuples that I’m not updating.</p>
<p>165<br>00:08:41,919 –&gt; 00:08:44,199<br>Same thing when I’m going to do a right.</p>
<p>166<br>00:08:44,200 –&gt; 00:08:47,920<br>If I’m only updating one tuple, I had to bring in 20 tuples in the page into memory.</p>
<p>167<br>00:08:47,920 –&gt; 00:08:52,720<br>Now I got to write those 22ples back out.</p>
<p>168<br>00:08:52,720 –&gt; 00:08:56,720<br>And the last issue is that we’re going to get a potentially a lot of random disk IO.</p>
<p>169<br>00:08:56,720 –&gt; 00:09:03,240<br>Again, the sort of a cop out answer for people asking, is this more efficient or what approach</p>
<p>170<br>00:09:03,240 –&gt; 00:09:04,240<br>is better?</p>
<p>171<br>00:09:04,240 –&gt; 00:09:07,160<br>The answer is it always depends on databases.</p>
<p>172<br>00:09:07,160 –&gt; 00:09:11,800<br>So if your workload is only updating a single tuple at a time for a per query, then maybe</p>
<p>173<br>00:09:11,800 –&gt; 00:09:13,600<br>this architecture isn’t so bad.</p>
<p>174<br>00:09:13,600 –&gt; 00:09:18,960<br>But if I’m updating 20 tuples at a time, and those 22ples are in 20 separate pages,</p>
<p>175<br>00:09:18,960 –&gt; 00:09:22,320<br>I got to go read 20 separate pages from disk into memory.</p>
<p>176<br>00:09:22,320 –&gt; 00:09:23,320<br>I got to update them.</p>
<p>177<br>00:09:23,320 –&gt; 00:09:27,519<br>I got to write out 20 different pages in memory, or start from memory to disk.</p>
<p>178<br>00:09:27,519 –&gt; 00:09:28,759<br>Now that’s random IO.</p>
<p>179<br>00:09:28,759 –&gt; 00:09:33,200<br>And that’s going to be slower.</p>
<p>180<br>00:09:33,200 –&gt; 00:09:37,560<br>And then not necessarily a problem with the architecture itself, but it may be the case</p>
<p>181<br>00:09:37,560 –&gt; 00:09:42,160<br>that we’re operating in an environment where we can’t do those in place updates that we</p>
<p>182<br>00:09:42,159 –&gt; 00:09:44,399<br>assume we could do in a slot of page architecture.</p>
<p>183<br>00:09:44,399 –&gt; 00:09:49,120<br>I mean, I can’t fetch a page that’s in disk, bringing it to memory, update it, and then</p>
<p>184<br>00:09:49,120 –&gt; 00:09:52,559<br>write it back to where I got it from.</p>
<p>185<br>00:09:52,559 –&gt; 00:09:56,480<br>You can’t do this in some cloud storage systems.</p>
<p>186<br>00:09:56,480 –&gt; 00:10:01,360<br>As three, you can trick it out using versioning, but I can’t do in place updates in some</p>
<p>187<br>00:10:01,360 –&gt; 00:10:02,839<br>cloud database systems.</p>
<p>188<br>00:10:02,839 –&gt; 00:10:07,240<br>And the Hadoop file system is not that common anymore, but there’s another good example</p>
<p>189<br>00:10:07,240 –&gt; 00:10:10,959<br>of like, that’s a to share the file system where again, I can’t do in place updates, I</p>
<p>190<br>00:10:10,960 –&gt; 00:10:13,240<br>can only do a pens.</p>
<p>191<br>00:10:13,240 –&gt; 00:10:16,879<br>So this tube-oriented slide of page architecture wouldn’t work in this environment because I</p>
<p>192<br>00:10:16,879 –&gt; 00:10:21,080<br>can’t do, I can’t modify a page and write it back where I got it.</p>
<p>193<br>00:10:21,080 –&gt; 00:10:24,320<br>All right, so this is why we need to look at potentially alternative methods.</p>
<p>194<br>00:10:24,320 –&gt; 00:10:28,040<br>In particular, all the problems that I just talked about, there’ll be solved with the</p>
<p>195<br>00:10:28,040 –&gt; 00:10:32,320<br>log-structured storage scheme.</p>
<p>196<br>00:10:32,320 –&gt; 00:10:36,280<br>And beyond the sort of heat file of the slide of the page architecture, log-structured storage</p>
<p>197<br>00:10:36,280 –&gt; 00:10:39,400<br>is probably the second most common approach people take in database systems.</p>
<p>198<br>00:10:39,399 –&gt; 00:10:44,439<br>It’s probably even more common today because of embedded storage managers like RocksDB,</p>
<p>199<br>00:10:44,439 –&gt; 00:10:45,439<br>which are log-structured.</p>
<p>200<br>00:10:45,439 –&gt; 00:10:49,600<br>So if you’ve ever seen a database system that’s using RocksDB, they’re inherently log-structured</p>
<p>201<br>00:10:49,600 –&gt; 00:10:52,840<br>because RocksDB is log-structured.</p>
<p>202<br>00:10:52,840 –&gt; 00:10:55,600<br>And then we’ll talk about another approach, not exactly log-structured, it’s sort of a</p>
<p>203<br>00:10:55,600 –&gt; 00:10:58,480<br>malgamation of the two, will be index-organized storage.</p>
<p>204<br>00:10:58,480 –&gt; 00:11:02,039<br>This is what my SQL and SQLite and other use, and then we’ll finish off talking about</p>
<p>205<br>00:11:02,039 –&gt; 00:11:05,199<br>how to actually represent the data of attributes in tuples.</p>
<p>206<br>00:11:05,199 –&gt; 00:11:09,240<br>All right, we’re sort of, again, we were working out what a file looks like, what a page looks</p>
<p>207<br>00:11:09,240 –&gt; 00:11:12,120<br>like, what a stostutter in that world, and then we’ll spend more time talking about what</p>
<p>208<br>00:11:12,120 –&gt; 00:11:15,840<br>actual individual tuples look like, the values in the individual tuples.</p>
<p>209<br>00:11:15,840 –&gt; 00:11:16,840<br>Okay?</p>
<p>210<br>00:11:16,840 –&gt; 00:11:18,240<br>All right.</p>
<p>211<br>00:11:18,240 –&gt; 00:11:25,200<br>So log-structured storage is an old idea.</p>
<p>212<br>00:11:25,200 –&gt; 00:11:30,200<br>It’s loosely related to log-structured file systems, which predates it about 10 years.</p>
<p>213<br>00:11:30,200 –&gt; 00:11:32,560<br>Log-structured file systems were like in the 1980s.</p>
<p>214<br>00:11:32,560 –&gt; 00:11:37,759<br>The log-structured storage was first proposed in the mid-90s.</p>
<p>215<br>00:11:38,319 –&gt; 00:11:41,679<br>Actually, in the textbook they’ll call log-structured merstries.</p>
<p>216<br>00:11:41,679 –&gt; 00:11:44,759<br>I’m not going to describe what the actual log-structured merstries looks like, because I don’t</p>
<p>217<br>00:11:44,759 –&gt; 00:11:48,000<br>think you need to know the details of the tree part of it.</p>
<p>218<br>00:11:48,000 –&gt; 00:11:49,159<br>All right?</p>
<p>219<br>00:11:49,159 –&gt; 00:11:53,879<br>So I’ll describe basically the same idea, but without bringing in the tree, because that</p>
<p>220<br>00:11:53,879 –&gt; 00:11:56,840<br>mixed things is something more complicated.</p>
<p>221<br>00:11:56,840 –&gt; 00:12:00,279<br>But the highlight is what I care about, what I want you guys to understand.</p>
<p>222<br>00:12:00,279 –&gt; 00:12:06,360<br>So the basic idea of log-structured storage is that instead of storing individual tuples,</p>
<p>223<br>00:12:06,360 –&gt; 00:12:10,680<br>we’re going to maintain a log record of the changes to those tuples.</p>
<p>224<br>00:12:10,680 –&gt; 00:12:14,279<br>I think it’s like a key value store, key value system.</p>
<p>225<br>00:12:14,279 –&gt; 00:12:19,680<br>So I’m going to have the, some operation, either just put in delete, and then I’m going</p>
<p>226<br>00:12:19,680 –&gt; 00:12:23,600<br>to have a key value pair with the key corresponding to some tuple identifier.</p>
<p>227<br>00:12:23,600 –&gt; 00:12:27,039<br>You can’t use the record idea we did before, because we’re not going to have pages.</p>
<p>228<br>00:12:27,039 –&gt; 00:12:28,440<br>We’re not going to have all sets and slots.</p>
<p>229<br>00:12:28,440 –&gt; 00:12:29,600<br>So we’re not going to be that.</p>
<p>230<br>00:12:29,600 –&gt; 00:12:35,120<br>But it’ll be some key identifier, and then the payload will be, here’s the actual tuple</p>
<p>231<br>00:12:35,120 –&gt; 00:12:36,120<br>itself.</p>
<p>232<br>00:12:36,120 –&gt; 00:12:40,039<br>And then I’m trying to install for the put.</p>
<p>233<br>00:12:40,039 –&gt; 00:12:44,639<br>And so as the application inserts data, it makes changes.</p>
<p>234<br>00:12:44,639 –&gt; 00:12:50,720<br>We’re going to pin new log entries to an in-memory buffer, just in the order that they arrive.</p>
<p>235<br>00:12:50,720 –&gt; 00:12:53,560<br>And then at some point, the buffer is going to get full, and we’re going to write it out</p>
<p>236<br>00:12:53,560 –&gt; 00:12:54,560<br>the desk.</p>
<p>237<br>00:12:54,560 –&gt; 00:12:56,960<br>Pretty simple, right?</p>
<p>238<br>00:12:56,960 –&gt; 00:13:00,159<br>All right, so let’s see the example here.</p>
<p>239<br>00:13:00,159 –&gt; 00:13:03,560<br>So again, the only two operations we’re going to have are put in delete.</p>
<p>240<br>00:13:03,560 –&gt; 00:13:04,560<br>Right?</p>
<p>241<br>00:13:04,559 –&gt; 00:13:06,159<br>No insert, because that’s just a put.</p>
<p>242<br>00:13:06,159 –&gt; 00:13:10,239<br>There’s no update, because that just a put on doing blind right over top of whatever is</p>
<p>243<br>00:13:10,239 –&gt; 00:13:12,399<br>there before.</p>
<p>244<br>00:13:12,399 –&gt; 00:13:18,679<br>And so in our log file in memory, we’re going to go from oldest to newest.</p>
<p>245<br>00:13:18,679 –&gt; 00:13:22,759<br>So at the beginning of the file or beginning of the buffer, that’ll be the oldest entries,</p>
<p>246<br>00:13:22,759 –&gt; 00:13:26,639<br>and then we’re just impending to them as we make changes.</p>
<p>247<br>00:13:26,639 –&gt; 00:13:32,239<br>All right, so the application may say, I want to go ahead and do a put on record 103.</p>
<p>248<br>00:13:32,239 –&gt; 00:13:33,239<br>Where the 103 came from?</p>
<p>249<br>00:13:33,240 –&gt; 00:13:34,240<br>We don’t care.</p>
<p>250<br>00:13:34,240 –&gt; 00:13:38,519<br>It’s something that’s some other upper part of the system that figured that out for us.</p>
<p>251<br>00:13:38,519 –&gt; 00:13:42,820<br>And then again, the payload in the log record to be, we’re setting the value to whatever</p>
<p>252<br>00:13:42,820 –&gt; 00:13:47,320<br>record 103 is to 1, A1.</p>
<p>253<br>00:13:47,320 –&gt; 00:13:48,320<br>Same thing.</p>
<p>254<br>00:13:48,320 –&gt; 00:13:49,320<br>Next guy comes along.</p>
<p>255<br>00:13:49,320 –&gt; 00:13:53,039<br>He wants to do a put on 104, and then updates that record.</p>
<p>256<br>00:13:53,039 –&gt; 00:13:54,039<br>Right?</p>
<p>257<br>00:13:54,039 –&gt; 00:13:59,879<br>And then if we have a delete, we just again, we just delete, have a delete operation in</p>
<p>258<br>00:13:59,879 –&gt; 00:14:03,399<br>a log record, and then with again, the same two-point identifier.</p>
<p>259<br>00:14:03,399 –&gt; 00:14:05,960<br>Keep it pending to the log as we go along.</p>
<p>260<br>00:14:05,960 –&gt; 00:14:08,960<br>Right?</p>
<p>261<br>00:14:08,960 –&gt; 00:14:16,399<br>So in this example here, we don’t need to go actually read what the original record was,</p>
<p>262<br>00:14:16,399 –&gt; 00:14:21,600<br>the original two-point was, any time you want to update the log.</p>
<p>263<br>00:14:21,600 –&gt; 00:14:23,840<br>At least again, this is the lower bounds of the system.</p>
<p>264<br>00:14:23,840 –&gt; 00:14:29,720<br>Obviously, if I’m doing a query like update table set ID or set value equals value plus</p>
<p>265<br>00:14:29,720 –&gt; 00:14:32,040<br>1, I got to know what the original value was.</p>
<p>266<br>00:14:32,040 –&gt; 00:14:33,040<br>Right?</p>
<p>267<br>00:14:33,040 –&gt; 00:14:34,759<br>And that’s essentially doing a read, followed by a write.</p>
<p>268<br>00:14:34,759 –&gt; 00:14:40,440<br>But at this lowest level of the system, we don’t have to know what the original value</p>
<p>269<br>00:14:40,440 –&gt; 00:14:43,440<br>was for a given key.</p>
<p>270<br>00:14:43,440 –&gt; 00:14:44,440<br>Right?</p>
<p>271<br>00:14:44,440 –&gt; 00:14:50,639<br>And again, that’s different than the two-point oriented architecture where I had to go fetch</p>
<p>272<br>00:14:50,639 –&gt; 00:14:54,240<br>the page that had the original two-point, and then I can update it.</p>
<p>273<br>00:14:54,240 –&gt; 00:14:57,160<br>I don’t have to do that with this.</p>
<p>274<br>00:14:57,160 –&gt; 00:14:58,160<br>Right?</p>
<p>275<br>00:14:58,719 –&gt; 00:15:04,719<br>So again, at some point, this memory page will get full, and we got to write about the</p>
<p>276<br>00:15:04,719 –&gt; 00:15:05,719<br>disk.</p>
<p>277<br>00:15:05,719 –&gt; 00:15:06,719<br>Right?</p>
<p>278<br>00:15:06,719 –&gt; 00:15:10,120<br>And that’s just literally just taking the entire contents of the memory page and plopping</p>
<p>279<br>00:15:10,120 –&gt; 00:15:12,639<br>it down to a bunch of pages on the disk.</p>
<p>280<br>00:15:12,639 –&gt; 00:15:17,719<br>Clear out my memory buffer and then start filling it up with new log entries.</p>
<p>281<br>00:15:17,719 –&gt; 00:15:20,559<br>And then when that gets full, same thing.</p>
<p>282<br>00:15:20,559 –&gt; 00:15:22,959<br>I write that out.</p>
<p>283<br>00:15:22,959 –&gt; 00:15:26,959<br>Now, important thing about this, there are just two important things to point out when</p>
<p>284<br>00:15:26,959 –&gt; 00:15:27,959<br>we do this right.</p>
<p>285<br>00:15:27,960 –&gt; 00:15:31,160<br>First of all, this is all sequential IO now.</p>
<p>286<br>00:15:31,160 –&gt; 00:15:32,160<br>Right?</p>
<p>287<br>00:15:32,160 –&gt; 00:15:36,720<br>Because my memory page could be like a megabyte, 10 megabytes.</p>
<p>288<br>00:15:36,720 –&gt; 00:15:41,400<br>When that gets full, I write out sequential, there’s 10 megabytes to the file and disk.</p>
<p>289<br>00:15:41,400 –&gt; 00:15:45,120<br>So no matter, again, in the two-point oriented architecture or the page oriented architecture,</p>
<p>290<br>00:15:45,120 –&gt; 00:15:50,840<br>where I would have 20 two-point spent across 20 different pages, in this environment, with</p>
<p>291<br>00:15:50,840 –&gt; 00:15:54,920<br>this setup, those 22-points are always going to be on the same page when I write them</p>
<p>292<br>00:15:54,920 –&gt; 00:15:55,920<br>out.</p>
<p>293<br>00:15:55,919 –&gt; 00:15:59,240<br>Because there’s depending log records.</p>
<p>294<br>00:15:59,240 –&gt; 00:16:03,639<br>The other important thing in this architecture is that once a page is written to disk, it’s</p>
<p>295<br>00:16:03,639 –&gt; 00:16:04,639<br>immutable.</p>
<p>296<br>00:16:04,639 –&gt; 00:16:09,479<br>And then we can never go back and do in-place updates.</p>
<p>297<br>00:16:09,479 –&gt; 00:16:10,959<br>Well, compact it.</p>
<p>298<br>00:16:10,959 –&gt; 00:16:11,959<br>We’ll see that in a second.</p>
<p>299<br>00:16:11,959 –&gt; 00:16:13,559<br>Basically, we do in garbage collection.</p>
<p>300<br>00:16:13,559 –&gt; 00:16:17,639<br>But we never can overwrite a log record that I was already there before.</p>
<p>301<br>00:16:17,639 –&gt; 00:16:22,240<br>We’re not going to distribute the data since just yet, but there is some advantage to making</p>
<p>302<br>00:16:22,240 –&gt; 00:16:23,599<br>sure your files are immutable.</p>
<p>303<br>00:16:24,320 –&gt; 00:16:29,480<br>Ignoring the, oh, well, if I’m on a cloud storage, I can’t do in-place updates.</p>
<p>304<br>00:16:29,480 –&gt; 00:16:32,080<br>But it does make it easy now if it’s just depending the log.</p>
<p>305<br>00:16:32,080 –&gt; 00:16:36,040<br>Because essentially, what packs us or something a raft is doing, there’s adding log records.</p>
<p>306<br>00:16:36,040 –&gt; 00:16:37,040<br>Log records.</p>
<p>307<br>00:16:37,040 –&gt; 00:16:38,920<br>And never go back and making changes.</p>
<p>308<br>00:16:38,920 –&gt; 00:16:43,040<br>Because if you change in the log, it’s going to be a new log entry.</p>
<p>309<br>00:16:43,040 –&gt; 00:16:48,160<br>So this makes the architecture a lot easier once it’s on disk and you don’t update it.</p>
<p>310<br>00:16:48,160 –&gt; 00:16:53,360<br>Now, for now, we’re going to ignore what happens if I need to write the memory buffer out</p>
<p>311<br>00:16:53,360 –&gt; 00:16:56,919<br>before I want to, before it’s completely full.</p>
<p>312<br>00:16:56,919 –&gt; 00:17:00,680<br>Like if I have running a query or transaction that wants to make sure that my changes are</p>
<p>313<br>00:17:00,680 –&gt; 00:17:05,319<br>written to disk before I tell the outside world that the data is safely written to disk,</p>
<p>314<br>00:17:05,319 –&gt; 00:17:11,539<br>I may write this log buffer out before it’s finished or before it’s full, but I’ll write</p>
<p>315<br>00:17:11,539 –&gt; 00:17:15,480<br>it to a separate location like a local disk where I can do these kinds of writes.</p>
<p>316<br>00:17:15,480 –&gt; 00:17:19,079<br>But we’ll ignore that for now.</p>
<p>317<br>00:17:20,079 –&gt; 00:17:24,879<br>Again, so in a log-shake-and-architecture, this is going to make our writes really fast,</p>
<p>318<br>00:17:24,879 –&gt; 00:17:27,480<br>much faster than in a two-porian architecture.</p>
<p>319<br>00:17:27,480 –&gt; 00:17:31,919<br>Because again, we’re just depending log records and we write them out sequentially.</p>
<p>320<br>00:17:31,919 –&gt; 00:17:35,000<br>What’s potentially going to be slower now?</p>
<p>321<br>00:17:35,000 –&gt; 00:17:36,000<br>Read, right?</p>
<p>322<br>00:17:36,000 –&gt; 00:17:39,119<br>Again, in computer science and database systems, there’s no free lunch.</p>
<p>323<br>00:17:39,119 –&gt; 00:17:43,399<br>So we’re making the writes go faster, but now the reads potentially go slower.</p>
<p>324<br>00:17:43,399 –&gt; 00:17:45,199<br>So to do a read, what do we have to do?</p>
<p>325<br>00:17:45,200 –&gt; 00:17:51,559<br>So again, assuming something in our system has figured out the ID or the key of the log</p>
<p>326<br>00:17:51,559 –&gt; 00:17:57,160<br>record I want, like 102, 103, 104, we ignore that for now.</p>
<p>327<br>00:17:57,160 –&gt; 00:18:02,519<br>In order for us to find the log record for a given key, we first want to check the</p>
<p>328<br>00:18:02,519 –&gt; 00:18:08,880<br>InMemory page, start at the end, because that’s the newest records, and they just scan</p>
<p>329<br>00:18:08,880 –&gt; 00:18:14,480<br>it sequentially in reverse order going back to the beginning until we find the log entry</p>
<p>330<br>00:18:14,480 –&gt; 00:18:17,280<br>that we want.</p>
<p>331<br>00:18:17,280 –&gt; 00:18:19,680<br>If it’s not there, we may have to go to disk.</p>
<p>332<br>00:18:19,680 –&gt; 00:18:22,760<br>We’ll cover that in a second.</p>
<p>333<br>00:18:22,760 –&gt; 00:18:25,280<br>So is this efficient?</p>
<p>334<br>00:18:25,280 –&gt; 00:18:26,960<br>No, right?</p>
<p>335<br>00:18:26,960 –&gt; 00:18:29,960<br>So the way to get around this, and this is where that log structure, and the text book comes</p>
<p>336<br>00:18:29,960 –&gt; 00:18:34,920<br>in, but again, we don’t have to worry about the details, is that they’re going to maintain</p>
<p>337<br>00:18:34,920 –&gt; 00:18:36,920<br>some kind of index, right?</p>
<p>338<br>00:18:36,920 –&gt; 00:18:42,880<br>So for every single record ID, it’ll tell you where in the InMemory buffer page is it</p>
<p>339<br>00:18:42,880 –&gt; 00:18:47,519<br>located, or if it’s not in memory, where is it on disk?</p>
<p>340<br>00:18:47,519 –&gt; 00:18:48,519<br>Right?</p>
<p>341<br>00:18:48,519 –&gt; 00:18:52,720<br>So to get record ID 104, I just do some look up in this index.</p>
<p>342<br>00:18:52,720 –&gt; 00:18:55,000<br>I’m not telling you what data structure it is, it doesn’t matter.</p>
<p>343<br>00:18:55,000 –&gt; 00:18:59,360<br>It’s typically going to be a B plus tree, but some systems you just try, some systems you</p>
<p>344<br>00:18:59,360 –&gt; 00:19:00,759<br>skip list, it doesn’t matter.</p>
<p>345<br>00:19:00,759 –&gt; 00:19:01,759<br>Right?</p>
<p>346<br>00:19:01,759 –&gt; 00:19:05,800<br>Do my look up at 5104, and then I’ll tell you what offset in the memory page, in the</p>
<p>347<br>00:19:05,799 –&gt; 00:19:08,440<br>memory buffer, has the data that I’m looking for.</p>
<p>348<br>00:19:08,440 –&gt; 00:19:09,440<br>Right?</p>
<p>349<br>00:19:09,440 –&gt; 00:19:13,399<br>In the case I want to look at 103, then I got to go out to disk and get it.</p>
<p>350<br>00:19:13,399 –&gt; 00:19:14,399<br>Right?</p>
<p>351<br>00:19:14,399 –&gt; 00:19:17,879<br>So far, so good?</p>
<p>352<br>00:19:17,879 –&gt; 00:19:18,879<br>Yes.</p>
<p>353<br>00:19:18,879 –&gt; 00:19:25,919<br>So without getting into details about what the index is, is it possible that it’s implemented</p>
<p>354<br>00:19:25,919 –&gt; 00:19:29,960<br>in a pad on where the policy is?</p>
<p>355<br>00:19:29,960 –&gt; 00:19:38,960<br>So your question is, is it possible to implement the index in a pen-only file system?</p>
<p>356<br>00:19:38,960 –&gt; 00:19:39,960<br>Yeah.</p>
<p>357<br>00:19:39,960 –&gt; 00:19:47,400<br>So, yeah, so the way you would do this is like, you can sort of just treat this as a log</p>
<p>358<br>00:19:47,400 –&gt; 00:19:52,000<br>itself, and then in memory you build a data structure on top of it.</p>
<p>359<br>00:19:52,000 –&gt; 00:19:57,640<br>So like, in a B plus tree, in a typical, the typical is done, is like, when you write the</p>
<p>360<br>00:19:57,640 –&gt; 00:20:03,440<br>pages out the disk, you’re still maintaining the data structure itself, like the pointers</p>
<p>361<br>00:20:03,440 –&gt; 00:20:05,960<br>between the children and parents and so forth.</p>
<p>362<br>00:20:05,960 –&gt; 00:20:11,640<br>In this environment, you would basically reconstruct the in-memory index by replaying the log.</p>
<p>363<br>00:20:11,640 –&gt; 00:20:14,960<br>So you could do it in a read-only file system.</p>
<p>364<br>00:20:14,960 –&gt; 00:20:19,840<br>Actually, I don’t know what ROX DB does.</p>
<p>365<br>00:20:19,840 –&gt; 00:20:20,840<br>Yes?</p>
<p>366<br>00:20:20,839 –&gt; 00:20:27,959<br>Is this index the same index as what we get when we run great index in SQLite?</p>
<p>367<br>00:20:27,959 –&gt; 00:20:33,679<br>Question is, is this index the same index you would get when you run great index in SQLite?</p>
<p>368<br>00:20:33,679 –&gt; 00:20:35,679<br>And specifically SQLite?</p>
<p>369<br>00:20:35,679 –&gt; 00:20:36,679<br>No.</p>
<p>370<br>00:20:36,679 –&gt; 00:20:42,279<br>Well, SQLite is not log structured.</p>
<p>371<br>00:20:42,279 –&gt; 00:20:51,759<br>Basically, is this the same index as a primary key index?</p>
<p>372<br>00:20:51,759 –&gt; 00:20:54,960<br>Potentially yes, but not always.</p>
<p>373<br>00:20:54,960 –&gt; 00:20:55,960<br>SQLite is kind of complicated.</p>
<p>374<br>00:20:55,960 –&gt; 00:21:02,960<br>They’re indexed or negative pages, and they can have the non-indexes and the primary key</p>
<p>375<br>00:21:02,960 –&gt; 00:21:08,000<br>table indexes give me a second to that.</p>
<p>376<br>00:21:08,000 –&gt; 00:21:13,839<br>Think of this as like the internal bookkeeping of fine records.</p>
<p>377<br>00:21:13,839 –&gt; 00:21:21,079<br>It’s not something you would need to expose to the SQL queries themselves, but you could</p>
<p>378<br>00:21:21,079 –&gt; 00:21:23,079<br>use them for that.</p>
<p>379<br>00:21:23,079 –&gt; 00:21:24,079<br>Yes?</p>
<p>380<br>00:21:24,079 –&gt; 00:21:31,079<br>So the only thing that we’re ever looking at is the index is that point into the memory</p>
<p>381<br>00:21:31,079 –&gt; 00:21:32,079<br>page.</p>
<p>382<br>00:21:32,079 –&gt; 00:21:36,919<br>So why would we just maintain a bunch of pointers to the latest update rather than sorry</p>
<p>383<br>00:21:36,919 –&gt; 00:21:38,639<br>everything that’s happened?</p>
<p>384<br>00:21:38,639 –&gt; 00:21:43,799<br>So your question is, you see that this index is pointing to things that happen in memory,</p>
<p>385<br>00:21:43,799 –&gt; 00:21:44,799<br>which is not true, right?</p>
<p>386<br>00:21:44,799 –&gt; 00:21:45,799<br>You could point down the disk.</p>
<p>387<br>00:21:45,799 –&gt; 00:21:47,799<br>Sorry, it’s only points in one thing.</p>
<p>388<br>00:21:47,799 –&gt; 00:21:50,759<br>It’s only point in the latest version of the yes.</p>
<p>389<br>00:21:50,759 –&gt; 00:21:53,079<br>Why would we store everything?</p>
<p>390<br>00:21:53,079 –&gt; 00:21:54,079<br>Why would we store everything down here?</p>
<p>391<br>00:21:54,079 –&gt; 00:21:56,079<br>We’ll get it out in a second.</p>
<p>392<br>00:21:56,079 –&gt; 00:22:02,000<br>But like, in this case here, I have, what was it?</p>
<p>393<br>00:22:02,000 –&gt; 00:22:03,399<br>ID equals 103.</p>
<p>394<br>00:22:03,399 –&gt; 00:22:04,399<br>It’s not in memory.</p>
<p>395<br>00:22:04,399 –&gt; 00:22:05,399<br>It’s somewhere on disk.</p>
<p>396<br>00:22:05,399 –&gt; 00:22:07,399<br>So, but where?</p>
<p>397<br>00:22:07,399 –&gt; 00:22:08,399<br>Right?</p>
<p>398<br>00:22:08,399 –&gt; 00:22:09,879<br>I can’t just blow away the whole file.</p>
<p>399<br>00:22:09,879 –&gt; 00:22:12,000<br>I would have to pull it out.</p>
<p>400<br>00:22:12,000 –&gt; 00:22:13,000<br>Right?</p>
<p>401<br>00:22:13,000 –&gt; 00:22:14,000<br>And that’s expensive.</p>
<p>402<br>00:22:14,000 –&gt; 00:22:15,000<br>And that’s compaction.</p>
<p>403<br>00:22:15,000 –&gt; 00:22:17,000<br>We’ll get that in a second.</p>
<p>404<br>00:22:17,000 –&gt; 00:22:18,000<br>Yes?</p>
<p>405<br>00:22:18,000 –&gt; 00:22:22,000<br>Why do we need to store the latest loglet before delete?</p>
<p>406<br>00:22:22,000 –&gt; 00:22:29,000<br>Because if it’s not present then it just isn’t there.</p>
<p>407<br>00:22:29,000 –&gt; 00:22:30,000<br>And all of it is.</p>
<p>408<br>00:22:30,000 –&gt; 00:22:35,200<br>So, statement is, why do we need to store this delete record?</p>
<p>409<br>00:22:35,200 –&gt; 00:22:43,079<br>If it’s been deleted, why do you even store that?</p>
<p>410<br>00:22:43,079 –&gt; 00:22:47,480<br>Because there’s going to be a put for like, this, they wanted to, there’s a put before</p>
<p>411<br>00:22:47,480 –&gt; 00:22:48,480<br>it, right?</p>
<p>412<br>00:22:48,480 –&gt; 00:22:50,759<br>Because say there was another put that got written out the disk.</p>
<p>413<br>00:22:50,759 –&gt; 00:22:59,839<br>I, again, think of like, I’m going back in time and I want to make sure that like, if I,</p>
<p>414<br>00:22:59,839 –&gt; 00:23:02,799<br>if I don’t have that delete then it does exist, right?</p>
<p>415<br>00:23:02,799 –&gt; 00:23:05,799<br>Because I can’t go back and just, okay, you want to do that deleted.</p>
<p>416<br>00:23:05,799 –&gt; 00:23:07,480<br>Let me find a page where it’s in and pull it out.</p>
<p>417<br>00:23:07,480 –&gt; 00:23:08,480<br>I can’t do that.</p>
<p>418<br>00:23:08,480 –&gt; 00:23:12,680<br>So, I just pin a log, I can say, okay, if you’re going back in time and you see 102, no,</p>
<p>419<br>00:23:12,680 –&gt; 00:23:13,680<br>it’s been deleted.</p>
<p>420<br>00:23:14,680 –&gt; 00:23:20,680<br>And then it will call us them in a second to remove the extra entries of those things.</p>
<p>421<br>00:23:20,680 –&gt; 00:23:22,680<br>Okay.</p>
<p>422<br>00:23:22,680 –&gt; 00:23:28,440<br>So, as both these guys sort of alluded to is like, well, some of these log records we don’t</p>
<p>423<br>00:23:28,440 –&gt; 00:23:31,600<br>need to maintain these forever, right?</p>
<p>424<br>00:23:31,600 –&gt; 00:23:35,279<br>And delete was, was, was, was able to this or puts over the same key over and over again,</p>
<p>425<br>00:23:35,279 –&gt; 00:23:36,279<br>right?</p>
<p>426<br>00:23:36,279 –&gt; 00:23:40,160<br>And so, in a log structured database system, what they’re going to do is they’re periodically</p>
<p>427<br>00:23:40,160 –&gt; 00:23:47,160<br>going to run some background job that will compact the pages to coalesce them to reduce</p>
<p>428<br>00:23:47,160 –&gt; 00:23:49,160<br>redundant operations.</p>
<p>429<br>00:23:49,160 –&gt; 00:23:50,160<br>Right?</p>
<p>430<br>00:23:50,160 –&gt; 00:23:53,880<br>So, in this case here, I have page one, one, page two.</p>
<p>431<br>00:23:53,880 –&gt; 00:23:58,000<br>Think of this going as a newest to oldest, sorry, oldest to newest.</p>
<p>432<br>00:23:58,000 –&gt; 00:24:00,480<br>So, this one is older than this one.</p>
<p>433<br>00:24:00,480 –&gt; 00:24:04,360<br>And so, if I want to compact them, then all I need to do is recognize that here are the</p>
<p>434<br>00:24:04,360 –&gt; 00:24:10,120<br>latest entries that I care about for the keys that are referenced in these two pages.</p>
<p>435<br>00:24:10,119 –&gt; 00:24:11,119<br>Right?</p>
<p>436<br>00:24:11,119 –&gt; 00:24:15,000<br>So, one of three, one of four, and then we delete one of one and one of two, and then</p>
<p>437<br>00:24:15,000 –&gt; 00:24:16,000<br>the put one of five.</p>
<p>438<br>00:24:16,000 –&gt; 00:24:17,000<br>Right?</p>
<p>439<br>00:24:17,000 –&gt; 00:24:21,399<br>Again, so like, there’s a put one of five here, but because this is newer than this put</p>
<p>440<br>00:24:21,399 –&gt; 00:24:25,039<br>one of five, we know we don’t, you know, we want this one, not this one.</p>
<p>441<br>00:24:25,039 –&gt; 00:24:28,959<br>So, instead of storing two put one of fives, we only need to store one in our coalesces</p>
<p>442<br>00:24:28,959 –&gt; 00:24:29,959<br>pages.</p>
<p>443<br>00:24:29,959 –&gt; 00:24:30,959<br>Right?</p>
<p>444<br>00:24:30,959 –&gt; 00:24:36,239<br>And as, as he brought up as well, like, in maybe the case that I actually don’t need to</p>
<p>445<br>00:24:36,240 –&gt; 00:24:42,000<br>store the deletes at this point as well, because there’s some other upper part of the system</p>
<p>446<br>00:24:42,000 –&gt; 00:24:46,240<br>that says, all right, I’ve removed one or two, one, one for my index.</p>
<p>447<br>00:24:46,240 –&gt; 00:24:47,559<br>So, anybody has a look up?</p>
<p>448<br>00:24:47,559 –&gt; 00:24:48,559<br>Let’s see, a key not bound.</p>
<p>449<br>00:24:48,559 –&gt; 00:24:52,160<br>And therefore, I don’t need to store the log entry for this.</p>
<p>450<br>00:24:52,160 –&gt; 00:24:53,160<br>Right?</p>
<p>451<br>00:24:53,160 –&gt; 00:24:55,799<br>So, this is called compaction.</p>
<p>452<br>00:24:55,799 –&gt; 00:24:59,640<br>And this is, again, no free lunch.</p>
<p>453<br>00:24:59,640 –&gt; 00:25:03,120<br>The log records, the log search is towards, is going to make the inserts much faster,</p>
<p>454<br>00:25:03,120 –&gt; 00:25:04,880<br>because it’s just depending to the log.</p>
<p>455<br>00:25:05,040 –&gt; 00:25:07,120<br>But in some point, we’re going to have to go clean things up.</p>
<p>456<br>00:25:09,200 –&gt; 00:25:10,200<br>Right?</p>
<p>457<br>00:25:10,200 –&gt; 00:25:14,120<br>So, again, the idea is that we do this compaction.</p>
<p>458<br>00:25:14,120 –&gt; 00:25:20,800<br>Now we’re down to a compressed form of the log record.</p>
<p>459<br>00:25:20,800 –&gt; 00:25:22,400<br>Again, this is only on disk.</p>
<p>460<br>00:25:22,400 –&gt; 00:25:23,840<br>We can’t do in-place updates.</p>
<p>461<br>00:25:23,840 –&gt; 00:25:27,920<br>So, this is literally taking one disk page, another disk page, and then writing out a new one.</p>
<p>462<br>00:25:27,920 –&gt; 00:25:29,920<br>We can’t overwrite an existing one.</p>
<p>463<br>00:25:30,920 –&gt; 00:25:37,920<br>Another important thing to keep track of, too, is that once it’s on disk, we know that it’s going to be older than,</p>
<p>464<br>00:25:37,920 –&gt; 00:25:41,920<br>or once we have a page on disk, and once we’ve already compacted it,</p>
<p>465<br>00:25:41,920 –&gt; 00:25:46,920<br>removing the redundant, or the operations on the same key over and over again,</p>
<p>466<br>00:25:46,920 –&gt; 00:25:51,920<br>that means that within a disk page, we’ve compacted, it only contains,</p>
<p>467<br>00:25:51,920 –&gt; 00:25:53,920<br>or each key is only going to be referenced once.</p>
<p>468<br>00:25:55,920 –&gt; 00:25:58,920<br>At this point, we don’t care about the temporal ordering anymore of the log.</p>
<p>469<br>00:25:58,920 –&gt; 00:26:00,920<br>We don’t care about news to orders.</p>
<p>470<br>00:26:00,920 –&gt; 00:26:01,920<br>Right?</p>
<p>471<br>00:26:01,920 –&gt; 00:26:08,920<br>So now, if the operation we need to support is go find me key 103, 104, 105, or whatever.</p>
<p>472<br>00:26:08,920 –&gt; 00:26:13,920<br>In the disk, the temporal ordering doesn’t help us, and actually what we want to do is sort the disk pages,</p>
<p>473<br>00:26:13,920 –&gt; 00:26:19,920<br>sort the keys based, sort the records of the log records in the disk page based on the keys.</p>
<p>474<br>00:26:19,920 –&gt; 00:26:21,920<br>Right?</p>
<p>475<br>00:26:21,920 –&gt; 00:26:23,920<br>See, we do something like this.</p>
<p>476<br>00:26:24,920 –&gt; 00:26:28,920<br>Because again, now all I need to know now is if I’m looking at this disk page,</p>
<p>477<br>00:26:28,920 –&gt; 00:26:31,920<br>I know that these pages are older than each other.</p>
<p>478<br>00:26:31,920 –&gt; 00:26:32,920<br>Right?</p>
<p>479<br>00:26:32,920 –&gt; 00:26:37,920<br>So I have sort of some metadata like that, but each log record, I don’t need to know whether one’s older than another.</p>
<p>480<br>00:26:39,920 –&gt; 00:26:45,920<br>So, when you do this compaction, and then you sort them based on the key values,</p>
<p>481<br>00:26:45,920 –&gt; 00:26:48,920<br>these are sometimes called sort of string tables or SS tables.</p>
<p>482<br>00:26:49,920 –&gt; 00:26:55,920<br>I think this term is coined by Jeff Dean and the Sanjay guy when they wrote level DB at Google.</p>
<p>483<br>00:26:55,920 –&gt; 00:26:58,920<br>This is for a big table in the mid-2000s.</p>
<p>484<br>00:27:00,920 –&gt; 00:27:05,920<br>And the advantage of this is that when I have to go fetch this disk page in,</p>
<p>485<br>00:27:05,920 –&gt; 00:27:10,920<br>I’m not looking for like, give me the put for 103 at this time stamp.</p>
<p>486<br>00:27:10,920 –&gt; 00:27:12,920<br>You’re just looking for put 103.</p>
<p>487<br>00:27:12,920 –&gt; 00:27:16,920<br>And so you want to do a look up to find that record quickly as possible.</p>
<p>488<br>00:27:17,920 –&gt; 00:27:21,920<br>And so if you’re sorted, you can then build like an index or a filter,</p>
<p>489<br>00:27:21,920 –&gt; 00:27:24,920<br>some way to quickly jump to that record you’re looking for,</p>
<p>490<br>00:27:24,920 –&gt; 00:27:27,920<br>rather than having to do binary search across the entire file.</p>
<p>491<br>00:27:27,920 –&gt; 00:27:32,920<br>So there’s some metadata and the header for each of these SS table pages that keeps track of,</p>
<p>492<br>00:27:32,920 –&gt; 00:27:40,920<br>sorry, files, comprise of multiple pages that will keep track of where the offsets are for the different keys.</p>
<p>493<br>00:27:41,920 –&gt; 00:27:42,920<br>Yes.</p>
<p>494<br>00:27:47,920 –&gt; 00:27:55,920<br>The question is, wouldn’t the index that we’re talking about already point to the exact location of where something is?</p>
<p>495<br>00:27:55,920 –&gt; 00:27:56,920<br>Not necessarily.</p>
<p>496<br>00:27:56,920 –&gt; 00:28:05,920<br>You may want to keep a more core screen index that says,</p>
<p>497<br>00:28:05,920 –&gt; 00:28:10,920<br>here’s not maybe the exact offset of the thing you’re looking for, but here’s the file that has it.</p>
<p>498<br>00:28:10,920 –&gt; 00:28:14,920<br>And once you get to that file, it’ll tell you where to find it.</p>
<p>499<br>00:28:15,920 –&gt; 00:28:17,920<br>Yes, so I may not draw a good example here.</p>
<p>500<br>00:28:17,920 –&gt; 00:28:20,920<br>So this, I’m saying, disk page, this could be multiple pages for an SSD file.</p>
<p>501<br>00:28:20,920 –&gt; 00:28:24,920<br>These things get big, so it’s not going to be a single page.</p>
<p>502<br>00:28:25,920 –&gt; 00:28:26,920<br>And back, yes.</p>
<p>503<br>00:28:29,920 –&gt; 00:28:31,920<br>For the SS table or the one back of memory?</p>
<p>504<br>00:28:32,920 –&gt; 00:28:33,920<br>Back of memory.</p>
<p>505<br>00:28:34,920 –&gt; 00:28:38,920<br>Yes, because you don’t want to have to recreate it upon restart.</p>
<p>506<br>00:28:38,920 –&gt; 00:28:43,920<br>And as I was saying it before, either you could just write the file, the pages themselves to disk,</p>
<p>507<br>00:28:44,920 –&gt; 00:28:48,920<br>or you could just maintain a log record that says, here’s how to rebuild the index.</p>
<p>508<br>00:28:50,920 –&gt; 00:28:51,920<br>Yes.</p>
<p>509<br>00:28:51,920 –&gt; 00:28:54,920<br>Why don’t we write the pages in sorted order first place?</p>
<p>510<br>00:28:54,920 –&gt; 00:28:56,920<br>Because if it’s a memory, you could get rid of it.</p>
<p>511<br>00:28:56,920 –&gt; 00:29:01,920<br>Yes, the question is, why don’t we write the pages in sorted order at the beginning of the, that’s what they do, yes.</p>
<p>512<br>00:29:02,920 –&gt; 00:29:08,920<br>Yeah, we’re in the confection, have any impact on the read performance because you might have to take some logs.</p>
<p>513<br>00:29:08,920 –&gt; 00:29:09,920<br>Absolutely, yes.</p>
<p>514<br>00:29:09,920 –&gt; 00:29:14,920<br>So this David is, and he’s right, is a compaction going to have an impact on the performance of the reads?</p>
<p>515<br>00:29:14,920 –&gt; 00:29:18,920<br>Because not only you’re just taking logs, logs, you’re doing disk IOs, right?</p>
<p>516<br>00:29:19,920 –&gt; 00:29:22,920<br>Because now you’re like, you’re, we’ll get to different types of compactions a second.</p>
<p>517<br>00:29:22,920 –&gt; 00:29:27,920<br>Now you’re potentially bringing in gigabytes of files in, compacting them and writing them back out.</p>
<p>518<br>00:29:27,920 –&gt; 00:29:28,920<br>So absolutely, yes.</p>
<p>519<br>00:29:28,920 –&gt; 00:29:29,920<br>Again, no free lunch.</p>
<p>520<br>00:29:32,920 –&gt; 00:29:33,920<br>Okay.</p>
<p>521<br>00:29:36,920 –&gt; 00:29:40,920<br>So there’s sort of two main ways you can do compaction.</p>
<p>522<br>00:29:40,920 –&gt; 00:29:45,920<br>And this terminology here is, I’ll use is what to use in, in rocks DB.</p>
<p>523<br>00:29:46,920 –&gt; 00:29:55,920<br>So the most simple form is called universal compaction, where you’re just taking adjacent sorted log files that are on disk.</p>
<p>524<br>00:29:55,920 –&gt; 00:29:57,920<br>Again, this means multiple pages.</p>
<p>525<br>00:29:57,920 –&gt; 00:30:00,920<br>Think of like, again, megabytes, gigabytes, terabytes.</p>
<p>526<br>00:30:00,920 –&gt; 00:30:06,920<br>And then you just want to take two, two, two sort of these sort of log files that are adjacent and then compact them.</p>
<p>527<br>00:30:06,920 –&gt; 00:30:07,920<br>Right?</p>
<p>528<br>00:30:07,920 –&gt; 00:30:19,920<br>So I would take these two guys, basically do a sort merge, or they’re already sorted, so now I’m just doing a merge and figure out whether, you know, whether the, the different keys you’re looking at, whether one is subsumed by another.</p>
<p>529<br>00:30:19,920 –&gt; 00:30:22,920<br>Like, assuming that this one, but I said, this one’s older than this one.</p>
<p>530<br>00:30:22,920 –&gt; 00:30:28,920<br>So if I see it, an update, or put for like, you know, key one or three here, and a key one or three there, then I know I want that one.</p>
<p>531<br>00:30:28,920 –&gt; 00:30:29,920<br>And I can throw the other one away.</p>
<p>532<br>00:30:31,920 –&gt; 00:30:32,920<br>Right?</p>
<p>533<br>00:30:32,920 –&gt; 00:30:37,920<br>And I can do the same thing for any possible combination of these, these sort of log files.</p>
<p>534<br>00:30:37,920 –&gt; 00:30:42,920<br>I can keep calling them, I can send them into more compact forms.</p>
<p>535<br>00:30:42,920 –&gt; 00:30:47,920<br>Another approach is to do what it’s called level compaction.</p>
<p>536<br>00:30:47,920 –&gt; 00:30:51,920<br>Again, this is what the level and level DB comes from.</p>
<p>537<br>00:30:51,920 –&gt; 00:30:55,920<br>Actually, who here is sort of level DB?</p>
<p>538<br>00:30:55,920 –&gt; 00:30:56,920<br>Very few.</p>
<p>539<br>00:30:56,920 –&gt; 00:30:58,920<br>He here has heard of rocks DB.</p>
<p>540<br>00:30:58,920 –&gt; 00:30:59,920<br>More.</p>
<p>541<br>00:30:59,920 –&gt; 00:31:00,920<br>Okay.</p>
<p>542<br>00:31:00,920 –&gt; 00:31:01,920<br>Not much more.</p>
<p>543<br>00:31:01,920 –&gt; 00:31:04,920<br>Rocks DB is Facebook’s fork of level DB.</p>
<p>544<br>00:31:04,920 –&gt; 00:31:05,920<br>Google wrote level DB.</p>
<p>545<br>00:31:05,920 –&gt; 00:31:07,920<br>Rocks DB forked it.</p>
<p>546<br>00:31:07,920 –&gt; 00:31:09,920<br>Very first thing they did.</p>
<p>547<br>00:31:09,920 –&gt; 00:31:10,920<br>Remove M-map.</p>
<p>548<br>00:31:10,920 –&gt; 00:31:11,920<br>Right?</p>
<p>549<br>00:31:11,920 –&gt; 00:31:14,920<br>And then they expanded and did a bunch of other stuff.</p>
<p>550<br>00:31:14,920 –&gt; 00:31:17,920<br>And so this level compaction comes from level DB.</p>
<p>551<br>00:31:17,920 –&gt; 00:31:20,920<br>Right, so you have your sort of file and disk.</p>
<p>552<br>00:31:20,920 –&gt; 00:31:23,920<br>And at level zero, they’re going to be a certain size.</p>
<p>553<br>00:31:23,920 –&gt; 00:31:25,920<br>And you keep adding more sort of sort of files.</p>
<p>554<br>00:31:25,920 –&gt; 00:31:27,920<br>And to a some point, you run compaction.</p>
<p>555<br>00:31:27,920 –&gt; 00:31:31,920<br>And then you’ll combine them down into a larger file at the next level.</p>
<p>556<br>00:31:31,920 –&gt; 00:31:32,920<br>Right?</p>
<p>557<br>00:31:32,920 –&gt; 00:31:35,920<br>Make, make, make a more of them at the top level.</p>
<p>558<br>00:31:35,920 –&gt; 00:31:37,920<br>And at some point, that’ll get merged together.</p>
<p>559<br>00:31:37,920 –&gt; 00:31:40,920<br>And once I have enough at the next level, then I’ll run compaction for that one.</p>
<p>560<br>00:31:40,920 –&gt; 00:31:41,920<br>And produce something at the low level.</p>
<p>561<br>00:31:41,920 –&gt; 00:31:42,920<br>Sort of cascading down.</p>
<p>562<br>00:31:42,920 –&gt; 00:31:45,920<br>I’m getting larger and larger files as I go down.</p>
<p>563<br>00:31:45,920 –&gt; 00:31:46,920<br>Right?</p>
<p>564<br>00:31:46,920 –&gt; 00:31:56,920<br>So as I said, because Rocks DB has sort of become the default choice for a lot of database vendors,</p>
<p>565<br>00:31:56,920 –&gt; 00:32:03,920<br>people building data systems, as like the underlying storage manager to use,</p>
<p>566<br>00:32:03,920 –&gt; 00:32:06,920<br>they’re essentially log structure.</p>
<p>567<br>00:32:07,920 –&gt; 00:32:10,920<br>But then what they’re building is how a Rocks DB is all the SQL parsing layer,</p>
<p>568<br>00:32:10,920 –&gt; 00:32:14,920<br>the SQL execution, the indexes, all the additional things we’ll talk about throughout the semester.</p>
<p>569<br>00:32:14,920 –&gt; 00:32:19,920<br>And like the Rocks DB essentially is providing a key value API.</p>
<p>570<br>00:32:19,920 –&gt; 00:32:24,920<br>Like you don’t, in my example is here, I just said, here’s the value,</p>
<p>571<br>00:32:24,920 –&gt; 00:32:27,920<br>here’s the payload I’m putting out and I’m stirring in the log.</p>
<p>572<br>00:32:27,920 –&gt; 00:32:30,920<br>It has no notion of attributes or columns.</p>
<p>573<br>00:32:30,920 –&gt; 00:32:31,920<br>Right?</p>
<p>574<br>00:32:31,920 –&gt; 00:32:34,920<br>So even though I say I have 10 columns on my table, but I only update one of them,</p>
<p>575<br>00:32:34,920 –&gt; 00:32:37,920<br>my put record has to contain all 10 columns.</p>
<p>576<br>00:32:37,920 –&gt; 00:32:42,920<br>We’ll see multi-versioning how we can be later in the semester after the midterm,</p>
<p>577<br>00:32:42,920 –&gt; 00:32:46,920<br>but we can be smarter with this, which essentially looks a lot like log structure storage,</p>
<p>578<br>00:32:46,920 –&gt; 00:32:48,920<br>but for now we can ignore that.</p>
<p>579<br>00:32:48,920 –&gt; 00:32:54,920<br>It’s almost how Postgres, this is how Postgres was originally envisioned in the 1980s.</p>
<p>580<br>00:32:54,920 –&gt; 00:32:57,920<br>It looks a lot like this.</p>
<p>581<br>00:32:57,920 –&gt; 00:33:02,920<br>So as I said, Rocks DB is super popular, and it’s a focal level DB,</p>
<p>582<br>00:33:02,920 –&gt; 00:33:08,920<br>and this is just a sampling of different companies that are using a log structure storage.</p>
<p>583<br>00:33:08,920 –&gt; 00:33:12,920<br>Again, some are based on Rocks DB, Cockroach DB originally started off using Rocks DB.</p>
<p>584<br>00:33:12,920 –&gt; 00:33:15,920<br>They threw it away and wrote their own thing and go called Pebble,</p>
<p>585<br>00:33:15,920 –&gt; 00:33:18,920<br>because Sandra has their own log structure storage.</p>
<p>586<br>00:33:18,920 –&gt; 00:33:22,920<br>TidyB has TidyKV, I think D graph uses Badger DB,</p>
<p>587<br>00:33:22,920 –&gt; 00:33:27,920<br>but there’s a bunch of these log structure systems.</p>
<p>588<br>00:33:27,920 –&gt; 00:33:30,920<br>So we’ve already said the reads are slower, but what are some other problems?</p>
<p>589<br>00:33:30,920 –&gt; 00:33:32,920<br>We would have with log structure storage.</p>
<p>590<br>00:33:32,920 –&gt; 00:33:35,920<br>We said, re-with slower, and the compactroom is expensive.</p>
<p>591<br>00:33:35,920 –&gt; 00:33:39,920<br>There’s one more core issue with this approach.</p>
<p>592<br>00:33:39,920 –&gt; 00:33:40,920<br>Yes?</p>
<p>593<br>00:33:40,920 –&gt; 00:33:42,920<br>It seems less this efficient.</p>
<p>594<br>00:33:42,920 –&gt; 00:33:44,920<br>What do you mean, what do you mean, disc-efficient?</p>
<p>595<br>00:33:44,920 –&gt; 00:33:47,920<br>You have to store extra copies of every two-fold,</p>
<p>596<br>00:33:47,920 –&gt; 00:33:49,920<br>and when you compact, you have to decrease,</p>
<p>597<br>00:33:49,920 –&gt; 00:33:53,920<br>like you have to use other parts of disc to create the compacted picture.</p>
<p>598<br>00:33:53,920 –&gt; 00:33:58,920<br>So the statement is that it’s less efficient because you have to store</p>
<p>599<br>00:33:58,920 –&gt; 00:34:00,920<br>some pinching multiple copies of a two-fold,</p>
<p>600<br>00:34:00,920 –&gt; 00:34:02,920<br>because there’s a bunch of puts for them.</p>
<p>601<br>00:34:02,920 –&gt; 00:34:05,920<br>And then when you do compaction, you basically have to have a staging area,</p>
<p>602<br>00:34:05,920 –&gt; 00:34:09,920<br>or, alas, where you had the two original files you’re trying to compact,</p>
<p>603<br>00:34:09,920 –&gt; 00:34:11,920<br>two or more, and then you’re writing out a new one.</p>
<p>604<br>00:34:11,920 –&gt; 00:34:12,920<br>Yes.</p>
<p>605<br>00:34:12,920 –&gt; 00:34:18,920<br>That’s, I would say, yes. That’s an issue, yes.</p>
<p>606<br>00:34:18,920 –&gt; 00:34:22,920<br>But what about the, related to this point of compaction, what am I doing?</p>
<p>607<br>00:34:22,920 –&gt; 00:34:27,920<br>Well, at some point earlier, I had these log records in memory.</p>
<p>608<br>00:34:27,920 –&gt; 00:34:28,920<br>I wrote them at the disc.</p>
<p>609<br>00:34:28,920 –&gt; 00:34:31,920<br>Now for compaction, what am I doing?</p>
<p>610<br>00:34:31,920 –&gt; 00:34:36,920<br>Reading it back into memory, writing out, back out the disc.</p>
<p>611<br>00:34:36,920 –&gt; 00:34:38,920<br>So this is called write amplification.</p>
<p>612<br>00:34:38,920 –&gt; 00:34:42,920<br>And the idea is that, the issue is that, for every sort of logical write,</p>
<p>613<br>00:34:42,920 –&gt; 00:34:46,920<br>I do my application, like in sort of two-fold, update a single two-fold,</p>
<p>614<br>00:34:46,920 –&gt; 00:34:50,920<br>how many times am I going to read and write it back to disc?</p>
<p>615<br>00:34:50,920 –&gt; 00:34:56,920<br>And in a log-churched approach, potentially infinite.</p>
<p>616<br>00:34:56,920 –&gt; 00:34:59,920<br>Right? If I just keep compacting, compacting over and over again,</p>
<p>617<br>00:34:59,920 –&gt; 00:35:01,920<br>obviously that doesn’t happen.</p>
<p>618<br>00:35:01,920 –&gt; 00:35:06,920<br>But I could potentially do, for a single logical write,</p>
<p>619<br>00:35:06,920 –&gt; 00:35:11,920<br>I could do dozens of physical writes, because I’m bringing it back to memory</p>
<p>620<br>00:35:11,920 –&gt; 00:35:14,920<br>and writing it back out.</p>
<p>621<br>00:35:14,920 –&gt; 00:35:19,920<br>And the page architecture with a lot of pages, we don’t have this problem.</p>
<p>622<br>00:35:19,920 –&gt; 00:35:22,920<br>When I do an update a single two-fold, I bring it, bring it to memory,</p>
<p>623<br>00:35:22,920 –&gt; 00:35:25,920<br>I update it, I write it back out.</p>
<p>624<br>00:35:25,920 –&gt; 00:35:29,920<br>And then if I never updated again, I’d never write it out again.</p>
<p>625<br>00:35:29,920 –&gt; 00:35:32,920<br>We get a gnar back up, so we can ignore the right-hand log,</p>
<p>626<br>00:35:32,920 –&gt; 00:35:34,920<br>we’ll get to that later in the semester.</p>
<p>627<br>00:35:34,920 –&gt; 00:35:38,920<br>But if I’m not reading, I’m not using it, I’m not bringing it to memory</p>
<p>628<br>00:35:38,920 –&gt; 00:35:40,920<br>and writing back out.</p>
<p>629<br>00:35:40,920 –&gt; 00:35:42,920<br>And in a log-churched approach, you have to.</p>
<p>630<br>00:35:42,920 –&gt; 00:35:44,920<br>Okay?</p>
<p>631<br>00:35:44,920 –&gt; 00:35:47,920<br>So again, if you want to go beyond this, there’s the log-churched,</p>
<p>632<br>00:35:47,920 –&gt; 00:35:49,920<br>commercially part of the textbook.</p>
<p>633<br>00:35:49,920 –&gt; 00:35:52,920<br>I think it’s a bit, it’s overly complicated,</p>
<p>634<br>00:35:52,920 –&gt; 00:35:55,920<br>because it’s really about how do you merge these trees,</p>
<p>635<br>00:35:55,920 –&gt; 00:35:57,920<br>it almost looks like the level compaction,</p>
<p>636<br>00:35:57,920 –&gt; 00:36:00,920<br>but I understand that the low level data structure.</p>
<p>637<br>00:36:00,920 –&gt; 00:36:03,920<br>The key thing I want you to understand is here’s a different approach</p>
<p>638<br>00:36:03,920 –&gt; 00:36:07,920<br>to storing tuples through these log records.</p>
<p>639<br>00:36:07,920 –&gt; 00:36:11,920<br>And we’ll see this idea pop up again when we talk about multivertion control</p>
<p>640<br>00:36:11,920 –&gt; 00:36:14,920<br>and when we talk about distributed transactions, distributed databases.</p>
<p>641<br>00:36:14,920 –&gt; 00:36:15,920<br>Yes?</p>
<p>642<br>00:36:15,920 –&gt; 00:36:18,920<br>Why is level compaction in the textbook?</p>
<p>643<br>00:36:18,920 –&gt; 00:36:21,920<br>The question is why is level compaction preferred over universal compaction?</p>
<p>644<br>00:36:21,920 –&gt; 00:36:24,920<br>I don’t know if it actually is.</p>
<p>645<br>00:36:24,920 –&gt; 00:36:27,920<br>I don’t think it makes a difference.</p>
<p>646<br>00:36:27,920 –&gt; 00:36:32,920<br>And I don’t know what the trade-offs are between the two of them.</p>
<p>647<br>00:36:32,920 –&gt; 00:36:39,920<br>Other than it’s like a, I think it’s sort of like a cleaner architecture in terms of like,</p>
<p>648<br>00:36:39,920 –&gt; 00:36:41,920<br>I know at this level, I’m going to get a compacted,</p>
<p>649<br>00:36:41,920 –&gt; 00:36:43,920<br>and it’s going to go to this side and go to the next level.</p>
<p>650<br>00:36:43,920 –&gt; 00:36:46,920<br>Whereas in the universal compaction, you have to have some additional logic inside.</p>
<p>651<br>00:36:46,920 –&gt; 00:36:47,920<br>Okay?</p>
<p>652<br>00:36:47,920 –&gt; 00:36:49,920<br>If I could have merged this guy and this guy or this guy and this guy,</p>
<p>653<br>00:36:49,920 –&gt; 00:36:51,920<br>which one should I do?</p>
<p>654<br>00:36:51,920 –&gt; 00:36:56,920<br>But I don’t think the RoxyB manual has a lot of good information on those, the blog articles.</p>
<p>655<br>00:36:56,920 –&gt; 00:37:00,920<br>I can post on Piazza if you want afterwards.</p>
<p>656<br>00:37:00,920 –&gt; 00:37:01,920<br>Yes?</p>
<p>657<br>00:37:01,920 –&gt; 00:37:05,920<br>So you previously said that those tree audit compactions,</p>
<p>658<br>00:37:05,920 –&gt; 00:37:06,920<br>what does that mean?</p>
<p>659<br>00:37:06,920 –&gt; 00:37:09,920<br>Is it like funny secrets, or is it like all of every read?</p>
<p>660<br>00:37:09,920 –&gt; 00:37:13,920<br>Yes, so the question is, what do I mean by peer-to-conpaction?</p>
<p>661<br>00:37:13,920 –&gt; 00:37:17,920<br>You would have some kind of trigger threshold or something that says it’s time to compact.</p>
<p>662<br>00:37:17,920 –&gt; 00:37:25,920<br>If it’s a level compaction, it could be, okay, I’ve got three of these guys go ahead and run compaction.</p>
<p>663<br>00:37:25,920 –&gt; 00:37:28,920<br>Or it could be, I’ve done this many or right, let’s go ahead and compact.</p>
<p>664<br>00:37:28,920 –&gt; 00:37:35,920<br>It can be done basically at one hour or it’s not, that’s not have to be triggered by a read.</p>
<p>665<br>00:37:35,920 –&gt; 00:37:39,920<br>Correct, it doesn’t have to be triggered by a read, it can be done whenever it, yes.</p>
<p>666<br>00:37:39,920 –&gt; 00:37:42,920<br>But it’s like, how does this?</p>
<p>667<br>00:37:42,920 –&gt; 00:37:49,920<br>It’s like, you need to change the oil in your car.</p>
<p>668<br>00:37:49,920 –&gt; 00:37:55,920<br>You can go a long time beyond the miles when you’re supposed to, but it’s kind of like you shouldn’t.</p>
<p>669<br>00:37:55,920 –&gt; 00:38:01,920<br>So it’s sort of like the best practices you want to, you want to make sure you do the upkeep that you need to do.</p>
<p>670<br>00:38:01,920 –&gt; 00:38:05,920<br>But of course, if you’re running it every second, then that’s going to make your reads go slower.</p>
<p>671<br>00:38:05,920 –&gt; 00:38:08,920<br>So it’s the balance how to figure out how to when to do it.</p>
<p>672<br>00:38:08,920 –&gt; 00:38:11,920<br>And again, we’ll see this when we talk about Postgres and Multivirginers.</p>
<p>673<br>00:38:11,920 –&gt; 00:38:13,920<br>There’s this thing called the auto vacuum.</p>
<p>674<br>00:38:13,920 –&gt; 00:38:21,920<br>When should it run? How it should run? It depends on the workload and the hardware.</p>
<p>675<br>00:38:21,920 –&gt; 00:38:25,920<br>Okay.</p>
<p>676<br>00:38:25,920 –&gt; 00:38:35,920<br>So the two approaches we talked about so far, again, the log structure storage and the sort of the page orange storage.</p>
<p>677<br>00:38:35,920 –&gt; 00:38:37,920<br>These are two-pointer storage.</p>
<p>678<br>00:38:37,920 –&gt; 00:38:48,920<br>These are, and these approaches, we all are going to lie on indexes to find individual tuples that are separate from the sort of core storage of the tables and the tuples themselves.</p>
<p>679<br>00:38:48,920 –&gt; 00:39:01,920<br>Right? In the two-pointer storage, there’s these pages, they’re on ordered, and to get that record ID, it gives us the page number and the slot number, there’s some other magical data structure index, I said, that’s going to get us there.</p>
<p>680<br>00:39:01,920 –&gt; 00:39:10,920<br>Same thing for the log structure storage. We need an index to tell us, for a given record ID, where to go find the data we’re looking for.</p>
<p>681<br>00:39:10,920 –&gt; 00:39:21,920<br>And so an alternative approach is that what if we just keep the tuples automatically sorted by just putting it inside the index itself?</p>
<p>682<br>00:39:21,920 –&gt; 00:39:28,920<br>And then now you don’t have a separate district between, here’s the log structure storage and the index, or here’s the slot of pages, and here’s the index.</p>
<p>683<br>00:39:28,920 –&gt; 00:39:31,920<br>It’s all just indexes.</p>
<p>684<br>00:39:31,920 –&gt; 00:39:35,920<br>And so this is what is called an index-organized storage or index-organized tables.</p>
<p>685<br>00:39:35,920 –&gt; 00:39:43,920<br>And the idea here is that assuming we have some tree data structure, or could be a hash table, we’ll for now we’ll assume trees.</p>
<p>686<br>00:39:43,920 –&gt; 00:39:57,920<br>Instead of having the leaf nodes in the tree with values that provide us the record ID, that tells where to go find the page that has a data we’re looking for, what if the leaf nodes themselves were just the data pages with the tuples?</p>
<p>687<br>00:39:57,920 –&gt; 00:40:10,920<br>So now when I do a look-up and say, find me key 102, I follow this index, and then proof at the bottom, proof at the bottom, and there’s the index I’m looking for.</p>
<p>688<br>00:40:10,920 –&gt; 00:40:14,920<br>Or sorry, there’s the data that I’m looking for.</p>
<p>689<br>00:40:14,920 –&gt; 00:40:16,920<br>So this sort of idea looks like it.</p>
<p>690<br>00:40:16,920 –&gt; 00:40:20,920<br>Again, this is a rough diagram on a B tree, we’ll try to cover soon.</p>
<p>691<br>00:40:20,920 –&gt; 00:40:22,920<br>There’s a situation in the inner nodes, and then the leaf nodes.</p>
<p>692<br>00:40:22,920 –&gt; 00:40:27,920<br>The inner nodes are basically guideposts that tell you for a given key, should I go left or right?</p>
<p>693<br>00:40:27,920 –&gt; 00:40:33,920<br>And then the leaf nodes themselves, these will look a lot just like slot of pages.</p>
<p>694<br>00:40:34,920 –&gt; 00:40:48,920<br>But the difference is that we’re going to sort them in the actual two, or in the page itself, based on the key, and not just a random location in the, based on where we had a free space in the slot of right.</p>
<p>695<br>00:40:48,920 –&gt; 00:41:02,920<br>So now, again, when I want to do a look-up, find me key 102, I traverse the index, I get to a leaf node, I pop over here, and then I do binary search on the list of keys, and then that’ll give me an offset to go find where the data I’m looking for.</p>
<p>696<br>00:41:03,920 –&gt; 00:41:10,920<br>So this is what, this is how my SQL want to use the inner DB engine, this is what you get for SQL light, this is what you get as well.</p>
<p>697<br>00:41:10,920 –&gt; 00:41:17,920<br>I think I said last class in SQL light, they had this internal primary key called the row ID, right?</p>
<p>698<br>00:41:17,920 –&gt; 00:41:24,920<br>And we could see it through SQL, but it’s different than the primary key you may define in your table itself, right?</p>
<p>699<br>00:41:24,920 –&gt; 00:41:34,920<br>Because they’re using index-organized storage, and then the row ID is the key that you do a look-ups inside of this index.</p>
<p>700<br>00:41:34,920 –&gt; 00:41:53,920<br>So for the real primary, sort of the logical primary key, say like a student email address, you would have a separate index that then maps the email address to the row ID, then you do a look-up in the primary key index to get the actual two-poll you’re looking for.</p>
<p>701<br>00:41:54,920 –&gt; 00:41:55,920<br>Yes.</p>
<p>702<br>00:41:59,920 –&gt; 00:42:04,920<br>The question is, is two keys one key for, to get to the page and one key inside the page?</p>
<p>703<br>00:42:04,920 –&gt; 00:42:12,920<br>No, so like if I, again, if I’m, if I SQL light, find me row ID equals one, I just traverse this index, the keys are based on row ID.</p>
<p>704<br>00:42:12,920 –&gt; 00:42:18,920<br>I land in the page, now I need to find within the page where row ID one is, and I do my look-up on this.</p>
<p>705<br>00:42:19,920 –&gt; 00:42:20,920<br>The entire tree is sorted.</p>
<p>706<br>00:42:20,920 –&gt; 00:42:25,920<br>The entire tree is sorted, yes. It has to be, because it’s a balanced tree.</p>
<p>707<br>00:42:27,920 –&gt; 00:42:34,920<br>So you get this in SQL server and, and, and, and Oracle, but not by default, you have to tell it, I want this.</p>
<p>708<br>00:42:34,920 –&gt; 00:42:41,920<br>If you use my SQL Serialite, you get this by default. I don’t, I don’t think you can turn it off. Yes.</p>
<p>709<br>00:42:42,920 –&gt; 00:42:47,920<br>Does this approach do suffer from the downside by fragmentation?</p>
<p>710<br>00:42:47,920 –&gt; 00:42:50,920<br>Yes, so his question is, he’s, it’s, it’s, it’s a good point.</p>
<p>711<br>00:42:50,920 –&gt; 00:42:59,920<br>Does this approach still suffer from the things we talked about before, like fragmentation and, and, uh, random IO?</p>
<p>712<br>00:42:59,920 –&gt; 00:43:10,920<br>Well, so, for fragmentation, yes, it’s unavoidable, because in a B plus tree, uh, it needs to at least have full, so you could, you’re gonna have a bunch of leaf nodes that are, that are, that are, that are good.</p>
<p>713<br>00:43:11,920 –&gt; 00:43:12,920<br>That’s unavoidable.</p>
<p>714<br>00:43:12,920 –&gt; 00:43:20,920<br>In terms of the random IO, if it’s updates to random locations in the, in the leaf nodes, yes. That’s unavoidable.</p>
<p>715<br>00:43:20,920 –&gt; 00:43:31,920<br>But if you’re just inserting, right? Then again, using, uh, using SQLite’s row ID as an example, the row ID is just an eternal counter.</p>
<p>716<br>00:43:31,920 –&gt; 00:43:36,920<br>For every new tuple, recommend that counter by one, one, two, three, four, five, six, seven. It’s a monotonically increasing.</p>
<p>717<br>00:43:36,920 –&gt; 00:43:43,920<br>So if I just keep inserting to SQLite, I’m just gonna keep appending to this side of the tree, and not just the other side of the tree.</p>
<p>718<br>00:43:43,920 –&gt; 00:43:58,920<br>So it’s not as bad as doing a bunch of random IO. It’s not as good as doing the sequential IO you get law-structured, but it’s better than, it may have, in a tuple-oriented storage, because, at least now, the tree is guiding me to only update pages on, on the side over here.</p>
<p>719<br>00:43:58,920 –&gt; 00:44:00,920<br>So there is some benefit to it.</p>
<p>720<br>00:44:00,920 –&gt; 00:44:02,920<br>Yes.</p>
<p>721<br>00:44:02,920 –&gt; 00:44:07,920<br>So the row ID is used for finding a page and the key of that is finding the tuple?</p>
<p>722<br>00:44:07,920 –&gt; 00:44:23,920<br>So the question is, the row ID is, the row ID is finding a page and key ID is finding a tuple. No, so, what I was trying to say is in SQLite, there’s the primary key index that stores the tuples and the leaf nodes.</p>
<p>723<br>00:44:23,920 –&gt; 00:44:30,920<br>But instead of getting whatever the primary key you tell it, like in your create table statement, they have an internal row ID is the primary key.</p>
<p>724<br>00:44:30,920 –&gt; 00:44:41,920<br>So if you do a look up, like, you know, where email address equals Andy, there’s some other index that’s going to give you the row ID, and then you use that to reverse the primary key index.</p>
<p>725<br>00:44:41,920 –&gt; 00:44:51,920<br>In my SQL and ODB, they don’t do that with a row ID. It’ll be the real primary key to declare in the create table statement. That’ll be the key you’re using here.</p>
<p>726<br>00:44:51,920 –&gt; 00:44:54,920<br>And that’s the look up that you have over here.</p>
<p>727<br>00:45:00,920 –&gt; 00:45:11,920<br>Again, and then the pages look like slot architecture where the key and the offsets are growing in one direction and then the tuples are growing in another direction.</p>
<p>728<br>00:45:11,920 –&gt; 00:45:15,920<br>Okay.</p>
<p>729<br>00:45:15,920 –&gt; 00:45:31,920<br>So the three major approaches for storing tuples and sort of within files are going to be the heap storage with this lot of pages, the log structure storage with the pens and the SS tables getting rid of the desk, and then this index organized storage.</p>
<p>730<br>00:45:31,920 –&gt; 00:45:38,920<br>And there’s other one like the isams, but these are archaic or their legacy.</p>
<p>731<br>00:45:38,920 –&gt; 00:45:41,920<br>We don’t need to worry about it.</p>
<p>732<br>00:45:42,920 –&gt; 00:45:46,920<br>All right. So let’s talk about now.</p>
<p>733<br>00:45:46,920 –&gt; 00:45:56,920<br>Once we got once we have a once we got to this, like a tuple, let’s talk about what’s actually in it now.</p>
<p>734<br>00:45:56,920 –&gt; 00:45:59,920<br>So a tuple is just a sequence of bytes.</p>
<p>735<br>00:45:59,920 –&gt; 00:46:05,920<br>And it’s the job of the data is minute system based on the schema that it’s storing in its catalog.</p>
<p>736<br>00:46:05,920 –&gt; 00:46:10,920<br>Like when you call a crate table, I have these attributes of these types.</p>
<p>737<br>00:46:10,920 –&gt; 00:46:17,920<br>It’s the job of the data system to interpret what those bytes actually are and how to do whatever the operation is you want to want on it.</p>
<p>738<br>00:46:17,920 –&gt; 00:46:26,920<br>If I have two columns, column A plus column B, the data system is going to know, okay, well column A is 32 bit integer, column B is 64 bit integer.</p>
<p>739<br>00:46:26,920 –&gt; 00:46:32,920<br>Therefore, I need to do the addition operator based on those two types.</p>
<p>740<br>00:46:33,920 –&gt; 00:46:41,920<br>And so you can sort of think again, just think of it as just a byte buffer, you know, a char array.</p>
<p>741<br>00:46:41,920 –&gt; 00:46:48,920<br>There’ll be some header that says it keeps track of like maybe the size of it, the nulls will probably be on the second.</p>
<p>742<br>00:46:48,920 –&gt; 00:46:56,920<br>And then after the header is done at the first offset, you would have the first column, the ID column, here.</p>
<p>743<br>00:46:56,920 –&gt; 00:47:01,920<br>And then follow, and we know the ID is the integer, so that’s going to be 32 bits.</p>
<p>744<br>00:47:01,920 –&gt; 00:47:05,920<br>Then after 32 bits, we’ll have the value, which would be 64 bits.</p>
<p>745<br>00:47:05,920 –&gt; 00:47:19,920<br>And so internally, basically the data system, if you want to do it in a C++, is looking, gets the starting location of the, of the tuple, right, using whatever the slot array method or how we get to jump to that offset in a page.</p>
<p>746<br>00:47:20,920 –&gt; 00:47:24,920<br>The header is always going to be the same size for every single tuples, we now have to jump past that.</p>
<p>747<br>00:47:24,920 –&gt; 00:47:34,920<br>And then now we just do simple arithmetic to say, I know that the, the, the offset of this first column that I’m looking for is this, so many bits or bytes after the header.</p>
<p>748<br>00:47:34,920 –&gt; 00:47:37,920<br>All right, I want the second column how to get, how to get there.</p>
<p>749<br>00:47:37,920 –&gt; 00:47:47,920<br>VAR Charters are a little complicated, you have to store the length of the field, and that could, that could be in the header, right, or, or in line for now, doesn’t matter.</p>
<p>750<br>00:47:47,920 –&gt; 00:47:57,920<br>But essentially what you’re just doing, you’re just taking some address, and you’re doing the interpret, the interpret cast to say the, the system itself should treat that address.</p>
<p>751<br>00:47:57,920 –&gt; 00:48:02,920<br>That’s talking about that dress as a 30 bit, and you’re 64 bit, and you’re whatever the type is.</p>
<p>752<br>00:48:02,920 –&gt; 00:48:03,920<br>Yes.</p>
<p>753<br>00:48:03,920 –&gt; 00:48:06,920<br>Yes.</p>
<p>754<br>00:48:06,920 –&gt; 00:48:10,920<br>Who else would be doing it?</p>
<p>755<br>00:48:10,920 –&gt; 00:48:15,920<br>We’re writing SQL, right, like some SQL, there’s no interpret cast as SQL. This is like the implementation.</p>
<p>756<br>00:48:15,920 –&gt; 00:48:17,920<br>Yeah.</p>
<p>757<br>00:48:17,920 –&gt; 00:48:24,920<br>Again, this class is like we’re doing this, not, not the top of the program.</p>
<p>758<br>00:48:24,920 –&gt; 00:48:38,920<br>All right, so, so many brothers up last class, and, and, which is good topic, and I want to include it, is one of the things we need to be careful now of, of, in, as we start storing these bits, is dealing with alignment.</p>
<p>759<br>00:48:38,920 –&gt; 00:48:48,920<br>To make sure that the data we’re storing aligns to the, to how the CPU actually wants to operate on data.</p>
<p>760<br>00:48:48,920 –&gt; 00:48:50,920<br>So let me admit this.</p>
<p>761<br>00:48:50,920 –&gt; 00:48:59,920<br>Actually, the reason I put Andy Sucks is like, people take my slides, and they don’t know what Andy Sucks means, and so, I, I Google that, and you find who’s to you copies it.</p>
<p>762<br>00:49:00,920 –&gt; 00:49:22,920<br>All right, so, we need to make sure that all their attributes are aligned to, based on the word boundaries of the CPU, or whatever the architecture we’re running on, to ensure that we don’t end up with unexpected behavior when we do operations on this data, and, and that the CPU doesn’t have to do extra work.</p>
<p>763<br>00:49:22,920 –&gt; 00:49:33,920<br>So let’s say I have a table, I have four columns here, I have a 32-bit integer, a, 64-bit timestamp, a two, four-byte char, and then a zip code, right?</p>
<p>764<br>00:49:33,920 –&gt; 00:49:40,920<br>And so, assume that we’re going to, we’re going to break up our char array representing this two-ball into 64-bit words.</p>
<p>765<br>00:49:40,920 –&gt; 00:49:51,920<br>And the cache lines are 64 bytes, but post-crested lines are based on 64 bits, or I don’t know what SQLite does, but they’re all doing some variation of this.</p>
<p>766<br>00:49:51,920 –&gt; 00:50:07,920<br>All right, so, the first thing we’re going to do is, again, we have our, for IDCOM, that’s 32 bits, we store that there, then we have this, this date timestamp, the creation date, that’s 64 bits, so we just store that right after that, and so forth with the, the other ones.</p>
<p>767<br>00:50:07,920 –&gt; 00:50:24,920<br>So, again, now, when I want to do a lookup in my system to do some operation on this, this, this, byte array that I’ve gotten for this two-ball, say on the customer date, the creation date, the problem with this is that that attribute is going to span two words, right?</p>
<p>768<br>00:50:24,920 –&gt; 00:50:33,920<br>Because this was, each word is 64 bits, the first ID field was 32 bits, so this 64 bits spans two consecutive words.</p>
<p>769<br>00:50:33,920 –&gt; 00:50:45,920<br>So, if you really know what happens when you do this in a CPU, right, when you try to jump to a memory address and do some operation on something that spans the word boundaries.</p>
<p>770<br>00:50:45,920 –&gt; 00:50:49,920<br>What does x86 do?</p>
<p>771<br>00:50:49,920 –&gt; 00:50:58,920<br>So, x86, Intel looks to make your life easy and not buy the word about these things, so they’ll do the extra reads for you.</p>
<p>772<br>00:50:58,920 –&gt; 00:51:18,920<br>So, they want to hide it, they want to hide all the complexities of the architecture, so they’ll do extra work, but now this is going to make your data to some run slower because what should have been, you know, one, one register read or one cashline read to go fetch something into a CPU register, now is going to be two cashline reads, right?</p>
<p>773<br>00:51:18,920 –&gt; 00:51:37,920<br>But again, there’s no error, Intel takes care of it for you, but not every system, not every architecture will do that. Previously before in ARM, they would give you, they would reject it, they would recognize that you’re trying to do a misaligned operation and then throw an error, hoping you would catch it.</p>
<p>774<br>00:51:37,920 –&gt; 00:51:47,920<br>Now, in the newer versions, I think ARM 7, they handle it now like Intel does, but it’s just slower.</p>
<p>775<br>00:51:48,920 –&gt; 00:51:59,920<br>This is rare, but what could happen is that it’ll do the reads for you, but there’s no guarantee that the bits are going to land in the right order, right?</p>
<p>776<br>00:51:59,920 –&gt; 00:52:10,920<br>So, going back here, I have to do two reads to get this word and this word to get put together the date attribute, and they put the last bits in front of the other ones.</p>
<p>777<br>00:52:10,920 –&gt; 00:52:25,920<br>It seems like a terrible idea, but the older CPUs would do that. Of course, that means now you program in random errors and messed up data, and people are going to notice and complain, and that’s bad. Again, that’s part of the reason why Intel tries to hide that from you, even though it makes your thing run slower.</p>
<p>778<br>00:52:25,920 –&gt; 00:52:38,920<br>So, we need to make sure that none of the attributes in our tuple, essentially in our byte array, because again, now we’re talking about things we brought into memory, that none of them are going to span these boundaries.</p>
<p>779<br>00:52:39,920 –&gt; 00:53:00,920<br>So, the two approaches to handle this are padding and reordering. So, with padding, the basic idea is to recognize that if I’m breaking up to 64 bit words, as I add my attributes as going across, if I recognize that the next attribute doesn’t fit within my single word, then I’ll just put a bunch of zeros there and pad that.</p>
<p>780<br>00:53:01,920 –&gt; 00:53:14,920<br>And then internally, the bookkeeping of a system, when it’s interpreting these bytes, it knows that, okay, I need this ID here, and then the date attribute, that’s going to be the next word, so just ignore these 32 bits there.</p>
<p>781<br>00:53:14,920 –&gt; 00:53:30,920<br>The other approach is to reordering. I don’t think any most of the systems don’t do this automatically. Some of the academic systems, we built one that did this, we’ll do this automatically.</p>
<p>782<br>00:53:30,920 –&gt; 00:53:47,920<br>Most systems will lay out the bits exactly where you tell it, and then put padding in to make it better. The idea here is that if I keep the logical view of the table, whatever defined the table statement, I’ll tell you things are sorted in this order.</p>
<p>783<br>00:53:47,920 –&gt; 00:53:57,920<br>But underneath the covers, I’ll just move things around to, so I can pack things in better, and then if necessary, I’ll pad bits at the end like that.</p>
<p>784<br>00:53:57,920 –&gt; 00:54:02,920<br>How long does a bar chart start to do this? Especially for the ordering or the filing.</p>
<p>785<br>00:54:02,920 –&gt; 00:54:07,920<br>This question is, how do bar charts handle this case, especially for padding?</p>
<p>786<br>00:54:07,920 –&gt; 00:54:21,920<br>Yeah, for padding. That’s what I’m saying. So, in the systems that do automatic reordering, you don’t store the bar charts in line, and less there’s 64 bits or less.</p>
<p>787<br>00:54:21,920 –&gt; 00:54:36,920<br>And instead, you store a pointer to some other location that, we’ll save in a second, these external, these oversized attribute tables or pages that are sort of separated. So, you can do this reordering and not worry about verve length things.</p>
<p>788<br>00:54:36,920 –&gt; 00:54:38,920<br>Yeah.</p>
<p>789<br>00:54:38,920 –&gt; 00:54:41,920<br>Do we need to last words for the two things?</p>
<p>790<br>00:54:41,920 –&gt; 00:54:46,920<br>Do I need this last, like this thing here? Do I need this? No.</p>
<p>791<br>00:54:50,920 –&gt; 00:54:59,920<br>So, we can see this in Postgres. Postgres will not do automatic reordering, but it will do padding.</p>
<p>792<br>00:54:59,920 –&gt; 00:55:16,920<br>And there’s some simple things we can see about, like if we reorder the reorder, reorder the create table, say, reorder tuples that we can store things in less space.</p>
<p>793<br>00:55:16,920 –&gt; 00:55:28,920<br>So, there’s more Postgres syntax here, but Postgres has this nice little function called row, and essentially it just takes the comma, separated list of values you give it.</p>
<p>794<br>00:55:28,920 –&gt; 00:55:33,920<br>And it makes a row, right? And then we can cast it now.</p>
<p>795<br>00:55:33,920 –&gt; 00:55:44,920<br>We can add this colon colon thing at the end of all our values, and that’ll basically casting the value to a given type.</p>
<p>796<br>00:55:44,920 –&gt; 00:55:53,920<br>So, I can do a small ant, a regular ant, and a big ant. So, 2 byte ant, 4 byte ant, or 8 byte ant, right?</p>
<p>797<br>00:55:54,920 –&gt; 00:56:06,920<br>So, now Postgres has a nice little function called PG column size that’ll tell you the size of this record, this tuple, in bytes.</p>
<p>798<br>00:56:06,920 –&gt; 00:56:15,920<br>So, in this case here, it’s telling me the size of this row that I created for bytes. So, I go back to my previous one, and run that.</p>
<p>799<br>00:56:16,920 –&gt; 00:56:23,920<br>Sorry.</p>
<p>800<br>00:56:28,920 –&gt; 00:56:36,920<br>Go back to the row I had before without casting to types until these 36, right?</p>
<p>801<br>00:56:36,920 –&gt; 00:56:56,920<br>Which makes sense because this last one here, I was making that 64 bit integer, or Postgres, I think in this case, it’s storing it as all 8 bytes, 4 byte ant, 32 bit ant, and then a little extra space for padding.</p>
<p>802<br>00:56:57,920 –&gt; 00:57:17,920<br>So, we can see this now if we take a, let me do it first without the size. So, let’s make a row that has some char’s, and then 2 byte, 4 byte, and 8 byte integers.</p>
<p>803<br>00:57:17,920 –&gt; 00:57:29,920<br>But I’m intermixing the char’s with the integers, right? So, if now if I say, I suppose, what is the size of this? I get 48 bytes.</p>
<p>804<br>00:57:29,920 –&gt; 00:57:39,920<br>But if I redo it where I put all the integers first, basically reordering as I was shown before, and then put the char’s all at the end, now I get down to 44 bytes.</p>
<p>805<br>00:57:39,920 –&gt; 00:57:49,920<br>Again, Postgres has to pad things out to make sure that everything is 64 bit aligned. But it doesn’t do this where you automatically, you have to tell Postgres I want this.</p>
<p>806<br>00:57:49,920 –&gt; 00:57:54,920<br>Again, where there’s some systems that can do this automatically.</p>
<p>807<br>00:57:55,920 –&gt; 00:58:07,920<br>Makes sense? Again, I like this because just through SQL commands, we can get a view to the internals of the storage manager of a database system to say, how is it actually laying things out?</p>
<p>808<br>00:58:08,920 –&gt; 00:58:09,920<br>Okay?</p>
<p>809<br>00:58:13,920 –&gt; 00:58:25,920<br>So now, let’s talk about the bar char’s a little bit. Let’s talk about the other sort of the core SQL data types and how the new system is actually going to represent them.</p>
<p>810<br>00:58:26,920 –&gt; 00:58:39,920<br>So for all integer data types, these are essentially going to be the same thing as you get when you allocate a variable of an integer type or a large in whatever in C++.</p>
<p>811<br>00:58:39,920 –&gt; 00:58:59,920<br>It’s going to be the same representation because that’s what the harbor supports. The harbor is going to have a standard representation for whatever two complement integers either signed or unsigned, whatever you get in C++, that follows the standard and that’s what the harbor supports and that’s what you get in SQL.</p>
<p>812<br>00:59:00,920 –&gt; 00:59:16,920<br>For floating point numbers, there will be floating point or real numbers. Again, that’s defined in the IEEE 754 standard, that specifies how harbor should represent these decimal numbers.</p>
<p>813<br>00:59:16,920 –&gt; 00:59:25,920<br>But every data system is also going to have what are called fixed point decimals. So numeric or decimal, where each of those implementations are going to be different per system.</p>
<p>814<br>00:59:26,920 –&gt; 00:59:43,920<br>And we can see the performance difference of the two approaches in a second. For bar char, bar binary, text and blobs, these are typically going to be stored as something that with a header that tells you the length of it, followed by the bytes of the actual value.</p>
<p>815<br>00:59:43,920 –&gt; 00:59:55,920<br>And if it’s too big to be stored in line in the two both itself within a page, there will be a pointer to some other page that has the data that you need for this attribute.</p>
<p>816<br>00:59:55,920 –&gt; 01:00:10,920<br>So I said for a memory system, if it’s less than 64 bits, they’ll store it in line if it’s not, then they store pointer in a dispased database system. It’s going to depend on the implementation.</p>
<p>817<br>01:00:11,920 –&gt; 01:00:26,920<br>And we’ll see that in a second. For timestamps, dates, and intervals and so forth, these are going to be typically 32 or 64 bit integers. That’s just the number of milliseconds or microseconds since the Unix e-pot by January 1, 1970.</p>
<p>818<br>01:00:26,920 –&gt; 01:00:46,920<br>And if you want to store this with timestamp information, typically they’ll store it as based on UTC timestamp, or GMT0, and then they store additional metadata to say what timestamp are you in, and they can convert it as needed. And the system handles that for you.</p>
<p>819<br>01:00:46,920 –&gt; 01:01:06,920<br>So because for these types up here, the integer types, because we’re relying on the hardware to store whatever, to store the data, how the hardware wants to represent it, that typically needs you just can’t copy the files, like the raw database files that you generate from one architecture to another.</p>
<p>820<br>01:01:06,920 –&gt; 01:01:20,920<br>So if it’s big Indian or little Indian, like x86 is little Indian power and arm or big Indian, like you can’t take the binary files from the data system and put it to another one, because the bits are going to flip and it’ll get messed up.</p>
<p>821<br>01:01:20,920 –&gt; 01:01:40,920<br>So SQLite avoids this problem because they store everything as actually varchars. And at runtime, they cast things based on the type in the attribute, because then they get that portability guarantee, no matter where you plop the file in, they’ll always have it in the right order.</p>
<p>822<br>01:01:41,920 –&gt; 01:01:50,920<br>So spend a little time talking about fluids and reels and Americs. And then again, this will be a good example of where the database systems are going to do something different.</p>
<p>823<br>01:01:51,920 –&gt; 01:02:01,920<br>And the, you can’t just rely on the hardware to do certain things where you, because we care about correctness of data and the hardware can’t guarantee that for us.</p>
<p>824<br>01:02:02,920 –&gt; 01:02:13,920<br>So for variable precision numbers, just like before in integers, we’re going to rely on the SQLite’s implementation for this.</p>
<p>825<br>01:02:14,920 –&gt; 01:02:21,920<br>So if you call float, real or double in SQL, you’ll get the same float or double you would get in SQLite’s.</p>
<p>826<br>01:02:22,920 –&gt; 01:02:29,920<br>So typically, these are going to be faster than the fixed point numbers, so we’ll see in a second, because the hardware can natively support this.</p>
<p>827<br>01:02:32,920 –&gt; 01:02:46,920<br>But the problem is though, they’re not going to have the, they can’t guarantee that the correctness of values when you start doing larger calculations, because they’re rounding issues, because you can’t store exactly, you know, decimals in hardware.</p>
<p>828<br>01:02:47,920 –&gt; 01:02:56,920<br>So everyone’s probably seen, you know, a simple test program like this when you first learn C or C++, right? I have two floaty point numbers, two thirty to do bit floaty point numbers.</p>
<p>829<br>01:02:57,920 –&gt; 01:03:02,920<br>I want to store 0.1 and 0.2, and then I just want to add them together and see what the output is.</p>
<p>830<br>01:03:03,920 –&gt; 01:03:12,920<br>So in the first version, I’ll just call printf to dump out the, you know, x plus y like that, and I would expect I would get something that should look at 0.3.</p>
<p>831<br>01:03:14,920 –&gt; 01:03:17,920<br>And when I run that, I actually get that, that looks, that looks okay.</p>
<p>832<br>01:03:18,920 –&gt; 01:03:29,920<br>But in actual Audi, if I increase the number of digits, I’m going to write out in my printf statement, now end up with something that looks like this.</p>
<p>833<br>01:03:32,920 –&gt; 01:03:37,920<br>Because again, the horror can’t represent 0.3 exactly, it’s going to be some approximation based on that.</p>
<p>834<br>01:03:38,920 –&gt; 01:03:46,920<br>So okay, if I’m doing, you know, a simple program like before, where I was doing x plus y, and I print that out to a human, yeah, sure, maybe that’s not a big deal, right?</p>
<p>835<br>01:03:47,920 –&gt; 01:03:58,920<br>But if I’m doing, you know, complex calculations, because I’m trying to land something on the moon, or, you know, put a satellite in space, or if it’s your bank account, and you’re doing interest calculations, then this rounding arrow is actually going to matter.</p>
<p>836<br>01:03:59,920 –&gt; 01:04:00,920<br>And people are going to notice in the plane.</p>
<p>837<br>01:04:02,920 –&gt; 01:04:13,920<br>So for this reason, database systems are also going to provide these fixed precision numbers, or fixed point decimals, where the data systems are going to do a bunch of extra work to make sure that you don’t have these rounding errors.</p>
<p>838<br>01:04:13,920 –&gt; 01:04:20,920<br>You can get this in Java with big decimal, you can get this in Python, I think with decimal type as well, right?</p>
<p>839<br>01:04:21,920 –&gt; 01:04:31,920<br>They’re all basically, all the different systems are going to do something slightly different, but at a high level essentially they’re going to store a, a, a, a very long representation of the number you’re trying to represent.</p>
<p>840<br>01:04:32,920 –&gt; 01:04:39,920<br>And then additional metadata tell you where the decimal point is, or whether it’s signed or unsigned, or is it negative, or not a number and so forth, right?</p>
<p>841<br>01:04:39,920 –&gt; 01:04:42,920<br>Again, we have to do this extra work because the horror can’t guarantee this for us.</p>
<p>842<br>01:04:44,920 –&gt; 01:04:57,920<br>So here’s what Postgres does. So this is the numeric type of Postgres. This is actually from the source code itself, and you can see that they’re going to represent the type of numeric as some kind of struct, with a bunch of additional metadata about what the number actually is.</p>
<p>843<br>01:04:58,920 –&gt; 01:05:07,920<br>But the core thing they’re storing that internally, along with this metadata of like, here’s how to store the actual number itself, is this numeric digit array here.</p>
<p>844<br>01:05:07,920 –&gt; 01:05:21,920<br>Well, that’s just a typecast to an unsigned chart above. So they’re literally storing your decimal as a, as a string value, and then they use this metadata to figure out, you know, how to then interpret that string to, to put it to be the correct form.</p>
<p>845<br>01:05:23,920 –&gt; 01:05:27,920<br>So again, the horror doesn’t know anything about this. This is what the data system has, has simple but it.</p>
<p>846<br>01:05:27,920 –&gt; 01:05:38,920<br>So we can’t just do x plus y, but we can in c plus plus, we’ve got to do more complicated arithmetic when you want to start calculating or using these numeric types in queries.</p>
<p>847<br>01:05:39,920 –&gt; 01:05:52,920<br>So this is a pretty snippet of the addition function for two numerics in Postgres. And as you can see, there’s a bunch of checks for that struct, where checkers see whether it’s zero, or negative, or sign, or whatever. And this is just to add two numbers together.</p>
<p>848<br>01:05:52,920 –&gt; 01:05:59,920<br>This is obviously way more expensive than, you know, calling a single instruction in the CPU, you know, x plus y.</p>
<p>849<br>01:06:01,920 –&gt; 01:06:15,920<br>I don’t want to give the impression I’m, I’m, I’m, I’m shaming Postgres. My SQL has the same issue, right? They’re doing the same thing. They’re going to store their, uh, set it their digits as a bar chart that can store it as a third-debit integer.</p>
<p>850<br>01:06:15,920 –&gt; 01:06:29,920<br>Again, they have additional metadata to keep track of what the, what the thing, what the numeric type actually is. And just like Postgres, they’re going to have a, you know, their own implementations of doing addition that does need all the additional checks.</p>
<p>851<br>01:06:31,920 –&gt; 01:06:34,920<br>It’s not sexy, but you know, you do need it.</p>
<p>852<br>01:06:34,920 –&gt; 01:06:53,920<br>So in the sake of time, if you have time in the end, we can do a demo to show you the performance difference. But it’s about 2x, right? The, the, the numeric versions, or the, the, the, the, the davis implemented versions of these decimals, it’d be about 2x slower than the, than like the hardware versions.</p>
<p>853<br>01:06:53,920 –&gt; 01:07:08,920<br>All right, for nulls, the, the most common way to do this is that for every single tuple in that header will be a bitmap that keeps track of which attributes that are set the null for that to give in tuple.</p>
<p>854<br>01:07:09,920 –&gt; 01:07:21,920<br>Right? And again, the, the header, the size of this bitmap will vary based on the number attributes you do have, which we know whether it could be null or not because it’s in the create table statement.</p>
<p>855<br>01:07:21,920 –&gt; 01:07:39,920<br>Right? Again, this is the advantage of using a schema instead of destroying JSON, whatever in there, we have a schema. We know whether a column has been been defined as not null or not. And therefore, if it, if it has been declared as not null, we don’t need to store this bitmap or you don’t need to store entry for it.</p>
<p>856<br>01:07:40,920 –&gt; 01:07:48,920<br>So this is the most common approach. Now there’s been some overhead here, right? For every single tuple now in the header, we got to have this, this, this bitmap.</p>
<p>857<br>01:07:48,920 –&gt; 01:08:04,920<br>Last common, but another approach to do this would be to have special values where you basically say there’s some value within the range of values I could have for each type that if I had that value, then I assume that it’s, it’s a null.</p>
<p>858<br>01:08:05,920 –&gt; 01:08:17,920<br>So if I want to know whether a, a 30-bit engine is, is null, then I’ll say the, the 30-bit min number I could have, like negative whatever it is, if my value is that, then I’ll treat that as null.</p>
<p>859<br>01:08:18,920 –&gt; 01:08:33,920<br>So there’s one less value I could potentially store, and now there’s a bunch of extra stuff I had to do in the rest of my system to keep track of, okay, if I’m looking at a 30-bit integer, if it is that min value, then I know it’s null. And not, you know, not let people insert it arbitrarily.</p>
<p>860<br>01:08:34,920 –&gt; 01:08:51,920<br>The worst choice, and I don’t have a, I don’t have a screenshot of this, actually I might, the worst choice, if I only see one system ever actually do, is for every single tuple itself, sorry, everything will attribute in the tuple, you have a little flag in front of it, tells you whether it’s null or not.</p>
<p>861<br>01:08:52,920 –&gt; 01:09:10,920<br>And the reason why this is terrible is because, it’s like when we talked about alignment, right, I can’t have a, you know, I can’t have a 32-bit integer and put one bit in front of it to say, hey, this thing is null or not, I got to store another byte.</p>
<p>862<br>01:09:10,920 –&gt; 01:09:24,920<br>I said, now all my 30-bit integers, and if I want to be 64-bit aligned, and maybe I got to store the double size, so like, if, to store 30-bit integer, to keep track of this null, if I’m putting this flag in front of it, I may have to store another 30-bit, just to have one bit to say that it’s null or not.</p>
<p>863<br>01:09:24,920 –&gt; 01:09:37,920<br>Do I have a screenshot here on the C? The only system that I know that actually did this was MemSQL, which is the earlier name of, of single store.</p>
<p>864<br>01:09:37,920 –&gt; 01:09:47,920<br>So despite them, you know, sponsoring the class, I don’t have the screenshot here, I’ll put some slack. That was the sheetish idea, it’s one of the sheetish ideas I’ve ever seen.</p>
<p>865<br>01:09:47,920 –&gt; 01:09:53,920<br>But they got rid of it, because it’s super wasteful, and they do the column header now.</p>
<p>866<br>01:09:53,920 –&gt; 01:10:05,920<br>For large values, like really large values, the most data systems are not going to let you store them directly in the page itself.</p>
<p>867<br>01:10:05,920 –&gt; 01:10:16,920<br>Again, a page size is defined by the data system, and every single page within that table has to have the same page size.</p>
<p>868<br>01:10:16,920 –&gt; 01:10:23,920<br>There’s an experimental system at a Germany that they can support via link pages, we can ignore that, nobody else does that.</p>
<p>869<br>01:10:23,920 –&gt; 01:10:32,920<br>But so that means that, like at some point, I’ve decided, should I store this large varchar, large string in my tuple page or not?</p>
<p>870<br>01:10:33,920 –&gt; 01:10:41,920<br>For this, if it exceeds, for everything that they’re going to have different thresholds, say, when can you not store it, and when you have to put it into what is called an overflow page.</p>
<p>871<br>01:10:41,920 –&gt; 01:10:48,920<br>So in Postgres, they call it the Toast, I forget about this actually stands for, but any attribute that’s larger than two kilobytes, those storage is a separate page.</p>
<p>872<br>01:10:48,920 –&gt; 01:10:57,920<br>And then in the actual tuple itself, those have a pointer, a record ID, and an offset, then points to where to go find the actual value that you’re looking for.</p>
<p>873<br>01:10:58,920 –&gt; 01:11:15,920<br>And again, you as the SQL programmer, you don’t know this, you don’t care, you call a select star on the query, and the day systems are responsible for going, reading the base tuple, recognizing that it’s pointing to an overflow page, go get that data, and then copy it into the buffer that it then produces the output for you.</p>
<p>874<br>01:11:15,920 –&gt; 01:11:19,920<br>So it hides underneath the covers that it’s actually done this for you.</p>
<p>875<br>01:11:19,920 –&gt; 01:11:27,920<br>So Postgres is two kilobytes, they’re up to eight kilobytes. I think you can tune this, but it goes up to, obviously you can’t exceed eight kilobytes.</p>
<p>876<br>01:11:27,920 –&gt; 01:11:39,920<br>And my SQL, the overflow size is one half the current page size, and then in SQL Server, surprisingly, you can set the default is if it exceeds the size of the page, then it overflows.</p>
<p>877<br>01:11:39,920 –&gt; 01:11:51,920<br>So the size of the data trying to store in this oversized attribute plus the regular data, the combination of that exceeds the size of a page, then they’ll put the oversized data to another page.</p>
<p>878<br>01:11:51,920 –&gt; 01:12:02,920<br>And you can chain these things together. So if you say you want to store for whatever reason, a one gigabyte video, or 10 gigabyte video, your data system couldn’t let you do that.</p>
<p>879<br>01:12:02,920 –&gt; 01:12:13,920<br>And then this overflow page, since they all have to be the same fixed length size as well, it could just have a pointer to say, okay, here’s the data for this range of the data for this attribute, but oh, by the way, here’s a pointer to the next page.</p>
<p>880<br>01:12:13,920 –&gt; 01:12:21,920<br>And you’ve got to follow along that linked list, go get all the data and put it back together.</p>
<p>881<br>01:12:21,920 –&gt; 01:12:35,920<br>So the last thing you can do is called external file storage, just short of value storage. And this is where the database system is not going to store the large attribute in pages that it manages.</p>
<p>882<br>01:12:35,920 –&gt; 01:12:54,920<br>It’s going to write it out to your local file system, and then internally store the URI or the URL, where that data is located, so that when you query against the table, and you go get that attribute, it goes to the OS and goes gets that data, copies it into its buffer, and then hands it back to you.</p>
<p>883<br>01:12:55,920 –&gt; 01:13:05,920<br>So I think only postcard or sort of Oracle and SQL Server can do this. In Oracle, they’re called B files, Microsoft called file streams.</p>
<p>884<br>01:13:05,920 –&gt; 01:13:18,920<br>And again, it’s just a URI to some data on this, and it does the CIS call to go get it from the operating system. And postcards, you can do this for the confrorn data wrappers.</p>
<p>885<br>01:13:18,920 –&gt; 01:13:30,920<br>There’s additional mechanisms to go store data and cloud storage, and then again, now within a single SQL interface, I can go fetch the data, and it haven’t appeared as if it was in the table itself.</p>
<p>886<br>01:13:30,920 –&gt; 01:13:38,920<br>So when we write things out to these external files, the data system cannot make any changes to it.</p>
<p>887<br>01:13:38,920 –&gt; 01:13:53,920<br>It’s like you’re written out to the file system, I’m not going to go and make in place updates to it. I can’t update it. I can only read it in, and then if I delete the two-po that’s pointing to this file, there’s mechanisms inside, do I just want to delete the file as well.</p>
<p>888<br>01:13:53,920 –&gt; 01:14:07,920<br>And so the reason why you may want to do this is because, as I said, you don’t want to store a 10 gigabyte file in your database system for management reasons, because then it’s a log record, that comes expensive.</p>
<p>889<br>01:14:07,920 –&gt; 01:14:22,920<br>But also, too, typically, database-minute systems are stored on higher end hardware, and that makes storage expensive. Like if you use Amazon RDS, I think they charge 4x more for storage, and they didn’t get from EBS.</p>
<p>890<br>01:14:22,920 –&gt; 01:14:35,920<br>And certainly EBS is even more if you have a locally attached disk. So you don’t want to be storing these large files that maybe are only read directly in the data that’s managed by the files that are managed by the data system.</p>
<p>891<br>01:14:35,920 –&gt; 01:14:40,920<br>Let the OS on some cheaper storage handle that for you.</p>
<p>892<br>01:14:40,920 –&gt; 01:14:50,920<br>So there’s a paper from, I’m 15 years old now, from Jim Gray, which is one of the guys that went that the attorney went for databases in the 90s, and he invented a lot of the stuff we’re talking about this semester.</p>
<p>893<br>01:14:50,920 –&gt; 01:14:59,920<br>He had a paper he wrote at Microsoft a few years ago that talks about whether should you store large data in a data system or not.</p>
<p>894<br>01:14:59,920 –&gt; 01:15:06,920<br>And I think for their recommendation, they said anything larger than 250 kilobytes stored externally.</p>
<p>895<br>01:15:06,920 –&gt; 01:15:16,920<br>Again, this is a while ago. I don’t, I wouldn’t recommend that anymore. And actually we had the guy that invented SQL Light. He came to CMU, gave a talk five years ago.</p>
<p>896<br>01:15:16,920 –&gt; 01:15:24,920<br>And he mentioned that in his experience, it’s actually better to store things in SQL Light, like if you’re running on a phone app.</p>
<p>897<br>01:15:24,920 –&gt; 01:15:34,920<br>So if you have like your application has a bunch of thumbnails, images, you’re better off storing that in the data system because now when you go retrieve them, your application already has the handles of the data system open.</p>
<p>898<br>01:15:34,920 –&gt; 01:15:45,920<br>It’s already in the files already open. So it’s much faster to go get those thumbnails directly from the data system versus having to do a bunch of F opens and F reads to a bunch of files on disk.</p>
<p>899<br>01:15:45,920 –&gt; 01:15:53,920<br>So I would say, I mean, this is pure conjecture. 50 megs or less is probably OK. Anything beyond that, you want to use external storage.</p>
<p>900<br>01:15:53,920 –&gt; 01:16:02,920<br>And ORMs like Django and other other application frameworks, they have mechanisms to handle that for you.</p>
<p>901<br>01:16:03,920 –&gt; 01:16:12,920<br>So next class, next class will continue on storage, talk about storage models and then column versus road, road storage.</p>
<p>902<br>01:16:12,920 –&gt; 01:16:20,920<br>And this will be again, explain to you why ducty B is faster than SQL Light. And on that note, the ducty B people will set me stickers.</p>
<p>903<br>01:16:20,920 –&gt; 01:16:24,920<br>If you want one, come get one. I have pins too. Hit it.</p>
<p>904<br>01:16:33,920 –&gt; 01:16:51,920<br>I’m the poppy with the motherfucking ho ho 28 a gram depending on if it’s good. You ain’t hit them all yet. Still got your sugar. I smack you with the bottom of the tip to tell you.</p>
<p>905<br>01:16:52,920 –&gt; 01:16:57,920<br>Show me what it’s safe set for I blow your face back. I got a block on tap. The feds can’t trace that.</p>
<p>906<br>01:16:57,920 –&gt; 01:17:08,920<br>Style is like temp, but proof. You can’t lace that at the Dominican. Oh you got. Call me Dominican. Black Skelly. Black leather. Black sweat Timberlands. My whole black 38 is sent you to the perigates.</p>
<p>907<br>01:17:08,920 –&gt; 01:17:16,920<br>You get the zombie trying to skate and that’s your first mistake. I ain’t lying for that cake. You’re famous. See you wait. My grandson’s happy wait. The Randthaw ever stayed.</p>
<p>908<br>01:17:16,920 –&gt; 01:17:23,920<br>When he had to how I’m living, I tell him I’m living great.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CMU15445 P5F202304 DatabaseStoragePart2</div>
      <div>http://example.com/2025/10/24/CMU15445 P5F202304-DatabaseStoragePart2/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月24日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/24/CMU15445%20P7F202306-DatabaseMemoryDiskI%E2%A7%B8OManagement/" title="CMU15445 P7F202306 DatabaseMemoryDiskI⧸OManagement">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CMU15445 P7F202306 DatabaseMemoryDiskI⧸OManagement</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/24/CMU15445%20P4F202303-DatabaseStoragePart1/" title="CMU15445 P4F202303 DatabaseStoragePart1">
                        <span class="hidden-mobile">CMU15445 P4F202303 DatabaseStoragePart1</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
