

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:06,000Canneke Mellon University’s advanced database systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio boardies. 300:00:17,000 –&gt; 00:00:18,00">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU15721 P13S202412 DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems">
<meta property="og:url" content="http://example.com/2025/10/24/CMU15721%20P13S202412-DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:06,000Canneke Mellon University’s advanced database systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio boardies. 300:00:17,000 –&gt; 00:00:18,00">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-24T11:57:41.745Z">
<meta property="article:modified_time" content="2025-10-24T12:06:28.544Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>CMU15721 P13S202412 DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CMU15721 P13S202412 DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-24 19:57" pubdate>
          2025年10月24日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          14k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          117 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CMU15721 P13S202412 DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:06,000<br>Canneke Mellon University’s advanced database systems courses</p>
<p>2<br>00:00:06,000 –&gt; 00:00:09,000<br>filming front of the live studio boardies.</p>
<p>3<br>00:00:17,000 –&gt; 00:00:18,000<br>We’re all gonna die.</p>
<p>4<br>00:00:18,000 –&gt; 00:00:19,000<br>Okay.</p>
<p>5<br>00:00:19,000 –&gt; 00:00:21,000<br>In the meantime, let’s do the databases.</p>
<p>6<br>00:00:21,000 –&gt; 00:00:24,000<br>Alright, so today’s class we’re gonna talk about networking protocols.</p>
<p>7<br>00:00:24,000 –&gt; 00:00:26,000<br>And then this will be the…</p>
<p>8<br>00:00:26,000 –&gt; 00:00:28,000<br>We’re sort of hitting the…</p>
<p>9<br>00:00:28,000 –&gt; 00:00:30,000<br>We’re called the second third…</p>
<p>10<br>00:00:30,000 –&gt; 00:00:33,000<br>We’re finishing up sort of the second third of the semester of the materials.</p>
<p>11<br>00:00:33,000 –&gt; 00:00:37,000<br>So this week and then for the next two weeks we’ll talk about query optimization.</p>
<p>12<br>00:00:37,000 –&gt; 00:00:41,000<br>And then after that we’ll go through and start reading the papers for</p>
<p>13<br>00:00:41,000 –&gt; 00:00:44,000<br>you know, major systems and understanding, you know, how they work and putting…</p>
<p>14<br>00:00:44,000 –&gt; 00:00:49,000<br>The things we talk about this semester start seeing how they’re gonna be applied by the companies</p>
<p>15<br>00:00:49,000 –&gt; 00:00:51,000<br>and the people building these various systems.</p>
<p>16<br>00:00:51,000 –&gt; 00:00:52,000<br>Okay?</p>
<p>17<br>00:00:52,000 –&gt; 00:00:56,000<br>So last class was all about how to take user-dried functions that some…</p>
<p>18<br>00:00:56,000 –&gt; 00:01:00,000<br>The application level has written because they went in bed logic that would normally be in the application.</p>
<p>19<br>00:01:00,000 –&gt; 00:01:04,000<br>They went in bed that directly inside of the database system and evoked through a query.</p>
<p>20<br>00:01:04,000 –&gt; 00:01:11,000<br>And the idea was through inlining techniques we can convert the UDF constructs into…</p>
<p>21<br>00:01:11,000 –&gt; 00:01:16,000<br>To SQL or the Azure Algebra and then have that be exposed to the query optimization</p>
<p>22<br>00:01:16,000 –&gt; 00:01:21,000<br>or to figure out what the intent and what the user-dried function actually wanted to do.</p>
<p>23<br>00:01:21,000 –&gt; 00:01:26,000<br>Alright, so this is an example again of pushing the application logic into the database system.</p>
<p>24<br>00:01:26,000 –&gt; 00:01:34,000<br>So as I said at the end of last class, today’s lecture is about how to sort of do the opposite of get data out of the database system</p>
<p>25<br>00:01:34,000 –&gt; 00:01:39,000<br>and bring it over to the application so the application could process it and do what it wants.</p>
<p>26<br>00:01:39,000 –&gt; 00:01:45,000<br>So we’ll first talk about, you know, start off with talking about what these different database access APIs look like.</p>
<p>27<br>00:01:45,000 –&gt; 00:01:50,000<br>Then we’ll go into more details of what the network protocols look like and that was the paper you guys were assigned to read</p>
<p>28<br>00:01:50,000 –&gt; 00:01:58,000<br>about actually what do the bits look like and how it’s inefficient for in modern application scenarios</p>
<p>29<br>00:01:58,000 –&gt; 00:02:04,000<br>where data scientists maybe working in pandas or some Python notebook and want to just want to do a select star</p>
<p>30<br>00:02:04,000 –&gt; 00:02:08,000<br>and get a bunch of data out and then do all the processing on the client side.</p>
<p>31<br>00:02:08,000 –&gt; 00:02:18,000<br>So we’ll see how the sort of the major database system today, the existing protocols are insufficient or not designed for that kind of workload.</p>
<p>32<br>00:02:18,000 –&gt; 00:02:23,000<br>The answer is going to be the end is going to be Apache Arrow is the solution.</p>
<p>33<br>00:02:23,000 –&gt; 00:02:30,000<br>Right? So the paper you guys read came out before the arrow, the database connectivity library stuff was defined</p>
<p>34<br>00:02:30,000 –&gt; 00:02:35,000<br>but they basically are reinventing the same thing and then ADBC and Arrow would do the same thing.</p>
<p>35<br>00:02:35,000 –&gt; 00:02:37,000<br>We’ll build up to that.</p>
<p>36<br>00:02:37,000 –&gt; 00:02:43,000<br>Then we’ll talk about additional optimizations we can do on the server side to make things run faster at the networking stack</p>
<p>37<br>00:02:43,000 –&gt; 00:02:48,000<br>or potentially for other parts of the system by either doing kernel bypass or user space bypass</p>
<p>38<br>00:02:48,000 –&gt; 00:02:54,000<br>and then we’ll finish up quickly to talk about what some additional optimizations we can do on the client side</p>
<p>39<br>00:02:54,000 –&gt; 00:03:00,000<br>if we know our Python program or whatever it is is talking to a database system and it’s going to put some data into a data print.</p>
<p>40<br>00:03:00,000 –&gt; 00:03:02,000<br>Right?</p>
<p>41<br>00:03:02,000 –&gt; 00:03:10,000<br>So I would say some of the things we’ll talk about today will be applicable for back end communication between the various database like the workers in your system.</p>
<p>42<br>00:03:10,000 –&gt; 00:03:19,000<br>Like, you know, if it’s a parallel system and one worker needs to communicate with another worker or needs to communicate with the optimizer service or the scheduler service.</p>
<p>43<br>00:03:19,000 –&gt; 00:03:23,000<br>Right? A lot of these things we’ll talk about in that environment will still matter.</p>
<p>44<br>00:03:23,000 –&gt; 00:03:27,000<br>Certainly kernel bypass stuff could help or you use bypass stuff can help.</p>
<p>45<br>00:03:27,000 –&gt; 00:03:35,000<br>But like the, you know, this is really, we’re going to mostly focus on like how do we actually expose data to the client and have to make that</p>
<p>46<br>00:03:35,000 –&gt; 00:03:46,000<br>that one efficiently. But we’ll see when we go through the discussions of the real world systems where some, some, there are some optimization if you can apply it in the back end.</p>
<p>47<br>00:03:46,000 –&gt; 00:03:56,000<br>All right. So last class, I showed a really quick demo of opening up the postgres terminal and, you know, writing a SQL query and hitting enter and then getting back some results.</p>
<p>48<br>00:03:56,000 –&gt; 00:04:04,000<br>Right? That’s, so that’s sort of like the, you know, a basic AAP access method to the database system where you’re, you know,</p>
<p>49<br>00:04:04,000 –&gt; 00:04:11,000<br>send a SQL query and getting back results that are meant to be printed out on the screen. Right? Because it’s meant to be interpretable by humans.</p>
<p>50<br>00:04:11,000 –&gt; 00:04:15,000<br>But most, you know, most queries aren’t going to run like that.</p>
<p>51<br>00:04:15,000 –&gt; 00:04:24,000<br>Most queries are going to want data in a typically a binary form because it’s going to be fed into some kind of application code that wants to do some additional processing on it.</p>
<p>52<br>00:04:24,000 –&gt; 00:04:33,000<br>Right? So like in my example of the terminal, that’s just plain text. In actually, in that case, the postgres is actually sending the same plain text data over the wire back to the client.</p>
<p>53<br>00:04:33,000 –&gt; 00:04:39,000<br>We’ll see one system in particular that actually does that no matter whether it’s talking to an application or a terminal.</p>
<p>54<br>00:04:39,000 –&gt; 00:04:44,000<br>But most systems are going to be doing binary data serialization.</p>
<p>55<br>00:04:44,000 –&gt; 00:04:52,000<br>So you wouldn’t actually want to write your application by just like piping out to to to P SQL or whatever the the command line terminal you want to use.</p>
<p>56<br>00:04:52,000 –&gt; 00:04:55,000<br>Instead, you’re going to write your application using one of these different methods.</p>
<p>57<br>00:04:56,000 –&gt; 00:05:05,000<br>And these aren’t these aren’t mutually exclusive. Like you could at you know, depending on your application, maybe he’s written in C sharp or C but flaws, you would use this if it’s Python, use that and so forth.</p>
<p>58<br>00:05:05,000 –&gt; 00:05:10,000<br>So various systems are going to support some of these, but we’ll see when we when we go through it.</p>
<p>59<br>00:05:10,000 –&gt; 00:05:17,000<br>The thing that we’re really going to care about is it’s like the low level never key PI of what the hell again how we’re going to put bits on the wire.</p>
<p>60<br>00:05:17,000 –&gt; 00:05:22,000<br>And then all of these methods except for maybe the last one can hide all that.</p>
<p>61<br>00:05:23,000 –&gt; 00:05:33,000<br>So the first one is like this is this is sort of this is a proprietary API that the system exposes to you typically through like a C library.</p>
<p>62<br>00:05:33,000 –&gt; 00:05:38,000<br>And it’s like you wouldn’t want to write this for your application.</p>
<p>63<br>00:05:38,000 –&gt; 00:05:43,000<br>This is like if you’re writing a driver for these other ones here, you would use kind of these kind of things.</p>
<p>64<br>00:05:43,000 –&gt; 00:05:46,000<br>And you can look at the documentation for like my SQL and Postgres, right.</p>
<p>65<br>00:05:46,000 –&gt; 00:05:51,000<br>You’ll have information about the API for like in the low level C library.</p>
<p>66<br>00:05:51,000 –&gt; 00:05:56,000<br>Like how do you open up a connection, how do you send a query, how do you do authentication and so forth, right.</p>
<p>67<br>00:05:56,000 –&gt; 00:06:13,000<br>And you can use chat to BT to write this kind of stuff, right. You basically say, you know, write me a C program that uses a lib, lib pq which is the low level C API interface that you would use to program in Postgres.</p>
<p>68<br>00:06:13,000 –&gt; 00:06:18,000<br>But again, like you typically don’t write programs like this, you’ll use some other abstraction.</p>
<p>69<br>00:06:18,000 –&gt; 00:06:25,000<br>You need to use a higher level abstraction like an ORM like you can Django, Active Record, Ruby and Rails, SQL lives in Node.js, right.</p>
<p>70<br>00:06:25,000 –&gt; 00:06:32,000<br>On either covers, they may be calling the C API, but use the application programmer, aren’t writing coding as these things.</p>
<p>71<br>00:06:32,000 –&gt; 00:06:35,000<br>So I want to focus now on these two.</p>
<p>72<br>00:06:35,000 –&gt; 00:06:41,000<br>The Python one came later in the 90s, but you’ll soon see how things get built up over time.</p>
<p>73<br>00:06:41,000 –&gt; 00:06:48,000<br>And a lot of things we’ll talk about for you as in JDBC, as a pickle for whatever the pick your favorite library.</p>
<p>74<br>00:06:48,000 –&gt; 00:06:54,000<br>So I pick your favorite programming language that has a specification with how do you do connectivity and they would basically fall into the same thing.</p>
<p>75<br>00:06:55,000 –&gt; 00:07:11,000<br>Because the big idea of what these APIs are going to do for us is that in theory, instead of programming against the low level like C API, like these things, instead we could program against these technically database system agnostic APIs.</p>
<p>76<br>00:07:11,000 –&gt; 00:07:18,000<br>And then if we decided, you know, change what database system we want to use, we wouldn’t have to change our any other application code.</p>
<p>77<br>00:07:18,000 –&gt; 00:07:27,000<br>Of course, that’s not entirely true if you’re writing raw SQL, because as we said many times, the SQL dialect could be different from one system to the next, but we can ignore that.</p>
<p>78<br>00:07:27,000 –&gt; 00:07:32,000<br>So the history for this goes back into the late 80s, early 90s.</p>
<p>79<br>00:07:32,000 –&gt; 00:07:41,000<br>Basically, prior to something like JDBC, it was just these C libraries that all the various database system vendors provided.</p>
<p>80<br>00:07:41,000 –&gt; 00:07:50,000<br>So things weren’t portable. You would write again to a low level API talk to the database system that was very specific to the one database system you were using.</p>
<p>81<br>00:07:50,000 –&gt; 00:08:02,000<br>And so there was early, people identify early on that would be nice that people writing a lot of applications, be nice to have a standard way to do database connectivity and to send queries, give back results.</p>
<p>82<br>00:08:02,000 –&gt; 00:08:10,000<br>First attempt was in the late 80s from Sybase. They had something generically called DB library that was meant to be like an open source standard.</p>
<p>83<br>00:08:10,000 –&gt; 00:08:13,000<br>I don’t know if I actually have the sort of, it needed to be the standard everyone can implement.</p>
<p>84<br>00:08:13,000 –&gt; 00:08:24,000<br>That didn’t go anywhere. And then Microsoft teamed up with this other company called Sima Technologies in the early 1990s and they put forth this thing called UDBC.</p>
<p>85<br>00:08:24,000 –&gt; 00:08:30,000<br>And so now pretty much every database system that you can think of today is going to have an ODBC implementation.</p>
<p>86<br>00:08:30,000 –&gt; 00:08:38,000<br>Even if it’s actually not a relational database system, it doesn’t support SQL. Like MongoDB has an ODBC implementation.</p>
<p>87<br>00:08:38,000 –&gt; 00:08:47,000<br>Because again, it’s someone you have to put in the query command that you want to send over. And ODBC doesn’t know, doesn’t care whether it’s SQL or not.</p>
<p>88<br>00:08:47,000 –&gt; 00:08:54,000<br>Here’s the thing I need to send to the server. But there’s other APIs that are like iterative results sets, buying parameters to values and so forth.</p>
<p>89<br>00:08:54,000 –&gt; 00:08:58,000<br>Our values to parameters are so forth. So the high level looks like this.</p>
<p>90<br>00:08:58,000 –&gt; 00:09:09,000<br>So the ODBC is based on the device driver model. It’s similar to how the hardware works in PCs, where if you buy like a graphics card, the vendor that sell you to the graphic card,</p>
<p>91<br>00:09:09,000 –&gt; 00:09:15,000<br>they’re also going to provide you with a driver that you can install in your OS, made about to communicate with the hardware.</p>
<p>92<br>00:09:15,000 –&gt; 00:09:26,000<br>So the same idea. The database system vendor is going to be responsible for providing you with a driver that you can use based on the ODBC spec, then communicate with the database server.</p>
<p>93<br>00:09:26,000 –&gt; 00:09:44,000<br>So the application wants to run some queries on the database. They go through the ODBC driver. And then the ODBC driver is responsible for sending the request over to the database server, getting the result, and then marshalling it back into the form that’s required by the ODBC spec, then expose it to your application.</p>
<p>94<br>00:09:44,000 –&gt; 00:09:56,000<br>So this can mean things like if my client is expecting everything to be 32 bit integers, but the database server sends back 64 bit integers, then the drivers are also converting that and cleaning things up.</p>
<p>95<br>00:09:56,000 –&gt; 00:10:02,000<br>It also can do other things like there’s certain features that are in the ODBC spec that the database system doesn’t support.</p>
<p>96<br>00:10:02,000 –&gt; 00:10:17,000<br>For example, like Postgres doesn’t support cursors, like true cursors, then the driver can emulate that basically. Send the query over, give you back a cursor to it, and then use iterating over the results that are cached on the client side.</p>
<p>97<br>00:10:17,000 –&gt; 00:10:29,000<br>So you can do a bunch of stuff in the driver. So the thing that we care about today is this piece here, the request going out and the response coming back, they weren’t called the wire protocol, they never protocol the database system.</p>
<p>98<br>00:10:29,000 –&gt; 00:10:32,000<br>So this is what we’re going to focus on. Yes.</p>
<p>99<br>00:10:32,000 –&gt; 00:10:39,000<br>The commands received by ODBC, for example, where do they get insured into the string?</p>
<p>100<br>00:10:39,000 –&gt; 00:10:44,000<br>Do they run through the query optimizer? Is it just like it converted the SQL into everything?</p>
<p>101<br>00:10:44,000 –&gt; 00:10:51,000<br>So the question is like, if I have a SQL query, where does that get, like trying to do a plan?</p>
<p>102<br>00:10:51,000 –&gt; 00:10:57,000<br>My understanding is when you are using ODBC, you’re using standard calls that don’t have SQL.</p>
<p>103<br>00:10:57,000 –&gt; 00:11:07,000<br>No, no, no, they, like, there’ll be a, like, prepare statement command and you put a string in that’ll be whatever the flavor is SQL, the database system supports.</p>
<p>104<br>00:11:07,000 –&gt; 00:11:12,000<br>And that won’t be, that can’t, there’s no way that can be universal across the database systems.</p>
<p>105<br>00:11:12,000 –&gt; 00:11:17,000<br>But like the API call to say, here’s the query I want to run and then execute it, get back result.</p>
<p>106<br>00:11:17,000 –&gt; 00:11:27,000<br>Now iterate over the result set and give me the, for each row, the second attribute, and I want it as an integer, all that standardized.</p>
<p>107<br>00:11:27,000 –&gt; 00:11:33,000<br>But the SQL itself just goes over the wire and then all the parsing, the planning, the optimizing, all that happens over here.</p>
<p>108<br>00:11:34,000 –&gt; 00:11:40,000<br>Yeah, again, this is basically going to be calling typically the C API that an image move forward.</p>
<p>109<br>00:11:43,000 –&gt; 00:11:53,000<br>Right, so let’s talk about, so again, this was the first one, the big one that really took off and again, early to mid 90s, everybody was supporting ODBC at this point.</p>
<p>110<br>00:11:54,000 –&gt; 00:12:07,000<br>And then Java comes along mid 90s and then some recognize that, you know, if you were to be on Java applications in the enterprise, they’d either talk about, talk about data systems or talk to data systems.</p>
<p>111<br>00:12:07,000 –&gt; 00:12:11,000<br>So they had a support, you know, something similar to ODBC, but for Java.</p>
<p>112<br>00:12:11,000 –&gt; 00:12:19,000<br>Right, and at the time again, ODBC was very much window specific, but since then it’s, it’s sort of generic and it’s expanded.</p>
<p>113<br>00:12:20,000 –&gt; 00:12:28,000<br>But again, but at the time, you know, it was, it was, it was, it was windows for static and for, and for C puzzle’s applications.</p>
<p>114<br>00:12:28,000 –&gt; 00:12:35,000<br>So it wouldn’t work in, in the Java world. Right, and the same way that Russ is the hot thing now, Java was the hot thing in the mid 90s.</p>
<p>115<br>00:12:35,000 –&gt; 00:12:41,000<br>But the idea was like, you write your program once and the GAMM can then run it anywhere, like that was mind blowing people back then.</p>
<p>116<br>00:12:41,000 –&gt; 00:12:44,000<br>Go was the hot thing 10 years ago, there was some kind of fad.</p>
<p>117<br>00:12:45,000 –&gt; 00:12:54,000<br>All right, so JTBC comes along and the, you can sort of think of this as like, again, it’s basically the same thing as ODC, just now it’s for Java instead of C.</p>
<p>118<br>00:12:54,000 –&gt; 00:13:04,000<br>But because they were trying to bootstrap this, this new connectivity API to an existing ecosystem of a bunch of database systems that already spread to ODC,</p>
<p>119<br>00:13:04,000 –&gt; 00:13:09,000<br>and they want to be able to people get up and running for any possible data systems as soon as possible.</p>
<p>120<br>00:13:10,000 –&gt; 00:13:19,000<br>They have a different, different variations of how you can build it a native, or how to build a JTBC library or API or implementation of it.</p>
<p>121<br>00:13:20,000 –&gt; 00:13:24,000<br>And they have various methods to like sort of bridge the gap between what was available at the time versus what came on later.</p>
<p>122<br>00:13:25,000 –&gt; 00:13:34,000<br>So the, the four purges are, the first one is that there is no native JTBC implementation, a Java implementation of, of communicating with the data system.</p>
<p>123<br>00:13:34,000 –&gt; 00:13:47,000<br>So instead what you provide is a, basically a bridge or a wrapper in Java that then invokes ODC, like the actual shared objects, the C code, that then that communicates with the database system.</p>
<p>124<br>00:13:48,000 –&gt; 00:13:57,000<br>Right, so this was meant to be like, again, if you, if you have a database system that doesn’t support JTBC yet, you could just wrap something around ODC and use that.</p>
<p>125<br>00:13:58,000 –&gt; 00:14:11,000<br>The next approach was that you would use, have JTBC calls make JNI invocations down into the C code of, of, of, of, of, that’s the C API and have that go over the wire to the database system.</p>
<p>126<br>00:14:11,000 –&gt; 00:14:19,000<br>Right, and again, this is because, think of like taking the bytes, putting into buffers, all that was done in C, and then the thing was just copying the data into Java.</p>
<p>127<br>00:14:20,000 –&gt; 00:14:29,000<br>Another approach is basically you have a separate middleware, like a separate server running that the JTBC thing then would talk to, and then that middleware then would use ODC to talk to your, your database system.</p>
<p>128<br>00:14:30,000 –&gt; 00:14:32,000<br>Right, so sort of extra hop them to make the call you needed.</p>
<p>129<br>00:14:33,000 –&gt; 00:14:48,000<br>And the last one is, is obviously going to be more ideal, is that you have a pure Java implementation that, if that calls, it makes the JTBC calls that you’re, you provide them in the application directly into the, the, the vendor specific wire protocol commands.</p>
<p>130<br>00:14:49,000 –&gt; 00:14:55,000<br>Right, so every single database has been at this point is going to have their own native Java, JTBC invocations.</p>
<p>131<br>00:14:55,000 –&gt; 00:15:05,000<br>But again, think of how many times you come across something like in rust, or some car, you want to use, and there isn’t a native implementation that’s just calling in the C, that’s really the top, the top thing up there.</p>
<p>132<br>00:15:05,000 –&gt; 00:15:12,000<br>So the top one has been removed, and this is the one, this is the best one, and this is the most common one, at least for the most major data systems today.</p>
<p>133<br>00:15:13,000 –&gt; 00:15:24,000<br>All right, so, as I was saying, the thing we care about is what’s being sent over the wire to communicate from the client, whether it’s ODC, GDC, or whatever it is, to the database server.</p>
<p>134<br>00:15:25,000 –&gt; 00:15:39,000<br>And so every database system, for the most part, is going to implement their own proprietary wire protocol, typically over TCP, IP, and it’s going to use that to begin to, to, to send the bytes back and forth and acknowledge this and get, take queries in and get responses back.</p>
<p>135<br>00:15:40,000 –&gt; 00:15:50,000<br>If you’re running on the same box, and it’s in its Linux, you can use Unix domain sockets to get, get faster performance, because you’re not going through the full TCP, IP stack, and the OS, both on the client side and the server side.</p>
<p>136<br>00:15:51,000 –&gt; 00:15:58,000<br>You can do this in Postgres, but again, if you’re running in the cloud, the DB server is like some far away location, you’re not going to be able to do this.</p>
<p>137<br>00:15:59,000 –&gt; 00:16:13,000<br>Those systems, I’m not aware of any system that uses UDP to communicate between the client and the server, TCP has overhead because you have to send the acknowledgments and back and forth, or UDP sort of throw it over and hope it makes it.</p>
<p>138<br>00:16:14,000 –&gt; 00:16:27,000<br>So no system I’m aware of, we’ll do this from between the client and the server. We’ll see one system later on, Yellowbrick, they’ll actually do this between the communicate, use UDP to communicate the backend servers, because it’s just so much faster.</p>
<p>139<br>00:16:27,000 –&gt; 00:16:36,000<br>And they basically have to do their own, you know, retry and acknowledgments on their own, but in that case, because they’re trying to get the best performance possible, it was worth it for them to implement this.</p>
<p>140<br>00:16:37,000 –&gt; 00:16:45,000<br>Postgres uses UDP to communicate between the stats collector and the different workers, but again, that’s all in the backend on the same box. It’s not between the client and the server.</p>
<p>141<br>00:16:46,000 –&gt; 00:16:53,000<br>So typically what happens is the ways you would communicate with the data server is that the client comes along, connects to the data system.</p>
<p>142<br>00:16:53,000 –&gt; 00:17:04,000<br>There’s always going to be some kind of authentication process, right, or even giving a token that you’ve authenticated with something else, or you do username password or whatever the mechanism is.</p>
<p>143<br>00:17:05,000 –&gt; 00:17:12,000<br>Ideally, you want this to be using SSL or TLS, but you don’t need to own peer to sniff your packets.</p>
<p>144<br>00:17:12,000 –&gt; 00:17:19,000<br>Then you send over the query, the data system will then block that connection, well, I’m not sure because you can do ASIC and stuff like that.</p>
<p>145<br>00:17:19,000 –&gt; 00:17:25,000<br>It’ll run that query, and then soon it starts getting results, it serializes them and sends them back over the wire.</p>
<p>146<br>00:17:26,000 –&gt; 00:17:31,000<br>Now some systems can do cursors, for example, and start spooling you some of the results, even though the query starts running.</p>
<p>147<br>00:17:31,000 –&gt; 00:17:40,000<br>The query is still running, but as far as I know, most of the cloud systems is like all, once you get all the results, then you can send things back.</p>
<p>148<br>00:17:40,000 –&gt; 00:17:51,000<br>Obviously, it depends on the query too. If the root node in the query plan is like an order by with a limit on it, you need to see all the data before you need to start sending anything up.</p>
<p>149<br>00:17:52,000 –&gt; 00:18:02,000<br>The thing we care about today is this step here, and we’ll talk a little bit at the end of what we can do to speed that piece up faster.</p>
<p>150<br>00:18:02,000 –&gt; 00:18:11,000<br>I always say also to the paper you guys read, they talk about how this part is actually not that big of a deal.</p>
<p>151<br>00:18:11,000 –&gt; 00:18:17,000<br>We spent the whole semester before how to talk about how to build a fast database system, how to run queries really fast.</p>
<p>152<br>00:18:18,000 –&gt; 00:18:23,000<br>Obviously, if you’re reading pet by the data, I’m sure that’s going to take a long time.</p>
<p>153<br>00:18:23,000 –&gt; 00:18:37,000<br>But in the paper you guys read, and then this other work that came out on the single connector X, this thing is actually in this expensive part, sending that over the network in back to the client.</p>
<p>154<br>00:18:38,000 –&gt; 00:18:44,000<br>The query themselves aren’t going to be that big. The biggest SQL query that you can get is the top is going to be 10 megabytes.</p>
<p>155<br>00:18:44,000 –&gt; 00:18:49,000<br>We have the SQL string. That’s not expensive to send. It’s sending the results back.</p>
<p>156<br>00:18:51,000 –&gt; 00:19:00,000<br>Because it’ll be very steps along the way because you made the copy in the form that the client or network protocol wants, and that may not be the same as your natively storing in the database.</p>
<p>157<br>00:19:00,000 –&gt; 00:19:02,000<br>How would a SQL query be 10 megabytes?</p>
<p>158<br>00:19:03,000 –&gt; 00:19:09,000<br>This is the example I actually come from Google. They told me that they had, it’s not hard to imagine either.</p>
<p>159<br>00:19:09,000 –&gt; 00:19:14,000<br>They had some dashboard where you can click a bunch of checkbox of what you want to visualize.</p>
<p>160<br>00:19:14,000 –&gt; 00:19:21,000<br>All that’s doing is concatenating search options in a giant in clause, and then before you know it, you got a 10 megabyte SQL string.</p>
<p>161<br>00:19:21,000 –&gt; 00:19:27,000<br>It’s rare. I’m not saying it’s common, but you can imagine something like that.</p>
<p>162<br>00:19:28,000 –&gt; 00:19:38,000<br>If we didn’t really talk about tricks or how NICNs go faster, you basically, in that case, if your NCLAWS is huge, you basically go to hash table.</p>
<p>163<br>00:19:38,000 –&gt; 00:19:44,000<br>On the expression itself, then you use that to probe when you do low-cups. It’s like a join.</p>
<p>164<br>00:19:44,000 –&gt; 00:19:51,000<br>It’s like you think of NCLAWS as like materializing another temp table. If it’s huge, if it’s big.</p>
<p>165<br>00:19:51,000 –&gt; 00:19:54,000<br>Other questions?</p>
<p>166<br>00:19:55,000 –&gt; 00:19:57,000<br>Okay.</p>
<p>167<br>00:19:57,000 –&gt; 00:20:04,000<br>So, if you’re going to build a new database system today, you have two choices.</p>
<p>168<br>00:20:04,000 –&gt; 00:20:17,000<br>You either can implement your own wire protocol by scratch, and then in which case, you have to write your JDBC, ODDC client libraries, the drivers to support talking to your database system.</p>
<p>169<br>00:20:18,000 –&gt; 00:20:29,000<br>The more common thing to do now, though, is just use an existing wire protocol from existing database system, because then you can just inherit their driver ecosystem for free.</p>
<p>170<br>00:20:29,000 –&gt; 00:20:38,000<br>It’s not enough to say, okay, I speak the wire protocol to say you’re compatible with another database system.</p>
<p>171<br>00:20:39,000 –&gt; 00:20:48,000<br>That’s the bare minimum. If you just spoke the wire protocol, the client drivers don’t know, typically don’t know, don’t care what the SQL query looks like related to his question.</p>
<p>172<br>00:20:48,000 –&gt; 00:20:57,000<br>They’re not parsing on the client side to see, are you really sending me a postgres, you know, a postgres compatible query? They’re just sort of sending the text over.</p>
<p>173<br>00:20:57,000 –&gt; 00:21:02,000<br>So, if you want to be able to support more of the ecosystem, then you have to support the catalogs and other functionality.</p>
<p>174<br>00:21:02,000 –&gt; 00:21:06,000<br>But the bare minimum you would need is just to say, I need a wire protocol.</p>
<p>175<br>00:21:06,000 –&gt; 00:21:16,000<br>So, it’s about 50-50 now. It didn’t be, didn’t use to be this way. But the two most common wire protocols that are going to be reused is we might seek on postgres.</p>
<p>176<br>00:21:16,000 –&gt; 00:21:21,000<br>My SQL used to be number one postgres is actually becoming more, more, more popular.</p>
<p>177<br>00:21:21,000 –&gt; 00:21:27,000<br>That’s partly because there’s a lot of, there’s a lot of databases that are like forks of postgres, where they keep the sort of the top half, including the network layer.</p>
<p>178<br>00:21:27,000 –&gt; 00:21:34,000<br>So you’re speaking the wire protocol, and then they rewrite the bottom layer. That’s what Neon does and redshift and others do.</p>
<p>179<br>00:21:34,000 –&gt; 00:21:44,000<br>The third most common wire protocol is actually redis. This is because it’s so simple. It’s like just text-based, like getting sets and simple things like that.</p>
<p>180<br>00:21:44,000 –&gt; 00:22:00,000<br>But again, if you support these existing protocols, someone can run against your new data system without having to rewrite their application or change what driver they’re using, because you just piggyback off of the existing driver implementations.</p>
<p>181<br>00:22:00,000 –&gt; 00:22:11,000<br>Snowflake interestingly did not do this. I think it’s a different time. Snowflake decided we’re going to write our own wire protocol from scratch, including their own SQL dialect from scratch.</p>
<p>182<br>00:22:11,000 –&gt; 00:22:26,000<br>They started in 2011, 2012. I think if you’re going to build a new system today, it’ll be a hard decision to do that. Because there’s just so much stuff you can reuse if you speak the postgres wire protocol.</p>
<p>183<br>00:22:26,000 –&gt; 00:22:37,000<br>So the paper I had you guys read was about how to improve the wire protocol between these different data systems.</p>
<p>184<br>00:22:37,000 –&gt; 00:22:41,000<br>And they sort of focused on four key design decisions.</p>
<p>185<br>00:22:41,000 –&gt; 00:23:05,000<br>So the background of this paper is that this is from the Monet TV light project, which was a precursor to DuckDB. So Hanna and Mark, who are the authors of this paper, as part of the work they were doing when trying to make Monet TV be embeddable, they realize all the problems they were having of getting data in and out into pandas and R programs, even if you’re still running on the same process.</p>
<p>186<br>00:23:05,000 –&gt; 00:23:14,000<br>So this is sort of what led them to throw away the code and start putting DuckDB. So this again, it’s the same team, but this before DuckDB came a thing.</p>
<p>187<br>00:23:14,000 –&gt; 00:23:23,000<br>And again, this paper is focused on doing large data exports. So it’s not complex queries are doing a bunch of joins and it much sophisticated aggregations.</p>
<p>188<br>00:23:23,000 –&gt; 00:23:37,000<br>It’s more or less like select star queries or you can get a subset of the columns projected out to then feed that into a pandas or Python program to do additional computation or trained machine learning models and so forth.</p>
<p>189<br>00:23:37,000 –&gt; 00:23:42,000<br>So this is the paper is really about how to get data out of the server into the client.</p>
<p>190<br>00:23:43,000 –&gt; 00:23:50,000<br>So now whatever, again, whatever organizations we’re going to talk about today, you’re going to have to also implement them in the client driver.</p>
<p>191<br>00:23:50,000 –&gt; 00:23:59,000<br>Because if you start compressing things on the server side, send that over the wire, if the client doesn’t know how to decompress them, then like the data is useless.</p>
<p>192<br>00:24:00,000 –&gt; 00:24:12,000<br>Likewise, if I convert from the raw oriented format to a columnar format, if the client doesn’t know how to do that, transpose, then it’s all useless.</p>
<p>193<br>00:24:12,000 –&gt; 00:24:27,000<br>And so typically client drivers are being very conservative and they’re not going to want to have a lot of extended capabilities in them because now you have to support that for every single possible language you ever want to support.</p>
<p>194<br>00:24:28,000 –&gt; 00:24:36,000<br>So if you have the C API and you just wrap that around the various different programming languages, then that’s fine because you just sort of implement it once.</p>
<p>195<br>00:24:36,000 –&gt; 00:24:43,000<br>But as I was saying before, ideally you want to have a native implementation of your client driver in whatever program language you’re running in.</p>
<p>196<br>00:24:43,000 –&gt; 00:24:50,000<br>So you don’t have this copying over between C or whatever program language you want.</p>
<p>197<br>00:24:50,000 –&gt; 00:24:58,000<br>So if now you have all these additional features in your client driver, well now everybody who, every programming language that implements your client driver has to implement the same thing.</p>
<p>198<br>00:24:58,000 –&gt; 00:25:06,000<br>And that becomes, could become problematic, fractured, people don’t implement all the same capabilities.</p>
<p>199<br>00:25:06,000 –&gt; 00:25:11,000<br>So there’s a trade-office, how sophisticated we can be versus what people are actually able to do when the client drivers.</p>
<p>200<br>00:25:12,000 –&gt; 00:25:32,000<br>Furthermore, in a modern scenario, we haven’t really talked about Lambda functions or serverless applications, but a very common scenario now is like the communication with the data server is like I spin up a Lambda function, which is say some Python thing that is run, it connects to the database server, does authentication, sends some queries, get back results, and then does some minor processing, and then goes away.</p>
<p>201<br>00:25:32,000 –&gt; 00:25:44,000<br>So in that case, you’re paying for the compute time on the serverless function, and you don’t want to have a bunch of expensive decitalization if you have a very sophisticated, you know, a client protocol.</p>
<p>202<br>00:25:44,000 –&gt; 00:25:49,000<br>And I think, and again, the answer is going to be Apache arrows, going to be the right solution to this, but that’s sort of spoiler.</p>
<p>203<br>00:25:49,000 –&gt; 00:25:54,000<br>So we’re going to go through these to form major pieces, moment one, and see what the trade-offs are.</p>
<p>204<br>00:25:54,000 –&gt; 00:26:00,000<br>Again, not just for performance, but also again for the engineering side of the client.</p>
<p>205<br>00:26:01,000 –&gt; 00:26:08,000<br>So the first one is going to be kind of obvious, right, because we started off in the semester, Roastroir versus a column store.</p>
<p>206<br>00:26:08,000 –&gt; 00:26:19,000<br>And ODBC and JDBC are, you know, by their nature, are Roast oriented APIs because they were developed in the 1990s, early 1990s before, a kilometer databases were a thing.</p>
<p>207<br>00:26:19,000 –&gt; 00:26:25,000<br>The paper column on our databases is the first one in column stores is like 82, 83, but that’s a theory paper.</p>
<p>208<br>00:26:25,000 –&gt; 00:26:30,000<br>There was a Swedish system that was technically a column store, but like in the 70s, when no one has ever heard of that.</p>
<p>209<br>00:26:30,000 –&gt; 00:26:36,000<br>Sybase IQ is probably the first one that came along with, it was a true column store invitation, but that’s like 97, 98.</p>
<p>210<br>00:26:36,000 –&gt; 00:26:40,000<br>So again, ODBC comes along in 1990, column stores aren’t a thing.</p>
<p>211<br>00:26:40,000 –&gt; 00:26:48,000<br>And most applications people are writing are like business applications that are like going fetching, you know, one order record, or, you know, single entities, single information.</p>
<p>212<br>00:26:49,000 –&gt; 00:26:52,000<br>Right, so it was inherently Roast oriented.</p>
<p>213<br>00:26:52,000 –&gt; 00:26:58,000<br>So in this world, what’s going to happen is the server is going to take all the two pulls that it’s getting part of the output.</p>
<p>214<br>00:26:58,000 –&gt; 00:27:09,000<br>And even though the, on the server side, it may be storing them as a column store, it’s going to stick them back together, materializing them back together because the client protocol, the wire protocol, once it in a Roast oriented manner.</p>
<p>215<br>00:27:10,000 –&gt; 00:27:21,000<br>Because then you write applications and sort of pseudo JdBC stuff like this, we’re going to iterate over the results set and get one tubal out of time and extract out the data you want Ro by Ro.</p>
<p>216<br>00:27:21,000 –&gt; 00:27:37,000<br>But if we switch to a column format, then this tech can be bad too because if I ever need to get multiple data for a single tubal across multiple columns,</p>
<p>217<br>00:27:37,000 –&gt; 00:27:44,000<br>then I have to write some weird code of like iterate over the columns and iterate over the next rows and try to put, you know, stitch things back together.</p>
<p>218<br>00:27:44,000 –&gt; 00:27:48,000<br>Again, this is not real code. It’s just some pseudo code here, right?</p>
<p>219<br>00:27:48,000 –&gt; 00:27:51,000<br>So the solution is basically the same thing we talked about at the beginning.</p>
<p>220<br>00:27:51,000 –&gt; 00:27:58,000<br>We want a packed space model because because now we can operate over batches of of tuples.</p>
<p>221<br>00:27:58,000 –&gt; 00:28:13,000<br>And although we’re going to be sending them the data out in a, you know, a columnar fashion, they’ll group them together in row groups or small enough chunks where all the data we would need for a single tubal will be, will be close together.</p>
<p>222<br>00:28:13,000 –&gt; 00:28:15,000<br>Right?</p>
<p>223<br>00:28:16,000 –&gt; 00:28:20,000<br>So this is what Arrow does as we talked about.</p>
<p>224<br>00:28:20,000 –&gt; 00:28:28,000<br>And so Arrow has this thing called the Arrow database connectivity and it’s basically like JDBC or ABC.</p>
<p>225<br>00:28:28,000 –&gt; 00:28:40,000<br>It’s a specification programming API for to how to interact with a database system and operate over getting back, getting back vectors.</p>
<p>226<br>00:28:40,000 –&gt; 00:28:53,000<br>So if now your database system supports ADBC, which some systems do, like snowflake, for example, then now I can make requests send a SQL query over to the database system and get it back in native arrow form.</p>
<p>227<br>00:28:53,000 –&gt; 00:29:07,000<br>And then I can integrate that and use that in my application anyway that I want with one without having to do any copying or decilization because it’s already in the vector format.</p>
<p>228<br>00:29:07,000 –&gt; 00:29:18,000<br>So we’re not going to go through like what ADBC is like it’s not everyone actually supports it, but this is going to be, this is basically what Hanis and Mark are going to propose like, hey, we know this vector based API.</p>
<p>229<br>00:29:18,000 –&gt; 00:29:22,000<br>And this is what this is what came out later.</p>
<p>230<br>00:29:22,000 –&gt; 00:29:29,000<br>Right? Because the paper you guys read predates, predates ADBC.</p>
<p>231<br>00:29:29,000 –&gt; 00:29:35,000<br>So now if we want to do in summing sending sending things back as vectors, how we want to support compression.</p>
<p>232<br>00:29:35,000 –&gt; 00:29:52,000<br>And this basically is going to smell like again all the stuff we talked about before in storage of this trade off between having general purpose naive compression that was taking blocks of data and throwing gzip or snappy at it versus having a more lightweight encoding scheme that’s specific to the actual data that I’m storing.</p>
<p>233<br>00:29:53,000 –&gt; 00:29:58,000<br>So again, the easiest approach is to do just gzip or snappy or z standard.</p>
<p>234<br>00:29:58,000 –&gt; 00:30:14,000<br>And this is basically you do all the same wire protocol construction of the map of the packets of messages that you would normally do, but right before you send it over the wire, you just run gzip or snap you wanted to compress it before it sends it over and the client basically does the reverse of it.</p>
<p>235<br>00:30:14,000 –&gt; 00:30:17,000<br>So this is not that common.</p>
<p>236<br>00:30:17,000 –&gt; 00:30:31,000<br>It’s not owned by default for most systems, but I know for like Oracle and actually if you know if it can be owned by default, but like a real low light compression, but Oracle and my sequel and BigQuery, these are things you can go add on after the fact.</p>
<p>237<br>00:30:31,000 –&gt; 00:30:37,000<br>BigQuery is doing this over HTTP. So I think it’s part of the HTTP’s client protocol, they’re adding gzip.</p>
<p>238<br>00:30:38,000 –&gt; 00:30:46,000<br>Oracle added this in, I think, 2013. My sequel has had it, I think, for a while.</p>
<p>239<br>00:30:46,000 –&gt; 00:30:54,000<br>There was a patch to do this and add this in Postgres 2018, but that didn’t go anywhere. So Postgres doesn’t support this.</p>
<p>240<br>00:30:55,000 –&gt; 00:31:05,000<br>And then the next approach is doing all the stuff we talked about before using dictionary coding, RLE, Dustin coding, frame of reference coding.</p>
<p>241<br>00:31:05,000 –&gt; 00:31:18,000<br>And again, the idea is that you recognize the data type of the data you’re sending back over the response and just runs this compression scheme, whatever you want on it.</p>
<p>242<br>00:31:19,000 –&gt; 00:31:29,000<br>So nobody does this because again, it’d be a different arrow because you can’t if it’s arrow does dictionary coding, like that’s the only coding scheme that I think supports out of the box.</p>
<p>243<br>00:31:29,000 –&gt; 00:31:36,000<br>So like if you get if you get data back as arrow, it’d be already dictionary coded, but they’re not doing the delta coding or at least up as well.</p>
<p>244<br>00:31:36,000 –&gt; 00:31:42,000<br>Again, nobody does this because they were saying before you have to have all your client drivers also support this as well.</p>
<p>245<br>00:31:43,000 –&gt; 00:31:51,000<br>And typically the way it works is like when your client connects to the data server, it’s like when you do like an SSH handshake, you say, here’s what I, here’s the features I can support.</p>
<p>246<br>00:31:51,000 –&gt; 00:32:02,000<br>And the client server then picked the sort of bare minimum they would have. So you could have like a bunch of old, you know, you have a bunch of clients showing up with old driver implementations and then not support any of these things.</p>
<p>247<br>00:32:02,000 –&gt; 00:32:10,000<br>So things part of reason nobody does this. And again, from engineering side, you have to support this all the different type of limitations.</p>
<p>248<br>00:32:10,000 –&gt; 00:32:19,000<br>Yes. Is it really either or can’t you have for free? Like for where there’s a bit of a lot of those?</p>
<p>249<br>00:32:19,000 –&gt; 00:32:23,000<br>Yes, same as like it’s not exclusive. Like you could do both. Yes.</p>
<p>250<br>00:32:23,000 –&gt; 00:32:35,000<br>And then furthermore, depending on what how you like serialize the data, like if you’re just doing text encoding when you pat things out, then this one’s going to make a big, big difference versus like that’s right.</p>
<p>251<br>00:32:35,000 –&gt; 00:32:47,000<br>So they’re not music. But I’m saying nobody would as far as I know other than air adbc nobody does this because I was saying the drivers have to support it.</p>
<p>252<br>00:32:47,000 –&gt; 00:32:55,000<br>So basically everything I’m saying here is all things we talked about earlier when we talked about getting things from the object store from desk.</p>
<p>253<br>00:32:55,000 –&gt; 00:33:14,000<br>When the communication channel between the storage or the between the client and the server is slow, then heavyweight compression is going to be much better because we’re willing to pay that trade off of spending more CPU cycles to compress the data down to smaller, smaller sizes because then that’ll speed things up as we send it over.</p>
<p>254<br>00:33:14,000 –&gt; 00:33:24,000<br>Right. And obviously the larger the chunks of data were sending over the better compression ratio will get.</p>
<p>255<br>00:33:24,000 –&gt; 00:33:29,000<br>Next is how do we want to send a heavyweight and sort of serialize and code the data we’re sending over.</p>
<p>256<br>00:33:29,000 –&gt; 00:33:46,000<br>So the first approach is the most common one we do binary encoding. And this is where the you’re basically sending the data from the client to the server in the same loadable binary form that it’s being represented in the in your database, at least ideally not always the case though.</p>
<p>257<br>00:33:47,000 –&gt; 00:33:58,000<br>And in this case here, the client is responsible for dealing with any Indian issues like if the data is being stored in a little Indian and your client for some reason is running on a big Indian machine, then the clients responsible for doing that conversion.</p>
<p>258<br>00:33:58,000 –&gt; 00:34:12,000<br>Because the idea there is the database servers just trying to get you data as fast as possible. And the clients can then since there’s more clients than servers typically you can spread out the computational cost of doing that conversion across all the different clients.</p>
<p>259<br>00:34:13,000 –&gt; 00:34:22,000<br>So another question is going to be, okay, if we want to use the binary encoding, how are we going to decide what serialization scheme we’re going to use.</p>
<p>260<br>00:34:22,000 –&gt; 00:34:41,000<br>And in the paper you guys read, they argue that rolling your own serialization format is better than using existing libraries because these existing libraries bring up a bunch of other infrastructure, other things that you may not actually care about that are add additional computation overhead and storage overhead or space overhead for the packet.</p>
<p>261<br>00:34:41,000 –&gt; 00:34:57,000<br>So what do you mean by this? So you can write your own serialization format like how to take a result set of three attributes and integer floats and whatever and pack them down into the byte representation that you spend sending the wire.</p>
<p>262<br>00:34:57,000 –&gt; 00:35:07,000<br>Or alternatively you use one of these libraries like protobuffers, thrift or flat buffers is the newer one, the better one. There’s cat and proto, there’s a bunch of these other ones.</p>
<p>263<br>00:35:07,000 –&gt; 00:35:16,000<br>They basically provide you the capabilities to define the schema of the message you’re sending and serialize it out.</p>
<p>264<br>00:35:17,000 –&gt; 00:35:27,000<br>So one year somebody asked me why doesn’t any, if we’re going to be sending back data through protobuffs, why didn’t the store protobuffs natively. And I was like, nobody does that, that sounds like a bad idea.</p>
<p>265<br>00:35:27,000 –&gt; 00:35:40,000<br>Turns out somebody does do it because they email me later on. There is a system, I think it’s like a toy project called ProfiniB where the wire protocol sends out protocol buffers and internally storage, they’re storing everything as protocol buffers as well.</p>
<p>266<br>00:35:41,000 –&gt; 00:35:48,000<br>Because it’s just bytes, right? So in that case you don’t do any serialization or resilization when someone requests something because you just send over the stuff you’ve already stored as protobuffs.</p>
<p>267<br>00:35:48,000 –&gt; 00:36:01,000<br>I’m not saying it’s a good idea, but it does exist. The other challenge also too is like with protobuffs that’s least, that one is the separate enough from GRPC where you don’t have to bring in all the infrastructure for GRPC.</p>
<p>268<br>00:36:02,000 –&gt; 00:36:12,000<br>In Thrift as far as I remember, you bring in the threading models, thread pools, and buffer pools as well. This brings out way more infrastructure if you choose to use this.</p>
<p>269<br>00:36:12,000 –&gt; 00:36:21,000<br>Flat buffers is like protoboffs. It’s pretty simplistic and it’s just the serialization format.</p>
<p>270<br>00:36:22,000 –&gt; 00:36:29,000<br>There’s other things that these guys provide you as well which may meant to be useful because they can find keep track of the versioning of your messages and so forth.</p>
<p>271<br>00:36:29,000 –&gt; 00:36:42,000<br>So over time if you expand the capabilities or the internal data members of the packets of messages you’re sending when you send that results to queries in protobuff will keep track of the different versions of it.</p>
<p>272<br>00:36:42,000 –&gt; 00:36:45,000<br>So you know version of the API you’re interacting with.</p>
<p>273<br>00:36:46,000 –&gt; 00:37:04,000<br>The other approach is to do text encoding. This is like the simplest thing to do is you take no matter what the data is and you run the equivalent of like two string or stir on it to convert it from the binary form to a string form and then you just send it over as variable string to the client.</p>
<p>274<br>00:37:05,000 –&gt; 00:37:18,000<br>And this one is nice because you don’t have to worry about any in this because it’s some ask your utf8 format. The client then takes your text and converts it back to the binary format and they can put it in whatever form that it wants.</p>
<p>275<br>00:37:20,000 –&gt; 00:37:27,000<br>For missing values you could have a separate bitmap to keep track of what values are null. It’s moaning to be, they just store the value null.</p>
<p>276<br>00:37:27,000 –&gt; 00:37:30,000<br>The string null represent you have a null string.</p>
<p>277<br>00:37:30,000 –&gt; 00:37:32,000<br>Yes.</p>
<p>278<br>00:37:32,000 –&gt; 00:37:34,000<br>You mean either way is all the data right?</p>
<p>279<br>00:37:34,000 –&gt; 00:37:45,000<br>Yeah, so yes. Well you need I to add to make it ask me and then reverse it with a do I. Yes.</p>
<p>280<br>00:37:45,000 –&gt; 00:37:50,000<br>So is this a good idea or bad idea? Yes.</p>
<p>281<br>00:37:50,000 –&gt; 00:37:56,000<br>So what happens if you have a string of your database that is not worth the word null?</p>
<p>282<br>00:37:56,000 –&gt; 00:38:05,000<br>As he points out what if the string of literary is just null? What do you do? I don’t know. This is moaning to be. I forgot they did.</p>
<p>283<br>00:38:05,000 –&gt; 00:38:18,000<br>Is this a good idea? Other than his like like how do you store null? Is this a good idea or bad idea? Why? He says bad idea. Why?</p>
<p>284<br>00:38:18,000 –&gt; 00:38:20,000<br>What is his hand gesture?</p>
<p>285<br>00:38:20,000 –&gt; 00:38:22,000<br>What is the size of the data?</p>
<p>286<br>00:38:22,000 –&gt; 00:38:24,000<br>The size of the data, huh?</p>
<p>287<br>00:38:24,000 –&gt; 00:38:29,000<br>Why do we need to ask? Why do we need to ask? Why do we need to ask?</p>
<p>288<br>00:38:29,000 –&gt; 00:38:37,000<br>Why do we usually say this is the start of the string is how long it is to treat the next couple of light of string.</p>
<p>289<br>00:38:37,000 –&gt; 00:38:41,000<br>Why do you need like a translated at all?</p>
<p>290<br>00:38:41,000 –&gt; 00:38:59,000<br>So like, it can be like this. If I have a 4 by 30 bit integer, 1, 2, 3, 4, 5, 6, when I send it over the wire to the client, I’m literally going to convert it into the string, the ASCII string, character 1, character 2, character 3, character 4, 5, 6.</p>
<p>291<br>00:38:59,000 –&gt; 00:39:12,000<br>And I’ll do what you said. I’ll either store the length of the string in front of it or I can do null termination. But like every piece of data that I’m sending over in a record is going to be a string formula.</p>
<p>292<br>00:39:12,000 –&gt; 00:39:16,000<br>But it binary was the difference.</p>
<p>293<br>00:39:16,000 –&gt; 00:39:17,000<br>Was the difference?</p>
<p>294<br>00:39:17,000 –&gt; 00:39:18,000<br>Yeah.</p>
<p>295<br>00:39:18,000 –&gt; 00:39:19,000<br>So like, I can store.</p>
<p>296<br>00:39:19,000 –&gt; 00:39:27,000<br>No, no, no, no. So like, this is storing, like, this is a, if you look at the bits, this will be 32 bits to store this number.</p>
<p>297<br>00:39:27,000 –&gt; 00:39:28,000<br>So that number of numbers.</p>
<p>298<br>00:39:28,000 –&gt; 00:39:35,000<br>Yes. This is going to be, each of these is going to be say, one byte to store the, sort of the character 1, the ASCII character 1.</p>
<p>299<br>00:39:35,000 –&gt; 00:39:36,000<br>Right?</p>
<p>300<br>00:39:36,000 –&gt; 00:39:38,000<br>Any of the sort of size to it.</p>
<p>301<br>00:39:38,000 –&gt; 00:39:45,000<br>Any of the sort of size or the null terminator or he fix the line, which is the next one.</p>
<p>302<br>00:39:45,000 –&gt; 00:39:46,000<br>So good idea, bad idea.</p>
<p>303<br>00:39:46,000 –&gt; 00:39:54,000<br>That idea, figure, it’s more data. And only if you’re not going to use that and what happens to, you know, it spends what I put out to you.</p>
<p>304<br>00:39:54,000 –&gt; 00:39:57,000<br>It also seems like compression income is the wrong direction.</p>
<p>305<br>00:39:57,000 –&gt; 00:39:58,000<br>Yeah.</p>
<p>306<br>00:39:58,000 –&gt; 00:40:01,000<br>Yeah. So he’s going to go, instead of compressing this, you go in the wrong direction.</p>
<p>307<br>00:40:01,000 –&gt; 00:40:07,000<br>But then if you do, if you put G zip on top of this, it’s going to compress the hell out there and do fantastic.</p>
<p>308<br>00:40:07,000 –&gt; 00:40:09,000<br>So.</p>
<p>309<br>00:40:10,000 –&gt; 00:40:11,000<br>Potentially, yes.</p>
<p>310<br>00:40:19,000 –&gt; 00:40:20,000<br>Yes.</p>
<p>311<br>00:40:24,000 –&gt; 00:40:27,000<br>Because there’s more things to compress.</p>
<p>312<br>00:40:27,000 –&gt; 00:40:29,000<br>There’s more bits.</p>
<p>313<br>00:40:35,000 –&gt; 00:40:37,000<br>Well, look at the results on a second.</p>
<p>314<br>00:40:39,000 –&gt; 00:40:45,000<br>What’s that, Samian?</p>
<p>315<br>00:40:45,000 –&gt; 00:40:50,000<br>So if you run the four bytes of threads, four bytes of them, what’s it run?</p>
<p>316<br>00:40:50,000 –&gt; 00:40:53,000<br>And I’ll stick like to end result, which one is this small?</p>
<p>317<br>00:40:53,000 –&gt; 00:40:54,000<br>It’s correct.</p>
<p>318<br>00:40:54,000 –&gt; 00:41:03,000<br>The statement is, if you compress the 30 bits of this versus whatever the six bytes plus the null terminator or the length,</p>
<p>319<br>00:41:03,000 –&gt; 00:41:05,000<br>like is that thing ever going to be smaller than this?</p>
<p>320<br>00:41:06,000 –&gt; 00:41:07,000<br>Now.</p>
<p>321<br>00:41:07,000 –&gt; 00:41:09,000<br>You might be able to do a picture inside.</p>
<p>322<br>00:41:09,000 –&gt; 00:41:10,000<br>Yes.</p>
<p>323<br>00:41:10,000 –&gt; 00:41:17,000<br>It’s really good data based notes better about how to serialize things, rather than just always doing the same.</p>
<p>324<br>00:41:17,000 –&gt; 00:41:20,000<br>The statement is, the news says we want to know better whether to serialize this.</p>
<p>325<br>00:41:20,000 –&gt; 00:41:22,000<br>Rather than just always doing the same thing.</p>
<p>326<br>00:41:22,000 –&gt; 00:41:24,000<br>In theory, yes.</p>
<p>327<br>00:41:24,000 –&gt; 00:41:27,000<br>Do you want to spend the time on the server side to do that?</p>
<p>328<br>00:41:27,000 –&gt; 00:41:28,000<br>Figure that out.</p>
<p>329<br>00:41:31,000 –&gt; 00:41:33,000<br>All right, we’ll come back to this.</p>
<p>330<br>00:41:34,000 –&gt; 00:41:43,000<br>So if you roll your own, those systems are going to do binary coding, but roll the own and not use one of these missing libraries.</p>
<p>331<br>00:41:43,000 –&gt; 00:41:47,000<br>But then it’s all the stuff we talked about before when we talked about data file formats.</p>
<p>332<br>00:41:47,000 –&gt; 00:41:54,000<br>We have to do the null mass, keep track of data types, the sizes of the data and the messages.</p>
<p>333<br>00:41:54,000 –&gt; 00:41:56,000<br>That’s fine.</p>
<p>334<br>00:41:56,000 –&gt; 00:41:59,000<br>We know how to write that stuff because we had to do it for storage anyway.</p>
<p>335<br>00:42:00,000 –&gt; 00:42:03,000<br>It’s just more work, whereas like ProDubuff gives you much stuff for free.</p>
<p>336<br>00:42:03,000 –&gt; 00:42:06,000<br>But you, you, you, you, is all things in CSP across.</p>
<p>337<br>00:42:08,000 –&gt; 00:42:09,000<br>All right, this one we’ve already talked about.</p>
<p>338<br>00:42:09,000 –&gt; 00:42:12,000<br>How are you going to represent actually the length of strings?</p>
<p>339<br>00:42:12,000 –&gt; 00:42:17,000<br>You could do the, the, the C style, have the null termiter byte at the end.</p>
<p>340<br>00:42:17,000 –&gt; 00:42:22,000<br>And then can the client to just scan along and to what finds the null termiterances?</p>
<p>341<br>00:42:22,000 –&gt; 00:42:24,000<br>Okay, and I’ve all the data that I need.</p>
<p>342<br>00:42:25,000 –&gt; 00:42:29,000<br>This makes it harder than potentially do jumps into fixed length offsets.</p>
<p>343<br>00:42:29,000 –&gt; 00:42:35,000<br>As we talked about before, if you’re, if you’re trying to do store things as, as, as sending things over vector batches.</p>
<p>344<br>00:42:35,000 –&gt; 00:42:39,000<br>The most common ones we like, like prefix prefixes, which we, we were talking about for.</p>
<p>345<br>00:42:39,000 –&gt; 00:42:43,000<br>And then some systems I think this was, I think, minute DB.</p>
<p>346<br>00:42:43,000 –&gt; 00:42:49,000<br>They’re just going to pat out the, the, the string with additional characters.</p>
<p>347<br>00:42:49,000 –&gt; 00:42:53,000<br>To be whatever the, the max size of the edge could be.</p>
<p>348<br>00:42:53,000 –&gt; 00:42:58,000<br>Like if I have a, if it’s a bar chart 16, I have a bunch of four character strings.</p>
<p>349<br>00:42:58,000 –&gt; 00:43:00,000<br>Just going to pat out the rest one bunch of spaces.</p>
<p>350<br>00:43:00,000 –&gt; 00:43:01,000<br>Yes.</p>
<p>351<br>00:43:01,000 –&gt; 00:43:02,000<br>Of course, it would be the best one.</p>
<p>352<br>00:43:02,000 –&gt; 00:43:03,000<br>Say again.</p>
<p>353<br>00:43:03,000 –&gt; 00:43:05,000<br>Of course, please tell us what it would be the best one.</p>
<p>354<br>00:43:05,000 –&gt; 00:43:08,000<br>His question, it’s, it’s, it’s, it’s, it’s, it’s, it’s going to be the best.</p>
<p>355<br>00:43:08,000 –&gt; 00:43:09,000<br>Yeah.</p>
<p>356<br>00:43:09,000 –&gt; 00:43:10,000<br>Why?</p>
<p>357<br>00:43:10,000 –&gt; 00:43:15,000<br>So if it’s fixed length, then if you are adding your battery for zero, so G-sickity can get that.</p>
<p>358<br>00:43:15,000 –&gt; 00:43:16,000<br>Yes.</p>
<p>359<br>00:43:16,000 –&gt; 00:43:20,000<br>And if it’s fixed, you can jump around like fast if you want.</p>
<p>360<br>00:43:20,000 –&gt; 00:43:24,000<br>You say it is, if it’s, if it’s fixed with, and you pat it with one to zero,</p>
<p>361<br>00:43:24,000 –&gt; 00:43:25,000<br>it’s G-sickity can compress that.</p>
<p>362<br>00:43:25,000 –&gt; 00:43:28,000<br>But then also to, now everything be fixed length, you can jump around as needed.</p>
<p>363<br>00:43:28,000 –&gt; 00:43:32,000<br>And you don’t need to be close to, like, you don’t need to press V to the end, then you can.</p>
<p>364<br>00:43:32,000 –&gt; 00:43:33,000<br>Correct.</p>
<p>365<br>00:43:33,000 –&gt; 00:43:37,000<br>So again, depends on, as all things, it depends on what, what the query wants to do with it.</p>
<p>366<br>00:43:37,000 –&gt; 00:43:38,000<br>Right?</p>
<p>367<br>00:43:38,000 –&gt; 00:43:41,000<br>And furthermore, also to it, if the column is like a bar chart 1024,</p>
<p>368<br>00:43:41,000 –&gt; 00:43:46,000<br>and I have a bunch of one character strings in it, then that’s wasting a ton of space.</p>
<p>369<br>00:43:46,000 –&gt; 00:43:49,000<br>My question would be why would, why would, why would, why would people do that?</p>
<p>370<br>00:43:49,000 –&gt; 00:43:52,000<br>People are stupid. You see all sorts of crazy things in real data, is this?</p>
<p>371<br>00:43:52,000 –&gt; 00:43:53,000<br>Right?</p>
<p>372<br>00:43:53,000 –&gt; 00:43:54,000<br>Yes.</p>
<p>373<br>00:43:54,000 –&gt; 00:43:57,000<br>What is the first one, does it have any advantages?</p>
<p>374<br>00:43:57,000 –&gt; 00:43:59,000<br>The first one has advantages.</p>
<p>375<br>00:43:59,000 –&gt; 00:44:05,000<br>On the server side, you can reuse like, LibC’s string functions.</p>
<p>376<br>00:44:05,000 –&gt; 00:44:07,000<br>What?</p>
<p>377<br>00:44:07,000 –&gt; 00:44:10,000<br>It’s not what it is at all for.</p>
<p>378<br>00:44:10,000 –&gt; 00:44:11,000<br>Yeah.</p>
<p>379<br>00:44:11,000 –&gt; 00:44:15,000<br>So when we put our first system, like my second, third year, or second year at CMU,</p>
<p>380<br>00:44:15,000 –&gt; 00:44:16,000<br>we did this.</p>
<p>381<br>00:44:16,000 –&gt; 00:44:19,000<br>And then of course, then we go over the wire protocol, because you’re sticking the, because wire protocol,</p>
<p>382<br>00:44:19,000 –&gt; 00:44:25,000<br>personally didn’t want an entrepreneur, didn’t have a copy of the string and add the length in front of it.</p>
<p>383<br>00:44:25,000 –&gt; 00:44:31,000<br>Do you have like one character in the back row, the column you write for?</p>
<p>384<br>00:44:31,000 –&gt; 00:44:34,000<br>One gz if you get it back, if you’re bounding everything.</p>
<p>385<br>00:44:34,000 –&gt; 00:44:42,000<br>So, the same thing is, if you have the bar chart 1024, and you, and you pad it out, you know, you, you know,</p>
<p>386<br>00:44:42,000 –&gt; 00:44:45,000<br>the small strings won’t gz handle that for you.</p>
<p>387<br>00:44:45,000 –&gt; 00:44:48,000<br>If you use gz, okay, yes.</p>
<p>388<br>00:44:48,000 –&gt; 00:44:56,000<br>It takes time, but it also, if you use it, even snappy or z-standard will be fast, but like, you got, like, not all the,</p>
<p>389<br>00:44:56,000 –&gt; 00:44:58,000<br>the day you set the server support that.</p>
<p>390<br>00:44:58,000 –&gt; 00:45:00,000<br>I just said, Postgres doesn’t support this.</p>
<p>391<br>00:45:00,000 –&gt; 00:45:03,000<br>Postgres wire protocol itself has no notion of compression.</p>
<p>392<br>00:45:03,000 –&gt; 00:45:09,000<br>You can hack it by like, tunneling all your traffic over SSH and compress that, but that’s actually hot,</p>
<p>393<br>00:45:09,000 –&gt; 00:45:11,000<br>and that’s some, that sounds crazy.</p>
<p>394<br>00:45:11,000 –&gt; 00:45:17,000<br>Like, the Postgres wire protocol, as far as I know, at least in 2024, does not have like a flag, say, this is going to be compressed.</p>
<p>395<br>00:45:17,000 –&gt; 00:45:19,000<br>My, my sequel has it.</p>
<p>396<br>00:45:19,000 –&gt; 00:45:20,000<br>Or a whole hasn’t.</p>
<p>397<br>00:45:20,000 –&gt; 00:45:24,000<br>Not, not, not, not, other systems do not.</p>
<p>398<br>00:45:24,000 –&gt; 00:45:29,000<br>So, again, sometimes ones can be faster, sometimes, uh, twos can be faster.</p>
<p>399<br>00:45:29,000 –&gt; 00:45:32,000<br>Um, no system is going to do both.</p>
<p>400<br>00:45:32,000 –&gt; 00:45:37,000<br>Uh, no system is going to try to figure out, okay, based on what your, you know, what the data looks like and what your query looks like.</p>
<p>401<br>00:45:37,000 –&gt; 00:45:38,000<br>I’m going to give you one versus the other.</p>
<p>402<br>00:45:38,000 –&gt; 00:45:47,000<br>Because again, that’s more engineering overhead that you got to support now on the, on the server side, and on the client side, and it’s just not worth it.</p>
<p>403<br>00:45:47,000 –&gt; 00:45:50,000<br>Right? This will be the fastest if your data set size is small.</p>
<p>404<br>00:45:50,000 –&gt; 00:45:52,000<br>It’s all char ones.</p>
<p>405<br>00:45:52,000 –&gt; 00:45:54,000<br>This is going to be the fastest.</p>
<p>406<br>00:45:54,000 –&gt; 00:45:59,000<br>Because you don’t store the, the length.</p>
<p>407<br>00:45:59,000 –&gt; 00:46:06,000<br>Okay, I’m going to show, um, let’s say also to like, as all things we talked about for, these aren’t independent, right?</p>
<p>408<br>00:46:06,000 –&gt; 00:46:12,000<br>Like, if I, if I choose one of these, that’ll affect whether, you know, how, what kind of complexity that want to use.</p>
<p>409<br>00:46:12,000 –&gt; 00:46:16,000<br>That’s very something to the stuff we talked about when we talked about data on disk.</p>
<p>410<br>00:46:16,000 –&gt; 00:46:18,000<br>So, I’m going to show two graphs here.</p>
<p>411<br>00:46:18,000 –&gt; 00:46:24,000<br>So, the first is going to be what happens when we just send one tuple from, from the data system to the client.</p>
<p>412<br>00:46:24,000 –&gt; 00:46:34,000<br>And the idea is here just to look at what the overheads of like, just all the infrastructure around the messages of sending the query and getting, getting back to the result.</p>
<p>413<br>00:46:34,000 –&gt; 00:46:40,000<br>So, and for all these systems, except for Hive, these are all going to be using O2BC.</p>
<p>414<br>00:46:40,000 –&gt; 00:46:43,000<br>Hive is going to be using JDBC.</p>
<p>415<br>00:46:43,000 –&gt; 00:46:48,000<br>I think, forget the reason why they did that.</p>
<p>416<br>00:46:48,000 –&gt; 00:46:50,000<br>So, here’s the numbers.</p>
<p>417<br>00:46:50,000 –&gt; 00:46:55,000<br>Right? And they’re, they’re listed in order of, of, of performance.</p>
<p>418<br>00:46:55,000 –&gt; 00:47:02,000<br>So, the first thing to point out here is that, here’s, here’s a MoneDB that’s using the text encoding thing we’ve talked about before.</p>
<p>419<br>00:47:02,000 –&gt; 00:47:08,000<br>And they’re sending over, converting all the binary data into string form and sending that over.</p>
<p>420<br>00:47:08,000 –&gt; 00:47:12,000<br>Right? All the other ones are using binary encoding.</p>
<p>421<br>00:47:12,000 –&gt; 00:47:20,000<br>But yet, MoneDB is, is the, what, the second fastest or third fastest? Right?</p>
<p>422<br>00:47:20,000 –&gt; 00:47:23,000<br>Why?</p>
<p>423<br>00:47:23,000 –&gt; 00:47:25,000<br>Probably a g-zip.</p>
<p>424<br>00:47:25,000 –&gt; 00:47:26,000<br>You said power g-zip.</p>
<p>425<br>00:47:26,000 –&gt; 00:47:29,000<br>What’s that?</p>
<p>426<br>00:47:29,000 –&gt; 00:47:32,000<br>It might still seem to be faster without…</p>
<p>427<br>00:47:32,000 –&gt; 00:47:33,000<br>Yep.</p>
<p>428<br>00:47:33,000 –&gt; 00:47:35,000<br>So, that’s what we’re just going to do.</p>
<p>429<br>00:47:35,000 –&gt; 00:47:38,000<br>G-zip, helping this, helping him here?</p>
<p>430<br>00:47:38,000 –&gt; 00:47:39,000<br>No.</p>
<p>431<br>00:47:39,000 –&gt; 00:47:42,000<br>So, all right. So, let’s talk about why the other ones are slow. Right?</p>
<p>432<br>00:47:42,000 –&gt; 00:47:44,000<br>So, so the slowest one is Hive. Right?</p>
<p>433<br>00:47:44,000 –&gt; 00:47:49,000<br>The reason why that’s, according to the paper, why that slow is, they’re using Thrift.</p>
<p>434<br>00:47:49,000 –&gt; 00:47:54,000<br>So, Thrift is going to do, you know, copying things in and out of, of Thrift buffers.</p>
<p>435<br>00:47:54,000 –&gt; 00:47:59,000<br>So, that additional M-copies get data, you know, onto Thrift on the server side,</p>
<p>436<br>00:47:59,000 –&gt; 00:48:02,000<br>and then on the client side, copying out of their buffers as well.</p>
<p>437<br>00:48:02,000 –&gt; 00:48:10,000<br>And then Thrift is also going to, you know, sending over a bunch of different meta data about what the structure of the,</p>
<p>438<br>00:48:10,000 –&gt; 00:48:18,000<br>of the, of the, of the structure of the message is going to be, you know, they’re sending that over as well.</p>
<p>439<br>00:48:18,000 –&gt; 00:48:26,000<br>So, the size of the, of the packet, the message for sending the same tuple as all those systems is just much, much higher.</p>
<p>440<br>00:48:26,000 –&gt; 00:48:33,000<br>DB2 is, the second slowest because they’re actually, I mean Oracle does this, as well, but for some reason it’s, it’s more</p>
<p>441<br>00:48:33,000 –&gt; 00:48:37,000<br>pre-nicious than this one. They’re actually also basically re-implementing</p>
<p>442<br>00:48:37,000 –&gt; 00:48:44,000<br>acknowledgements on top of TCP IP. So, TCP IP is already going to be doing like, you know, sending acts back.</p>
<p>443<br>00:48:44,000 –&gt; 00:48:49,000<br>They’re going to be doing that as well above that to make sure that like, okay, I got your message for this,</p>
<p>444<br>00:48:49,000 –&gt; 00:48:53,000<br>you know, the daily server, for this, you know, I got this packet, I’m ready to give me the next one.</p>
<p>445<br>00:48:53,000 –&gt; 00:49:02,000<br>Right? So, the protocol itself is just way more chatty because for some reason they’re implementing, re-implementing this idea of, you know, of acknowledgements, yes.</p>
<p>446<br>00:49:02,000 –&gt; 00:49:05,000<br>Was it based on beauty of the idea? Is that what they’re doing?</p>
<p>447<br>00:49:05,000 –&gt; 00:49:07,000<br>His question is, is it based on UDP? I have no idea.</p>
<p>448<br>00:49:08,000 –&gt; 00:49:13,000<br>Also, too, like, since it’s a proprietary protocol, they can’t see the implementation on the server side.</p>
<p>449<br>00:49:13,000 –&gt; 00:49:16,000<br>This is what the payment is speculating. Yes.</p>
<p>450<br>00:49:16,000 –&gt; 00:49:19,000<br>How is it possible for the so slow one?</p>
<p>451<br>00:49:19,000 –&gt; 00:49:22,000<br>For one to, how many bits is that?</p>
<p>452<br>00:49:22,000 –&gt; 00:49:24,000<br>How many bit’s is that?</p>
<p>453<br>00:49:24,000 –&gt; 00:49:27,000<br>At most, let’s say, from TPCH?</p>
<p>454<br>00:49:27,000 –&gt; 00:49:30,000<br>It’s less than, let’s have a kill right.</p>
<p>455<br>00:49:31,000 –&gt; 00:49:33,000<br>So, let’s take the whole script.</p>
<p>456<br>00:49:33,000 –&gt; 00:49:40,000<br>I think also, too, like, this is, I think this is end to end time, right?</p>
<p>457<br>00:49:40,000 –&gt; 00:49:42,000<br>And not just sending the message.</p>
<p>458<br>00:49:42,000 –&gt; 00:49:51,000<br>So, like, this is like sending the query and then high basically converts the query into a map-reduced job, then it dispatches that, gets back to the results, sends it back.</p>
<p>459<br>00:49:51,000 –&gt; 00:49:53,000<br>So, I think it includes that.</p>
<p>460<br>00:49:53,000 –&gt; 00:49:56,000<br>But I had to double check.</p>
<p>461<br>00:49:56,000 –&gt; 00:50:02,000<br>And this client on the same machine as the server, I see what else I say.</p>
<p>462<br>00:50:02,000 –&gt; 00:50:08,000<br>The minimum query exact shoot time, they would query multiple times, the data system would cache the query plan and the result.</p>
<p>463<br>00:50:08,000 –&gt; 00:50:10,000<br>So, I came back to what I said. It wasn’t running the map-reduced job.</p>
<p>464<br>00:50:10,000 –&gt; 00:50:14,000<br>In literally, it’s just, like, how to get data in and out as fast as possible.</p>
<p>465<br>00:50:14,000 –&gt; 00:50:15,000<br>Right?</p>
<p>466<br>00:50:15,000 –&gt; 00:50:17,000<br>Okay, it’s one second.</p>
<p>467<br>00:50:17,000 –&gt; 00:50:19,000<br>It’s wrong.</p>
<p>468<br>00:50:19,000 –&gt; 00:50:21,000<br>How does not have a great system?</p>
<p>469<br>00:50:21,000 –&gt; 00:50:30,000<br>There’s a reason why Facebook ditched it and rewrote, pressed O.</p>
<p>470<br>00:50:30,000 –&gt; 00:50:41,000<br>Hi, it was a stopgap solution in the late 2000s when, and I was sort of part of this, like, the map-reduced paper came out from Google.</p>
<p>471<br>00:50:41,000 –&gt; 00:50:45,000<br>Yahoo took it, sort of re-impleanted the ideas as a Hadoop.</p>
<p>472<br>00:50:45,000 –&gt; 00:50:51,000<br>Hadoop was like the hot thing. I was like, this is amazing. This is how you should be doing analytics and big data stuff.</p>
<p>473<br>00:50:51,000 –&gt; 00:50:56,000<br>The relational database people, which I was a part of, you guys are all doing it wrong.</p>
<p>474<br>00:50:56,000 –&gt; 00:51:01,000<br>You’re re-venting stuff. It was a men in the 90s for parallel databases, distributed databases.</p>
<p>475<br>00:51:01,000 –&gt; 00:51:05,000<br>And then, like, declarative languages like SQL is a good idea.</p>
<p>476<br>00:51:05,000 –&gt; 00:51:11,000<br>Processing data on partition tables. That’s a good idea.</p>
<p>477<br>00:51:11,000 –&gt; 00:51:15,000<br>And then people realize, oh yeah, writing these map-reduced jobs in Java sucks.</p>
<p>478<br>00:51:15,000 –&gt; 00:51:17,000<br>Be nice we had SQL.</p>
<p>479<br>00:51:17,000 –&gt; 00:51:23,000<br>So then they built high, which is basically a translator from SQL, and it would then cogent a map-reduced Java program.</p>
<p>480<br>00:51:23,000 –&gt; 00:51:29,000<br>So, yeah, you’re making a face. It’s not saying it’s a good idea.</p>
<p>481<br>00:51:29,000 –&gt; 00:51:32,000<br>Yeah, okay, for this, again, they were surprised at how slow DB2 was, again, as you were saying.</p>
<p>482<br>00:51:32,000 –&gt; 00:51:39,000<br>It’s such a small amount of data, but again, I think the protocol is just so chatting.</p>
<p>483<br>00:51:39,000 –&gt; 00:51:42,000<br>All right, so let’s now look, we’ll send more data.</p>
<p>484<br>00:51:42,000 –&gt; 00:51:45,000<br>So for this one, we’re going to send a million tables from TPCH.</p>
<p>485<br>00:51:45,000 –&gt; 00:51:49,000<br>And what they’re going to do is they’re going to scale along the X-axis.</p>
<p>486<br>00:51:49,000 –&gt; 00:51:55,000<br>They’re going to artificially slow down what the network latency is between the client and the server.</p>
<p>487<br>00:51:55,000 –&gt; 00:52:00,000<br>And so the first line I want to show is just for my SQL with GZIP and my SQL without GZIP.</p>
<p>488<br>00:52:00,000 –&gt; 00:52:05,000<br>So this basically corroborates what we talked about before with storage,</p>
<p>489<br>00:52:05,000 –&gt; 00:52:08,000<br>getting things again from S3 or the object store, whatever.</p>
<p>490<br>00:52:08,000 –&gt; 00:52:16,000<br>When the network’s really fast, you don’t want to compress the data because the CPU cost of doing that digital compression is just not worth the penalty,</p>
<p>491<br>00:52:16,000 –&gt; 00:52:19,000<br>or it’s not worth it because the network is so fast.</p>
<p>492<br>00:52:19,000 –&gt; 00:52:24,000<br>And so that’s why you see this gap here when the network’s really fast, not using compression is the better way to go,</p>
<p>493<br>00:52:24,000 –&gt; 00:52:26,000<br>even though you are sending more bytes.</p>
<p>494<br>00:52:26,000 –&gt; 00:52:33,000<br>But then even though we are long scale here, but as we get to a slower speed, so 100 milliseconds for the latency,</p>
<p>495<br>00:52:33,000 –&gt; 00:52:39,000<br>again, we’re long scale, but the compression one actually is slightly better.</p>
<p>496<br>00:52:39,000 –&gt; 00:52:48,000<br>Because in that case, the CPU is not the dominating factor of getting the data out.</p>
<p>497<br>00:52:48,000 –&gt; 00:52:52,000<br>The compression over has bad when the trade-off of the network is fast.</p>
<p>498<br>00:52:52,000 –&gt; 00:52:55,000<br>So now we bring back all the other ones.</p>
<p>499<br>00:52:55,000 –&gt; 00:53:00,000<br>And they all basically convert or are moving along the same way as expected.</p>
<p>500<br>00:53:00,000 –&gt; 00:53:07,000<br>The time it takes to get the data out of the database server goes up as the network gets slower.</p>
<p>501<br>00:53:07,000 –&gt; 00:53:16,000<br>What’s surprising here is that you kind of see that in the case of Oracle, they’re one of the faster ones when the network gets fast,</p>
<p>502<br>00:53:16,000 –&gt; 00:53:20,000<br>but then as the network gets slower, they’re now the second slowest.</p>
<p>503<br>00:53:20,000 –&gt; 00:53:22,000<br>DB2 is always the slowest.</p>
<p>504<br>00:53:22,000 –&gt; 00:53:27,000<br>Hi, I’ve actually beat, yeah, hi, I’ve actually beat DB2 when the slower network.</p>
<p>505<br>00:53:27,000 –&gt; 00:53:33,000<br>And so the Oracle is a, Oracle is a proprietary protocol.</p>
<p>506<br>00:53:33,000 –&gt; 00:53:39,000<br>We can’t see the implementation of it, but they speculate, they speculate again just like in the case of DB2,</p>
<p>507<br>00:53:39,000 –&gt; 00:53:48,000<br>Oracle is also sending their own acknowledgments back and forth, and it just becomes more dominating cost with the network gets slower.</p>
<p>508<br>00:53:48,000 –&gt; 00:53:57,000<br>So again, all of these except for hot, sorry, except for a mony DB are binary protocols,</p>
<p>509<br>00:53:57,000 –&gt; 00:54:06,000<br>but a mony DB is actually what, is the third best after my SQL and my SQL and GZIP?</p>
<p>510<br>00:54:06,000 –&gt; 00:54:08,000<br>Because it’s simple, yes.</p>
<p>511<br>00:54:08,000 –&gt; 00:54:13,000<br>Is the benefit from compression over the white daughter’s often at my people?</p>
<p>512<br>00:54:13,000 –&gt; 00:54:18,000<br>Question is, do you get the same benefit of compression for the other sets of as my SQL?</p>
<p>513<br>00:54:18,000 –&gt; 00:54:22,000<br>I would assume yes, like Oracle, you could test it.</p>
<p>514<br>00:54:22,000 –&gt; 00:54:28,000<br>I would say yes, because the Oracle wire protocol, it’s, the actual bits themselves,</p>
<p>515<br>00:54:28,000 –&gt; 00:54:32,000<br>maybe different than what my SQL is, but it’s a binary based protocol like my SQL.</p>
<p>516<br>00:54:32,000 –&gt; 00:54:34,000<br>So it’d probably be the same.</p>
<p>517<br>00:54:34,000 –&gt; 00:54:37,000<br>Why do they only, if one of them is a bit of a white daughter?</p>
<p>518<br>00:54:37,000 –&gt; 00:54:40,000<br>Exception, why do they only turn on GZIP for my SQL?</p>
<p>519<br>00:54:40,000 –&gt; 00:54:41,000<br>I don’t know.</p>
<p>520<br>00:54:41,000 –&gt; 00:54:42,000<br>Yep.</p>
<p>521<br>00:54:45,000 –&gt; 00:54:46,000<br>Okay.</p>
<p>522<br>00:54:46,000 –&gt; 00:54:48,000<br>So I’m going to show another result from a different paper.</p>
<p>523<br>00:54:48,000 –&gt; 00:54:53,000<br>This is a paper we wrote with one of my former master students,</p>
<p>524<br>00:54:53,000 –&gt; 00:54:57,000<br>now a PhD student at MIT, and then West McKinney, the guy from Apache Arrow.</p>
<p>525<br>00:54:57,000 –&gt; 00:55:02,000<br>So for this one, this is from our older system, Peloton, our noise page,</p>
<p>526<br>00:55:02,000 –&gt; 00:55:07,000<br>and the idea was how fast can we get the line item table out of,</p>
<p>527<br>00:55:07,000 –&gt; 00:55:09,000<br>or the line table out in TBCC, so I’ll get, okay.</p>
<p>528<br>00:55:09,000 –&gt; 00:55:14,000<br>Probably a seven gigabyte data, how can we fast clean get it to the client?</p>
<p>529<br>00:55:14,000 –&gt; 00:55:19,000<br>So the client isn’t doing any, any, any computation on it, which is how fast can you get it?</p>
<p>530<br>00:55:19,000 –&gt; 00:55:23,000<br>And so the, our system is supported, the Postgres wire protocol,</p>
<p>531<br>00:55:23,000 –&gt; 00:55:27,000<br>so this is like, this is the default like Postgres wire protocol without compression,</p>
<p>532<br>00:55:27,000 –&gt; 00:55:29,000<br>row base, this is how fast you can get the data out.</p>
<p>533<br>00:55:30,000 –&gt; 00:55:34,000<br>So natively our system was storing everything as Apache Arrow tables.</p>
<p>534<br>00:55:34,000 –&gt; 00:55:37,000<br>So that, in our system, you can do transactions, then over time,</p>
<p>535<br>00:55:37,000 –&gt; 00:55:41,000<br>as the data got cold and you weren’t modifying anymore,</p>
<p>536<br>00:55:41,000 –&gt; 00:55:46,000<br>it would just dim flips and bits around, and then it would be natively sorting Apache Arrow.</p>
<p>537<br>00:55:46,000 –&gt; 00:55:53,000<br>So this next bar here is what you get from what they were posing in the paper you guys read,</p>
<p>538<br>00:55:53,000 –&gt; 00:55:57,000<br>like here’s the vectorized version of the, of the Postgres wire protocol,</p>
<p>539<br>00:55:57,000 –&gt; 00:56:02,000<br>we were sending things as a PAX format rather than as road-wiring to it.</p>
<p>540<br>00:56:02,000 –&gt; 00:56:06,000<br>But then the next approach is using, early precursor to ADBC,</p>
<p>541<br>00:56:06,000 –&gt; 00:56:12,000<br>the arrow connectivity stuff, where this is like natively sending out a,</p>
<p>542<br>00:56:12,000 –&gt; 00:56:17,000<br>the Apache Arrow data in its form without doing any translations,</p>
<p>543<br>00:56:17,000 –&gt; 00:56:20,000<br>just natively shoving that to the Python application.</p>
<p>544<br>00:56:20,000 –&gt; 00:56:23,000<br>And so it’s faster because there’s no conversion over the,</p>
<p>545<br>00:56:23,000 –&gt; 00:56:26,000<br>to convert it into a different form, right?</p>
<p>546<br>00:56:26,000 –&gt; 00:56:29,000<br>It’s exactly for what, you know, we’re sending the data, we’re storing natively memory,</p>
<p>547<br>00:56:29,000 –&gt; 00:56:32,000<br>we’re just storing that shoving that, there’s bytes right out.</p>
<p>548<br>00:56:32,000 –&gt; 00:56:35,000<br>And so now the last one is RDMA, I’ll cover what that is in the second.</p>
<p>549<br>00:56:35,000 –&gt; 00:56:38,000<br>Basically this is like a network accelerator to do kernel bypass,</p>
<p>550<br>00:56:38,000 –&gt; 00:56:40,000<br>to, to, to, to get the data out of memory,</p>
<p>551<br>00:56:40,000 –&gt; 00:56:45,000<br>put it on the nick and send it out without having to copy things into the CPU first.</p>
<p>552<br>00:56:46,000 –&gt; 00:56:50,000<br>And I forget we use, I think we used a fan of it for this one.</p>
<p>553<br>00:56:50,000 –&gt; 00:56:54,000<br>But again, this one also is just sending out native arrow arrow blocks,</p>
<p>554<br>00:56:54,000 –&gt; 00:56:56,000<br>rather than doing the conversion.</p>
<p>555<br>00:56:56,000 –&gt; 00:57:00,000<br>So again, even though the paper you guys read didn’t, didn’t implement,</p>
<p>556<br>00:57:00,000 –&gt; 00:57:04,000<br>you know, didn’t have, you know, arrow at the time to send, send it out,</p>
<p>557<br>00:57:04,000 –&gt; 00:57:08,000<br>the, the performance difference, I think, would look like this.</p>
<p>558<br>00:57:08,000 –&gt; 00:57:12,000<br>So again, so I’m saying, something that ADBC just shoving data out as arrow</p>
<p>559<br>00:57:12,000 –&gt; 00:57:15,000<br>is the right way to go if you’re building a modern system today.</p>
<p>560<br>00:57:15,000 –&gt; 00:57:16,000<br>Yes.</p>
<p>561<br>00:57:16,000 –&gt; 00:57:18,000<br>Is there a cost of converting whatever it is,</p>
<p>562<br>00:57:18,000 –&gt; 00:57:20,000<br>most of the arrow for this?</p>
<p>563<br>00:57:20,000 –&gt; 00:57:22,000<br>It’s questions, is there a cost of convert, whatever,</p>
<p>564<br>00:57:22,000 –&gt; 00:57:23,000<br>postgres is into arrow?</p>
<p>565<br>00:57:23,000 –&gt; 00:57:24,000<br>Yeah.</p>
<p>566<br>00:57:24,000 –&gt; 00:57:25,000<br>I mean, certainly yes.</p>
<p>567<br>00:57:25,000 –&gt; 00:57:28,000<br>So, doesn’t, doesn’t that want to keep, like,</p>
<p>568<br>00:57:28,000 –&gt; 00:57:31,000<br>that shows the cost of converting, like, postgres,</p>
<p>569<br>00:57:31,000 –&gt; 00:57:33,000<br>is the, whatever, format, the paper?</p>
<p>570<br>00:57:33,000 –&gt; 00:57:37,000<br>No, this is the cost of converting arrow into the,</p>
<p>571<br>00:57:37,000 –&gt; 00:57:41,000<br>a postgres compatible protocol that sends things in a vectorized format.</p>
<p>572<br>00:57:41,000 –&gt; 00:57:46,000<br>This is like, I don’t do any copying, I do literally shove the bytes out.</p>
<p>573<br>00:57:46,000 –&gt; 00:57:51,000<br>And then the paper talks about it like, to do,</p>
<p>574<br>00:57:51,000 –&gt; 00:57:55,000<br>like, to do something like this, to rewrite your right protocol,</p>
<p>575<br>00:57:55,000 –&gt; 00:57:57,000<br>it’d be very unlikely that the date,</p>
<p>576<br>00:57:57,000 –&gt; 00:57:59,000<br>you’re storing that data in a navly anyway.</p>
<p>577<br>00:57:59,000 –&gt; 00:58:04,000<br>So you, if you just have things, to convert things to arrow,</p>
<p>578<br>00:58:04,000 –&gt; 00:58:06,000<br>or have things already be arrow internally,</p>
<p>579<br>00:58:06,000 –&gt; 00:58:08,000<br>then that’s a better way to do this.</p>
<p>580<br>00:58:08,000 –&gt; 00:58:10,000<br>That’s why you see some systems, like,</p>
<p>581<br>00:58:10,000 –&gt; 00:58:12,000<br>you made a result going from one operator to the next,</p>
<p>582<br>00:58:12,000 –&gt; 00:58:15,000<br>to the query planner, how they exchange data between the different workers,</p>
<p>583<br>00:58:15,000 –&gt; 00:58:22,000<br>if everything’s an arrow, then, like, you have the infrastructure to shove the data, like that.</p>
<p>584<br>00:58:22,000 –&gt; 00:58:23,000<br>Okay.</p>
<p>585<br>00:58:23,000 –&gt; 00:58:28,000<br>So, the, these, these, these members should show here,</p>
<p>586<br>00:58:28,000 –&gt; 00:58:32,000<br>the, we talked about how, like, okay, the,</p>
<p>587<br>00:58:32,000 –&gt; 00:58:34,000<br>the network protocol, like, you can press things,</p>
<p>588<br>00:58:34,000 –&gt; 00:58:37,000<br>is it, how are you encoding the serialization format,</p>
<p>589<br>00:58:37,000 –&gt; 00:58:38,000<br>how much metadata you’re sending around?</p>
<p>590<br>00:58:38,000 –&gt; 00:58:42,000<br>Like, that was what we focused on, but that isn’t always going to be the,</p>
<p>591<br>00:58:42,000 –&gt; 00:58:45,000<br>the major slowdown of sending things over the network.</p>
<p>592<br>00:58:45,000 –&gt; 00:58:46,000<br>Right?</p>
<p>593<br>00:58:46,000 –&gt; 00:58:49,000<br>As I said many times, the OS is going to be a problem for us.</p>
<p>594<br>00:58:49,000 –&gt; 00:58:51,000<br>It’s always going to try to ruin our lives,</p>
<p>595<br>00:58:51,000 –&gt; 00:58:54,000<br>make things harder for us, break up our marriages, and whatever.</p>
<p>596<br>00:58:54,000 –&gt; 00:58:56,000<br>Right? And in particular, TCPIP stack,</p>
<p>597<br>00:58:56,000 –&gt; 00:58:58,000<br>it’s just going to be super slow,</p>
<p>598<br>00:58:58,000 –&gt; 00:59:00,000<br>and ideally, we want to try to avoid it.</p>
<p>599<br>00:59:00,000 –&gt; 00:59:04,000<br>So why is it slow? Well, it’s, it’s, you know,</p>
<p>600<br>00:59:05,000 –&gt; 00:59:08,000<br>the networking implementation is based on this model of interrupts.</p>
<p>601<br>00:59:08,000 –&gt; 00:59:11,000<br>So, like, you know, they’re requiring, they’re assuming these interrupts</p>
<p>602<br>00:59:11,000 –&gt; 00:59:13,000<br>are going to come along, and that’s how it’s going to trigger things like,</p>
<p>603<br>00:59:13,000 –&gt; 00:59:15,000<br>hey, bytes are ready to go in and out, and that, you know,</p>
<p>604<br>00:59:15,000 –&gt; 00:59:17,000<br>and you’re going to do a context switch, like,</p>
<p>605<br>00:59:17,000 –&gt; 00:59:18,000<br>all that becomes super expensive.</p>
<p>606<br>00:59:18,000 –&gt; 00:59:20,000<br>Then you get data coming on the Nick,</p>
<p>607<br>00:59:20,000 –&gt; 00:59:23,000<br>the OS wants to copy that in its own internal kernel buffers,</p>
<p>608<br>00:59:23,000 –&gt; 00:59:25,000<br>and then, before it hands you that memory,</p>
<p>609<br>00:59:25,000 –&gt; 00:59:27,000<br>it’s going to copy into your user space buffers.</p>
<p>610<br>00:59:27,000 –&gt; 00:59:28,000<br>Right?</p>
<p>611<br>00:59:28,000 –&gt; 00:59:29,000<br>What was that face?</p>
<p>612<br>00:59:29,000 –&gt; 00:59:30,000<br>What’s that, what’s wrong?</p>
<p>613<br>00:59:30,000 –&gt; 00:59:31,000<br>What?</p>
<p>614<br>00:59:31,000 –&gt; 00:59:32,000<br>Sorry.</p>
<p>615<br>00:59:33,000 –&gt; 00:59:37,000<br>Yeah, this sucks. Yeah.</p>
<p>616<br>00:59:37,000 –&gt; 00:59:39,000<br>It’s a terrible.</p>
<p>617<br>00:59:39,000 –&gt; 00:59:42,000<br>Furthermore, all right, so the kernel has got a bunch of threads coming down,</p>
<p>618<br>00:59:42,000 –&gt; 00:59:44,000<br>and they’re handling the interrupts, they’re handling things coming over the,</p>
<p>619<br>00:59:44,000 –&gt; 00:59:46,000<br>the Nicks and hardware and so forth.</p>
<p>620<br>00:59:46,000 –&gt; 00:59:48,000<br>Well, those have to be scheduled.</p>
<p>621<br>00:59:48,000 –&gt; 00:59:51,000<br>They have to maintain their own latches for their own internal data structures.</p>
<p>622<br>00:59:51,000 –&gt; 00:59:54,000<br>All that is going to be problematic, right?</p>
<p>623<br>00:59:54,000 –&gt; 00:59:59,000<br>So, we want to figure out a way that we can avoid the OS as much as possible.</p>
<p>624<br>00:59:59,000 –&gt; 01:00:01,000<br>Yeah, we need the OS to survive.</p>
<p>625<br>01:00:01,000 –&gt; 01:00:05,000<br>We need it to give us some memory and obviously schedule us,</p>
<p>626<br>01:00:05,000 –&gt; 01:00:08,000<br>but after that, we want to avoid it as much as possible.</p>
<p>627<br>01:00:08,000 –&gt; 01:00:11,000<br>And that’s going to allow us our users to run faster.</p>
<p>628<br>01:00:11,000 –&gt; 01:00:17,000<br>So, what I’ll talk about next is going to be focusing primarily on for networking stuff,</p>
<p>629<br>01:00:17,000 –&gt; 01:00:19,000<br>but this also applies for disk.</p>
<p>630<br>01:00:19,000 –&gt; 01:00:23,000<br>You want to avoid the OS for disk as much as possible, too.</p>
<p>631<br>01:00:23,000 –&gt; 01:00:25,000<br>All right, so the first approach to me,</p>
<p>632<br>01:00:25,000 –&gt; 01:00:27,000<br>what I call kernel bypass.</p>
<p>633<br>01:00:27,000 –&gt; 01:00:31,000<br>And the idea here is that we want to be able to get data directly from the hardware,</p>
<p>634<br>01:00:31,000 –&gt; 01:00:34,000<br>in this case, the Nick, the thing that the American interface,</p>
<p>635<br>01:00:34,000 –&gt; 01:00:38,000<br>we want to get that into our database system running in user space,</p>
<p>636<br>01:00:38,000 –&gt; 01:00:40,000<br>into our memory up there without having to go through us,</p>
<p>637<br>01:00:40,000 –&gt; 01:00:46,000<br>without doing any copying, ideally without having to talk to the OS TCP IP stack.</p>
<p>638<br>01:00:46,000 –&gt; 01:00:48,000<br>All right?</p>
<p>639<br>01:00:48,000 –&gt; 01:00:50,000<br>And so, there’s three different ways you can do this.</p>
<p>640<br>01:00:50,000 –&gt; 01:00:56,000<br>There’s the DVDK, RDMA, and then IOU Ring is going to be the,</p>
<p>641<br>01:00:56,000 –&gt; 01:00:58,000<br>the newer one, right?</p>
<p>642<br>01:00:58,000 –&gt; 01:01:01,000<br>So, the way to think about this is like,</p>
<p>643<br>01:01:01,000 –&gt; 01:01:04,000<br>OS Linux is a time sharing system,</p>
<p>644<br>01:01:04,000 –&gt; 01:01:08,000<br>and that means it’s going to rely on these slow, expensive interrupts to, again,</p>
<p>645<br>01:01:08,000 –&gt; 01:01:11,000<br>tell it when there’s something new showing up,</p>
<p>646<br>01:01:11,000 –&gt; 01:01:13,000<br>and take away some, you know, take away,</p>
<p>647<br>01:01:13,000 –&gt; 01:01:17,000<br>exuding some thread to go let now the kernel thread deal with whatever that,</p>
<p>648<br>01:01:17,000 –&gt; 01:01:19,000<br>you know, the interrupt handler, right?</p>
<p>649<br>01:01:19,000 –&gt; 01:01:21,000<br>And then all these additional threads on the inside,</p>
<p>650<br>01:01:21,000 –&gt; 01:01:23,000<br>they’re going to maintain their own latches,</p>
<p>651<br>01:01:23,000 –&gt; 01:01:25,000<br>and all those things are going to be problematic for us.</p>
<p>652<br>01:01:25,000 –&gt; 01:01:28,000<br>Linux has gotten a lot better in the last, I mean, the 10 years,</p>
<p>653<br>01:01:28,000 –&gt; 01:01:32,000<br>or the 10 years it’s gotten way better for handling with, you know,</p>
<p>654<br>01:01:32,000 –&gt; 01:01:34,000<br>large amount of core counts.</p>
<p>655<br>01:01:34,000 –&gt; 01:01:36,000<br>It’s gotten way more scale than it used to be,</p>
<p>656<br>01:01:36,000 –&gt; 01:01:39,000<br>but, you know, whenever there’s contention,</p>
<p>657<br>01:01:39,000 –&gt; 01:01:40,000<br>no matter how great your code is,</p>
<p>658<br>01:01:40,000 –&gt; 01:01:42,000<br>everything’s always going to fall over.</p>
<p>659<br>01:01:42,000 –&gt; 01:01:44,000<br>We’re going to avoid as much as possible.</p>
<p>660<br>01:01:44,000 –&gt; 01:01:46,000<br>All right, so let’s go through these one by one.</p>
<p>661<br>01:01:46,000 –&gt; 01:01:49,000<br>So, the DVDK, the data plane development kit,</p>
<p>662<br>01:01:49,000 –&gt; 01:01:51,000<br>this is from something from Intel.</p>
<p>663<br>01:01:51,000 –&gt; 01:01:54,000<br>So, it’s a set of libraries that allow your user space program</p>
<p>664<br>01:01:54,000 –&gt; 01:01:56,000<br>to interact with the Nick directly.</p>
<p>665<br>01:01:56,000 –&gt; 01:02:00,000<br>There’s an equipment for, in the storage world,</p>
<p>666<br>01:02:00,000 –&gt; 01:02:04,000<br>called the SBDK, the storage plane data kit, also from Intel.</p>
<p>667<br>01:02:04,000 –&gt; 01:02:07,000<br>And the idea here is that you treat whatever,</p>
<p>668<br>01:02:07,000 –&gt; 01:02:11,000<br>the harbor device you’re trying to interact with as a raw device,</p>
<p>669<br>01:02:11,000 –&gt; 01:02:14,000<br>meaning you’re responsible for like reading the low, low bits</p>
<p>670<br>01:02:14,000 –&gt; 01:02:18,000<br>in the memory space of that device and interacting with it.</p>
<p>671<br>01:02:18,000 –&gt; 01:02:21,000<br>And this goes against the unit’s philosophy where everything’s a file,</p>
<p>672<br>01:02:21,000 –&gt; 01:02:24,000<br>no matter whether it’s a file on disk or it’s a harbor device,</p>
<p>673<br>01:02:24,000 –&gt; 01:02:26,000<br>you interact with these things that’s files,</p>
<p>674<br>01:02:26,000 –&gt; 01:02:29,000<br>you have your efforts and so forth.</p>
<p>675<br>01:02:29,000 –&gt; 01:02:32,000<br>But this breaks this model entirely.</p>
<p>676<br>01:02:32,000 –&gt; 01:02:39,000<br>So, now, because now the OS is removing the OS from the low level layers,</p>
<p>677<br>01:02:39,000 –&gt; 01:02:42,000<br>like 3 and 4, that means that, and our database is,</p>
<p>678<br>01:02:42,000 –&gt; 01:02:44,000<br>and we’re responsible for doing a bunch of stuff</p>
<p>679<br>01:02:44,000 –&gt; 01:02:46,000<br>that the OS would do for us.</p>
<p>680<br>01:02:46,000 –&gt; 01:02:49,000<br>And ideally, we could do this better, but not always.</p>
<p>681<br>01:02:49,000 –&gt; 01:02:52,000<br>So, the most obvious thing for doing this using the DBDK to do</p>
<p>682<br>01:02:52,000 –&gt; 01:02:57,000<br>networking stuff, well now, since there isn’t the TCP,</p>
<p>683<br>01:02:57,000 –&gt; 01:03:01,000<br>the OS hasn’t run the TCP IP stack for you on the device,</p>
<p>684<br>01:03:01,000 –&gt; 01:03:03,000<br>we have to do that in our database system.</p>
<p>685<br>01:03:03,000 –&gt; 01:03:07,000<br>You either write it by hand, or you can use open source library like F stack,</p>
<p>686<br>01:03:07,000 –&gt; 01:03:10,000<br>they basically re-implement in user space TCP IP,</p>
<p>687<br>01:03:10,000 –&gt; 01:03:13,000<br>like sending the sequence numbers, sending Mac, X,</p>
<p>688<br>01:03:13,000 –&gt; 01:03:16,000<br>like all that we have to do ourselves, the OS isn’t going to do this,</p>
<p>689<br>01:03:16,000 –&gt; 01:03:18,000<br>and the harbor doesn’t do it.</p>
<p>690<br>01:03:18,000 –&gt; 01:03:20,000<br>The advantage is that we don’t have any data copying,</p>
<p>691<br>01:03:20,000 –&gt; 01:03:23,000<br>because we’re now getting literally raw buffers of packets,</p>
<p>692<br>01:03:23,000 –&gt; 01:03:27,000<br>we get to manage what those are off the device.</p>
<p>693<br>01:03:27,000 –&gt; 01:03:31,000<br>We’re not calling a read, excuse me, there’s no syscalls,</p>
<p>694<br>01:03:31,000 –&gt; 01:03:36,000<br>everything is done again, reading directly into memory.</p>
<p>695<br>01:03:36,000 –&gt; 01:03:38,000<br>So, this sounds amazing, right?</p>
<p>696<br>01:03:38,000 –&gt; 01:03:40,000<br>Well, it’s not that common, right?</p>
<p>697<br>01:03:40,000 –&gt; 01:03:44,000<br>As far as we know, there’s only two systems that actually implement our used DBDK.</p>
<p>698<br>01:03:44,000 –&gt; 01:03:49,000<br>The first is ScaliaDBs, and they have this framework called C-star,</p>
<p>699<br>01:03:49,000 –&gt; 01:03:55,000<br>that they’re built on top of ScaliaDB is a re-imlimitation of a patch of Cassandra and C++,</p>
<p>700<br>01:03:55,000 –&gt; 01:03:58,000<br>with like code routines and DBDK and some other optimizations,</p>
<p>701<br>01:03:58,000 –&gt; 01:04:00,000<br>on where Cassandra’s entirely in Java.</p>
<p>702<br>01:04:00,000 –&gt; 01:04:02,000<br>And then yellow brick will cover later on,</p>
<p>703<br>01:04:02,000 –&gt; 01:04:04,000<br>they also use this as well.</p>
<p>704<br>01:04:04,000 –&gt; 01:04:10,000<br>But they had the ScaliaDB guys gave a talk with us a few years ago during the pandemic,</p>
<p>705<br>01:04:10,000 –&gt; 01:04:12,000<br>and they mentioned how in the C-star they yes,</p>
<p>706<br>01:04:12,000 –&gt; 01:04:17,000<br>they use code routines as well, DBDK, but DBDK for them has been a total nightmare to deal with,</p>
<p>707<br>01:04:17,000 –&gt; 01:04:19,000<br>and I think it’s turned off by default at this point.</p>
<p>708<br>01:04:19,000 –&gt; 01:04:22,000<br>I saw the yellow brick CTO a few weeks ago at Citer,</p>
<p>709<br>01:04:22,000 –&gt; 01:04:26,000<br>and as far as I know, they’re still using DBDK for their implementation.</p>
<p>710<br>01:04:26,000 –&gt; 01:04:28,000<br>Again, they’re doing this in the back end,</p>
<p>711<br>01:04:28,000 –&gt; 01:04:32,000<br>not between the client and the server.</p>
<p>712<br>01:04:32,000 –&gt; 01:04:33,000<br>Right, why is it so hard?</p>
<p>713<br>01:04:33,000 –&gt; 01:04:36,000<br>Well, okay, because you have to implement a bunch of stuff that you also normally do for you,</p>
<p>714<br>01:04:36,000 –&gt; 01:04:37,000<br>you have to implement it yourself.</p>
<p>715<br>01:04:37,000 –&gt; 01:04:38,000<br>And we tried this in our system,</p>
<p>716<br>01:04:38,000 –&gt; 01:04:41,000<br>we had one of my best master students try to use F-stack to speed up</p>
<p>717<br>01:04:42,000 –&gt; 01:04:44,000<br>another project we were doing to make a Postgres Proxy Run faster,</p>
<p>718<br>01:04:44,000 –&gt; 01:04:46,000<br>and we couldn’t make it work.</p>
<p>719<br>01:04:46,000 –&gt; 01:04:49,000<br>The engineering cost is just way too high.</p>
<p>720<br>01:04:49,000 –&gt; 01:04:54,000<br>So it’s a bit crude, but this is one of my favorite tweets of all time.</p>
<p>721<br>01:04:54,000 –&gt; 01:04:56,000<br>So this guy’s talking about the SBDK,</p>
<p>722<br>01:04:56,000 –&gt; 01:04:58,000<br>which again, that’s where the storage 98K,</p>
<p>723<br>01:04:58,000 –&gt; 01:05:00,000<br>but the DBDK certainly applies here.</p>
<p>724<br>01:05:00,000 –&gt; 01:05:02,000<br>So all this kernel bypass stuff is fantastic.</p>
<p>725<br>01:05:02,000 –&gt; 01:05:04,000<br>You think you’re going to get a big win,</p>
<p>726<br>01:05:04,000 –&gt; 01:05:05,000<br>but it’s like pin your pants, cut your cold,</p>
<p>727<br>01:05:05,000 –&gt; 01:05:07,000<br>and then you regret it pretty quickly.</p>
<p>728<br>01:05:07,000 –&gt; 01:05:09,000<br>Is this the guy who’s the real Iaduring?</p>
<p>729<br>01:05:10,000 –&gt; 01:05:11,000<br>Is it?</p>
<p>730<br>01:05:11,000 –&gt; 01:05:12,000<br>Yeah.</p>
<p>731<br>01:05:12,000 –&gt; 01:05:13,000<br>Okay, yeah.</p>
<p>732<br>01:05:13,000 –&gt; 01:05:14,000<br>Thank you.</p>
<p>733<br>01:05:14,000 –&gt; 01:05:15,000<br>Okay.</p>
<p>734<br>01:05:15,000 –&gt; 01:05:18,000<br>All right, so the next approach is to do RDAB.</p>
<p>735<br>01:05:18,000 –&gt; 01:05:20,000<br>And in this way, you have a,</p>
<p>736<br>01:05:20,000 –&gt; 01:05:25,000<br>it’s like NVMe, there’s an API that the hardware provides,</p>
<p>737<br>01:05:25,000 –&gt; 01:05:28,000<br>allows you to write directly into the hardware device</p>
<p>738<br>01:05:28,000 –&gt; 01:05:34,000<br>and get access things on a machine as if it was local.</p>
<p>739<br>01:05:34,000 –&gt; 01:05:36,000<br>So for this one’s a bit more tricky,</p>
<p>740<br>01:05:36,000 –&gt; 01:05:38,000<br>because now if you’re reading right into memory addresses,</p>
<p>741<br>01:05:38,000 –&gt; 01:05:40,000<br>on a run machine, you’ve got to be sure that, you know,</p>
<p>742<br>01:05:40,000 –&gt; 01:05:42,000<br>what you’re actually reading is what you’re expecting to read.</p>
<p>743<br>01:05:42,000 –&gt; 01:05:45,000<br>So there isn’t more handshaking up to do to set this up.</p>
<p>744<br>01:05:45,000 –&gt; 01:05:47,000<br>So there’s typically, again, something you maybe</p>
<p>745<br>01:05:47,000 –&gt; 01:05:49,000<br>want to use on the client in the server,</p>
<p>746<br>01:05:49,000 –&gt; 01:05:50,000<br>you want to do this in the back end.</p>
<p>747<br>01:05:50,000 –&gt; 01:05:53,000<br>But if you can pull this off, then you get a huge win.</p>
<p>748<br>01:05:53,000 –&gt; 01:05:56,000<br>So it used to be you could only do this on a thinner band,</p>
<p>749<br>01:05:56,000 –&gt; 01:05:59,000<br>which was sold by Melanox.</p>
<p>750<br>01:05:59,000 –&gt; 01:06:03,000<br>I think the video bought Melanox recently, or at some point.</p>
<p>751<br>01:06:03,000 –&gt; 01:06:06,000<br>The video is, you know, they have NVMe link as well,</p>
<p>752<br>01:06:06,000 –&gt; 01:06:10,000<br>but like, and then Barraki is basically,</p>
<p>753<br>01:06:10,000 –&gt; 01:06:14,000<br>Ardemy over, converged ethernet or something like that.</p>
<p>754<br>01:06:14,000 –&gt; 01:06:16,000<br>This is more common now.</p>
<p>755<br>01:06:16,000 –&gt; 01:06:19,000<br>So Ardemy is not used that often.</p>
<p>756<br>01:06:19,000 –&gt; 01:06:21,000<br>Like the only system I know that does this,</p>
<p>757<br>01:06:21,000 –&gt; 01:06:23,000<br>like the cell is used, Oracle for X-A-Data.</p>
<p>758<br>01:06:23,000 –&gt; 01:06:25,000<br>Again, but that’s like you buy the whole rack.</p>
<p>759<br>01:06:25,000 –&gt; 01:06:28,000<br>You buy the rack of compute in the rack of storage,</p>
<p>760<br>01:06:28,000 –&gt; 01:06:32,000<br>and they’re using Ardemy to communicate with the compute in the storage.</p>
<p>761<br>01:06:32,000 –&gt; 01:06:37,000<br>You can get Ardemy on Amazon, but like,</p>
<p>762<br>01:06:37,000 –&gt; 01:06:40,000<br>you can’t even only be able to do the communicate between your machines</p>
<p>763<br>01:06:40,000 –&gt; 01:06:43,000<br>that have that, and it’s a lot more work to get that set up.</p>
<p>764<br>01:06:43,000 –&gt; 01:06:44,000<br>Yes.</p>
<p>765<br>01:06:44,000 –&gt; 01:06:48,000<br>So how the source basically is that the client knows exactly what address,</p>
<p>766<br>01:06:48,000 –&gt; 01:06:51,000<br>the state of storage on the server.</p>
<p>767<br>01:06:51,000 –&gt; 01:06:52,000<br>Yes.</p>
<p>768<br>01:06:52,000 –&gt; 01:06:54,000<br>It just says, give me two X-1, two, two, four.</p>
<p>769<br>01:06:54,000 –&gt; 01:06:55,000<br>Yeah.</p>
<p>770<br>01:06:55,000 –&gt; 01:06:56,000<br>So it’s a statement as, and it’s correct.</p>
<p>771<br>01:06:56,000 –&gt; 01:06:59,000<br>Like the way this works is that the client,</p>
<p>772<br>01:06:59,000 –&gt; 01:07:02,000<br>or it doesn’t have to be again, the application could just be,</p>
<p>773<br>01:07:02,000 –&gt; 01:07:04,000<br>the thing that’s going to talk to you some of the machine,</p>
<p>774<br>01:07:04,000 –&gt; 01:07:07,000<br>has to know what memory address it wants to read,</p>
<p>775<br>01:07:07,000 –&gt; 01:07:10,000<br>assuming it has permissions, and then the request is,</p>
<p>776<br>01:07:10,000 –&gt; 01:07:12,000<br>give me the contents of that memory.</p>
<p>777<br>01:07:12,000 –&gt; 01:07:14,000<br>So the harbor knows how to go up to memory,</p>
<p>778<br>01:07:14,000 –&gt; 01:07:16,000<br>get whatever you want, and pull it back down,</p>
<p>779<br>01:07:16,000 –&gt; 01:07:18,000<br>and it doesn’t notify the CPU that it’s done that.</p>
<p>780<br>01:07:18,000 –&gt; 01:07:19,000<br>Yes.</p>
<p>781<br>01:07:19,000 –&gt; 01:07:21,000<br>Is there a security problem on the memory?</p>
<p>782<br>01:07:21,000 –&gt; 01:07:23,000<br>The question is, is there a security problem for this?</p>
<p>783<br>01:07:23,000 –&gt; 01:07:27,000<br>Sure, but like, you run this in your VPC,</p>
<p>784<br>01:07:27,000 –&gt; 01:07:30,000<br>you’re not letting, you’re not letting, you don’t expose this over,</p>
<p>785<br>01:07:30,000 –&gt; 01:07:33,000<br>over the, the public internet.</p>
<p>786<br>01:07:33,000 –&gt; 01:07:37,000<br>Again, if you’re buying X-a-data, these things are like millions of dollars.</p>
<p>787<br>01:07:37,000 –&gt; 01:07:40,000<br>You’re running this on-prem, it’s a locked cage.</p>
<p>788<br>01:07:40,000 –&gt; 01:07:44,000<br>You know, the traffic is just between these two things.</p>
<p>789<br>01:07:44,000 –&gt; 01:07:49,000<br>All right, so the last one is IOU ring,</p>
<p>790<br>01:07:49,000 –&gt; 01:07:51,000<br>which I think some of you guys are familiar with.</p>
<p>791<br>01:07:51,000 –&gt; 01:07:54,000<br>But this was an extension to, in Linux,</p>
<p>792<br>01:07:54,000 –&gt; 01:07:59,000<br>to sort of clean up their asynchronous IO API,</p>
<p>793<br>01:07:59,000 –&gt; 01:08:05,000<br>that allows you to, to, to do asynchronous requests to a harbor device,</p>
<p>794<br>01:08:05,000 –&gt; 01:08:07,000<br>either storage or network.</p>
<p>795<br>01:08:07,000 –&gt; 01:08:10,000<br>It was originally storage, and then they added networking two years ago.</p>
<p>796<br>01:08:10,000 –&gt; 01:08:14,000<br>And basically, the idea is that you have these circular buffers,</p>
<p>797<br>01:08:14,000 –&gt; 01:08:17,000<br>where you submit a request and say, I want this data from this,</p>
<p>798<br>01:08:17,000 –&gt; 01:08:20,000<br>this storage device, or this, this harbor device,</p>
<p>799<br>01:08:20,000 –&gt; 01:08:23,000<br>then you get like a callback, you provide it, say,</p>
<p>800<br>01:08:23,000 –&gt; 01:08:26,000<br>okay, when it’s available in my buffer, let me know.</p>
<p>801<br>01:08:26,000 –&gt; 01:08:28,000<br>So you can make a bunch of these requests.</p>
<p>802<br>01:08:28,000 –&gt; 01:08:32,000<br>I don’t think it’s, it’s not entirely bypassing the kernel,</p>
<p>803<br>01:08:32,000 –&gt; 01:08:35,000<br>it’s just less, you’re not paying the overhead on making the syscall,</p>
<p>804<br>01:08:35,000 –&gt; 01:08:38,000<br>to, to, to, and block waiting for the, for the data.</p>
<p>805<br>01:08:38,000 –&gt; 01:08:41,000<br>Right? So you make the request to do whatever it is,</p>
<p>806<br>01:08:41,000 –&gt; 01:08:44,000<br>to read it right, and whatever the, the, on, on the memory that you provide,</p>
<p>807<br>01:08:44,000 –&gt; 01:08:47,000<br>the, the OS, the OS does it for you in a kernel thread,</p>
<p>808<br>01:08:47,000 –&gt; 01:08:51,000<br>and then once it completes the, the, the task you have to do,</p>
<p>809<br>01:08:51,000 –&gt; 01:08:54,000<br>it puts the result in a queue, and then gives you, gives you a callback.</p>
<p>810<br>01:08:54,000 –&gt; 01:09:00,000<br>Right? So again, these are, are the low-lane team way to avoid the overhead,</p>
<p>811<br>01:09:00,000 –&gt; 01:09:03,000<br>or, or, or, of a full syscall, to talk to a harbor device,</p>
<p>812<br>01:09:03,000 –&gt; 01:09:07,000<br>but you’re still relying on the OS to do the low-level martian data in off the device.</p>
<p>813<br>01:09:07,000 –&gt; 01:09:08,000<br>Yes?</p>
<p>814<br>01:09:08,000 –&gt; 01:09:10,000<br>I thought you thought, but I thought those were called by,</p>
<p>815<br>01:09:10,000 –&gt; 01:09:12,000<br>I thought you just checked the completion kit.</p>
<p>816<br>01:09:12,000 –&gt; 01:09:13,000<br>The library, the library.</p>
<p>817<br>01:09:13,000 –&gt; 01:09:14,000<br>Four different ways to do it.</p>
<p>818<br>01:09:14,000 –&gt; 01:09:19,000<br>The library polling, like, you’re checking, or, you can also lock if you want to,</p>
<p>819<br>01:09:19,000 –&gt; 01:09:22,000<br>thinking, yeah, you don’t have to have to put that.</p>
<p>820<br>01:09:22,000 –&gt; 01:09:25,000<br>There’s, there’s much of these libraries,</p>
<p>821<br>01:09:25,000 –&gt; 01:09:26,000<br>and you guys look them up for Rust.</p>
<p>822<br>01:09:26,000 –&gt; 01:09:30,000<br>There’s one in, uh, in Linux, or in C++,</p>
<p>823<br>01:09:30,000 –&gt; 01:09:32,000<br>they, they provide different program APIs.</p>
<p>824<br>01:09:32,000 –&gt; 01:09:34,000<br>I don’t know which one’s the most common.</p>
<p>825<br>01:09:34,000 –&gt; 01:09:40,000<br>So, as far as I know, very few systems do this,</p>
<p>826<br>01:09:40,000 –&gt; 01:09:41,000<br>although you guys are,</p>
<p>827<br>01:09:41,000 –&gt; 01:09:45,000<br>Well, I knew, there’s two more.</p>
<p>828<br>01:09:45,000 –&gt; 01:09:46,000<br>Yeah.</p>
<p>829<br>01:09:46,000 –&gt; 01:09:50,000<br>The first one is, is, uh, QuestDB.</p>
<p>830<br>01:09:50,000 –&gt; 01:09:53,000<br>Uh, so they talk about in, with the 2022,</p>
<p>831<br>01:09:53,000 –&gt; 01:09:56,000<br>how they, they added IU, IU-U ring.</p>
<p>832<br>01:09:56,000 –&gt; 01:09:59,000<br>Um, and for this one, QuestDB is a Java,</p>
<p>833<br>01:09:59,000 –&gt; 01:10:01,000<br>the top part of that is Java,</p>
<p>834<br>01:10:01,000 –&gt; 01:10:03,000<br>and they use JNI to call it down C++ code.</p>
<p>835<br>01:10:03,000 –&gt; 01:10:07,000<br>Um, Tiger Beetles, another one, um,</p>
<p>836<br>01:10:07,000 –&gt; 01:10:09,000<br>and they’re using IO ring,</p>
<p>837<br>01:10:09,000 –&gt; 01:10:11,000<br>but this, this is for transactional stuff.</p>
<p>838<br>01:10:11,000 –&gt; 01:10:13,000<br>This is actually written in Zig, um, not Rust.</p>
<p>839<br>01:10:13,000 –&gt; 01:10:15,000<br>And so, I think there’s some library in Zig</p>
<p>840<br>01:10:15,000 –&gt; 01:10:17,000<br>that made this user from the do.</p>
<p>841<br>01:10:17,000 –&gt; 01:10:20,000<br>Um, but, uh, it’s in the student lab.</p>
<p>842<br>01:10:20,000 –&gt; 01:10:21,000<br>Yeah.</p>
<p>843<br>01:10:21,000 –&gt; 01:10:23,000<br>And we talked to somebody recently, or yesterday,</p>
<p>844<br>01:10:23,000 –&gt; 01:10:26,000<br>who was like, uh, the implement of FastLanes in Zig,</p>
<p>845<br>01:10:26,000 –&gt; 01:10:30,000<br>because the SIMD stuff was way better than, uh, then Rust.</p>
<p>846<br>01:10:30,000 –&gt; 01:10:32,000<br>The interesting one though is Clickhouse.</p>
<p>847<br>01:10:32,000 –&gt; 01:10:35,000<br>So, they came out with a blog article in 2021 about,</p>
<p>848<br>01:10:35,000 –&gt; 01:10:37,000<br>hey, they’re, they’re adding IU ring, uh,</p>
<p>849<br>01:10:37,000 –&gt; 01:10:39,000<br>in A-Circord IO to a Clickhouse.</p>
<p>850<br>01:10:39,000 –&gt; 01:10:41,000<br>I think there is a, we had a guy give a talk,</p>
<p>851<br>01:10:41,000 –&gt; 01:10:43,000<br>from, from the Postgres team,</p>
<p>852<br>01:10:43,000 –&gt; 01:10:45,000<br>about adding IU ring to Postgres,</p>
<p>853<br>01:10:45,000 –&gt; 01:10:47,000<br>but like, that’s gonna be, I think, years away,</p>
<p>854<br>01:10:47,000 –&gt; 01:10:50,000<br>because they’re rewriting the whole store’s layer in Postgres.</p>
<p>855<br>01:10:50,000 –&gt; 01:10:51,000<br>And I think they’re finally gonna get,</p>
<p>856<br>01:10:51,000 –&gt; 01:10:53,000<br>get rid of the OS page gash, which is nice.</p>
<p>857<br>01:10:53,000 –&gt; 01:10:55,000<br>But hey, so there’s this blog article talks about, hey, look,</p>
<p>858<br>01:10:55,000 –&gt; 01:10:56,000<br>here’s what IU ring can do for us.</p>
<p>859<br>01:10:56,000 –&gt; 01:10:58,000<br>Uh, it’s gonna be a big win.</p>
<p>860<br>01:10:58,000 –&gt; 01:10:59,000<br>He submitted the pull request.</p>
<p>861<br>01:10:59,000 –&gt; 01:11:00,000<br>But then when you go look at the pull requests,</p>
<p>862<br>01:11:00,000 –&gt; 01:11:02,000<br>loan behold, you come down here,</p>
<p>863<br>01:11:02,000 –&gt; 01:11:04,000<br>and here’s one, one of the original developers of, uh,</p>
<p>864<br>01:11:04,000 –&gt; 01:11:06,000<br>of, uh, Clickhouse and, uh, in current CTO.</p>
<p>865<br>01:11:06,000 –&gt; 01:11:08,000<br>He basically says like, yeah,</p>
<p>866<br>01:11:08,000 –&gt; 01:11:11,000<br>they tried adding it, but it was marginal improvement,</p>
<p>867<br>01:11:11,000 –&gt; 01:11:14,000<br>and, uh, it became an engineering nightmare.</p>
<p>868<br>01:11:14,000 –&gt; 01:11:16,000<br>He says it became so complicated that even an experienced</p>
<p>869<br>01:11:16,000 –&gt; 01:11:18,000<br>CTO engineer, the author of the code,</p>
<p>870<br>01:11:18,000 –&gt; 01:11:20,000<br>cannot figure out why there are rare hangs of queries.</p>
<p>871<br>01:11:20,000 –&gt; 01:11:22,000<br>Right, they found through their testing.</p>
<p>872<br>01:11:22,000 –&gt; 01:11:25,000<br>So that was, so the blog article was 2021.</p>
<p>873<br>01:11:25,000 –&gt; 01:11:28,000<br>This post is 2022, but then in the release of Postgres,</p>
<p>874<br>01:11:28,000 –&gt; 01:11:33,000<br>of, of, of, of, of, of Clickhouse in February 2023,</p>
<p>875<br>01:11:33,000 –&gt; 01:11:35,000<br>here’s the same dude, giving a live stream,</p>
<p>876<br>01:11:35,000 –&gt; 01:11:37,000<br>talking about how they’ve now added IU ring,</p>
<p>877<br>01:11:37,000 –&gt; 01:11:39,000<br>so they did end up merging this code,</p>
<p>878<br>01:11:39,000 –&gt; 01:11:41,000<br>and they’re touting it how it’s the,</p>
<p>879<br>01:11:41,000 –&gt; 01:11:43,000<br>the magic pill to make IO less slow,</p>
<p>880<br>01:11:43,000 –&gt; 01:11:45,000<br>right, in, in his webinar.</p>
<p>881<br>01:11:45,000 –&gt; 01:11:48,000<br>But then you go look at the pull request again,</p>
<p>882<br>01:11:48,000 –&gt; 01:11:50,000<br>and this is just a few weeks ago,</p>
<p>883<br>01:11:50,000 –&gt; 01:11:52,000<br>uh, a few months ago,</p>
<p>884<br>01:11:52,000 –&gt; 01:11:54,000<br>he’s posting here, I didn’t observe IOU ring to be much slower,</p>
<p>885<br>01:11:54,000 –&gt; 01:11:56,000<br>but also I have no big expectations,</p>
<p>886<br>01:11:56,000 –&gt; 01:11:58,000<br>because I wasn’t able to find cases when it’s faster,</p>
<p>887<br>01:11:58,000 –&gt; 01:11:59,000<br>because he’s responding to somebody up above</p>
<p>888<br>01:11:59,000 –&gt; 01:12:01,000<br>that talks about how like,</p>
<p>889<br>01:12:01,000 –&gt; 01:12:04,000<br>IOU ring when you enable that makes his queries run slow.</p>
<p>890<br>01:12:05,000 –&gt; 01:12:09,000<br>So, uh, I think, huh?</p>
<p>891<br>01:12:09,000 –&gt; 01:12:10,000<br>It’s all in the way that the question is,</p>
<p>892<br>01:12:10,000 –&gt; 01:12:11,000<br>yes, go ahead.</p>
<p>893<br>01:12:11,000 –&gt; 01:12:12,000<br>All of these systems,</p>
<p>894<br>01:12:12,000 –&gt; 01:12:13,000<br>none of them are like asynchronous,</p>
<p>895<br>01:12:13,000 –&gt; 01:12:14,000<br>like they’re all like,</p>
<p>896<br>01:12:14,000 –&gt; 01:12:17,000<br>built like to be synchronous, like, blocking.</p>
<p>897<br>01:12:19,000 –&gt; 01:12:20,000<br>Like, like, the,</p>
<p>898<br>01:12:20,000 –&gt; 01:12:21,000<br>the rest of the framework is nice,</p>
<p>899<br>01:12:21,000 –&gt; 01:12:25,000<br>like, the query execution code itself is blocking, yes.</p>
<p>900<br>01:12:25,000 –&gt; 01:12:27,000<br>So it’s like, how, how they ever get,</p>
<p>901<br>01:12:27,000 –&gt; 01:12:28,000<br>I mean,</p>
<p>902<br>01:12:28,000 –&gt; 01:12:29,000<br>before I said it,</p>
<p>903<br>01:12:29,000 –&gt; 01:12:31,000<br>other than like, just batching the system.</p>
<p>904<br>01:12:31,000 –&gt; 01:12:32,000<br>I, like, batching,</p>
<p>905<br>01:12:32,000 –&gt; 01:12:34,000<br>and then, yeah, and then like,</p>
<p>906<br>01:12:34,000 –&gt; 01:12:36,000<br>I need to read these 10 blocks,</p>
<p>907<br>01:12:36,000 –&gt; 01:12:37,000<br>go batch bunch of stuff,</p>
<p>908<br>01:12:37,000 –&gt; 01:12:38,000<br>go process someone that are available,</p>
<p>909<br>01:12:38,000 –&gt; 01:12:39,000<br>and then in the background,</p>
<p>910<br>01:12:39,000 –&gt; 01:12:40,000<br>you know, when it’s available,</p>
<p>911<br>01:12:40,000 –&gt; 01:12:41,000<br>I can process it.</p>
<p>912<br>01:12:41,000 –&gt; 01:12:42,000<br>I think that,</p>
<p>913<br>01:12:42,000 –&gt; 01:12:43,000<br>I think that,</p>
<p>914<br>01:12:43,000 –&gt; 01:12:44,000<br>I think I was doing it.</p>
<p>915<br>01:12:44,000 –&gt; 01:12:46,000<br>I don’t know about QuestDB.</p>
<p>916<br>01:12:46,000 –&gt; 01:12:48,000<br>QuestDB is like written by,</p>
<p>917<br>01:12:48,000 –&gt; 01:12:50,000<br>uh, HFT guys that are London,</p>
<p>918<br>01:12:50,000 –&gt; 01:12:51,000<br>and those dudes all sorts of,</p>
<p>919<br>01:12:51,000 –&gt; 01:12:52,000<br>like, they know how to make Java,</p>
<p>920<br>01:12:52,000 –&gt; 01:12:53,000<br>what really about,</p>
<p>921<br>01:12:53,000 –&gt; 01:12:55,000<br>so I just, I don’t know how they implement the virus.</p>
<p>922<br>01:12:58,000 –&gt; 01:12:59,000<br>Inclodible,</p>
<p>923<br>01:12:59,000 –&gt; 01:13:00,000<br>oh, they did it badly.</p>
<p>924<br>01:13:01,000 –&gt; 01:13:03,000<br>They’re using metamap,</p>
<p>925<br>01:13:03,000 –&gt; 01:13:05,000<br>and then they switch to Iod here,</p>
<p>926<br>01:13:05,000 –&gt; 01:13:06,000<br>and so, of course, they do that.</p>
<p>927<br>01:13:06,000 –&gt; 01:13:07,000<br>Yes.</p>
<p>928<br>01:13:07,000 –&gt; 01:13:08,000<br>So you, uh,</p>
<p>929<br>01:13:08,000 –&gt; 01:13:09,000<br>so you,</p>
<p>930<br>01:13:09,000 –&gt; 01:13:10,000<br>so you have a crappy MAP invitation,</p>
<p>931<br>01:13:10,000 –&gt; 01:13:11,000<br>and then they’re like,</p>
<p>932<br>01:13:11,000 –&gt; 01:13:12,000<br>okay,</p>
<p>933<br>01:13:12,000 –&gt; 01:13:13,000<br>it’s basically like,</p>
<p>934<br>01:13:13,000 –&gt; 01:13:14,000<br>if, like,</p>
<p>935<br>01:13:14,000 –&gt; 01:13:15,000<br>if I chop my leg off,</p>
<p>936<br>01:13:15,000 –&gt; 01:13:16,000<br>and I can barely walk,</p>
<p>937<br>01:13:16,000 –&gt; 01:13:17,000<br>but I still have the leg back on,</p>
<p>938<br>01:13:17,000 –&gt; 01:13:18,000<br>now I can walk.</p>
<p>939<br>01:13:18,000 –&gt; 01:13:20,000<br>Like, it’s, yeah, got it.</p>
<p>940<br>01:13:20,000 –&gt; 01:13:21,000<br>Okay.</p>
<p>941<br>01:13:21,000 –&gt; 01:13:23,000<br>All right, so I think,</p>
<p>942<br>01:13:23,000 –&gt; 01:13:24,000<br>I, I don’t want to comment,</p>
<p>943<br>01:13:24,000 –&gt; 01:13:26,000<br>I think that Jury’s still out.</p>
<p>944<br>01:13:26,000 –&gt; 01:13:27,000<br>I think that,</p>
<p>945<br>01:13:27,000 –&gt; 01:13:28,000<br>this is still pretty,</p>
<p>946<br>01:13:28,000 –&gt; 01:13:29,000<br>bleeding edge,</p>
<p>947<br>01:13:29,000 –&gt; 01:13:30,000<br>uh,</p>
<p>948<br>01:13:30,000 –&gt; 01:13:32,000<br>but it’s interesting when you guys come out.</p>
<p>949<br>01:13:32,000 –&gt; 01:13:34,000<br>All right.</p>
<p>950<br>01:13:34,000 –&gt; 01:13:36,000<br>So I’m going to quickly talk about two last things.</p>
<p>951<br>01:13:36,000 –&gt; 01:13:37,000<br>Um,</p>
<p>952<br>01:13:37,000 –&gt; 01:13:39,000<br>so these are all sort of user,</p>
<p>953<br>01:13:39,000 –&gt; 01:13:41,000<br>sort of kernel bypass methods,</p>
<p>954<br>01:13:41,000 –&gt; 01:13:42,000<br>um,</p>
<p>955<br>01:13:42,000 –&gt; 01:13:44,000<br>but there’s another alternative is,</p>
<p>956<br>01:13:44,000 –&gt; 01:13:45,000<br>instead of trying to,</p>
<p>957<br>01:13:45,000 –&gt; 01:13:47,000<br>avoid talking to the kernel,</p>
<p>958<br>01:13:47,000 –&gt; 01:13:50,000<br>what if we put things in the kernel that we would want?</p>
<p>959<br>01:13:50,000 –&gt; 01:13:51,000<br>Right?</p>
<p>960<br>01:13:51,000 –&gt; 01:13:53,000<br>To avoid copying up into user space.</p>
<p>961<br>01:13:53,000 –&gt; 01:13:54,000<br>So let’s take a time,</p>
<p>962<br>01:13:54,000 –&gt; 01:13:55,000<br>let me skip this.</p>
<p>963<br>01:13:55,000 –&gt; 01:13:56,000<br>Um,</p>
<p>964<br>01:13:56,000 –&gt; 01:13:58,000<br>so this, this is a technique called user bypass.</p>
<p>965<br>01:13:58,000 –&gt; 01:13:59,000<br>Um,</p>
<p>966<br>01:13:59,000 –&gt; 01:14:00,000<br>it’s not a new idea,</p>
<p>967<br>01:14:00,000 –&gt; 01:14:02,000<br>like people have done kernel modules and extendable,</p>
<p>968<br>01:14:02,000 –&gt; 01:14:03,000<br>uh, uh,</p>
<p>969<br>01:14:03,000 –&gt; 01:14:05,000<br>uh, OS kernels for, for decades.</p>
<p>970<br>01:14:05,000 –&gt; 01:14:07,000<br>Um, what makes it different now is,</p>
<p>971<br>01:14:07,000 –&gt; 01:14:08,000<br>we’ll see in the next slide.</p>
<p>972<br>01:14:08,000 –&gt; 01:14:10,000<br>But the idea here is that,</p>
<p>973<br>01:14:10,000 –&gt; 01:14:12,000<br>instead of trying to get bypass,</p>
<p>974<br>01:14:12,000 –&gt; 01:14:13,000<br>this part here,</p>
<p>975<br>01:14:13,000 –&gt; 01:14:16,000<br>and pull a bunch of this logic up into the database system,</p>
<p>976<br>01:14:16,000 –&gt; 01:14:18,000<br>what if we can put database system logic down in,</p>
<p>977<br>01:14:18,000 –&gt; 01:14:19,000<br>in the, in the kernel,</p>
<p>978<br>01:14:19,000 –&gt; 01:14:21,000<br>and so that when data comes in,</p>
<p>979<br>01:14:21,000 –&gt; 01:14:23,000<br>we can process it or do whatever you want on it,</p>
<p>980<br>01:14:23,000 –&gt; 01:14:24,000<br>it quickly is possible,</p>
<p>981<br>01:14:24,000 –&gt; 01:14:25,000<br>without having to copy the user space,</p>
<p>982<br>01:14:25,000 –&gt; 01:14:26,000<br>and then,</p>
<p>983<br>01:14:26,000 –&gt; 01:14:27,000<br>if necessary,</p>
<p>984<br>01:14:27,000 –&gt; 01:14:28,000<br>go back down to the Harvard</p>
<p>985<br>01:14:28,000 –&gt; 01:14:30,000<br>to send things back immediately.</p>
<p>986<br>01:14:30,000 –&gt; 01:14:33,000<br>So this makes sense when the,</p>
<p>987<br>01:14:33,000 –&gt; 01:14:34,000<br>the data you’re,</p>
<p>988<br>01:14:34,000 –&gt; 01:14:35,000<br>that’s,</p>
<p>989<br>01:14:35,000 –&gt; 01:14:37,000<br>that’s coming in with the network,</p>
<p>990<br>01:14:37,000 –&gt; 01:14:38,000<br>or whatever it is,</p>
<p>991<br>01:14:38,000 –&gt; 01:14:40,000<br>doesn’t need to be retained for a long time,</p>
<p>992<br>01:14:40,000 –&gt; 01:14:41,000<br>uh,</p>
<p>993<br>01:14:41,000 –&gt; 01:14:43,000<br>like if, if it’s a,</p>
<p>994<br>01:14:43,000 –&gt; 01:14:45,000<br>if it’s like a,</p>
<p>995<br>01:14:45,000 –&gt; 01:14:46,000<br>say, a,</p>
<p>996<br>01:14:46,000 –&gt; 01:14:47,000<br>a knowledge of message,</p>
<p>997<br>01:14:47,000 –&gt; 01:14:49,000<br>and it’s needed to keep track of that I got it,</p>
<p>998<br>01:14:49,000 –&gt; 01:14:50,000<br>and then,</p>
<p>999<br>01:14:50,000 –&gt; 01:14:51,000<br>I don’t need to retain it,</p>
<p>1000<br>01:14:51,000 –&gt; 01:14:52,000<br>then this,</p>
<p>1001<br>01:14:52,000 –&gt; 01:14:53,000<br>this technique of,</p>
<p>1002<br>01:14:53,000 –&gt; 01:14:54,000<br>potentially,</p>
<p>1003<br>01:14:54,000 –&gt; 01:14:55,000<br>right?</p>
<p>1004<br>01:14:55,000 –&gt; 01:14:56,000<br>So,</p>
<p>1005<br>01:14:56,000 –&gt; 01:14:58,000<br>because you void all the overhead of copying buffers,</p>
<p>1006<br>01:14:58,000 –&gt; 01:14:59,000<br>of sketching additional threads,</p>
<p>1007<br>01:14:59,000 –&gt; 01:15:00,000<br>and making system calls,</p>
<p>1008<br>01:15:00,000 –&gt; 01:15:02,000<br>because everything now is just running inside the kernel,</p>
<p>1009<br>01:15:02,000 –&gt; 01:15:03,000<br>right?</p>
<p>1010<br>01:15:03,000 –&gt; 01:15:05,000<br>Which is always going to be faster.</p>
<p>1011<br>01:15:05,000 –&gt; 01:15:06,000<br>So,</p>
<p>1012<br>01:15:06,000 –&gt; 01:15:07,000<br>as I said,</p>
<p>1013<br>01:15:07,000 –&gt; 01:15:09,000<br>kernel modules are,</p>
<p>1014<br>01:15:09,000 –&gt; 01:15:10,000<br>one way to do this,</p>
<p>1015<br>01:15:10,000 –&gt; 01:15:11,000<br>but like,</p>
<p>1016<br>01:15:11,000 –&gt; 01:15:12,000<br>if you’ve ever written a kernel module before,</p>
<p>1017<br>01:15:12,000 –&gt; 01:15:13,000<br>you can ask you at GBT,</p>
<p>1018<br>01:15:13,000 –&gt; 01:15:14,000<br>uh,</p>
<p>1019<br>01:15:14,000 –&gt; 01:15:15,000<br>it’s a pain in the ass,</p>
<p>1020<br>01:15:15,000 –&gt; 01:15:16,000<br>it’s super cumbersome,</p>
<p>1021<br>01:15:16,000 –&gt; 01:15:17,000<br>if you crash,</p>
<p>1022<br>01:15:17,000 –&gt; 01:15:18,000<br>what do you get?</p>
<p>1023<br>01:15:18,000 –&gt; 01:15:19,000<br>Kernel panic,</p>
<p>1024<br>01:15:19,000 –&gt; 01:15:20,000<br>you take everything down,</p>
<p>1025<br>01:15:20,000 –&gt; 01:15:21,000<br>and then in some scenarios,</p>
<p>1026<br>01:15:21,000 –&gt; 01:15:22,000<br>you can’t even load kernel modules</p>
<p>1027<br>01:15:22,000 –&gt; 01:15:23,000<br>for security reasons,</p>
<p>1028<br>01:15:23,000 –&gt; 01:15:24,000<br>like the,</p>
<p>1029<br>01:15:24,000 –&gt; 01:15:25,000<br>the horror won’t let you,</p>
<p>1030<br>01:15:25,000 –&gt; 01:15:26,000<br>you know,</p>
<p>1031<br>01:15:26,000 –&gt; 01:15:28,000<br>and load a unsigned,</p>
<p>1032<br>01:15:28,000 –&gt; 01:15:29,000<br>um, you know,</p>
<p>1033<br>01:15:29,000 –&gt; 01:15:31,000<br>unsigned kernel module, right?</p>
<p>1034<br>01:15:31,000 –&gt; 01:15:33,000<br>So, the thing that has changed,</p>
<p>1035<br>01:15:33,000 –&gt; 01:15:35,000<br>where to make this actually viable now,</p>
<p>1036<br>01:15:35,000 –&gt; 01:15:37,000<br>is something called ePBF.</p>
<p>1037<br>01:15:37,000 –&gt; 01:15:38,000<br>At a curiosity,</p>
<p>1038<br>01:15:38,000 –&gt; 01:15:39,000<br>here is sort of ePBF before,</p>
<p>1039<br>01:15:39,000 –&gt; 01:15:40,000<br>while other than people</p>
<p>1040<br>01:15:40,000 –&gt; 01:15:42,000<br>hang out in my student math, right?</p>
<p>1041<br>01:15:42,000 –&gt; 01:15:43,000<br>So,</p>
<p>1042<br>01:15:43,000 –&gt; 01:15:44,000<br>BBF is,</p>
<p>1043<br>01:15:44,000 –&gt; 01:15:46,000<br>uh,</p>
<p>1044<br>01:15:46,000 –&gt; 01:15:48,000<br>well, so what BBF knows what ePBF is?</p>
<p>1045<br>01:15:48,000 –&gt; 01:15:50,000<br>BBF extends to the Berkeley packet filters,</p>
<p>1046<br>01:15:50,000 –&gt; 01:15:51,000<br>so this is like,</p>
<p>1047<br>01:15:51,000 –&gt; 01:15:53,000<br>in the early 90s,</p>
<p>1048<br>01:15:53,000 –&gt; 01:15:54,000<br>they had, uh,</p>
<p>1049<br>01:15:54,000 –&gt; 01:15:55,000<br>it was made for BSD,</p>
<p>1050<br>01:15:55,000 –&gt; 01:15:57,000<br>they mentioned made it Linux,</p>
<p>1051<br>01:15:57,000 –&gt; 01:15:58,000<br>but it was, um,</p>
<p>1052<br>01:15:58,000 –&gt; 01:16:00,000<br>it was a way to specify, like,</p>
<p>1053<br>01:16:00,000 –&gt; 01:16:01,000<br>packet forwarding rules,</p>
<p>1054<br>01:16:01,000 –&gt; 01:16:03,000<br>uh, and filter rules,</p>
<p>1055<br>01:16:03,000 –&gt; 01:16:04,000<br>like through a DSL,</p>
<p>1056<br>01:16:04,000 –&gt; 01:16:06,000<br>you then load into, uh,</p>
<p>1057<br>01:16:06,000 –&gt; 01:16:08,000<br>to the kernel, right?</p>
<p>1058<br>01:16:08,000 –&gt; 01:16:09,000<br>And so,</p>
<p>1059<br>01:16:09,000 –&gt; 01:16:11,000<br>ePBF,</p>
<p>1060<br>01:16:11,000 –&gt; 01:16:12,000<br>not really about packet filter anymore,</p>
<p>1061<br>01:16:12,000 –&gt; 01:16:14,000<br>but it’s basically a way to take, uh,</p>
<p>1062<br>01:16:14,000 –&gt; 01:16:16,000<br>write safe code,</p>
<p>1063<br>01:16:16,000 –&gt; 01:16:18,000<br>uh, that then gets verified,</p>
<p>1064<br>01:16:18,000 –&gt; 01:16:19,000<br>and then load that dynamically,</p>
<p>1065<br>01:16:19,000 –&gt; 01:16:21,000<br>as a, as if it was a kernel module,</p>
<p>1066<br>01:16:21,000 –&gt; 01:16:22,000<br>on the fly.</p>
<p>1067<br>01:16:22,000 –&gt; 01:16:24,000<br>And the reason why I’m saying that,</p>
<p>1068<br>01:16:24,000 –&gt; 01:16:25,000<br>it’s sort of safe is that they,</p>
<p>1069<br>01:16:25,000 –&gt; 01:16:26,000<br>they give you a limited API,</p>
<p>1070<br>01:16:26,000 –&gt; 01:16:28,000<br>which are allowed to actually do,</p>
<p>1071<br>01:16:28,000 –&gt; 01:16:29,000<br>in these kernel module programs,</p>
<p>1072<br>01:16:29,000 –&gt; 01:16:30,000<br>that you’re running, right?</p>
<p>1073<br>01:16:30,000 –&gt; 01:16:31,000<br>So, you can’t call MATLAQ,</p>
<p>1074<br>01:16:31,000 –&gt; 01:16:33,000<br>you can’t, you know,</p>
<p>1075<br>01:16:33,000 –&gt; 01:16:35,000<br>you can’t sit in an info loop forever, right?</p>
<p>1076<br>01:16:35,000 –&gt; 01:16:36,000<br>Because they’re ideally,</p>
<p>1077<br>01:16:36,000 –&gt; 01:16:37,000<br>they’re trying to avoid you from,</p>
<p>1078<br>01:16:37,000 –&gt; 01:16:39,000<br>you know, taking down the kernel,</p>
<p>1079<br>01:16:39,000 –&gt; 01:16:40,000<br>and breaking everything.</p>
<p>1080<br>01:16:40,000 –&gt; 01:16:41,000<br>So, you write your code,</p>
<p>1081<br>01:16:41,000 –&gt; 01:16:42,000<br>your BBF program,</p>
<p>1082<br>01:16:42,000 –&gt; 01:16:43,000<br>in C code,</p>
<p>1083<br>01:16:43,000 –&gt; 01:16:44,000<br>you run it through their compiler,</p>
<p>1084<br>01:16:44,000 –&gt; 01:16:45,000<br>the generation’s bytecode,</p>
<p>1085<br>01:16:45,000 –&gt; 01:16:46,000<br>that then runs through a verifier,</p>
<p>1086<br>01:16:46,000 –&gt; 01:16:48,000<br>it literally does basically,</p>
<p>1087<br>01:16:48,000 –&gt; 01:16:49,000<br>branch expansion,</p>
<p>1088<br>01:16:49,000 –&gt; 01:16:50,000<br>it figures out all the different possible paths,</p>
<p>1089<br>01:16:50,000 –&gt; 01:16:51,000<br>you could go down in your code,</p>
<p>1090<br>01:16:51,000 –&gt; 01:16:53,000<br>and counts the number of instructions,</p>
<p>1091<br>01:16:53,000 –&gt; 01:16:54,000<br>that you would execute,</p>
<p>1092<br>01:16:54,000 –&gt; 01:16:55,000<br>and then throws an error,</p>
<p>1093<br>01:16:55,000 –&gt; 01:16:56,000<br>and throws back,</p>
<p>1094<br>01:16:56,000 –&gt; 01:16:57,000<br>uh, and rejects it,</p>
<p>1095<br>01:16:57,000 –&gt; 01:16:59,000<br>if you, if you have too many,</p>
<p>1096<br>01:16:59,000 –&gt; 01:17:00,000<br>uh, too many instructions.</p>
<p>1097<br>01:17:00,000 –&gt; 01:17:01,000<br>Right?</p>
<p>1098<br>01:17:01,000 –&gt; 01:17:02,000<br>So, this is,</p>
<p>1099<br>01:17:02,000 –&gt; 01:17:03,000<br>this is a wild thing,</p>
<p>1100<br>01:17:03,000 –&gt; 01:17:04,000<br>because again,</p>
<p>1101<br>01:17:04,000 –&gt; 01:17:06,000<br>this basically allows you to extend Linux,</p>
<p>1102<br>01:17:06,000 –&gt; 01:17:08,000<br>without having to recapile Linux.</p>
<p>1103<br>01:17:08,000 –&gt; 01:17:09,000<br>So, so,</p>
<p>1104<br>01:17:09,000 –&gt; 01:17:10,000<br>this is heavily used,</p>
<p>1105<br>01:17:10,000 –&gt; 01:17:12,000<br>like, Netflix for like observability,</p>
<p>1106<br>01:17:12,000 –&gt; 01:17:13,000<br>to be able to, you know,</p>
<p>1107<br>01:17:13,000 –&gt; 01:17:15,000<br>get metrics about what processes are running,</p>
<p>1108<br>01:17:15,000 –&gt; 01:17:17,000<br>and get the data out.</p>
<p>1109<br>01:17:18,000 –&gt; 01:17:19,000<br>But as, as the,</p>
<p>1110<br>01:17:19,000 –&gt; 01:17:21,000<br>you know, since Matt’s been working on it here,</p>
<p>1111<br>01:17:21,000 –&gt; 01:17:22,000<br>the API is expanding,</p>
<p>1112<br>01:17:22,000 –&gt; 01:17:23,000<br>so there’s a lot more things</p>
<p>1113<br>01:17:23,000 –&gt; 01:17:24,000<br>you can start doing now,</p>
<p>1114<br>01:17:24,000 –&gt; 01:17:26,000<br>you can basically run the entire database system,</p>
<p>1115<br>01:17:26,000 –&gt; 01:17:27,000<br>down in your,</p>
<p>1116<br>01:17:27,000 –&gt; 01:17:28,000<br>in your kernel.</p>
<p>1117<br>01:17:28,000 –&gt; 01:17:29,000<br>Whether or not,</p>
<p>1118<br>01:17:29,000 –&gt; 01:17:30,000<br>that’s a good idea or not,</p>
<p>1119<br>01:17:30,000 –&gt; 01:17:31,000<br>that’s what his,</p>
<p>1120<br>01:17:31,000 –&gt; 01:17:32,000<br>his reach is just going to figure out,</p>
<p>1121<br>01:17:32,000 –&gt; 01:17:33,000<br>but,</p>
<p>1122<br>01:17:33,000 –&gt; 01:17:34,000<br>there are,</p>
<p>1123<br>01:17:34,000 –&gt; 01:17:35,000<br>the idea is that,</p>
<p>1124<br>01:17:35,000 –&gt; 01:17:36,000<br>can we start thinking about what part of the database is,</p>
<p>1125<br>01:17:36,000 –&gt; 01:17:37,000<br>and that we’re spending a lot of time on,</p>
<p>1126<br>01:17:37,000 –&gt; 01:17:38,000<br>moving the data back and forth,</p>
<p>1127<br>01:17:38,000 –&gt; 01:17:39,000<br>between the OS,</p>
<p>1128<br>01:17:39,000 –&gt; 01:17:40,000<br>the hardware,</p>
<p>1129<br>01:17:40,000 –&gt; 01:17:41,000<br>and the,</p>
<p>1130<br>01:17:41,000 –&gt; 01:17:42,000<br>and the database system,</p>
<p>1131<br>01:17:42,000 –&gt; 01:17:44,000<br>what can we start pushing down?</p>
<p>1132<br>01:17:45,000 –&gt; 01:17:46,000<br>So, I’m going to show one graph</p>
<p>1133<br>01:17:46,000 –&gt; 01:17:47,000<br>from his paper,</p>
<p>1134<br>01:17:47,000 –&gt; 01:17:49,000<br>where he was re-implementing,</p>
<p>1135<br>01:17:49,000 –&gt; 01:17:52,000<br>Postgres Wire Protocol Proxy.</p>
<p>1136<br>01:17:52,000 –&gt; 01:17:54,000<br>So, the thing that a proxy was sitting in front of Postgres,</p>
<p>1137<br>01:17:54,000 –&gt; 01:17:56,000<br>the client connects to it,</p>
<p>1138<br>01:17:56,000 –&gt; 01:17:59,000<br>and the proxy maintains available connections</p>
<p>1139<br>01:17:59,000 –&gt; 01:18:00,000<br>to the database system,</p>
<p>1140<br>01:18:00,000 –&gt; 01:18:01,000<br>and just forward your packets along that.</p>
<p>1141<br>01:18:01,000 –&gt; 01:18:03,000<br>So, in this scenario here,</p>
<p>1142<br>01:18:03,000 –&gt; 01:18:05,000<br>packet shows up to send a query request,</p>
<p>1143<br>01:18:05,000 –&gt; 01:18:07,000<br>and then the proxy just looks at it,</p>
<p>1144<br>01:18:07,000 –&gt; 01:18:08,000<br>says, oh,</p>
<p>1145<br>01:18:08,000 –&gt; 01:18:09,000<br>he needs to go to the server in this sense,</p>
<p>1146<br>01:18:09,000 –&gt; 01:18:10,000<br>that’s all it’s really doing.</p>
<p>1147<br>01:18:10,000 –&gt; 01:18:11,000<br>It’s not, you know,</p>
<p>1148<br>01:18:11,000 –&gt; 01:18:12,000<br>it’s not doing any computation on it.</p>
<p>1149<br>01:18:12,000 –&gt; 01:18:14,000<br>So, we’re comparing its PG Bouncer,</p>
<p>1150<br>01:18:14,000 –&gt; 01:18:16,000<br>which is the most common,</p>
<p>1151<br>01:18:16,000 –&gt; 01:18:18,000<br>most common proxiedmitation used for Postgres.</p>
<p>1152<br>01:18:18,000 –&gt; 01:18:20,000<br>Odyssey is out of the Andex,</p>
<p>1153<br>01:18:20,000 –&gt; 01:18:21,000<br>and this is like doing,</p>
<p>1154<br>01:18:21,000 –&gt; 01:18:23,000<br>runs in user space,</p>
<p>1155<br>01:18:23,000 –&gt; 01:18:24,000<br>but they’re using, like,</p>
<p>1156<br>01:18:24,000 –&gt; 01:18:26,000<br>handwritten code routines,</p>
<p>1157<br>01:18:26,000 –&gt; 01:18:27,000<br>written in assembly,</p>
<p>1158<br>01:18:27,000 –&gt; 01:18:29,000<br>where the assembly overwrites the stacks</p>
<p>1159<br>01:18:29,000 –&gt; 01:18:31,000<br>of other threads to put inject,</p>
<p>1160<br>01:18:31,000 –&gt; 01:18:33,000<br>like, what the next thread to run,</p>
<p>1161<br>01:18:33,000 –&gt; 01:18:34,000<br>is very impressive,</p>
<p>1162<br>01:18:34,000 –&gt; 01:18:35,000<br>it’s very complicated.</p>
<p>1163<br>01:18:35,000 –&gt; 01:18:37,000<br>And then,</p>
<p>1164<br>01:18:37,000 –&gt; 01:18:38,000<br>ours is based on,</p>
<p>1165<br>01:18:38,000 –&gt; 01:18:40,000<br>it’s a fork of PG Bouncer,</p>
<p>1166<br>01:18:40,000 –&gt; 01:18:42,000<br>where all of the authentication stuff</p>
<p>1167<br>01:18:42,000 –&gt; 01:18:43,000<br>happens up in the user space,</p>
<p>1168<br>01:18:44,000 –&gt; 01:18:45,000<br>like, you know,</p>
<p>1169<br>01:18:45,000 –&gt; 01:18:46,000<br>SSL, setup, and things like that,</p>
<p>1170<br>01:18:46,000 –&gt; 01:18:47,000<br>all that,</p>
<p>1171<br>01:18:47,000 –&gt; 01:18:48,000<br>or user password stuff,</p>
<p>1172<br>01:18:48,000 –&gt; 01:18:49,000<br>all happens up there,</p>
<p>1173<br>01:18:49,000 –&gt; 01:18:50,000<br>but then when packets show up,</p>
<p>1174<br>01:18:50,000 –&gt; 01:18:51,000<br>just afford them,</p>
<p>1175<br>01:18:51,000 –&gt; 01:18:52,000<br>all that’s done down,</p>
<p>1176<br>01:18:52,000 –&gt; 01:18:53,000<br>done down,</p>
<p>1177<br>01:18:53,000 –&gt; 01:18:54,000<br>EPPF.</p>
<p>1178<br>01:18:54,000 –&gt; 01:18:55,000<br>And so, the main takeaway here,</p>
<p>1179<br>01:18:55,000 –&gt; 01:18:57,000<br>is if you run on a really small machine,</p>
<p>1180<br>01:18:57,000 –&gt; 01:18:59,000<br>you’re getting pretty significant</p>
<p>1181<br>01:18:59,000 –&gt; 01:19:00,000<br>performance equipment,</p>
<p>1182<br>01:19:00,000 –&gt; 01:19:01,000<br>because you’re not paying the penalty</p>
<p>1183<br>01:19:01,000 –&gt; 01:19:02,000<br>of copying things back and forth</p>
<p>1184<br>01:19:02,000 –&gt; 01:19:03,000<br>between the kernel.</p>
<p>1185<br>01:19:03,000 –&gt; 01:19:04,000<br>So,</p>
<p>1186<br>01:19:04,000 –&gt; 01:19:06,000<br>I’m not saying BPPF can be solved</p>
<p>1187<br>01:19:06,000 –&gt; 01:19:07,000<br>for all the things that we talked about today,</p>
<p>1188<br>01:19:07,000 –&gt; 01:19:08,000<br>but I think this is,</p>
<p>1189<br>01:19:08,000 –&gt; 01:19:09,000<br>this is,</p>
<p>1190<br>01:19:09,000 –&gt; 01:19:10,000<br>this is going to be a better solution</p>
<p>1191<br>01:19:10,000 –&gt; 01:19:12,000<br>than something like DPDK.</p>
<p>1192<br>01:19:13,000 –&gt; 01:19:15,000<br>And potentially IOU ring for some things,</p>
<p>1193<br>01:19:15,000 –&gt; 01:19:16,000<br>but not everything.</p>
<p>1194<br>01:19:18,000 –&gt; 01:19:19,000<br>All right.</p>
<p>1195<br>01:19:19,000 –&gt; 01:19:21,000<br>We got one minute left,</p>
<p>1196<br>01:19:21,000 –&gt; 01:19:22,000<br>so let me just bang through this real cool key.</p>
<p>1197<br>01:19:22,000 –&gt; 01:19:23,000<br>So,</p>
<p>1198<br>01:19:23,000 –&gt; 01:19:25,000<br>soon we do all the amazations</p>
<p>1199<br>01:19:25,000 –&gt; 01:19:26,000<br>to get things out of the server,</p>
<p>1200<br>01:19:26,000 –&gt; 01:19:27,000<br>back to the client,</p>
<p>1201<br>01:19:27,000 –&gt; 01:19:29,000<br>clients got to do something with it,</p>
<p>1202<br>01:19:29,000 –&gt; 01:19:31,000<br>put it into the form that the application needs.</p>
<p>1203<br>01:19:31,000 –&gt; 01:19:32,000<br>And as I said,</p>
<p>1204<br>01:19:32,000 –&gt; 01:19:33,000<br>if it’s JDBC.</p>
<p>1205<br>01:19:33,000 –&gt; 01:19:34,000<br>What we see,</p>
<p>1206<br>01:19:34,000 –&gt; 01:19:35,000<br>like, that’s copying things</p>
<p>1207<br>01:19:35,000 –&gt; 01:19:36,000<br>as a row into format,</p>
<p>1208<br>01:19:36,000 –&gt; 01:19:37,000<br>that’s, you know,</p>
<p>1209<br>01:19:37,000 –&gt; 01:19:39,000<br>the overhead is not going to be that significant,</p>
<p>1210<br>01:19:39,000 –&gt; 01:19:40,000<br>but if it’s the scenario where</p>
<p>1211<br>01:19:41,000 –&gt; 01:19:43,000<br>it’s a data scientist trying to get things out of</p>
<p>1212<br>01:19:43,000 –&gt; 01:19:44,000<br>the data system</p>
<p>1213<br>01:19:44,000 –&gt; 01:19:46,000<br>and put it into pandas,</p>
<p>1214<br>01:19:46,000 –&gt; 01:19:48,000<br>then that’s going to be sloped.</p>
<p>1215<br>01:19:48,000 –&gt; 01:19:49,000<br>So, this here,</p>
<p>1216<br>01:19:49,000 –&gt; 01:19:52,000<br>this is an experiment they did where they took pandas,</p>
<p>1217<br>01:19:52,000 –&gt; 01:19:55,000<br>ran a SQL query through pandas SQL API,</p>
<p>1218<br>01:19:55,000 –&gt; 01:19:57,000<br>and went to post with my SQL,</p>
<p>1219<br>01:19:57,000 –&gt; 01:19:58,000<br>got data back,</p>
<p>1220<br>01:19:58,000 –&gt; 01:19:59,000<br>and then converted it into a data frame.</p>
<p>1221<br>01:19:59,000 –&gt; 01:20:02,000<br>Data frame is like the table of traction in pandas</p>
<p>1222<br>01:20:02,000 –&gt; 01:20:04,000<br>and a bunch of other Python systems.</p>
<p>1223<br>01:20:04,000 –&gt; 01:20:06,000<br>So, in this case here,</p>
<p>1224<br>01:20:06,000 –&gt; 01:20:07,000<br>the chart showing that</p>
<p>1225<br>01:20:07,000 –&gt; 01:20:09,000<br>the query part is not that simple,</p>
<p>1226<br>01:20:09,000 –&gt; 01:20:10,000<br>it’s not that,</p>
<p>1227<br>01:20:10,000 –&gt; 01:20:11,000<br>it’s not, it’s not,</p>
<p>1228<br>01:20:11,000 –&gt; 01:20:12,000<br>it’s not, it’s not, it’s not,</p>
<p>1229<br>01:20:12,000 –&gt; 01:20:13,000<br>it’s not taken a long time,</p>
<p>1230<br>01:20:13,000 –&gt; 01:20:15,000<br>relative to all the cost of actually copying the data</p>
<p>1231<br>01:20:15,000 –&gt; 01:20:16,000<br>off the bits we got</p>
<p>1232<br>01:20:16,000 –&gt; 01:20:18,000<br>from the server</p>
<p>1233<br>01:20:18,000 –&gt; 01:20:20,000<br>and converting it into the data frame.</p>
<p>1234<br>01:20:20,000 –&gt; 01:20:21,000<br>Again,</p>
<p>1235<br>01:20:21,000 –&gt; 01:20:22,000<br>JDBC and Aero solve this problem</p>
<p>1236<br>01:20:22,000 –&gt; 01:20:23,000<br>because if your,</p>
<p>1237<br>01:20:23,000 –&gt; 01:20:25,000<br>if your Python code can interact</p>
<p>1238<br>01:20:25,000 –&gt; 01:20:27,000<br>natively operate on AeroData,</p>
<p>1239<br>01:20:27,000 –&gt; 01:20:29,000<br>then you don’t have to do this conversion.</p>
<p>1240<br>01:20:29,000 –&gt; 01:20:30,000<br>But if your system doesn’t support</p>
<p>1241<br>01:20:30,000 –&gt; 01:20:32,000<br>the JDBC, like my SQL Postgres,</p>
<p>1242<br>01:20:32,000 –&gt; 01:20:34,000<br>then you have to pay this penalty.</p>
<p>1243<br>01:20:34,000 –&gt; 01:20:36,000<br>So, the just what they’re doing</p>
<p>1244<br>01:20:36,000 –&gt; 01:20:38,000<br>is that they have this thing called Connector X,</p>
<p>1245<br>01:20:39,000 –&gt; 01:20:41,000<br>it is using folders</p>
<p>1246<br>01:20:41,000 –&gt; 01:20:42,000<br>and a couple other systems,</p>
<p>1247<br>01:20:42,000 –&gt; 01:20:44,000<br>I think as well, like moden.</p>
<p>1248<br>01:20:44,000 –&gt; 01:20:47,000<br>And basically, your SQL query shows up</p>
<p>1249<br>01:20:47,000 –&gt; 01:20:48,000<br>that you write in Python,</p>
<p>1250<br>01:20:48,000 –&gt; 01:20:50,000<br>they, you then also provide some information</p>
<p>1251<br>01:20:50,000 –&gt; 01:20:52,000<br>about how to split that query up into,</p>
<p>1252<br>01:20:52,000 –&gt; 01:20:53,000<br>to sub queries,</p>
<p>1253<br>01:20:53,000 –&gt; 01:20:54,000<br>or partition queries,</p>
<p>1254<br>01:20:54,000 –&gt; 01:20:56,000<br>like range partitioning.</p>
<p>1255<br>01:20:56,000 –&gt; 01:20:58,000<br>And then you send out multiple queries</p>
<p>1256<br>01:20:58,000 –&gt; 01:20:59,000<br>at the same time from different threads</p>
<p>1257<br>01:20:59,000 –&gt; 01:21:01,000<br>that are going to get a portion of the data</p>
<p>1258<br>01:21:01,000 –&gt; 01:21:02,000<br>that you would want</p>
<p>1259<br>01:21:02,000 –&gt; 01:21:04,000<br>to put into your Python program.</p>
<p>1260<br>01:21:04,000 –&gt; 01:21:05,000<br>And then each thread then</p>
<p>1261<br>01:21:05,000 –&gt; 01:21:07,000<br>going to populate the data frame</p>
<p>1262<br>01:21:07,000 –&gt; 01:21:09,000<br>at different chunks.</p>
<p>1263<br>01:21:09,000 –&gt; 01:21:10,000<br>So instead of taking one SQL query,</p>
<p>1264<br>01:21:10,000 –&gt; 01:21:12,000<br>get back a giant result,</p>
<p>1265<br>01:21:12,000 –&gt; 01:21:14,000<br>and then one thread populates the table,</p>
<p>1266<br>01:21:14,000 –&gt; 01:21:15,000<br>they take one SQL query,</p>
<p>1267<br>01:21:15,000 –&gt; 01:21:17,000<br>rewrite it by adding like additional expressions</p>
<p>1268<br>01:21:17,000 –&gt; 01:21:18,000<br>in the where clause,</p>
<p>1269<br>01:21:18,000 –&gt; 01:21:20,000<br>then send that out in parallel,</p>
<p>1270<br>01:21:20,000 –&gt; 01:21:21,000<br>get back multiple results,</p>
<p>1271<br>01:21:21,000 –&gt; 01:21:23,000<br>and then the threads put it together.</p>
<p>1272<br>01:21:23,000 –&gt; 01:21:24,000<br>I just want to bring this up,</p>
<p>1273<br>01:21:24,000 –&gt; 01:21:25,000<br>because it’s an alternative</p>
<p>1274<br>01:21:25,000 –&gt; 01:21:26,000<br>if you don’t have ADBC,</p>
<p>1275<br>01:21:26,000 –&gt; 01:21:28,000<br>that this is another portion to do this.</p>
<p>1276<br>01:21:28,000 –&gt; 01:21:29,000<br>All right, well, well over time,</p>
<p>1277<br>01:21:29,000 –&gt; 01:21:30,000<br>so I apologize.</p>
<p>1278<br>01:21:30,000 –&gt; 01:21:31,000<br>All right, so,</p>
<p>1279<br>01:21:31,000 –&gt; 01:21:33,000<br>that we can protocol matters a lot.</p>
<p>1280<br>01:21:33,000 –&gt; 01:21:35,000<br>Criminal bypass can make a big difference,</p>
<p>1281<br>01:21:35,000 –&gt; 01:21:36,000<br>but it’s a pain to ask to use.</p>
<p>1282<br>01:21:36,000 –&gt; 01:21:38,000<br>I think EPF is going to be the,</p>
<p>1283<br>01:21:38,000 –&gt; 01:21:40,000<br>something that’s going to get it</p>
<p>1284<br>01:21:40,000 –&gt; 01:21:42,000<br>more up to in the next 10 years or so.</p>
<p>1285<br>01:21:42,000 –&gt; 01:21:45,000<br>Okay, as EPF gets more expressive.</p>
<p>1286<br>01:21:45,000 –&gt; 01:21:49,000<br>Okay, so next class will be on query optimization,</p>
<p>1287<br>01:21:49,000 –&gt; 01:21:51,000<br>and we’ll have three lectures on that,</p>
<p>1288<br>01:21:51,000 –&gt; 01:21:52,000<br>and that’ll be again,</p>
<p>1289<br>01:21:52,000 –&gt; 01:21:54,000<br>the core material we need to understand</p>
<p>1290<br>01:21:54,000 –&gt; 01:21:56,000<br>before we start looking at other real-world invitations.</p>
<p>1291<br>01:21:56,000 –&gt; 01:22:00,000<br>And I know I haven’t posted the updated reading list,</p>
<p>1292<br>01:22:00,000 –&gt; 01:22:01,000<br>because I don’t know what paper to read</p>
<p>1293<br>01:22:01,000 –&gt; 01:22:02,000<br>for the first class,</p>
<p>1294<br>01:22:02,000 –&gt; 01:22:04,000<br>because like, there really isn’t a good one.</p>
<p>1295<br>01:22:04,000 –&gt; 01:22:06,000<br>But we’ll figure something out.</p>
<p>1296<br>01:22:06,000 –&gt; 01:22:08,000<br>But I’ll be the read list tonight.</p>
<p>1297<br>01:22:08,000 –&gt; 01:22:09,000<br>Okay?</p>
<p>1298<br>01:22:09,000 –&gt; 01:22:10,000<br>Any questions?</p>
<p>1299<br>01:22:10,000 –&gt; 01:22:11,000<br>Take out, you know,</p>
<p>1300<br>01:22:11,000 –&gt; 01:22:12,000<br>I’m ready to hide it.</p>
<p>1301<br>01:22:12,000 –&gt; 01:22:13,000<br>You’ve got a belt to get the 40-ounce box.</p>
<p>1302<br>01:22:13,000 –&gt; 01:22:14,000<br>Get a grip, take a sip,</p>
<p>1303<br>01:22:14,000 –&gt; 01:22:15,000<br>and you’ll be picking up bottles.</p>
<p>1304<br>01:22:15,000 –&gt; 01:22:17,000<br>Ain’t no puzzle, I’m just a person more man.</p>
<p>1305<br>01:22:17,000 –&gt; 01:22:18,000<br>I’m down in the 40,</p>
<p>1306<br>01:22:18,000 –&gt; 01:22:20,000<br>and I’m a 40, got four cans.</p>
<p>1307<br>01:22:20,000 –&gt; 01:22:22,000<br>Stack six packs on a table.</p>
<p>1308<br>01:22:22,000 –&gt; 01:22:24,000<br>And I’m able to see St. Aslan label.</p>
<p>1309<br>01:22:24,000 –&gt; 01:22:26,000<br>No short, put the fuck you know what I got them.</p>
<p>1310<br>01:22:26,000 –&gt; 01:22:27,000<br>I take off the cap,</p>
<p>1311<br>01:22:27,000 –&gt; 01:22:28,000<br>my first attempt.</p>
<p>1312<br>01:22:28,000 –&gt; 01:22:29,000<br>On the bottle.</p>
<p>1313<br>01:22:29,000 –&gt; 01:22:30,000<br>Don’t buy three in the freezer,</p>
<p>1314<br>01:22:30,000 –&gt; 01:22:31,000<br>so I can kill it.</p>
<p>1315<br>01:22:31,000 –&gt; 01:22:32,000<br>Careful with the bottle, baby.</p>
<p>1316<br>01:22:32,000 –&gt; 01:22:33,000<br>I’m just throwing a pill.</p>
<p>1317<br>01:22:33,000 –&gt; 01:22:34,000<br>Cause they knives and say the pain I’ve wet.</p>
<p>1318<br>01:22:34,000 –&gt; 01:22:35,000<br>You drink it down with the gauze,</p>
<p>1319<br>01:22:35,000 –&gt; 01:22:36,000<br>little byt of tape.</p>
<p>1320<br>01:22:36,000 –&gt; 01:22:37,000<br>Take back the pack of drugs.</p>
<p>1321<br>01:22:37,000 –&gt; 01:22:38,000<br>You gon’ get your soul saved now</p>
<p>1322<br>01:22:38,000 –&gt; 01:22:39,000<br>for drinking to the drugs.</p>
<p>1323<br>01:22:39,000 –&gt; 01:22:40,000<br>Billy Dan’s a chili tea,</p>
<p>1324<br>01:22:40,000 –&gt; 01:22:41,000<br>so tell me to be with us.</p>
<p>1325<br>01:22:41,000 –&gt; 01:22:42,000<br>Be a man to get a can of tape, huh?</p>
<p>1326<br>01:22:43,000 –&gt; 01:22:44,000<br>You gon’ get your soul saved now</p>
<p>1327<br>01:22:44,000 –&gt; 01:22:45,000<br>for drinking to the drugs.</p>
<p>1328<br>01:22:45,000 –&gt; 01:22:47,000<br>Billy Dan’s a chili tea,</p>
<p>1329<br>01:22:47,000 –&gt; 01:22:48,000<br>so tell me to be with us.</p>
<p>1330<br>01:22:48,000 –&gt; 01:22:49,000<br>Be a man to get a can of tape, huh?</p>
<p>1331<br>01:22:49,000 –&gt; 01:22:51,000<br>You gon’ get your soul saved now</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CMU15721 P13S202412 DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems</div>
      <div>http://example.com/2025/10/24/CMU15721 P13S202412-DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月24日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/24/CMU15721%20P14S202413-QueryOptimizerImplementation1CMUAdvancedDatabaseSystems/" title="CMU15721 P14S202413 QueryOptimizerImplementation1CMUAdvancedDatabaseSystems">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CMU15721 P14S202413 QueryOptimizerImplementation1CMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/24/CMU15721%20P15S202414-QueryOptimizerImplementation2CMUAdvancedDatabaseSystems/" title="CMU15721 P15S202414 QueryOptimizerImplementation2CMUAdvancedDatabaseSystems">
                        <span class="hidden-mobile">CMU15721 P15S202414 QueryOptimizerImplementation2CMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
