

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:06,000Carnegie Mellon University’s Advanced Database Systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio audience. 300:00:13,000 –&gt; 00:00:15,0">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU15721 P22S202422 AmazonRedshiftDataWarehouseSystemCMUAdvancedDatabaseSystems">
<meta property="og:url" content="http://example.com/2025/10/24/CMU15721%20P22S202422-AmazonRedshiftDataWarehouseSystemCMUAdvancedDatabaseSystems/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:06,000Carnegie Mellon University’s Advanced Database Systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio audience. 300:00:13,000 –&gt; 00:00:15,0">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-24T11:57:41.748Z">
<meta property="article:modified_time" content="2025-10-24T12:06:28.548Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>CMU15721 P22S202422 AmazonRedshiftDataWarehouseSystemCMUAdvancedDatabaseSystems - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CMU15721 P22S202422 AmazonRedshiftDataWarehouseSystemCMUAdvancedDatabaseSystems"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-24 19:57" pubdate>
          2025年10月24日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          58 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CMU15721 P22S202422 AmazonRedshiftDataWarehouseSystemCMUAdvancedDatabaseSystems</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:06,000<br>Carnegie Mellon University’s Advanced Database Systems courses</p>
<p>2<br>00:00:06,000 –&gt; 00:00:09,000<br>filming front of the live studio audience.</p>
<p>3<br>00:00:13,000 –&gt; 00:00:15,000<br>This is the last lecture of the semester.</p>
<p>4<br>00:00:15,000 –&gt; 00:00:18,000<br>We’re going to cover Amazon Redshift.</p>
<p>5<br>00:00:18,000 –&gt; 00:00:21,000<br>So the challenge to this lecture is like,</p>
<p>6<br>00:00:21,000 –&gt; 00:00:24,000<br>I’m not repeating myself because it’s a lot of these things</p>
<p>7<br>00:00:24,000 –&gt; 00:00:27,000<br>or the systems are doing the same thing over and over again.</p>
<p>8<br>00:00:27,000 –&gt; 00:00:30,000<br>I’ll talk a little bit about some of the pieces</p>
<p>9<br>00:00:30,000 –&gt; 00:00:33,000<br>that make Redshift unique, except for even the others.</p>
<p>10<br>00:00:33,000 –&gt; 00:00:36,000<br>I mean, the paper is a good paper in terms of like,</p>
<p>11<br>00:00:36,000 –&gt; 00:00:39,000<br>it covers a lot of stuff but doesn’t cover a lot of stuff in detail.</p>
<p>12<br>00:00:39,000 –&gt; 00:00:40,000<br>How they do it.</p>
<p>13<br>00:00:40,000 –&gt; 00:00:42,000<br>It’s like, we do this, this, this, and this.</p>
<p>14<br>00:00:42,000 –&gt; 00:00:45,000<br>So I can talk a little bit about what we know from them.</p>
<p>15<br>00:00:45,000 –&gt; 00:00:47,000<br>Before we get to that, the,</p>
<p>16<br>00:00:49,000 –&gt; 00:00:51,000<br>let’s end it again, finish things up.</p>
<p>17<br>00:00:51,000 –&gt; 00:00:54,000<br>Again, the final presentations are going to be next Thursday</p>
<p>18<br>00:00:54,000 –&gt; 00:00:56,000<br>in this room, 9 a.m.</p>
<p>19<br>00:00:56,000 –&gt; 00:00:58,000<br>Again, I haven’t checked what the vote call is,</p>
<p>20<br>00:00:58,000 –&gt; 00:01:01,000<br>but go vote whether you want, what do you want for breakfast.</p>
<p>21<br>00:01:01,000 –&gt; 00:01:04,000<br>And so for this one again, on the webpage,</p>
<p>22<br>00:01:04,000 –&gt; 00:01:07,000<br>it’ll say you need to email me your slides,</p>
<p>23<br>00:01:07,000 –&gt; 00:01:09,000<br>the final right up for the project,</p>
<p>24<br>00:01:09,000 –&gt; 00:01:12,000<br>and then this little JSON file we ask you to fill out.</p>
<p>25<br>00:01:12,000 –&gt; 00:01:14,000<br>What, yeah, we’ll get that.</p>
<p>26<br>00:01:14,000 –&gt; 00:01:17,000<br>Well, the little JSON file, like,</p>
<p>27<br>00:01:17,000 –&gt; 00:01:21,000<br>your name is and your project GitHub URL and everything.</p>
<p>28<br>00:01:21,000 –&gt; 00:01:23,000<br>And then we use that to generate the showcase webpage</p>
<p>29<br>00:01:23,000 –&gt; 00:01:25,000<br>that we then put on the website.</p>
<p>30<br>00:01:25,000 –&gt; 00:01:30,000<br>And then again, I’ve had, I’ve had people, you know,</p>
<p>31<br>00:01:30,000 –&gt; 00:01:33,000<br>former students, like they apply for a job,</p>
<p>32<br>00:01:33,000 –&gt; 00:01:36,000<br>and they had a database company, and they contacted me,</p>
<p>33<br>00:01:36,000 –&gt; 00:01:38,000<br>and they want to know what you guys did when you’re in this class,</p>
<p>34<br>00:01:38,000 –&gt; 00:01:41,000<br>and we had the showcase page, we can show them.</p>
<p>35<br>00:01:41,000 –&gt; 00:01:43,000<br>And also too, for people like, you know,</p>
<p>36<br>00:01:43,000 –&gt; 00:01:45,000<br>if you’re an international student,</p>
<p>37<br>00:01:45,000 –&gt; 00:01:47,000<br>you need to get what H1B stuff or whatever,</p>
<p>38<br>00:01:47,000 –&gt; 00:01:50,000<br>a visa you want to get later on.</p>
<p>39<br>00:01:50,000 –&gt; 00:01:52,000<br>Your lawyers will reach out to me,</p>
<p>40<br>00:01:52,000 –&gt; 00:01:55,000<br>ask me the right of letters, say what you did in my class,</p>
<p>41<br>00:01:55,000 –&gt; 00:01:57,000<br>what the skills you learned, and again, the showcase page,</p>
<p>42<br>00:01:57,000 –&gt; 00:02:00,000<br>helps me remember what you guys have done.</p>
<p>43<br>00:02:00,000 –&gt; 00:02:03,000<br>All right, so that again, so all that’s going to be do</p>
<p>44<br>00:02:03,000 –&gt; 00:02:05,000<br>Thursday morning at 9 a.m.</p>
<p>45<br>00:02:05,000 –&gt; 00:02:09,000<br>The final exam was going to be do it at the same time,</p>
<p>46<br>00:02:09,000 –&gt; 00:02:12,000<br>and I realized, and I forgot that I tried to do that last year,</p>
<p>47<br>00:02:12,000 –&gt; 00:02:13,000<br>and it was a bad idea.</p>
<p>48<br>00:02:13,000 –&gt; 00:02:18,000<br>So we bumped it now to be Saturday, May 4th at basically midnight.</p>
<p>49<br>00:02:18,000 –&gt; 00:02:19,000<br>Thank you.</p>
<p>50<br>00:02:19,000 –&gt; 00:02:20,000<br>Yeah, sure, yeah, yeah.</p>
<p>51<br>00:02:20,000 –&gt; 00:02:23,000<br>Now I should have not done it.</p>
<p>52<br>00:02:23,000 –&gt; 00:02:26,000<br>I should have remembered that I tried to this last year</p>
<p>53<br>00:02:26,000 –&gt; 00:02:27,000<br>in the state.</p>
<p>54<br>00:02:27,000 –&gt; 00:02:31,000<br>Yeah, so again, the prompt is on Piazza.</p>
<p>55<br>00:02:31,000 –&gt; 00:02:35,000<br>It’s basically saying you have to retrofit a new system,</p>
<p>56<br>00:02:35,000 –&gt; 00:02:37,000<br>retrofit an existing system,</p>
<p>57<br>00:02:37,000 –&gt; 00:02:41,000<br>and here’s a menu of optimizations that you could potentially do,</p>
<p>58<br>00:02:41,000 –&gt; 00:02:44,000<br>based on the things that we talked about throughout the entire semester,</p>
<p>59<br>00:02:44,000 –&gt; 00:02:47,000<br>and you got to pick three.</p>
<p>60<br>00:02:47,000 –&gt; 00:02:50,000<br>And you got to justify why you want to pick those three over others,</p>
<p>61<br>00:02:50,000 –&gt; 00:02:53,000<br>including with citations and other information that we’ve discussed</p>
<p>62<br>00:02:53,000 –&gt; 00:02:54,000<br>throughout the entire semester.</p>
<p>63<br>00:02:54,000 –&gt; 00:02:55,000<br>Okay?</p>
<p>64<br>00:02:55,000 –&gt; 00:02:57,000<br>So what is this?</p>
<p>65<br>00:02:57,000 –&gt; 00:02:58,000<br>Again, this is grad school.</p>
<p>66<br>00:02:58,000 –&gt; 00:02:59,000<br>This is CMU.</p>
<p>67<br>00:02:59,000 –&gt; 00:03:02,000<br>So there are…</p>
<p>68<br>00:03:02,000 –&gt; 00:03:03,000<br>How does this?</p>
<p>69<br>00:03:03,000 –&gt; 00:03:05,000<br>I don’t say there isn’t a wrong answer.</p>
<p>70<br>00:03:05,000 –&gt; 00:03:08,000<br>There clearly are wrong answers.</p>
<p>71<br>00:03:08,000 –&gt; 00:03:11,000<br>But like, you know, if you’re debating…</p>
<p>72<br>00:03:11,000 –&gt; 00:03:14,000<br>It’s forcing you to think about, okay, if I can only pick three,</p>
<p>73<br>00:03:14,000 –&gt; 00:03:20,000<br>what is going to be the biggest bang for the buck in terms of getting the best performance?</p>
<p>74<br>00:03:20,000 –&gt; 00:03:24,000<br>And you have to also think about, okay, if I choose one optimization,</p>
<p>75<br>00:03:24,000 –&gt; 00:03:28,000<br>does that mean, you know, it doesn’t actually do anything unless I choose the sub-attonization,</p>
<p>76<br>00:03:28,000 –&gt; 00:03:31,000<br>therefore I get to choose two together, and that takes away your choices.</p>
<p>77<br>00:03:31,000 –&gt; 00:03:32,000<br>Yes.</p>
<p>78<br>00:03:32,000 –&gt; 00:03:35,000<br>Is there something with specificity of the software that is just like…</p>
<p>79<br>00:03:35,000 –&gt; 00:03:36,000<br>Just performance.</p>
<p>80<br>00:03:36,000 –&gt; 00:03:37,000<br>Yes.</p>
<p>81<br>00:03:37,000 –&gt; 00:03:40,000<br>And you get a newer engineer in calls.</p>
<p>82<br>00:03:40,000 –&gt; 00:03:41,000<br>Right?</p>
<p>83<br>00:03:41,000 –&gt; 00:03:42,000<br>And again, that’s relative.</p>
<p>84<br>00:03:42,000 –&gt; 00:03:44,000<br>Like, you know, if you don’t have any experience with CIMB,</p>
<p>85<br>00:03:44,000 –&gt; 00:03:46,000<br>oh, that would be very hard.</p>
<p>86<br>00:03:46,000 –&gt; 00:03:47,000<br>First is like…</p>
<p>87<br>00:03:47,000 –&gt; 00:03:48,000<br>You’re an e-coriotrangerizer.</p>
<p>88<br>00:03:48,000 –&gt; 00:03:52,000<br>Which is hard for everyone, actually.</p>
<p>89<br>00:03:52,000 –&gt; 00:03:55,000<br>Yeah, so again, so…</p>
<p>90<br>00:03:55,000 –&gt; 00:03:59,000<br>You know, we post on Piazza if you have questions or what additional clarifications.</p>
<p>91<br>00:03:59,000 –&gt; 00:04:01,000<br>And then also, I haven’t posted this yet.</p>
<p>92<br>00:04:01,000 –&gt; 00:04:03,000<br>We’ll post the URL for the Google form.</p>
<p>93<br>00:04:03,000 –&gt; 00:04:06,000<br>You can fill out and say whether you use ChatGbT or not.</p>
<p>94<br>00:04:06,000 –&gt; 00:04:07,000<br>What does that mean?</p>
<p>95<br>00:04:07,000 –&gt; 00:04:09,000<br>You use ChatGbT on like…</p>
<p>96<br>00:04:09,000 –&gt; 00:04:14,000<br>If you want to copy the question into ChatGbT and say,</p>
<p>97<br>00:04:14,000 –&gt; 00:04:18,000<br>write me a 4-page essay with citations, go for it.</p>
<p>98<br>00:04:18,000 –&gt; 00:04:19,000<br>What would it like partially use?</p>
<p>99<br>00:04:19,000 –&gt; 00:04:20,000<br>That’s fine.</p>
<p>100<br>00:04:20,000 –&gt; 00:04:22,000<br>That’s an option when you say…</p>
<p>101<br>00:04:22,000 –&gt; 00:04:26,000<br>Oh, did I use ChatGbT or not, and then to what degree you did?</p>
<p>102<br>00:04:26,000 –&gt; 00:04:28,000<br>Does it have to be 4 pages that are…</p>
<p>103<br>00:04:28,000 –&gt; 00:04:29,000<br>At most 4 pages.</p>
<p>104<br>00:04:29,000 –&gt; 00:04:30,000<br>At most 4 pages.</p>
<p>105<br>00:04:30,000 –&gt; 00:04:32,000<br>At most 4 pages.</p>
<p>106<br>00:04:32,000 –&gt; 00:04:35,000<br>And again, the justification is key because…</p>
<p>107<br>00:04:35,000 –&gt; 00:04:37,000<br>Because Andy said it was a good idea, right?</p>
<p>108<br>00:04:37,000 –&gt; 00:04:40,000<br>And then we’ll read the basic things that we discussed.</p>
<p>109<br>00:04:40,000 –&gt; 00:04:41,000<br>Okay.</p>
<p>110<br>00:04:41,000 –&gt; 00:04:43,000<br>All right.</p>
<p>111<br>00:04:43,000 –&gt; 00:04:46,000<br>And then I can’t spell course.</p>
<p>112<br>00:04:46,000 –&gt; 00:04:47,000<br>Right.</p>
<p>113<br>00:04:47,000 –&gt; 00:04:48,000<br>Course evaluation.</p>
<p>114<br>00:04:48,000 –&gt; 00:04:51,000<br>I think we’ll send up the reminder emails for everyone.</p>
<p>115<br>00:04:51,000 –&gt; 00:04:52,000<br>Okay.</p>
<p>116<br>00:04:52,000 –&gt; 00:04:54,000<br>All right.</p>
<p>117<br>00:04:54,000 –&gt; 00:04:58,000<br>So last class, we talked about yellow brick.</p>
<p>118<br>00:04:58,000 –&gt; 00:05:01,000<br>And as I said, it’s not a well-known system.</p>
<p>119<br>00:05:01,000 –&gt; 00:05:04,000<br>But to me, it’s very fascinating because like…</p>
<p>120<br>00:05:04,000 –&gt; 00:05:08,000<br>If you just have really hardcore systems engineers on your team,</p>
<p>121<br>00:05:08,000 –&gt; 00:05:11,000<br>you know, the sky’s the limit of what you can do.</p>
<p>122<br>00:05:11,000 –&gt; 00:05:14,000<br>And the big thing, as I said, like they’re doing all this…</p>
<p>123<br>00:05:14,000 –&gt; 00:05:21,000<br>Trying to avoid the OS as much as possible because it’s always going to interfere with what the database system wants to do when it…</p>
<p>124<br>00:05:21,000 –&gt; 00:05:24,000<br>When it actually queries in terms of getting better performance and having the most control.</p>
<p>125<br>00:05:24,000 –&gt; 00:05:28,000<br>So they basically went around it entirely.</p>
<p>126<br>00:05:28,000 –&gt; 00:05:31,000<br>It’s not a true unicernal where like the…</p>
<p>127<br>00:05:31,000 –&gt; 00:05:35,000<br>The kernel is running nothing but the database system.</p>
<p>128<br>00:05:35,000 –&gt; 00:05:39,000<br>The Germans are actually working on a project on related to this.</p>
<p>129<br>00:05:39,000 –&gt; 00:05:41,000<br>But it’s about the closest you can get.</p>
<p>130<br>00:05:41,000 –&gt; 00:05:42,000<br>The system boots up.</p>
<p>131<br>00:05:42,000 –&gt; 00:05:43,000<br>They make tensis calls.</p>
<p>132<br>00:05:43,000 –&gt; 00:05:45,000<br>Get everything into user space.</p>
<p>133<br>00:05:45,000 –&gt; 00:05:48,000<br>And then let the OS only handle like logging stuff.</p>
<p>134<br>00:05:48,000 –&gt; 00:05:49,000<br>Or the basic things.</p>
<p>135<br>00:05:49,000 –&gt; 00:05:50,000<br>Right.</p>
<p>136<br>00:05:50,000 –&gt; 00:05:52,000<br>Again, so that’s super awesome.</p>
<p>137<br>00:05:52,000 –&gt; 00:05:53,000<br>I find it super interesting.</p>
<p>138<br>00:05:53,000 –&gt; 00:06:00,000<br>I don’t know how much the other, you know, systems we talked about this semester are doing the similar kind of things.</p>
<p>139<br>00:06:00,000 –&gt; 00:06:07,000<br>I don’t know if anybody is writing through a device driver, so the way they did them.</p>
<p>140<br>00:06:07,000 –&gt; 00:06:08,000<br>All right.</p>
<p>141<br>00:06:08,000 –&gt; 00:06:11,000<br>So talking about now Redshift from Amazon.</p>
<p>142<br>00:06:11,000 –&gt; 00:06:23,000<br>So the background you can understand is that there is a long history of people of companies and open source projects trying to make distributed versions of Postgres.</p>
<p>143<br>00:06:23,000 –&gt; 00:06:26,000<br>Again, Postgres came out in the 1980s at a Berkeley.</p>
<p>144<br>00:06:26,000 –&gt; 00:06:29,000<br>It was traditionally a single node system.</p>
<p>145<br>00:06:29,000 –&gt; 00:06:38,000<br>In the 1990s, there was a commercial version of Postgres called Alastra, which is a completely separate codebase as far as I know.</p>
<p>146<br>00:06:38,000 –&gt; 00:06:42,000<br>And the original academic version of Postgres didn’t support SQL as supported Quail.</p>
<p>147<br>00:06:42,000 –&gt; 00:06:48,000<br>And then some Berkeley grad students took the old academic version of Postgres, add a SQL to support to it.</p>
<p>148<br>00:06:48,000 –&gt; 00:06:52,000<br>That’s why it’s called Postgres QL as the official name.</p>
<p>149<br>00:06:52,000 –&gt; 00:06:58,000<br>And then as the 2000s came along, people were looking, you know, try to make it distributed.</p>
<p>150<br>00:06:58,000 –&gt; 00:07:06,000<br>And so there’s a lot of attempts to do this. And the old to be aside of things, there’s Postgres XE, StormDB, which was based on Postgres XE.</p>
<p>151<br>00:07:06,000 –&gt; 00:07:10,000<br>But then they went under or they got bought by Translattis and Translattis had their own thing.</p>
<p>152<br>00:07:10,000 –&gt; 00:07:13,000<br>Postgres XL was maybe the one that, what people are most excited about.</p>
<p>153<br>00:07:13,000 –&gt; 00:07:18,000<br>And that hasn’t been updated on anything since 2015, 2016 or something.</p>
<p>154<br>00:07:18,000 –&gt; 00:07:20,000<br>All right. So that project basically has died out.</p>
<p>155<br>00:07:20,000 –&gt; 00:07:25,000<br>Now there’s systems like YugoBite, for example, that took the front end of Postgres,</p>
<p>156<br>00:07:25,000 –&gt; 00:07:28,000<br>and then ripped out the bottom half and made that distributed.</p>
<p>157<br>00:07:28,000 –&gt; 00:07:32,000<br>That’s not exactly the same. If you were trying to do this, you know, natively inside of Postgres.</p>
<p>158<br>00:07:32,000 –&gt; 00:07:36,000<br>And then there’s a lot of systems that were doing this for O-Lap as well.</p>
<p>159<br>00:07:36,000 –&gt; 00:07:38,000<br>Again, the mid 2000s went this sort of so-called.</p>
<p>160<br>00:07:38,000 –&gt; 00:07:43,000<br>And this is when the first sort of batch of O-Lap systems came into place, or came onto the market.</p>
<p>161<br>00:07:43,000 –&gt; 00:07:48,000<br>Green plumb we talked about. Scytis was based on extensions inside of Postgres.</p>
<p>162<br>00:07:48,000 –&gt; 00:07:53,000<br>That got bought by Microsoft. And Vertica we talked about from Stormbriker and others.</p>
<p>163<br>00:07:54,000 –&gt; 00:07:57,000<br>And then Paracsel is another one that was trying to do this.</p>
<p>164<br>00:07:57,000 –&gt; 00:08:03,000<br>So the Paracsel one is interesting for us because this is what Redshift is based on.</p>
<p>165<br>00:08:03,000 –&gt; 00:08:10,000<br>And they’re completely up front about this. This is the original history or this is the lineage of what started Paracsel.</p>
<p>166<br>00:08:10,000 –&gt; 00:08:17,000<br>And the sort of the backstory, the rumor is at least that in 2010 with sort of AWS,</p>
<p>167<br>00:08:17,000 –&gt; 00:08:29,000<br>the cloud offering services taking off, they were looking at adding a data warehouse service that they could include in Amazon Web Services and sell it as a product.</p>
<p>168<br>00:08:29,000 –&gt; 00:08:34,000<br>And then they had this big internal debate whether they should just write a system from scratch,</p>
<p>169<br>00:08:34,000 –&gt; 00:08:40,000<br>or should they buy something off the shelf and use one of those.</p>
<p>170<br>00:08:40,000 –&gt; 00:08:47,000<br>The prom though around this time, all these, I think Scytis started in 2010. Scytis came a bit later.</p>
<p>171<br>00:08:47,000 –&gt; 00:08:55,000<br>But like all, there was all these sort of first wave of these special purpose O-Lap systems like the Green plong vertica, Paracsel,</p>
<p>172<br>00:08:55,000 –&gt; 00:09:02,000<br>Astrodata’s, Data Allegro, all of them had gotten bought up by this point except for Paracsel.</p>
<p>173<br>00:09:02,000 –&gt; 00:09:09,000<br>The Green plong got bought by EMC, Vertica got bought by HP, Data Allegro got bought by Microsoft,</p>
<p>174<br>00:09:09,000 –&gt; 00:09:14,000<br>and then within I think half a year of looking at the code, they said it was garbage and threw it all away.</p>
<p>175<br>00:09:14,000 –&gt; 00:09:21,000<br>They did $100 million for something they never used. Astrodata got bought by Teradata.</p>
<p>176<br>00:09:21,000 –&gt; 00:09:26,000<br>So Paracsel was the only sort of the last one at the dance they hadn’t got picked up yet.</p>
<p>177<br>00:09:26,000 –&gt; 00:09:34,000<br>And so what Amazon ended up doing was instead of buying them, they invested in them,</p>
<p>178<br>00:09:34,000 –&gt; 00:09:42,000<br>in like their series E or something like that. And as part of that investment, they got licensed to the source code to use it.</p>
<p>179<br>00:09:42,000 –&gt; 00:09:51,000<br>Anyway, they wanted. And I think they paid like $20 million for it, which is again, for how much money Russia makes now is a steal.</p>
<p>180<br>00:09:51,000 –&gt; 00:09:54,000<br>Of course, obviously they put a lot of engineering effort to make it all work.</p>
<p>181<br>00:09:54,000 –&gt; 00:09:59,000<br>But they paid $20 million to get the source code versus Vertica got bought for $100 million.</p>
<p>182<br>00:09:59,000 –&gt; 00:10:04,000<br>Data Allegro got bought for, you know, these are all the $100 million to $1 million. They got it for $20 million.</p>
<p>183<br>00:10:04,000 –&gt; 00:10:14,000<br>They could’ve hosted that. So this is what they did. And then they slapped it up on AWS and then started selling it as a service.</p>
<p>184<br>00:10:14,000 –&gt; 00:10:22,000<br>I think in 20, I say this is 2014, but I think it was maybe a let’s sooner. Right at the same time, it’s just like Snowflake came out.</p>
<p>185<br>00:10:22,000 –&gt; 00:10:29,000<br>So this is red shifted its Amazon’s what I call flagship OLAP database system, database as a service.</p>
<p>186<br>00:10:29,000 –&gt; 00:10:36,000<br>And again, the lineage is that it comes from Park Cell, which was a shared nothing fork of Postgres.</p>
<p>187<br>00:10:36,000 –&gt; 00:10:47,000<br>And so you’ll see that over time is evolved to a shared system. They didn’t really start off with like, you know, the way Snowflake did it being completely disaggregated storage.</p>
<p>188<br>00:10:47,000 –&gt; 00:10:52,000<br>They eventually had to add those pieces back in and they did it. They try to do this in a couple of different ways.</p>
<p>189<br>00:10:52,000 –&gt; 00:11:01,000<br>So they added just a storage for S3 in 2017. And then they added recently support for serverless deployments.</p>
<p>190<br>00:11:01,000 –&gt; 00:11:10,000<br>Basically now I don’t need to provision my computer cluster ahead of time. The way you would have to do in Snowflake, at least in original version of Snowflake, you just say, here’s my queries just stored right at it.</p>
<p>191<br>00:11:10,000 –&gt; 00:11:17,000<br>As far as I know, BigQuery has always been serverless. Like that one you’ve never provisioned. Like I want these nodes. You just say, here’s my credit card number.</p>
<p>192<br>00:11:17,000 –&gt; 00:11:27,000<br>Give me a string where I can send queries to. And then if you want guarantee capacity, you sort of pay extra for that. But there’s no provisioning machines.</p>
<p>193<br>00:11:27,000 –&gt; 00:11:35,000<br>So I would say red shift is going to be a more, what’s going to look like a more traditional data warehouse compared to BigQuery and Spark that we talked about before.</p>
<p>194<br>00:11:35,000 –&gt; 00:11:49,000<br>Even though it sort of fits in the category of the row is compared with these other data lake, a lake house systems, it’s going to look more like a traditional data warehouse similar to yellow brick, where they want to control all the data for you.</p>
<p>195<br>00:11:49,000 –&gt; 00:11:56,000<br>So they’re going to add the ability later on to be able to read data off S3 directly, like parquet files or whatever you have down there.</p>
<p>196<br>00:11:56,000 –&gt; 00:12:02,000<br>But by default, they want to put everything into what they call the red shift managed storage.</p>
<p>197<br>00:12:02,000 –&gt; 00:12:15,000<br>So as part of this, the design goal similar to what Snowflake was trying to achieve is that they want to remove as much as the management responsibilities from the user and have everything being controlled much as possible.</p>
<p>198<br>00:12:15,000 –&gt; 00:12:22,000<br>And as the paper you guys read, they have a bunch of sort of ML based or automatic based mechanisms to try to do this.</p>
<p>199<br>00:12:22,000 –&gt; 00:12:40,000<br>But I think the original implementation of it was, it was basically, the very first version of it was basically ParkSell and you got exposed to all the, you know, the internals things about, you know, about Postgres or ParkSell, the really things that you had to deal with as a user of the service.</p>
<p>200<br>00:12:40,000 –&gt; 00:12:46,000<br>So what’s sort of confusing about Amazon is that there’s two different versions of red shift.</p>
<p>201<br>00:12:46,000 –&gt; 00:12:53,000<br>And then there’s this other thing called Athena, which I don’t think the paper mentions, but that’s another OLAP system that they support.</p>
<p>202<br>00:12:53,000 –&gt; 00:12:58,000<br>So version version of red shift, I guess it says, I think came out in 2012, not 2014.</p>
<p>203<br>00:12:58,000 –&gt; 00:13:08,000<br>And again, that was always being stored in, you know, that was always, there’s a shared nothing system with storing things on the compute nodes themselves.</p>
<p>204<br>00:13:08,000 –&gt; 00:13:17,000<br>Then in 2016, they took Presto out of Facebook and then they just rebranded as Athena.</p>
<p>205<br>00:13:17,000 –&gt; 00:13:26,000<br>I think it’s based on the Trino line now, not the, which was based on Presto SQL, not the Presto DB1 from the Facebook Steel Controls now.</p>
<p>206<br>00:13:26,000 –&gt; 00:13:36,000<br>But they have sort of, this would be like more akin to a Lake House query engine where you just, you know, you just have a bunch of files on S3 and you can read from it.</p>
<p>207<br>00:13:36,000 –&gt; 00:13:41,000<br>And again, that’s what, that’s what Presto was originally designed for.</p>
<p>208<br>00:13:41,000 –&gt; 00:13:47,000<br>And then the spectrum extension to the original version of, of red shift came in 2017.</p>
<p>209<br>00:13:47,000 –&gt; 00:13:56,000<br>And this is basically allowing you to have through the red shift interface, a front end query data that’s on S3 without having to first import them,</p>
<p>210<br>00:13:56,000 –&gt; 00:14:03,000<br>to import them, to load them into, load them into the red shift managed storage.</p>
<p>211<br>00:14:03,000 –&gt; 00:14:16,000<br>So, again, so when you sign up now, I think you, I think you just say I want red shift and then like if you end up querying data that isn’t, that you’re not going to suck into the managed storage, then it just sort of goes to the spectrum thing.</p>
<p>212<br>00:14:16,000 –&gt; 00:14:20,000<br>I don’t think you specify I want spectrum, whereas Athena is a completely separate service.</p>
<p>213<br>00:14:20,000 –&gt; 00:14:38,000<br>And then they said it’s just, they’re just reselling a repackaging, Presto, which Amazon does a lot for a lot of systems, causes, causes problems with some, from Davis vendors for opens or software because Amazon often makes more money than they do.</p>
<p>214<br>00:14:38,000 –&gt; 00:14:48,000<br>And then, so what ends up happening is these major companies end up re-licensing opens or software to prevent Amazon from reselling it.</p>
<p>215<br>00:14:48,000 –&gt; 00:14:58,000<br>Elastic’s probably the most famous one that has done this, but they had to change the license because Amazon was making more money on elastic search than the actual company elastic was.</p>
<p>216<br>00:14:58,000 –&gt; 00:15:04,000<br>Okay, so at high level, this is what red shift is going to do for us. So again, a lot of this is going to be the same as the team before.</p>
<p>217<br>00:15:04,000 –&gt; 00:15:12,000<br>Share disk, this is going to storage again, even though it started off as a shared nothing, but then they switch move to share disk.</p>
<p>218<br>00:15:12,000 –&gt; 00:15:15,000<br>We push-based vectorized query processing.</p>
<p>219<br>00:15:15,000 –&gt; 00:15:23,000<br>Let’s talk about this in a second, but they’re going to be doing in trinzix, AVX2 and Cindy could written by hand by Amazon engineers.</p>
<p>220<br>00:15:23,000 –&gt; 00:15:30,000<br>What is novel about what they’re doing for cogeneration than the other systems is that they’re actually going to do both.</p>
<p>221<br>00:15:30,000 –&gt; 00:15:41,000<br>They’re going to do the vectorized style pre-compile primitives and also do the holistic source of source compilation that we sell on high queue.</p>
<p>222<br>00:15:41,000 –&gt; 00:15:48,000<br>So they’re actually going to be doing both these things. They’ll have compute site caching, packs column or storage will be the Rump of Priory storage.</p>
<p>223<br>00:15:48,000 –&gt; 00:15:56,000<br>I think they’re doing the candy store mergers, hash joins, another interesting aspect is that they’re going to have their own sort of hardware acceleration layer and they’re up front about it.</p>
<p>224<br>00:15:56,000 –&gt; 00:16:02,000<br>This is what it’s actually doing where it’s like big query, for example, they don’t publicly talk about the in-memory shuffle.</p>
<p>225<br>00:16:02,000 –&gt; 00:16:05,000<br>And as far as the notes, snowflake doesn’t have anything that they do.</p>
<p>226<br>00:16:05,000 –&gt; 00:16:17,000<br>And then they have a stratified query optimizer that paper mentions that’s how they’re going to be able to handle the one-off issues that they have for queries by having their own sort of rewrite or layer.</p>
<p>227<br>00:16:17,000 –&gt; 00:16:26,000<br>So for today, I’m going to mostly talk about this one and this one, but then these other things will come up as we go along.</p>
<p>228<br>00:16:26,000 –&gt; 00:16:40,000<br>So this is the diagram from the actual paper itself. And you can see all the different bits and pieces that make up the overall arching redshift system.</p>
<p>229<br>00:16:40,000 –&gt; 00:16:49,000<br>So at the bottom, you have this storage layer here. And what’s sort of confusing is that you have sort of S3 here and then you have this redshift managed storage next to it.</p>
<p>230<br>00:16:49,000 –&gt; 00:17:04,000<br>As far as I can tell, they are direction, you know, like, the easy to insist on themselves and locally attached storage who can then also spill over and read and write data from the S3 as well.</p>
<p>231<br>00:17:04,000 –&gt; 00:17:16,000<br>There’s this aqua thing that the hardware accelerator will talk about in a second, but that could be something that stands in between the compute nodes and the redshift managed storage.</p>
<p>232<br>00:17:16,000 –&gt; 00:17:33,000<br>They have these other spectrum nodes here. Again, I think these are just, I don’t know if they’re like, I don’t understand these things just to be like, it’s software that can then run in here in the actual compute nodes of the worker nodes with running queries that can just know how to go read data down from S3. Yes.</p>
<p>233<br>00:17:33,000 –&gt; 00:17:39,000<br>It’s a good question. What exactly is a spectrum just an isolated thing? Is it actually talking to anyone?</p>
<p>234<br>00:17:39,000 –&gt; 00:17:52,000<br>It’s a question. It’s a spectrum is an isolated thing. There’s no error. So this is what I’m saying. I don’t… Maybe I’m just misunderstanding what it’s in the paper. I mean, I procrastinate to talk with you. I don’t think he mentioned this.</p>
<p>235<br>00:17:52,000 –&gt; 00:17:58,000<br>Like, I thought this is just software because it’s just like, okay, you want to read some data on S3. My worker node knows how to go do that.</p>
<p>236<br>00:17:58,000 –&gt; 00:18:12,000<br>From what I understood from this talk this year is that his spectrum basically moves up from the… So the armist nodes are just S3 nodes with some more software on there. And like, spectrum moves up from S3 to 5.</p>
<p>237<br>00:18:12,000 –&gt; 00:18:19,000<br>So the question is like, for the RMS stuff, these are just S3 nodes with the extra stuff. Yes. And then the…</p>
<p>238<br>00:18:19,000 –&gt; 00:18:33,000<br>And to this? Yes. Does it take Amazon S3? No, I thought the spectrum nodes are just compute. It’s just compute. Because you can join the RMS data with the S3 data.</p>
<p>239<br>00:18:33,000 –&gt; 00:18:42,000<br>So we’ll see slides in a second. And so therefore, if you’re just doing query processing, that’s going to be done up with the compute nodes anyway.</p>
<p>240<br>00:18:42,000 –&gt; 00:18:49,000<br>So I don’t know what the separate spectrum nodes are actually mean. And then the…</p>
<p>241<br>00:18:49,000 –&gt; 00:19:05,000<br>Like, the compute… I used to name clusters versus register compute clusters. This is just like, how you sort of provision it. Do I want to have some organization in my company have access to a compute cluster that they can only use?</p>
<p>242<br>00:19:05,000 –&gt; 00:19:12,000<br>And therefore, it doesn’t interfere with… It doesn’t get slowed down if people are sort of going at the general pool for the organization.</p>
<p>243<br>00:19:12,000 –&gt; 00:19:19,000<br>But they also have the ability to scale up automatically if you specify, say, hey, go bring some to short nodes. Because these things are meant to be stateless.</p>
<p>244<br>00:19:19,000 –&gt; 00:19:28,000<br>Although, I think they also do have a local SSD cache as well. And then the compilation service, we’ll talk about that in a second.</p>
<p>245<br>00:19:28,000 –&gt; 00:19:35,000<br>But that is basically… Again, the thing that’s going to run GCC to do the compilation of the queries has to go along.</p>
<p>246<br>00:19:35,000 –&gt; 00:19:51,000<br>And what’s also confusing about the Redshift-Menestorge and how it relates to like compute nodes is when you provision Redshift, you specify you want the instance type to be the Redshift-Menestorge.</p>
<p>247<br>00:19:51,000 –&gt; 00:19:58,000<br>And so that, no, sometimes the literature makes it sound like, okay, well, it’s the node itself just knows how to go talk to…</p>
<p>248<br>00:19:58,000 –&gt; 00:20:04,000<br>Sorry, you get a single compute instance, but there’s also another instance that spins up that has this Redshift-Menestorge.</p>
<p>249<br>00:20:04,000 –&gt; 00:20:07,000<br>First, as you’re saying, is it just something sitting right above S3?</p>
<p>250<br>00:20:07,000 –&gt; 00:20:11,000<br>Yeah, it is S3 nodes with just additional code, yes.</p>
<p>251<br>00:20:11,000 –&gt; 00:20:14,000<br>Okay.</p>
<p>252<br>00:20:14,000 –&gt; 00:20:24,000<br>So, when they actually query, the actual engine itself is going to be push-based.</p>
<p>253<br>00:20:24,000 –&gt; 00:20:29,000<br>The example that they show in the paper looks like it’d be pull-based and they even call this out.</p>
<p>254<br>00:20:29,000 –&gt; 00:20:43,000<br>But they talk about how that would be too much state to maintain in a pull-based model that they switched to push-based, but they’d be careful about where they do certain operations to void-blowing out your CD-C.</p>
<p>255<br>00:20:43,000 –&gt; 00:20:51,000<br>So, there’s a lot of the same things that we talked about before in the hyper-paper when they were doing compilation that they’re trying to be worried about.</p>
<p>256<br>00:20:51,000 –&gt; 00:21:06,000<br>But one thing they do differently is that to help reduce the compilation cost, the compilation time of the queries themselves, that they’re still going to rely on some pre-compact primitives to do vectorized scans and filtering on other things.</p>
<p>257<br>00:21:06,000 –&gt; 00:21:12,000<br>So, they’re not going to do full pre-compact primitives that they vectorized was for the entire query plan.</p>
<p>258<br>00:21:12,000 –&gt; 00:21:20,000<br>It’s just for the lower portions and the leaves, they’re going to have things that are pre-compact that have been in line into the compile program.</p>
<p>259<br>00:21:20,000 –&gt; 00:21:26,000<br>And as I said, the code that they’re generating is not going to rely on auto-vectorization for any of these primitives.</p>
<p>260<br>00:21:26,000 –&gt; 00:21:32,000<br>Everything is going to be written from hand using intrinsic.</p>
<p>261<br>00:21:32,000 –&gt; 00:21:56,000<br>Another technique that they’re going to rely on in these scan loops to void stalls is that they recognize that you don’t want to do some operation on the tube we’re operating right now, and then loop back around in sort of the scan kernel, and then phase a stall because the next record you want to retrieve is not in the CPU cache or the CPU registers.</p>
<p>262<br>00:21:56,000 –&gt; 00:22:02,000<br>So, they’re going to use software pre-fetching, which I think we talked about with vectorization.</p>
<p>263<br>00:22:02,000 –&gt; 00:22:13,000<br>You basically can instruct the CPU to say, go fetch these next memory addresses, bring them into, I think it lands in L3, or maybe L2, I figured which one.</p>
<p>264<br>00:22:13,000 –&gt; 00:22:24,000<br>But like basically, go fetch the next thing, I know I’m going to read from memory into my CPU caches, and it’s timed in such a way because they control again those that they’re running on, they’re controlling the code that they’re generating.</p>
<p>265<br>00:22:24,000 –&gt; 00:22:34,000<br>So, they have heuristics to figure out at what point you want to invoke that software pre-fetch command so that when you come back around and actually need that tube, it’s actually ready for you.</p>
<p>266<br>00:22:34,000 –&gt; 00:22:37,000<br>And they basically use a circular buffer to place these things.</p>
<p>267<br>00:22:37,000 –&gt; 00:22:38,000<br>Yes.</p>
<p>268<br>00:22:38,000 –&gt; 00:22:40,000<br>Where did this source do source mean?</p>
<p>269<br>00:22:40,000 –&gt; 00:22:48,000<br>The query plan is the source, and then you emit a more source code for it.</p>
<p>270<br>00:22:48,000 –&gt; 00:22:56,000<br>Versus the hyper-style was taking the query plan and thinking of the source and spitting out the IR directly.</p>
<p>271<br>00:22:56,000 –&gt; 00:22:58,000<br>Yes.</p>
<p>272<br>00:22:58,000 –&gt; 00:23:08,000<br>So, I think we talked us about with the LACSOP operator fusion approach where we were introducing buffers in between in our pipeline.</p>
<p>273<br>00:23:08,000 –&gt; 00:23:19,000<br>So, there was a soft pipeline breaker, and then once that’s full, then move on to the next stage within my pipeline.</p>
<p>274<br>00:23:19,000 –&gt; 00:23:34,000<br>And so, the idea was that within that soft pipeline breaker, you would inject the pre-fetch commands so that you can do a little bit of work, the harbor go fetch is the pre-fetch is the thing you need, and then when you come back around, the data is available for you.</p>
<p>275<br>00:23:34,000 –&gt; 00:23:42,000<br>Because if you think about it, if you do too much work, then the data might get evicted by the next time you start using it.</p>
<p>276<br>00:23:42,000 –&gt; 00:23:49,000<br>If you do too few work inside that before you pre-fetch, or after you pre-fetch, then when you actually then need the data, it’s not available.</p>
<p>277<br>00:23:49,000 –&gt; 00:24:01,000<br>And again, because they’re doing all the compilation stuff themselves or generating the code, they have ways to figure out, you know, I’m this far along, and they’re trying to inject my pre-fetch commands.</p>
<p>278<br>00:24:01,000 –&gt; 00:24:15,000<br>So, the one thing that also they came out of the paper too is that, given from all the other systems we’ve talked about, they appear to be less aggressive in being adaptive compared to BigQuery and Snowflake and others.</p>
<p>279<br>00:24:15,000 –&gt; 00:24:25,000<br>Like, Snowflake was trying to do aggregate pushdowns, I think, photon and BigQuery were trying to figure out on the fly what the right, you know, data type they should be using.</p>
<p>280<br>00:24:25,000 –&gt; 00:24:38,000<br>So, what they really only talk about is that they have the ability to choose, you know, choose a vectorized implementations of different string functions, like upper, lower comparisons and things like that.</p>
<p>281<br>00:24:38,000 –&gt; 00:24:46,000<br>For when it’s asking data, and then if that’s incorrect, then they fall back to a slower version that operates on Unicode.</p>
<p>282<br>00:24:46,000 –&gt; 00:24:53,000<br>But that’s sort of the same trick that the others were doing, you know, they’re not really reorganizing the query plan themselves.</p>
<p>283<br>00:24:53,000 –&gt; 00:25:14,000<br>And the other one they talk about is, if you, for the join-thotes are doing sideways information passing, when you’re building the balloon-thoteer on the build side of a hash-join, they can recognize that if the hash-tale was getting too large and it’s spilling to disk, then you can size the balloon-thoteer be a little bit larger than you normally would,</p>
<p>284<br>00:25:14,000 –&gt; 00:25:21,000<br>because that will increase the likelihood that you don’t have false positives, and you don’t end up fetching things from disk.</p>
<p>285<br>00:25:21,000 –&gt; 00:25:35,000<br>But that’s really the only two adaptivity parts that they talk about, other than scaling up, the scaling up thing is more like on a per-query basis, do I need more compute nodes, because my current compute nodes are running other queries.</p>
<p>286<br>00:25:36,000 –&gt; 00:26:01,000<br>So the compilation piece of this is very fascinating as well, and this is, it’s similar to what Yellowbrick was doing where Yellowbrick talked about, instead of having the worker nodes be responsible for compiling the queries themselves, Amazon is going to have a separate service that’s running on the side with the dedicated nodes that basically call GCC and compile things.</p>
<p>287<br>00:26:02,000 –&gt; 00:26:19,000<br>And the idea is that the, you have caching, different layers of caching within the system, so you have a local cache where you have pre-compile query plans or fragments, and to be identified that the thing you’re trying to compile right now has already been compiled before, you just reuse that.</p>
<p>288<br>00:26:19,000 –&gt; 00:26:29,000<br>But then they have availability, which is, I think, ingenious, to maintain a cache across the entire fleet of machines across all of Redshift.</p>
<p>289<br>00:26:30,000 –&gt; 00:26:49,000<br>So now, like the idea is that if you come across a query that your cluster has never seen before, it doesn’t have the compile query plan in its cache, and Goldlook in this global cache, and see, did somebody else have something that’s very similar, and to be able to reuse that shared object, that pre-compiled, that compiled code.</p>
<p>290<br>00:26:50,000 –&gt; 00:27:01,000<br>And again, from a security standpoint, there isn’t any issue because it’s running arbitrary user code, it’s literally like scanned this table on this type with this kind of filter.</p>
<p>291<br>00:27:01,000 –&gt; 00:27:12,000<br>And so it doesn’t matter whether your table contains banking information, and my table contains blog information, at the end of the day, the data is a column of data, and they can reuse that.</p>
<p>292<br>00:27:13,000 –&gt; 00:27:20,000<br>So they talk about how the cache hit rate is like 99.95% for across all queries and across the entire fleet.</p>
<p>293<br>00:27:20,000 –&gt; 00:27:30,000<br>And then in the cases where if you don’t have the pre-compiled segment on your local cache, 87% of the time that when you go to the global cache, it’s going to be in there.</p>
<p>294<br>00:27:31,000 –&gt; 00:27:47,000<br>So this basically negates the cost of compilation, the thing we were worried about before, when we were talking about how to use this technique, and again, when we talked about IQ and MemSQL, and other systems that forked exactly as GCC, we talked about how it’s going to be second-stacked compile things.</p>
<p>295<br>00:27:47,000 –&gt; 00:27:52,000<br>Even Hyper was, in some cases, it was going to take hundreds of milliseconds to compile things.</p>
<p>296<br>00:27:53,000 –&gt; 00:27:55,000<br>All that goes away because everything’s cached.</p>
<p>297<br>00:27:55,000 –&gt; 00:27:56,000<br>Yes.</p>
<p>298<br>00:27:56,000 –&gt; 00:27:59,000<br>Question is how big is that cache?</p>
<p>299<br>00:27:59,000 –&gt; 00:28:03,000<br>I mean, it’s not going to be petabytes, right?</p>
<p>300<br>00:28:03,000 –&gt; 00:28:06,000<br>But it’s probably a couple of hundred gigs, sure.</p>
<p>301<br>00:28:06,000 –&gt; 00:28:09,000<br>But who cares? Is your Amazon?</p>
<p>302<br>00:28:09,000 –&gt; 00:28:13,000<br>How big is the S3 storage?</p>
<p>303<br>00:28:13,000 –&gt; 00:28:16,000<br>I don’t know. A lot.</p>
<p>304<br>00:28:17,000 –&gt; 00:28:22,000<br>So who cares if you have these cache query plans?</p>
<p>305<br>00:28:22,000 –&gt; 00:28:38,000<br>And then from their perspective, also, too, it’s a win-win situation because the customers are happy because the queries run faster, it’s less computationally expensive to fetch something from the cache than re-compile it.</p>
<p>306<br>00:28:39,000 –&gt; 00:28:42,000<br>So for them, this is an over-win situation.</p>
<p>307<br>00:28:42,000 –&gt; 00:28:45,000<br>And again, this is what you can do when it’s in the cloud.</p>
<p>308<br>00:28:45,000 –&gt; 00:28:52,000<br>Again, if you’re running Hyper and it’s local on your box, you can’t phone home to say, you know, do you have this compiled query plan?</p>
<p>309<br>00:28:52,000 –&gt; 00:28:54,000<br>Because it’s not designed that.</p>
<p>310<br>00:28:54,000 –&gt; 00:29:00,000<br>But when it’s a service running in the cloud, when you control everything, you can do this kind of trick.</p>
<p>311<br>00:29:01,000 –&gt; 00:29:11,000<br>So I saw a similar idea from, it’s a sort of commercial JVM company called Azul AZUL.</p>
<p>312<br>00:29:11,000 –&gt; 00:29:13,000<br>And they now have a compilation of the service.</p>
<p>313<br>00:29:13,000 –&gt; 00:29:28,000<br>I’m going to say, like, if you’re running your Java program, you can have their compiler, the local JVM say, I want a compiled version of this jar file, I’m going to run on this hardware.</p>
<p>314<br>00:29:28,000 –&gt; 00:29:32,000<br>You can call the service and get cache binaries from them.</p>
<p>315<br>00:29:32,000 –&gt; 00:29:33,000<br>Yes.</p>
<p>316<br>00:29:33,000 –&gt; 00:29:40,000<br>What I’m most impressed with is that the level of interaction of going to the cache isn’t as less costly than actually compiling.</p>
<p>317<br>00:29:40,000 –&gt; 00:29:46,000<br>So your statement is you’re more impressed that the cost of going to the cache is cheaper than just compiling locally?</p>
<p>318<br>00:29:46,000 –&gt; 00:29:53,000<br>Yeah, because using bi-locally just like 10 milliseconds or 100 milliseconds?</p>
<p>319<br>00:29:53,000 –&gt; 00:29:55,000<br>Seconds.</p>
<p>320<br>00:29:55,000 –&gt; 00:29:56,000<br>Yeah.</p>
<p>321<br>00:29:56,000 –&gt; 00:29:59,000<br>How large are these precompiled?</p>
<p>322<br>00:29:59,000 –&gt; 00:30:04,000<br>Like, let’s say in source code, like, are they more than like 100 lines?</p>
<p>323<br>00:30:04,000 –&gt; 00:30:13,000<br>Because if it’s precompiled operators, it should, like, one operator is not going to be more than like 1000 lines.</p>
<p>324<br>00:30:13,000 –&gt; 00:30:16,000<br>So a statement is like, how big in these programs actually be?</p>
<p>325<br>00:30:16,000 –&gt; 00:30:24,000<br>Because, like, you know, if it’s, because if you’re using some precomp, precompiled primitives for certain parts of the lower leaves,</p>
<p>326<br>00:30:24,000 –&gt; 00:30:28,000<br>but, you know, what about everything else? How much can that be?</p>
<p>327<br>00:30:28,000 –&gt; 00:30:32,000<br>I can be in the thousands, right? Like, for really big queries with a much advantage.</p>
<p>328<br>00:30:32,000 –&gt; 00:30:36,000<br>It’s all right. Just specifically for the precompiled primitives.</p>
<p>329<br>00:30:36,000 –&gt; 00:30:38,000<br>The precompiled primitives are usually pretty tight, right?</p>
<p>330<br>00:30:38,000 –&gt; 00:30:39,000<br>They go to the small ones.</p>
<p>331<br>00:30:39,000 –&gt; 00:30:40,000<br>They go to the small ones.</p>
<p>332<br>00:30:40,000 –&gt; 00:30:41,000<br>Yeah.</p>
<p>333<br>00:30:41,000 –&gt; 00:30:42,000<br>So everything else is like…</p>
<p>334<br>00:30:42,000 –&gt; 00:30:45,000<br>It’s all the scaffolding around it that then calls it as precompiled primitives.</p>
<p>335<br>00:30:45,000 –&gt; 00:30:48,000<br>That’s what they were trying to avoid compiling that.</p>
<p>336<br>00:30:48,000 –&gt; 00:30:50,000<br>What’s the point of having the precompiled primitives to be like?</p>
<p>337<br>00:30:50,000 –&gt; 00:30:57,000<br>The statement is why I have the precompiled primitives if you’re going to, you know, be able to compel everything.</p>
<p>338<br>00:30:57,000 –&gt; 00:31:00,000<br>I think the paper talks about how…</p>
<p>339<br>00:31:00,000 –&gt; 00:31:04,000<br>They come back and keep saying that it’s, I think, to reduce compilation costs.</p>
<p>340<br>00:31:04,000 –&gt; 00:31:08,000<br>Yeah, I think it makes sense.</p>
<p>341<br>00:31:08,000 –&gt; 00:31:14,000<br>But it makes, I mean, I think it makes sense because you can imagine like…</p>
<p>342<br>00:31:15,000 –&gt; 00:31:19,000<br>You know, here’s this one piece of code that I’m going to keep compiling over and over again.</p>
<p>343<br>00:31:19,000 –&gt; 00:31:26,000<br>At their scale, if you can compile it once and reuse it, it makes a huge difference.</p>
<p>344<br>00:31:26,000 –&gt; 00:31:32,000<br>And they talk about, again, there’s this overhead of, as we saw before, you know, with the precompiled primitives,</p>
<p>345<br>00:31:32,000 –&gt; 00:31:37,000<br>invoking of functions not free at runtime, obviously, because it’s a jump call on the CPU.</p>
<p>346<br>00:31:37,000 –&gt; 00:31:43,000<br>But if you do it on a batch of data and a vector, then it gets amortized.</p>
<p>347<br>00:31:44,000 –&gt; 00:31:46,000<br>And it becomes negligible.</p>
<p>348<br>00:31:49,000 –&gt; 00:31:54,000<br>So this would be, I mean, we’ll talk about this in the end, but like, Amazon’s not stupid.</p>
<p>349<br>00:31:54,000 –&gt; 00:32:00,000<br>They have all the metrics and telemetry across the entire system.</p>
<p>350<br>00:32:00,000 –&gt; 00:32:06,000<br>Like, they can identify, here’s the part where we’re, you know, here’s a part where it’s super inefficient for us,</p>
<p>351<br>00:32:06,000 –&gt; 00:32:09,000<br>and they can introduce caching and other things to speed things up.</p>
<p>352<br>00:32:09,000 –&gt; 00:32:13,000<br>So it’s not like they designed this because they thought, oh, that’s fun. Let’s go do this, right?</p>
<p>353<br>00:32:13,000 –&gt; 00:32:15,000<br>They did it for a reason.</p>
<p>354<br>00:32:15,000 –&gt; 00:32:21,000<br>And so, like, to your point, like, yeah, who cares about compiling the same, you know, same five-line function over and over again?</p>
<p>355<br>00:32:21,000 –&gt; 00:32:27,000<br>Think of, like, in Amazon’s scale, you’re doing this a billion times a day. That starts to add up.</p>
<p>356<br>00:32:27,000 –&gt; 00:32:34,000<br>And so, you know, this probably saves them, again, millions of dollars a year to have this.</p>
<p>357<br>00:32:35,000 –&gt; 00:32:38,000<br>And as I said, like, the customer’s happy too, because like, now queries are on super fast.</p>
<p>358<br>00:32:38,000 –&gt; 00:32:43,000<br>Because you’re just stitching a bunch of pre-compiled stuff put together.</p>
<p>359<br>00:32:43,000 –&gt; 00:32:49,000<br>I don’t think the paper talks about this, but I know that, you know, one of our students did an internship with them and worked on this project.</p>
<p>360<br>00:32:49,000 –&gt; 00:32:56,000<br>Like, they basically keep track of, in the cache, like, here’s all the source code, and then that they’ve ever generated.</p>
<p>361<br>00:32:56,000 –&gt; 00:32:59,000<br>And they have different compiled versions of it for the different versions of Redshift.</p>
<p>362<br>00:33:00,000 –&gt; 00:33:02,000<br>They’ve deployed in the different hardware that’s out there.</p>
<p>363<br>00:33:02,000 –&gt; 00:33:05,000<br>Because Amazon’s always putting out new Insta-Types and so forth.</p>
<p>364<br>00:33:05,000 –&gt; 00:33:08,000<br>And they don’t really tell you exactly what the CPU is.</p>
<p>365<br>00:33:08,000 –&gt; 00:33:13,000<br>That’s all hidden from you, but, you know, the obviously upgrade things over time.</p>
<p>366<br>00:33:13,000 –&gt; 00:33:23,000<br>So, they have the ability to have background workers go through, look in the cache, grab the original source code, and recompile it for the new versions.</p>
<p>367<br>00:33:23,000 –&gt; 00:33:26,000<br>So, it’s not just, like, for this fragment, here’s exactly one binary version.</p>
<p>368<br>00:33:27,000 –&gt; 00:33:32,000<br>There’s additional qualifiers you would have to select what version of the binary you want it.</p>
<p>369<br>00:33:32,000 –&gt; 00:33:35,000<br>And we solve the same thing with the yellow brick.</p>
<p>370<br>00:33:38,000 –&gt; 00:33:50,000<br>Alright, so the other thing that the paper talked about, although it’s rather short, but we can discuss a little bit, is that they have this hardware acceleration layer called Aqua, the Advanced Query Accelerator for Redshift.</p>
<p>371<br>00:33:50,000 –&gt; 00:33:55,000<br>As far as I can tell, this is just for Redshift and not Spectrum.</p>
<p>372<br>00:33:56,000 –&gt; 00:34:03,000<br>Right, because Spectrum is kind of trying to go against directly S3 storage, but I might be wrong with this.</p>
<p>373<br>00:34:03,000 –&gt; 00:34:22,000<br>But basically, they introduced an additional caching, what they call a computational storage layer, that sits in between the worker nodes and the storage layer, that has a bunch of FPGAs that you can do predicate pushdown and aggregation pushdown into these devices.</p>
<p>374<br>00:34:23,000 –&gt; 00:34:27,000<br>And do a bunch of computation on them before you hand it off up to the worker.</p>
<p>375<br>00:34:27,000 –&gt; 00:34:33,000<br>So, let’s say that, like the worker says, I want to get some data, I don’t want, you know, with this predicate like this.</p>
<p>376<br>00:34:33,000 –&gt; 00:34:41,000<br>And so, instead of going to directly the storage, you go to Aqua, and you say, this is the data I want to process.</p>
<p>377<br>00:34:41,000 –&gt; 00:34:44,000<br>I want to process, here’s the where clause I want for it.</p>
<p>378<br>00:34:44,000 –&gt; 00:34:51,000<br>And then this thing goes down to the storage layer, and just makes the raw get call to S3 or whatever to get it.</p>
<p>379<br>00:34:51,000 –&gt; 00:35:02,000<br>And brings it back into this side, does the processing on it and the FPGA, and then shoves it back up to the worker for the computation.</p>
<p>380<br>00:35:02,000 –&gt; 00:35:04,000<br>Right?</p>
<p>381<br>00:35:04,000 –&gt; 00:35:13,000<br>And the paper talks about how that this layer is not actually tied to your cluster, your workers, your data warehouse instance.</p>
<p>382<br>00:35:13,000 –&gt; 00:35:19,000<br>This is a global service that can be reused from multi-tenor across any possible cost per.</p>
<p>383<br>00:35:19,000 –&gt; 00:35:24,000<br>Simulator, the compilation service was across all the entire fleet of Amazon Redship users.</p>
<p>384<br>00:35:24,000 –&gt; 00:35:29,000<br>Same thing for this, this was like used by anybody.</p>
<p>385<br>00:35:29,000 –&gt; 00:35:41,000<br>And they talk about how the, when the advantage of having this additional separation between the storage layer and the work layer is that you can down do cluster resizing the worker level,</p>
<p>386<br>00:35:41,000 –&gt; 00:35:46,000<br>and not worry about having to shuffle things around, because this thing is sort of independent of it.</p>
<p>387<br>00:35:46,000 –&gt; 00:35:53,000<br>I think that’s a little bit of them being a remnant or the artifact of them, originally starting off being a shared nothing system.</p>
<p>388<br>00:35:53,000 –&gt; 00:36:07,000<br>So this was introduced in 2021, which is not that long ago, three years ago, and the paper is 2022, so they’re talking about it, but the paper was written in 2021 by the time it came out in 2022.</p>
<p>389<br>00:36:07,000 –&gt; 00:36:18,000<br>And then I think around 2022, people noticed that you no longer enable this feature, and I think the response was, oh yeah, it’s just always on.</p>
<p>390<br>00:36:18,000 –&gt; 00:36:31,000<br>But as far as I can tell, as far as I know, well, I haven’t cut anything here, that this was phased out. They actually got rid of this, but it didn’t publicly announce it.</p>
<p>391<br>00:36:31,000 –&gt; 00:36:39,000<br>And instead what they did was, at the storage layer, they have these, they may mention Nitro.</p>
<p>392<br>00:36:39,000 –&gt; 00:36:53,000<br>Nitro is the, Nitro is on a single thing, but that’s their sort of, what they call the project of how, how the running their own hyperbys are the specialized harbor that they’re running for all the different instances on Amazon.</p>
<p>393<br>00:36:53,000 –&gt; 00:37:04,000<br>And they have custom silicon on these Nitro instances to do networking, do additional processing for EBS and storing things.</p>
<p>394<br>00:37:04,000 –&gt; 00:37:13,000<br>And so one of the things that they’ve added is the hardware acceleration through Nitro and additional card to do the kind of stuff that they were doing originally on the FPGA.</p>
<p>395<br>00:37:14,000 –&gt; 00:37:27,000<br>So the, so this aspect is unique, but this sort of seemed like this was like a, not afterthought, has it?</p>
<p>396<br>00:37:27,000 –&gt; 00:37:34,000<br>Like, snowflake didn’t really do this. It’s basically doing trying to competitive push down to the storage.</p>
<p>397<br>00:37:34,000 –&gt; 00:37:40,000<br>But instead of adding much more stuff down here, they just had the extra layer in the middle.</p>
<p>398<br>00:37:40,000 –&gt; 00:37:43,000<br>Dremel does this as well, right, before it’s shuffle.</p>
<p>399<br>00:37:43,000 –&gt; 00:37:44,000<br>With FPGA’s?</p>
<p>400<br>00:37:44,000 –&gt; 00:37:46,000<br>Yeah, he’s sending it in the lecture.</p>
<p>401<br>00:37:46,000 –&gt; 00:37:47,000<br>Dremel?</p>
<p>402<br>00:37:47,000 –&gt; 00:37:48,000<br>That’s in BigQuery.</p>
<p>403<br>00:37:48,000 –&gt; 00:37:49,000<br>Oh, BigQuery, yeah, sorry, yeah.</p>
<p>404<br>00:37:49,000 –&gt; 00:37:51,000<br>Oh, sorry, sorry, sorry, I said, I said Dremio.</p>
<p>405<br>00:37:51,000 –&gt; 00:37:52,000<br>Yeah, sorry, Dremel.</p>
<p>406<br>00:37:52,000 –&gt; 00:37:53,000<br>Yes.</p>
<p>407<br>00:37:53,000 –&gt; 00:37:59,000<br>But that’s like on the shuffle nodes themselves, not like the storage layer.</p>
<p>408<br>00:37:59,000 –&gt; 00:38:00,000<br>Right?</p>
<p>409<br>00:38:00,000 –&gt; 00:38:04,000<br>I think what Amazon has done is pushed this kind of stuff down to the storage layer down here.</p>
<p>410<br>00:38:04,000 –&gt; 00:38:09,000<br>And so instead of having a separate standalone service, which this was, it’s all now just down here.</p>
<p>411<br>00:38:09,000 –&gt; 00:38:12,000<br>Right?</p>
<p>412<br>00:38:12,000 –&gt; 00:38:14,000<br>You can see this with S3.</p>
<p>413<br>00:38:14,000 –&gt; 00:38:18,000<br>Like, you, they have an S3 select API.</p>
<p>414<br>00:38:18,000 –&gt; 00:38:24,000<br>Like, you can basically do ware clauses on S3 independent of, of, of, of, redshift.</p>
<p>415<br>00:38:24,000 –&gt; 00:38:31,000<br>And I suspect that that’s how they’re relying on the same kind of mechanism.</p>
<p>416<br>00:38:31,000 –&gt; 00:38:32,000<br>But there wasn’t really a big announcement.</p>
<p>417<br>00:38:32,000 –&gt; 00:38:37,000<br>This Aqua just sort of, you know, just just disappeared as far as I can tell.</p>
<p>418<br>00:38:37,000 –&gt; 00:38:40,000<br>Without acknowledging that it’s been removed.</p>
<p>419<br>00:38:40,000 –&gt; 00:38:41,000<br>All right.</p>
<p>420<br>00:38:41,000 –&gt; 00:38:45,000<br>So with the query optimizer, then they don’t, they say much.</p>
<p>421<br>00:38:45,000 –&gt; 00:38:51,000<br>I know that it’s still based on, you know, it’s always been, been, been heavily modified over the years.</p>
<p>422<br>00:38:51,000 –&gt; 00:38:55,000<br>But it’s still heavily based on, in Postgres, this query optimizer.</p>
<p>423<br>00:38:55,000 –&gt; 00:39:00,000<br>So it’s going to be a bunch of, of, of, of, heuristics and rules in the very beginning to do some rewriting.</p>
<p>424<br>00:39:00,000 –&gt; 00:39:03,000<br>It’s part of what this, this piece down here does.</p>
<p>425<br>00:39:03,000 –&gt; 00:39:09,000<br>And then they’re going to do some going to call space search to figure out the optimal join on ring.</p>
<p>426<br>00:39:09,000 –&gt; 00:39:17,000<br>And again, unlike in, in Dremel and unlike in, in Databricks where they assume they’re not going to have query statistics.</p>
<p>427<br>00:39:17,000 –&gt; 00:39:30,000<br>In the case of a redshift, it’s on, if it’s on redshift, manage storage, they, they’ll run analyze and collect the data and, you know, train, build statistical models that the MIM feed into the call space optimizations.</p>
<p>428<br>00:39:30,000 –&gt; 00:39:43,000<br>For spectrum queries that are running after raw data, going after raw data on S3, as far as they can tell, the only thing they can do is go extract the, the, the meta data in the headers of folders or parking or files.</p>
<p>429<br>00:39:43,000 –&gt; 00:39:49,000<br>And try to push down filters based on those zone maps, like, you know, basic minmax calls and things like that.</p>
<p>430<br>00:39:49,000 –&gt; 00:39:54,000<br>And I think that gets cached up into the, in the compute layer.</p>
<p>431<br>00:39:54,000 –&gt; 00:39:58,000<br>So you’re not going, always going to read, reading S3 for every single file.</p>
<p>432<br>00:39:59,000 –&gt; 00:40:04,000<br>The paper makes a big deal about this query, we’re writing framework, QRF. Again, they aren’t describing what it actually is.</p>
<p>433<br>00:40:04,000 –&gt; 00:40:09,000<br>As far as you can tell, there’s no documentation about it, because again, it’s this internal thing.</p>
<p>434<br>00:40:09,000 –&gt; 00:40:23,000<br>But they talk about how it’s a DSL based approach where you can basically specify the patterns that you’re looking for and then the transformation rules if you match a pattern, which is what we’ve been talking about, you know, all before for query optimizers is basically how they work.</p>
<p>435<br>00:40:23,000 –&gt; 00:40:34,000<br>But they claim that their, their implementation of it, their, their method of doing this is really easy for, for anyone to come along and, you know, extend it.</p>
<p>436<br>00:40:34,000 –&gt; 00:40:39,000<br>They, they mentioned interns could use it in three day, get it working in three days or make changes in three days.</p>
<p>437<br>00:40:39,000 –&gt; 00:40:52,000<br>So this sounds like what the yellow brick people were talking about in last class, where they rather than making, you know, principal changes to the, the internals of the query optimizer and how it actually wants to do search and read.</p>
<p>438<br>00:40:52,000 –&gt; 00:41:06,000<br>And then they want to do searches and numerations and other things that they have these sort of one-off rules where they try to patch things up for queries as they come in based on, you know, to force the query plan in the form that they want it.</p>
<p>439<br>00:41:06,000 –&gt; 00:41:14,000<br>So another interesting thing that they, that Amazon does, in their documentation for Redshift is actually really, really good.</p>
<p>440<br>00:41:14,000 –&gt; 00:41:22,000<br>They have a whole documentation page on how to make queries run faster, especially running on on Redshift again, where you don’t have statistical information.</p>
<p>441<br>00:41:22,000 –&gt; 00:41:26,000<br>So they have a bunch of guidelines. I’m not going to read them all.</p>
<p>442<br>00:41:26,000 –&gt; 00:41:38,000<br>But like they talk about how, okay, well, if you know you’re running on the start schema, then you should put your facts, fact tables in S3 and all your dimension tables in in Redshift Manage Storage.</p>
<p>443<br>00:41:38,000 –&gt; 00:41:47,000<br>Because in that case, you can least get statistics for the Redshift Manage Storage data. And then that’s, you know, the, they’re optimizing what we smart enough to recognize.</p>
<p>444<br>00:41:47,000 –&gt; 00:41:55,000<br>Okay, well, batch maybe the where I’m going to build on my hash tables and I just have this giant pipeline where I probe all those hash tables with my, my fact table.</p>
<p>445<br>00:41:55,000 –&gt; 00:42:07,000<br>Well, they talk about how like you should write your queries in a certain way that you know that these things can be pushed down into, into the storage layer based on them being simple and whatnot.</p>
<p>446<br>00:42:07,000 –&gt; 00:42:20,000<br>You can actually also define statistics on these external tables or S3 tables. And that I think what happens is Amazon then goes and reads that data in, collects the statistics and then stores it as if it was a regular table.</p>
<p>447<br>00:42:21,000 –&gt; 00:42:38,000<br>So I find this kind of interesting. It’s like telling you what you should be doing as a user to deal with the fact that you may not have any statistics on S3 data instead of preempt, you know, preempt any problems that come later on.</p>
<p>448<br>00:42:39,000 –&gt; 00:42:58,000<br>So we talked about this already, the Redshift Manage Storage. Again, as I said, I think it’s stepper nodes, as you said, the running on S3 or sorry S3. And they’re going to have local attach SSDs that if they then fill up, then they spill to spill to S3.</p>
<p>449<br>00:42:58,000 –&gt; 00:43:06,000<br>So that’s why I don’t think they’re pure S3 nodes. I think they’re separate, like, you see, not easy to do, this is because they’re virtual, but I think it’s something separate.</p>
<p>450<br>00:43:07,000 –&gt; 00:43:24,000<br>And I think the computer knows also have their own local SSD cache as well. But when you put things in Redshift Manage Storage, that’s not going to be using Part K. It’s not going to be using an open source file format. It’s going to be using their proprietary format. And similar to what we saw in snowflake yellow brick and others.</p>
<p>451<br>00:43:25,000 –&gt; 00:43:43,000<br>So what it says on 9 in that spectrum are Edgey spectrums and flux in the Redshift where we can work directly on S3. Whereas for RMS, it would have to load into the proprietary format first and then they could run queries or Edgey just make calls the Edgey spectrum.</p>
<p>452<br>00:43:44,000 –&gt; 00:43:49,000<br>And then it can work in the native format or can all that on S3. So that’s the right.</p>
<p>453<br>00:43:50,000 –&gt; 00:44:03,000<br>So what she said was for spectrum, it is it has the ability to read data on S3 in any possible format and then feed that data into the regular Redshift compute nodes.</p>
<p>454<br>00:44:03,000 –&gt; 00:44:10,000<br>But again, going back to my original point, I don’t think they’re separate nodes. I think it’s just the same compute nodes.</p>
<p>455<br>00:44:11,000 –&gt; 00:44:17,000<br>And as the Redshift compute nodes, like the work nodes, you have to set the grid nodes.</p>
<p>456<br>00:44:17,000 –&gt; 00:44:20,000<br>Okay, you have to provision them separately.</p>
<p>457<br>00:44:21,000 –&gt; 00:44:28,000<br>They get provision, it is transparent, but it’s more of a based on your query, as you work with the thing.</p>
<p>458<br>00:44:31,000 –&gt; 00:44:33,000<br>Okay, let’s help out. Thank you.</p>
<p>459<br>00:44:34,000 –&gt; 00:44:47,000<br>Again, because they want to manage everything, so when you create a table schema that they’re going to specify exactly what compression schema and coding schema want to use, these are just a sample them.</p>
<p>460<br>00:44:47,000 –&gt; 00:44:58,000<br>And then they talk about how they have their own proprietary one called AZ64, that they claim is, you know, it gets comfortable compression to something like snappy, but it’s faster.</p>
<p>461<br>00:44:59,000 –&gt; 00:45:07,000<br>But as far as you know, there’s no public documentation that talks about it. I’m sure there’s a patent, but we don’t want to repatence in academia.</p>
<p>462<br>00:45:07,000 –&gt; 00:45:10,000<br>So it’s for plausible deniability.</p>
<p>463<br>00:45:10,000 –&gt; 00:45:12,000<br>Is there bad or bad?</p>
<p>464<br>00:45:12,000 –&gt; 00:45:15,000<br>Patents? Yeah, you don’t want to repatence.</p>
<p>465<br>00:45:15,000 –&gt; 00:45:24,000<br>If you’re a researcher, don’t repatence because then if you end up inventing the same thing, they can’t claim that you saw their ideas because you didn’t read the patent.</p>
<p>466<br>00:45:25,000 –&gt; 00:45:34,000<br>And it rents you from maybe reselling or doing it, monetizing, but it isn’t like this I have to cut.</p>
<p>467<br>00:45:34,000 –&gt; 00:45:36,000<br>What was the point of the story?</p>
<p>468<br>00:45:39,000 –&gt; 00:45:42,000<br>Don’t repatence. There you go. That’s the point of the story.</p>
<p>469<br>00:45:43,000 –&gt; 00:45:57,000<br>Okay. So here’s the paper. Here’s the graph in the paper where they show how fast sure things are.</p>
<p>470<br>00:45:57,000 –&gt; 00:46:01,000<br>So this is running TPCDS on three terabyte data set.</p>
<p>471<br>00:46:01,000 –&gt; 00:46:07,000<br>And so they have what they call the out-of-box experience, meaning like just bulk loads some data and then immediately run your queries at it.</p>
<p>472<br>00:46:07,000 –&gt; 00:46:18,000<br>And here’s the performance you’re getting relative to Redshift and then the tune one is like if you actually go, you can be at indexes, at compression properly, actually spend time to actually tighten things up.</p>
<p>473<br>00:46:18,000 –&gt; 00:46:20,000<br>Here’s what you can do.</p>
<p>474<br>00:46:20,000 –&gt; 00:46:22,000<br>Everybody says that’s the best.</p>
<p>475<br>00:46:22,000 –&gt; 00:46:25,000<br>So everybody’s really good at it.</p>
<p>476<br>00:46:25,000 –&gt; 00:46:30,000<br>The time to reading a series with what they’re versioning and they all have a figure that says, look we’re better than everybody else.</p>
<p>477<br>00:46:30,000 –&gt; 00:46:34,000<br>Yes. Well, we showed Yellowbrick last time, right?</p>
<p>478<br>00:46:35,000 –&gt; 00:46:41,000<br>So Yellowbrick is faster. Yellowbrick is not in here, but like they… Yellowbrick had…</p>
<p>479<br>00:46:41,000 –&gt; 00:46:50,000<br>Snowflake always has it as being number two, right? I think. But Yellowbrick had nothing Redshift slower than…</p>
<p>480<br>00:46:50,000 –&gt; 00:46:52,000<br>Snowflake as well.</p>
<p>481<br>00:46:52,000 –&gt; 00:46:53,000<br>Yes, Snowflake as well.</p>
<p>482<br>00:46:53,000 –&gt; 00:46:55,000<br>Wasn’t it worth a degree at all?</p>
<p>483<br>00:46:55,000 –&gt; 00:46:56,000<br>Yes.</p>
<p>484<br>00:46:57,000 –&gt; 00:47:03,000<br>What’s funny is that this time when I was even less accurate because they’re just doing TPCD at one time than one, two, three, four.</p>
<p>485<br>00:47:03,000 –&gt; 00:47:05,000<br>Sorry, it’s relative to Redshift. Sorry.</p>
<p>486<br>00:47:05,000 –&gt; 00:47:08,000<br>So they didn’t actually give numbers, they just give that to us.</p>
<p>487<br>00:47:08,000 –&gt; 00:47:11,000<br>So that’s what I think it’s important.</p>
<p>488<br>00:47:11,000 –&gt; 00:47:20,000<br>It’s rare to see absolute numbers in there just because again you don’t want your competitors using your own numbers against you.</p>
<p>489<br>00:47:20,000 –&gt; 00:47:25,000<br>So maybe this is… Say this is actually legitimate, right?</p>
<p>490<br>00:47:25,000 –&gt; 00:47:30,000<br>And maybe, you know… I’m not saying it’s not legitimate, I’m just saying like there’s too many different factors.</p>
<p>491<br>00:47:30,000 –&gt; 00:47:38,000<br>But say, you know, Snowflake really was slower and then they add new features to get this number down, so now they can point to say,</p>
<p>492<br>00:47:38,000 –&gt; 00:47:41,000<br>Redshift got this and we got that because we added this new feature.</p>
<p>493<br>00:47:41,000 –&gt; 00:47:45,000<br>So they want to avoid all that. And they said, Yellowbrick, that paper is great because they put roll numbers in.</p>
<p>494<br>00:47:45,000 –&gt; 00:47:52,000<br>No one does that. But there’s no way like Amazon Legal is going to let you put anything out like that.</p>
<p>495<br>00:47:52,000 –&gt; 00:48:03,000<br>So again, I hope again you guys are skeptical, I’ve found that everyone is, which is good, about what these numbers actually mean and actually telling us anything.</p>
<p>496<br>00:48:03,000 –&gt; 00:48:13,000<br>Other than to say, like, despite all their efforts to make everything be serverless and try to remove the need for a human to come and tune things,</p>
<p>497<br>00:48:13,000 –&gt; 00:48:22,000<br>you know, clearly it makes a difference. Again, this number is not this number, right? These are two separate, you know, base lines.</p>
<p>498<br>00:48:22,000 –&gt; 00:48:28,000<br>But like, you know, going from this to this for BigQuery, that’s a pretty big drop, right?</p>
<p>499<br>00:48:28,000 –&gt; 00:48:35,000<br>Because I can’t imagine the other ones got significantly slower and you know, BigQuery is just the same, if you’re tuning it, yes.</p>
<p>500<br>00:48:35,000 –&gt; 00:48:43,000<br>So when I see data like this, what should I look at to try and like, what information should I try to objectively get?</p>
<p>501<br>00:48:43,000 –&gt; 00:48:49,000<br>Should I try to say, oh, this means redshift is really good with large data sets with complex query links.</p>
<p>502<br>00:48:49,000 –&gt; 00:48:55,000<br>Yes, for sure I say, oh, maybe it’s the relative scale, but I should think about what should I think away from this.</p>
<p>503<br>00:48:55,000 –&gt; 00:49:02,000<br>So it goes back to that, I think that reddit post I showed before. And the question is, what should you take away from this?</p>
<p>504<br>00:49:02,000 –&gt; 00:49:13,000<br>It goes back to the, that reddit post where I said before, like, you can simplify the decision, like, if you’re already got much data on Amazon S3, then you probably just use redshift, right?</p>
<p>505<br>00:49:13,000 –&gt; 00:49:16,000<br>Or something that can access the raw files.</p>
<p>506<br>00:49:16,000 –&gt; 00:49:27,000<br>If your company were like, you know, it’s your job or responsibility to figure out what, you know, which one you can use and money and location and what cloud platform you can use is not an issue.</p>
<p>507<br>00:49:27,000 –&gt; 00:49:37,000<br>You just don’t like look at it and say, oh, I’m going to use this. There’s the whole process where you do a POC, they have solution architects help set up your cluster.</p>
<p>508<br>00:49:37,000 –&gt; 00:49:42,000<br>You know, if you’re signing for millions of dollars of, you know, years of service, right? Could you also not paying monthly?</p>
<p>509<br>00:49:42,000 –&gt; 00:49:56,000<br>You’re paying like, you’re prepaid ahead of time to get a discount. So you have like solution architects that help, you know, set up your, the environment, help take a sample, your workload, running on whatever you, you know, software you have now, data system you have now, and then no one experiments for you and give you feedback.</p>
<p>510<br>00:49:56,000 –&gt; 00:50:11,000<br>So it’s, it’s for you as a student who don’t, I don’t know you, I don’t seem to know how many money, but like, like, yeah, I know I was just seeing your costs.</p>
<p>511<br>00:50:12,000 –&gt; 00:50:22,000<br>So I mean, so like for you as a student, like, honestly, again, simplicity is what I would, I would aim for.</p>
<p>512<br>00:50:24,000 –&gt; 00:50:34,000<br>As we said before, you can cook the, you can not cook the books like, they can add on to career rewriting rules and they say, oh, it’s TPC, yes, make it do this one, make it do this one trick, because I know that’s going to make a huge difference performance.</p>
<p>513<br>00:50:35,000 –&gt; 00:50:46,000<br>So you have to take all this with a grain of salt. The nobody’s going to be making major, a sort of corporate level enterprise level, making major decisions about choosing one or whatever based on like benchmark results like this.</p>
<p>514<br>00:50:46,000 –&gt; 00:50:49,000<br>Right. This is just for them to brag in the paper, like the word faster.</p>
<p>515<br>00:50:50,000 –&gt; 00:50:52,000<br>So what is it that comparable?</p>
<p>516<br>00:50:52,000 –&gt; 00:50:54,000<br>A compare in terms of what?</p>
<p>517<br>00:50:54,000 –&gt; 00:50:58,000<br>Like they’re all comparably fast, so you can pick the one that’s the point.</p>
<p>518<br>00:50:59,000 –&gt; 00:51:10,000<br>I’m going to say this in a second. My end, my end, my sort of, including remarks for the semester is exactly as you said, given that you know, here’s all the optimizations that I can do.</p>
<p>519<br>00:51:10,000 –&gt; 00:51:21,000<br>We saw for the last couple of weeks of how they’re all doing vectorized execution. They’re all mostly doing push-based stuff. They’re all doing some, you know, pre-compile primitives or, you know, holistic query compilation.</p>
<p>520<br>00:51:21,000 –&gt; 00:51:26,000<br>They’re all doing what you should be doing to get a high performance overlap system.</p>
<p>521<br>00:51:26,000 –&gt; 00:51:29,000<br>The question, right? She’s only does the primitive, right? Doesn’t do the holistic.</p>
<p>522<br>00:51:29,000 –&gt; 00:51:32,000<br>No, they do both. That’s the whole thing.</p>
<p>523<br>00:51:32,000 –&gt; 00:51:38,000<br>They co-genosepose loss that they were they inject the pre-compile primitives into it.</p>
<p>524<br>00:51:38,000 –&gt; 00:51:42,000<br>Right? That’s unusual. Nobody else does that as far as they know.</p>
<p>525<br>00:51:42,000 –&gt; 00:51:43,000<br>Yes.</p>
<p>526<br>00:51:51,000 –&gt; 00:51:56,000<br>So, it’s not that you didn’t have that.</p>
<p>527<br>00:51:56,000 –&gt; 00:52:07,000<br>Good question. So, this question is like, how can snow like be successful as it is when it’s competing against Microsoft, the Googles, and the Amazon’s?</p>
<p>528<br>00:52:07,000 –&gt; 00:52:10,000<br>And the answer is because they got there early.</p>
<p>529<br>00:52:10,000 –&gt; 00:52:18,000<br>So, as I said, in 2012 or 2013 when they put out Redshift, it was basically Parksell slapped up on there.</p>
<p>530<br>00:52:18,000 –&gt; 00:52:24,000<br>And the idea was, in Amazon’s famous for this, they put it up there. If no one uses it, now it would just take it down. No big deal.</p>
<p>531<br>00:52:24,000 –&gt; 00:52:28,000<br>If people started using it and they started making money, then they throw more money into it and make it better.</p>
<p>532<br>00:52:28,000 –&gt; 00:52:37,000<br>Right? So, but Snowflake came out of the gate, probably getting, like, if you compare 2013 Snowflake or 2014 Slavic versus, you know, 2014 Redshift, Snowflake was probably faster.</p>
<p>533<br>00:52:37,000 –&gt; 00:52:45,000<br>I can’t prove it, but I’m this pure speculation. And, but over time, you know, Amazon threw a ton of money and it’d do all the stuff just off, make it faster.</p>
<p>534<br>00:52:45,000 –&gt; 00:52:52,000<br>But, like, Snowflake was at the right place at the right time and early enough, there wasn’t any other competition.</p>
<p>535<br>00:52:52,000 –&gt; 00:52:56,000<br>So, that’s why they were able to succeed and grow as much as they did.</p>
<p>536<br>00:52:57,000 –&gt; 00:53:17,000<br>So, now you may say, okay, well, what about the click houses, the Dremios, the Druids, Peanos, all these other ones that are coming to the party a little bit later, how are they going to compete against the, you know, against the giants and the incumbents like Snowflake?</p>
<p>537<br>00:53:17,000 –&gt; 00:53:31,000<br>It’s hard. It’s a hell battle. You just got to figure out what the, you know, it’s something to come to figure out, like, what’s the sort of one thing that they think they can do much better than what, you know, the big careers of the world can do.</p>
<p>538<br>00:53:31,000 –&gt; 00:53:34,000<br>It is hard, yes.</p>
<p>539<br>00:53:35,000 –&gt; 00:53:49,000<br>Correct. Yes. And, David, it’s like, say you have this amazing new idea, like, how are you going to, Amazon is throw a ton of money and implement it.</p>
<p>540<br>00:53:49,000 –&gt; 00:53:56,000<br>Yes. Now, big companies, they’re giant ships. You take a while to, like, you know, to move things, right?</p>
<p>541<br>00:53:56,000 –&gt; 00:54:10,000<br>This is sometimes called the innovators dilemma. Like, it’s, you’re making so much money on what you currently have, which, you know, at the time, maybe state of the art, and then something new comes along, but it radically changes what you, how you approach things.</p>
<p>542<br>00:54:10,000 –&gt; 00:54:17,000<br>You know, you’re not really incentivized to go make that change and therefore the upstart can come and compete you. That’s basically what Snowflake did, right?</p>
<p>543<br>00:54:17,000 –&gt; 00:54:31,000<br>Work already had and tear data already had cloud, you’re starting that cloud version, they already had like enterprise grade, OLAP systems that they could have sold on the cloud, but they were making so much money on prem that, you know, they didn’t, they didn’t invest in that maybe early as they should have.</p>
<p>544<br>00:54:31,000 –&gt; 00:54:48,000<br>Teradata is probably the best example of this, right? Or DB2 is another one. So this is what I was maybe seeing also early in the semester too, that like OLAP systems now more of the core engines, the kind of things we talked about in trying to semester, they basically come and commoditize.</p>
<p>545<br>00:54:48,000 –&gt; 00:55:05,000<br>And now you have something like VeloX or Data Fusion where like you can get a high performance OLAP, you know, execution engine out of the box, you know, free, and then you sort of build something around it to then, you know, run queries and do other things.</p>
<p>546<br>00:55:05,000 –&gt; 00:55:33,000<br>And so what makes maybe Snowflake unique in 2013, you know, is is enough anymore and it’s all about the user experience is all about how good the query plan query planer is, you know, how well can you read data in S3 without crying users to do a bunch of stuff like those are the, they’re harder to measure from a sort of scientific objective because there’s like, you know, qualitative aspects of the system, but I think those are going to really matter a lot.</p>
<p>547<br>00:55:35,000 –&gt; 00:55:53,000<br>I would say so the one area where you see like the pinos and others trying to differentiate from these other guys is that, you know, this is not really meant for real time queries like if I ingest data, you know, I want to be able to get query it almost immediately, that you’re not really not going to be able to do that with these systems that well.</p>
<p>548<br>00:55:53,000 –&gt; 00:56:19,000<br>And so there’s these they’ll call real real time OLAP systems where they’re either doing heavy indexing something like rock set does this pino does this or you’re doing automatic materialize use this what materialize does so there’s there’s systems where upon ingest of the new data you’re building some additional data structures that then let you can then query almost immediately in a way that you can’t really do with these these traditional OLAP systems in the cloud.</p>
<p>549<br>00:56:20,000 –&gt; 00:56:25,000<br>But snowflakes not dumb, they know people want to do that so they’re they’re adding the room kind of stuff. They take care of these things.</p>
<p>550<br>00:56:29,000 –&gt; 00:56:41,000<br>So that’s, you know, it’s hard to, you know, it’s hard to measure, you know, how, how good someone’s experience with the system is versus another without, you have to talk to humans and humans don’t know what they’re doing.</p>
<p>551<br>00:56:42,000 –&gt; 00:56:45,000<br>And so the best you can really do is with all the form of numbers.</p>
<p>552<br>00:56:46,000 –&gt; 00:57:01,000<br>So as I was saying with wretch if this is a good example of like a system that has evolved organically over the time because you know maybe start as a sort of shared nothing system even though things moving into the cloud was as we talked to the entire semester, you want to be disc I go to storage.</p>
<p>553<br>00:57:02,000 –&gt; 00:57:14,000<br>But then they’ve changed their architecture and add additional features based on what they’re seeing again they collect telemetry on everything every single query collect telemetry all these patterns and they analyze it.</p>
<p>554<br>00:57:15,000 –&gt; 00:57:20,000<br>To figure out here’s the things that they need to optimize or here’s the things they can make things run better.</p>
<p>555<br>00:57:21,000 –&gt; 00:57:34,000<br>I don’t know what the paper talks about this but I’m in for credits gives this example all the time the guy the semial alum who works on redshift now that they looked at their telemetry and saw that update queries were actually running really slow and there was a lot of them.</p>
<p>556<br>00:57:35,000 –&gt; 00:57:39,000<br>Which is not something you would think about if you’re trying to build like an OLAP system right because you think of mostly read only data.</p>
<p>557<br>00:57:40,000 –&gt; 00:57:50,000<br>So they went ahead and optimized update queries and that made a huge difference and reduced their cost made the customers happier and they can do that because they have that telemetry.</p>
<p>558<br>00:57:51,000 –&gt; 00:58:08,000<br>So going back to this compilation service or this aqua thing they added they didn’t add it because they thought it was cool it had a bunch FPGA sitting in the closet they had to get rid of they did it because they saw that the measurements from the data that collected that this the bottleneck let’s go try to add a new component add another layer to the main thing is running.</p>
<p>559<br>00:58:09,000 –&gt; 00:58:12,000<br>So that’s a lot faster.</p>
<p>560<br>00:58:13,000 –&gt; 00:58:24,000<br>That’s another advantage of being the cloud where you see everything versus on prem where you your photo of the firewall hopefully somebody then comes back report and says this is what this is what ran slow yes.</p>
<p>561<br>00:58:24,000 –&gt; 00:58:32,000<br>So I think the end of the all the scopes I had a question yes. Why is it all the academic papers looking at the CPS and all of these industry is getting CPS.</p>
<p>562<br>00:58:33,000 –&gt; 00:58:39,000<br>This question is why all the academic papers looking at TPCH and why all the commercial systems using TPCDS.</p>
<p>563<br>00:58:42,000 –&gt; 00:58:49,000<br>So TPCH is obviously easier to get up and running it’s 22 queries versus the TPCS DS is 11 or sorry 100 queries.</p>
<p>564<br>00:58:49,000 –&gt; 00:58:57,000<br>And there’s CTEs and things like that so I mean the Germans can run TPCDS I don’t know what they report numbers.</p>
<p>565<br>00:58:58,000 –&gt; 00:59:09,000<br>But the the amount of the the matter of the new to get TPCDS running versus TPCH is much higher because you got to CTEs I don’t think it’s any window functions in the CPCDS.</p>
<p>566<br>00:59:10,000 –&gt; 00:59:14,000<br>You got to make the query out from eyes are better it’s a higher bar from academic standpoint to get that running.</p>
<p>567<br>00:59:14,000 –&gt; 00:59:25,000<br>A classic another demo would be for on the old TPC side there’s TPCC that’s from 1992 and then there’s TPCE that’s from 2006 that’s supposed to be the successor to TPCC.</p>
<p>568<br>00:59:26,000 –&gt; 00:59:33,000<br>But nobody runs TPCE actually nobody in the commercial side usually runs it too because it’s a pain in the ass actually right the code and get up and running never do ever do runs TPCC.</p>
<p>569<br>00:59:35,000 –&gt; 00:59:39,000<br>I think it’s so at least just from a complexity of getting the thing actually running.</p>
<p>570<br>00:59:40,000 –&gt; 00:59:46,000<br>There’s a lot of other sort of implications of for TPCDS as well but for TPCE there’s nothing there’s not much.</p>
<p>571<br>00:59:47,000 –&gt; 00:59:50,000<br>I think so yeah I think it’s just complexity of that.</p>
<p>572<br>00:59:51,000 –&gt; 01:00:06,000<br>All right so as I said beginning Amazon make billions the B on on Reship each year right they don’t report this publicly but I think AWS makes like I think 100 million a year.</p>
<p>573<br>01:00:07,000 –&gt; 01:00:13,000<br>And I know that Reship is as the paper talks about was the fastest growing servers of the added in AWS.</p>
<p>574<br>01:00:14,000 –&gt; 01:00:23,000<br>I think got replaced by Aurora then that was the newest fastest growing one and for all this and also I don’t know what happens to have to make up but they’re making a ton of money on Reship.</p>
<p>575<br>01:00:24,000 –&gt; 01:00:34,000<br>But like part cell they got acquired by Action in 2013 for not much and then Action then rebranded as this thing called Action Matrix.</p>
<p>576<br>01:00:34,000 –&gt; 01:00:46,000<br>But then they killed off in 2016. So at the same the beginning Amazon bought the license to park cell for maybe 20 million and they’re making billions per year off of it.</p>
<p>577<br>01:00:47,000 –&gt; 01:00:54,000<br>Now again there’s obviously harbor costs there’s labor cost to build this but obviously from their perspective that was a cut throat.</p>
<p>578<br>01:00:55,000 –&gt; 01:00:58,000<br>That was a gangster move in their park.</p>
<p>579<br>01:00:59,000 –&gt; 01:01:11,000<br>Here it’s heard Action. Nobody. Action is what ingress became or so ingress is so ingress went public and ingress is the one the first relational systems before postgres.</p>
<p>580<br>01:01:12,000 –&gt; 01:01:18,000<br>They went public in the 80s got bought by computer associates got handed off passed around over a couple years.</p>
<p>581<br>01:01:18,000 –&gt; 01:01:34,000<br>They end up being a new holding company that they then changed the name from some ingress to actium and then now they basically buy up a bunch of these databases that are kind of in maintenance mode park cells and one of them they actually bought vector wise.</p>
<p>582<br>01:01:35,000 –&gt; 01:01:44,000<br>That was an image that was actually they were trying to do something real with that but they bought pervasive they buy bunch of these older databases and they sort of milk maintenance fees.</p>
<p>583<br>01:01:44,000 –&gt; 01:02:05,000<br>Then they got bought by another holding company at India and so they still sell ingress I think they I don’t know whether because I think they still call it ingress might be wrong but so parks again sold off for 20 million so so the license for 20 million I don’t know how much they got bought for but I don’t think it was was that much and then it died and then red shift lives on.</p>
<p>584<br>01:02:06,000 –&gt; 01:02:08,000<br>Again a lot of money and databases.</p>
<p>585<br>01:02:09,000 –&gt; 01:02:26,000<br>All right so that’s it for the semester this has been fun having you guys this is the first semester we’ve only had one person drop into our semester and it wasn’t for reasons outside of their control so I can appreciate everyone being here.</p>
<p>586<br>01:02:27,000 –&gt; 01:02:31,000<br>Thursday next next week we’ll do the final presentations it’ll be random order this time.</p>
<p>587<br>01:02:31,000 –&gt; 01:02:53,000<br>Randoms random okay and then I would say I didn’t pick red shift you didn’t pick red shift last for any reason because it was like you know the greatest whatever I think just covers a much of stuff that we’ve already covered and I want to make sure I include it because it’s a large system.</p>
<p>588<br>01:02:53,000 –&gt; 01:03:15,000<br>I don’t have office hours today because I got ahead the airport but send any send any emails if you want to talk personally this weekend or send me emails of it like you want additional information about your presentation should be and then the final again the PDF is on piazza if you have any clarification questions post that in the in piazza below okay.</p>
<p>589<br>01:03:15,000 –&gt; 01:03:18,000<br>Guys good luck with your class is seeing.</p>
<p>590<br>01:03:45,000 –&gt; 01:03:47,000<br>You drink it down with the guys.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CMU15721 P22S202422 AmazonRedshiftDataWarehouseSystemCMUAdvancedDatabaseSystems</div>
      <div>http://example.com/2025/10/24/CMU15721 P22S202422-AmazonRedshiftDataWarehouseSystemCMUAdvancedDatabaseSystems/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月24日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/24/CMU15721%20P5S202404-QueryExecutionProcessingPart1CMUAdvancedDatabaseSystems/" title="CMU15721 P5S202404 QueryExecutionProcessingPart1CMUAdvancedDatabaseSystems">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CMU15721 P5S202404 QueryExecutionProcessingPart1CMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/24/CMU15721%20P21S202421-YellowbrickDataWarehouseSystemCMUAdvancedDatabaseSystems/" title="CMU15721 P21S202421 YellowbrickDataWarehouseSystemCMUAdvancedDatabaseSystems">
                        <span class="hidden-mobile">CMU15721 P21S202421 YellowbrickDataWarehouseSystemCMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
