

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:08,000Good afternoon. Good morning. Good evening. Good night. Wherever you are. Let’s get started again. 200:00:08,000 –&gt; 00:00:14,000So today we have a guest lecture and">
<meta property="og:type" content="article">
<meta property="og:title" content="MIT6824 P10Lecture10 GuestLectureonGo RussCox">
<meta property="og:url" content="http://example.com/2025/10/24/MIT6824%20P10Lecture10-GuestLectureonGo-RussCox/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:08,000Good afternoon. Good morning. Good evening. Good night. Wherever you are. Let’s get started again. 200:00:08,000 –&gt; 00:00:14,000So today we have a guest lecture and">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-24T12:02:19.365Z">
<meta property="article:modified_time" content="2025-10-24T12:06:28.572Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>MIT6824 P10Lecture10 GuestLectureonGo RussCox - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="MIT6824 P10Lecture10 GuestLectureonGo RussCox"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-24 20:02" pubdate>
          2025年10月24日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          9.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          76 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">MIT6824 P10Lecture10 GuestLectureonGo RussCox</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:08,000<br>Good afternoon. Good morning. Good evening. Good night. Wherever you are. Let’s get started again.</p>
<p>2<br>00:00:08,000 –&gt; 00:00:14,000<br>So today we have a guest lecture and probably speaker needs little introduction.</p>
<p>3<br>00:00:14,000 –&gt; 00:00:23,000<br>I’m a guest with Russ Cox. We’ve won up the co-leads on the go project and we’ll talk a lot more about it.</p>
<p>4<br>00:00:23,000 –&gt; 00:00:26,000<br>Let me say a couple of words.</p>
<p>5<br>00:00:26,000 –&gt; 00:00:29,000<br>And not to write to him there’s Russ too much.</p>
<p>6<br>00:00:29,000 –&gt; 00:00:33,000<br>Russ has a long experience with distributed systems.</p>
<p>7<br>00:00:33,000 –&gt; 00:00:41,000<br>He was a developer and distributor to plan nine when he was a high school student and an undergrad at Harvard.</p>
<p>8<br>00:00:41,000 –&gt; 00:00:47,000<br>He joined the PZ program at MIT, which we met up.</p>
<p>9<br>00:00:47,000 –&gt; 00:00:56,000<br>And probably if you’ve taken any sort of you know P docks class, if you will, there’s going to be you will see Russ’s touches on it.</p>
<p>10<br>00:00:56,000 –&gt; 00:01:04,000<br>And certainly in A to four, you know, the go switch to go for us has been wonderful thing.</p>
<p>11<br>00:01:04,000 –&gt; 00:01:12,000<br>But if you divert in opinion, of course feel free to ask Russ questions and make suggestions.</p>
<p>12<br>00:01:12,000 –&gt; 00:01:18,000<br>He’s always welcome to entertain any ideas. So without Russ.</p>
<p>13<br>00:01:18,000 –&gt; 00:01:22,000<br>Great. Thanks. Can you still see the slides? Is that working?</p>
<p>14<br>00:01:22,000 –&gt; 00:01:29,000<br>Okay. Great. So, so we will go to support writing the sort of distributed systems that we were building at Google.</p>
<p>15<br>00:01:29,000 –&gt; 00:01:36,000<br>And that made go a great fit for you know what came next, which is now called cloud software and also a great fit for 84.</p>
<p>16<br>00:01:36,000 –&gt; 00:01:42,000<br>So in this lecture, I’m going to try to explain how I think about writing through programs and go.</p>
<p>17<br>00:01:42,000 –&gt; 00:01:49,000<br>And I’m going to walk through the sort of design and implementation of programs for four different patterns that I see come up often.</p>
<p>18<br>00:01:49,000 –&gt; 00:01:56,000<br>And along the way, I’m going to try to highlight some hints or rules of thumb that you keep in mind when designing your own go programs.</p>
<p>19<br>00:01:56,000 –&gt; 00:02:01,000<br>And I’m going to try to set up some of the links to older version of these slides. So, you know, you might have seen them already.</p>
<p>20<br>00:02:01,000 –&gt; 00:02:06,000<br>I hope that the lecture form is a bit more intelligible than just sort of looking at the slides.</p>
<p>21<br>00:02:06,000 –&gt; 00:02:19,000<br>And I hope that in general, these patterns are like common enough that, you know, maybe they’ll be helpful by themselves, but also that, you know, you’ll, you’ll, the hints will help you prepare for whatever it is you need to implement.</p>
<p>22<br>00:02:19,000 –&gt; 00:02:34,000<br>So to start is important to distinguish between concurrency and parallelism and concurrency is about how you write your programs about being able to compose independently executing control flows, whether you want to call them processes or threads or go routines.</p>
<p>23<br>00:02:34,000 –&gt; 00:02:40,000<br>So that your program can be dealing with lots of things at once without turning into a giant mess.</p>
<p>24<br>00:02:40,000 –&gt; 00:02:52,000<br>On the other hand, parallelism is about how the programs get executed about allowing multiple computations to run simultaneously so that the program can be doing lots of things at once, not just dealing with lots of things at once.</p>
<p>25<br>00:02:52,000 –&gt; 00:03:07,000<br>And so concurrency lends itself naturally to parallel execution, but today the focus is on how to use goes concurrency support to make your programs clearer, not to make them faster if they do they are faster, that’s wonderful, but, but that’s not the point today.</p>
<p>26<br>00:03:07,000 –&gt; 00:03:17,000<br>So I said I’d walk through the design and implementation of some programs for four common concurrency concurrency patterns that I see often.</p>
<p>27<br>00:03:17,000 –&gt; 00:03:27,000<br>But before we get to those, I want to start with what seems like a really trivial problem, but that illustrates one of the most important points about what it means to use concurrency to structure programs.</p>
<p>28<br>00:03:27,000 –&gt; 00:03:38,000<br>A decision that comes up over and over when you design concurrent programs is whether to represent states as code or as data and by as code, I mean the control flow in the program.</p>
<p>29<br>00:03:38,000 –&gt; 00:03:44,000<br>So suppose we’re reading characters from a file and we need to scan over a C style quoted string.</p>
<p>30<br>00:03:44,000 –&gt; 00:03:46,000<br>Oh, well, it’s a fly darn change.</p>
<p>31<br>00:03:46,000 –&gt; 00:03:47,000<br>Yeah, it will.</p>
<p>32<br>00:03:47,000 –&gt; 00:03:51,000<br>Well, it will. Can you see pro log board cancer state right now?</p>
<p>33<br>00:03:51,000 –&gt; 00:03:52,000<br>No, we see the title slide.</p>
<p>34<br>00:03:52,000 –&gt; 00:04:00,000<br>Oh, no. Yeah, I was wondering about that because there was like a border around this thing when I started and then it went away.</p>
<p>35<br>00:04:00,000 –&gt; 00:04:04,000<br>So let me, let me just unshare and reshare.</p>
<p>36<br>00:04:04,000 –&gt; 00:04:11,000<br>I have to figure out how to do that in zoom.</p>
<p>37<br>00:04:11,000 –&gt; 00:04:16,000<br>Unfortunately, the keynote menu wants to be up and I don’t know how to get to the zoom menu.</p>
<p>38<br>00:04:16,000 –&gt; 00:04:25,000<br>Um, my screen sharing is paused. Why is my screen sharing paused?</p>
<p>39<br>00:04:25,000 –&gt; 00:04:28,000<br>Can I resume? There we go.</p>
<p>40<br>00:04:28,000 –&gt; 00:04:36,000<br>All right, I don’t know. The zoom box says your screen sharing is paused. So if that now the board is back. So I’ll watch that.</p>
<p>41<br>00:04:36,000 –&gt; 00:04:42,000<br>All right. So, um, see, I was back here. So, so you know, we’re talking about reading a string.</p>
<p>42<br>00:04:42,000 –&gt; 00:04:49,000<br>It’s not a parallel program. It’s reading one character at a time. So there’s no opportunity for parallelism, but there is a good opportunity for concurrency.</p>
<p>43<br>00:04:49,000 –&gt; 00:04:56,000<br>So if we don’t actually care about the exact escape sequences in the string, the what we need to do is match this regular expression.</p>
<p>44<br>00:04:56,000 –&gt; 00:05:03,000<br>And we don’t have to worry about understanding it exactly. We’ll come back to what it means. But, but that’s basically all you have to do is, is influence this regular expression.</p>
<p>45<br>00:05:03,000 –&gt; 00:05:07,000<br>And so, you know, you probably all know you can turn a regular expression to a state machine.</p>
<p>46<br>00:05:07,000 –&gt; 00:05:11,000<br>And so we might use a tool that that generates this code.</p>
<p>47<br>00:05:11,000 –&gt; 00:05:17,000<br>And in this code, there’s a single variable state that’s the state of the machine. And the loop goes over the state.</p>
<p>48<br>00:05:17,000 –&gt; 00:05:23,000<br>One character at a time reads a character, depending on the state and the character changes to a different state until it gets to the end.</p>
<p>49<br>00:05:23,000 –&gt; 00:05:30,000<br>And so like this is a completely unreadable program. But it’s the kind of thing that, you know, an auto generated program might look like.</p>
<p>50<br>00:05:30,000 –&gt; 00:05:36,000<br>And the important point is that the program state is stored in data in this variable that’s called state.</p>
<p>51<br>00:05:36,000 –&gt; 00:05:42,000<br>And so, you can change it to store the state in code that’s often clearer.</p>
<p>52<br>00:05:42,000 –&gt; 00:05:44,000<br>So here’s what I mean.</p>
<p>53<br>00:05:44,000 –&gt; 00:05:50,000<br>Suppose we duplicate the read car calls into each case of the switch. So we haven’t made any semantic changes here.</p>
<p>54<br>00:05:50,000 –&gt; 00:05:54,000<br>We just took the read carat of the top and we moved it into the middle.</p>
<p>55<br>00:05:54,000 –&gt; 00:06:02,000<br>Now, instead of setting state and then immediately doing the switch again, we can change those into go to.</p>
<p>56<br>00:06:02,000 –&gt; 00:06:09,000<br>And then we can simplify a little bit further. There’s a go to state one that’s right before the state one label. We can get rid of that.</p>
<p>57<br>00:06:09,000 –&gt; 00:06:15,000<br>Then there’s a, I guess, yeah. So then there’s, you know, there’s only one way to get to state to.</p>
<p>58<br>00:06:15,000 –&gt; 00:06:19,000<br>So we might as well pull the state to code up and put it inside the if where the go to appears.</p>
<p>59<br>00:06:19,000 –&gt; 00:06:25,000<br>And then, you know, both sides of that if now end in go to state one. So we can hoist that out.</p>
<p>60<br>00:06:25,000 –&gt; 00:06:32,000<br>And now what’s left is actually a pretty simple program at you know state zero is never jumped to so it just begins there.</p>
<p>61<br>00:06:32,000 –&gt; 00:06:38,000<br>And then state one is just a regular loop. So we might as well make that look like a regular loop.</p>
<p>62<br>00:06:38,000 –&gt; 00:06:46,000<br>And now like this is, you know, looking like a program. And then finally we can, you know, get rid of some variables and simplify a little bit further.</p>
<p>63<br>00:06:46,000 –&gt; 00:06:54,000<br>And, and we can rotate the loop so that, you know, we don’t do a return true in the middle of the loop. We do the return true at the end.</p>
<p>64<br>00:06:54,000 –&gt; 00:06:59,000<br>And so now we’ve got this program that is actually, you know, reasonably nice.</p>
<p>65<br>00:06:59,000 –&gt; 00:07:04,000<br>And it’s worth mentioning that it’s possible to clean up, you know, much less egregious examples.</p>
<p>66<br>00:07:04,000 –&gt; 00:07:10,000<br>You know, if you would try to write this by hand, your first attempt might have been the thing on the left where you’ve got this extra piece of state.</p>
<p>67<br>00:07:10,000 –&gt; 00:07:20,000<br>And then you can apply the same kinds of transformations to move that state into the actual control flow and end up at the same program that we have on the right that’s cleaner.</p>
<p>68<br>00:07:20,000 –&gt; 00:07:24,000<br>So this is, you know, a useful transformation to keep in mind.</p>
<p>69<br>00:07:24,000 –&gt; 00:07:33,000<br>Anytime you have state that kind of looks like it might be just reiterating what’s what’s happening in the program counter.</p>
<p>70<br>00:07:33,000 –&gt; 00:07:40,000<br>And so, you know, you can see this if the, the original, in the original state, like if state equals zero, the program counter is at the beginning of the function.</p>
<p>71<br>00:07:40,000 –&gt; 00:07:49,000<br>And if state equals one, or if an escape equals false and the other version, the program counter is just inside the for loop and state equals two is, you know, further down in the for loop.</p>
<p>72<br>00:07:49,000 –&gt; 00:08:00,000<br>And the benefit of writing it this way instead of with the states is that it’s much easier to understand, like I can actually just walk through the code and explain it to you, you know, if you just read through the code, you read an opening quote.</p>
<p>73<br>00:08:00,000 –&gt; 00:08:11,000<br>And then you start looping and then until you find the closing quote, you read a character and if it’s a backslash, you stick the next character and that’s it, right, you can just read that off the page, which you couldn’t do in the original.</p>
<p>74<br>00:08:11,000 –&gt; 00:08:17,000<br>This version also happens to run faster, although that doesn’t really matter for us.</p>
<p>75<br>00:08:17,000 –&gt; 00:08:22,000<br>But as I mentioned, I’m going to highlight what I think are kind of important lessons as hints for designing your own go programs.</p>
<p>76<br>00:08:22,000 –&gt; 00:08:28,000<br>And this is the first one to convert data state into code state when it makes your programs clearer.</p>
<p>77<br>00:08:28,000 –&gt; 00:08:38,000<br>And again, like these are all hints, you should, you should, you know, for all of these, you should consider it as, you know, only if it helps, you can decide.</p>
<p>78<br>00:08:38,000 –&gt; 00:08:45,000<br>So one problem with this hint is that not all programs have the luxury of having complete control over their control flow.</p>
<p>79<br>00:08:45,000 –&gt; 00:08:57,000<br>So, you know, here’s a different example, instead of having a read care function that can be called, this code is written to have a process care method that you have to hand the character to one at a time.</p>
<p>80<br>00:08:57,000 –&gt; 00:09:07,000<br>And then process care has no choice really, but to, you know, encoded state in an explicit state variable, because after every character has to return back out.</p>
<p>81<br>00:09:07,000 –&gt; 00:09:14,000<br>And so it can’t save the state in the program counter and the stack, it has to have the state in an actual variable.</p>
<p>82<br>00:09:14,000 –&gt; 00:09:21,000<br>But in go, we have another choice, right, because we can’t save the state on that stack and in that program counter.</p>
<p>83<br>00:09:21,000 –&gt; 00:09:26,000<br>But, you know, we can make another go routine to hold that state for us.</p>
<p>84<br>00:09:26,000 –&gt; 00:09:33,000<br>And so, the closing, we already have this debug read string function that we really don’t want to rewrite in this other way.</p>
<p>85<br>00:09:33,000 –&gt; 00:09:38,000<br>We just want to reuse it. It works. Maybe it’s really big and hairy. It’s much more complicated than the thing we saw.</p>
<p>86<br>00:09:38,000 –&gt; 00:09:45,000<br>We just want to reuse it. And so the way we can do that and go is we can start a new go routine that does the read string part.</p>
<p>87<br>00:09:45,000 –&gt; 00:09:49,000<br>And it’s the same read string code as before. We pass in the character reader.</p>
<p>88<br>00:09:50,000 –&gt; 00:10:00,000<br>The, you know, the init method makes this this go routine to do the character reading. And then every time the process carer method is called.</p>
<p>89<br>00:10:00,000 –&gt; 00:10:05,000<br>We send a message to the go routine on the car channel that says, here’s the next character.</p>
<p>90<br>00:10:05,000 –&gt; 00:10:16,000<br>And then we receive a message back that says, like, tell me the current status and the current status is always either I need more input or, you know, it basically, you know, was it okay or not.</p>
<p>91<br>00:10:17,000 –&gt; 00:10:27,000<br>And so, you know, this lets us move the, the program counter that we couldn’t do on the first stack into the other stack of the go routine.</p>
<p>92<br>00:10:27,000 –&gt; 00:10:42,000<br>And so using additional go routines is a great way to hold additional code state and give you the ability to do these kinds of clean ups, even if the original structure, the problem makes it look like you can’t.</p>
<p>93<br>00:10:42,000 –&gt; 00:10:43,000<br>Go ahead.</p>
<p>94<br>00:10:43,000 –&gt; 00:10:46,000<br>I’m assuming you’re fine with that. People asking questions.</p>
<p>95<br>00:10:46,000 –&gt; 00:10:48,000<br>Yeah, absolutely. I just wanted to make sure that.</p>
<p>96<br>00:10:48,000 –&gt; 00:10:51,000<br>Yeah, yeah, definitely. Please interrupt.</p>
<p>97<br>00:10:51,000 –&gt; 00:10:57,000<br>And so, so the hint here is to use additional go routines to hold additional code state.</p>
<p>98<br>00:10:57,000 –&gt; 00:11:03,000<br>And there’s, there’s one caveat to this and then it’s not free to just make go routines, right?</p>
<p>99<br>00:11:03,000 –&gt; 00:11:07,000<br>You have to actually make sure that they exit because otherwise you’ll just accumulate them.</p>
<p>100<br>00:11:07,000 –&gt; 00:11:13,000<br>And so you do have to think about, you know, why does the go routine exit like, you know, is it going to get cleaned up?</p>
<p>101<br>00:11:13,000 –&gt; 00:11:22,000<br>And in this case, we know that, you know, q dot parse is going to return, where do you get a pars go?</p>
<p>102<br>00:11:22,000 –&gt; 00:11:25,000<br>Sorry, that’s not right.</p>
<p>103<br>00:11:25,000 –&gt; 00:11:32,000<br>Oh, sorry, the read string here, read string is going to return anytime it sends a message that says need more input.</p>
<p>104<br>00:11:32,000 –&gt; 00:11:33,000<br>Where to go?</p>
<p>105<br>00:11:33,000 –&gt; 00:11:39,000<br>There’s something missing from this slide.</p>
<p>106<br>00:11:39,000 –&gt; 00:11:44,000<br>Sorry, I went through this last night.</p>
<p>107<br>00:11:44,000 –&gt; 00:11:50,000<br>So, so as we go in, we go into a net, we kick off this go routine that’s going to call read care a bunch of times.</p>
<p>108<br>00:11:50,000 –&gt; 00:11:59,000<br>And then we read the status once and that that first status is going to happen because the, the first call to read care from read string is going to send I need more input.</p>
<p>109<br>00:11:59,000 –&gt; 00:12:02,000<br>And then we’re going to send a character back.</p>
<p>110<br>00:12:02,000 –&gt; 00:12:05,000<br>We’re going to send the character back and process care.</p>
<p>111<br>00:12:05,000 –&gt; 00:12:08,000<br>And then every time process car gets called, it returns a status.</p>
<p>112<br>00:12:08,000 –&gt; 00:12:15,000<br>And so up until you get, you know, need more input, you’re going to get the.</p>
<p>113<br>00:12:15,000 –&gt; 00:12:17,000<br>Sorry, this is not working.</p>
<p>114<br>00:12:17,000 –&gt; 00:12:21,000<br>You’re going to get a need more input for every time you want to read a character.</p>
<p>115<br>00:12:21,000 –&gt; 00:12:28,000<br>And then when it’s done reading characters, what I haven’t shown you here, what seems to be missing somehow is when things exit.</p>
<p>116<br>00:12:28,000 –&gt; 00:12:31,000<br>And when things exit, let’s see if it’s on this slide.</p>
<p>117<br>00:12:31,000 –&gt; 00:12:35,000<br>Yeah, so there’s a return success and a return bad input that I’d forgotten about.</p>
<p>118<br>00:12:35,000 –&gt; 00:12:39,000<br>And so, you know, these return a different status and then they’re done.</p>
<p>119<br>00:12:39,000 –&gt; 00:12:49,000<br>So when process care, you know, in the read string version, when it returns, you know, bad input or success, we say that, you know, it’s done.</p>
<p>120<br>00:12:49,000 –&gt; 00:12:54,000<br>So as long as the caller is going through.</p>
<p>121<br>00:12:54,000 –&gt; 00:13:00,000<br>And, you know, calling until it gets something that’s not need more input, then the goal routine will finish.</p>
<p>122<br>00:13:00,000 –&gt; 00:13:08,000<br>But, you know, maybe if we stop early, if the caller like hits an E O F and stops on its own without telling us that it’s done, there’s a goal routine left over.</p>
<p>123<br>00:13:08,000 –&gt; 00:13:10,000<br>And so that could be a problem.</p>
<p>124<br>00:13:10,000 –&gt; 00:13:15,000<br>And so you just, you need to make sure that you know when and why each goal routine will exit.</p>
<p>125<br>00:13:15,000 –&gt; 00:13:21,000<br>And the nice thing is that if you do make a mistake and you leave go routine stuck, they just sit there.</p>
<p>126<br>00:13:21,000 –&gt; 00:13:27,000<br>It’s like the best possible bug in the world because they just sit around waiting for you to look at them and all you have to do is remember to look for them.</p>
<p>127<br>00:13:27,000 –&gt; 00:13:30,000<br>And so, you know, here’s a very simple program.</p>
<p>128<br>00:13:30,000 –&gt; 00:13:33,000<br>It leaves go routines and it runs an HCP server.</p>
<p>129<br>00:13:33,000 –&gt; 00:13:41,000<br>And so, you know, if we run this, it kicks off a whole bunch of F go routines and they all block trying to send to a channel and then it makes the HCP server.</p>
<p>130<br>00:13:41,000 –&gt; 00:13:44,000<br>And so if I run this program, it just sits there.</p>
<p>131<br>00:13:44,000 –&gt; 00:13:51,000<br>And if I type control backslash on a unit system, I get a sig quit, which makes it crash and dump all the stacks of the go routines.</p>
<p>132<br>00:13:51,000 –&gt; 00:13:54,000<br>And you can see on this slide that, you know, it’s going to print over and over again.</p>
<p>133<br>00:13:54,000 –&gt; 00:13:59,000<br>Here’s the go routine and H called from G called from F and in the channel send.</p>
<p>134<br>00:13:59,000 –&gt; 00:14:03,000<br>And if you look at the line numbers, you can see exactly where they are.</p>
<p>135<br>00:14:03,000 –&gt; 00:14:07,000<br>Another option is that since we’re in an HCP server.</p>
<p>136<br>00:14:07,000 –&gt; 00:14:18,000<br>And the HCP server imports the net HCP P-PROF package, you can actually just visit the HCP server is debug P-PROF go routine URL, which gives you the stacks of all the running go routines.</p>
<p>137<br>00:14:18,000 –&gt; 00:14:24,000<br>And unlike the crash dump, it takes a little more effort and it deduplicates the go routines based on their stacks.</p>
<p>138<br>00:14:24,000 –&gt; 00:14:28,000<br>And so, and then it sorts them by how many there are of each stack.</p>
<p>139<br>00:14:28,000 –&gt; 00:14:31,000<br>And so if you have a go routine week, the leak shows up at the very top.</p>
<p>140<br>00:14:31,000 –&gt; 00:14:35,000<br>So in this case, you’ve got 100 go routines stock in age called from G called from F.</p>
<p>141<br>00:14:35,000 –&gt; 00:14:39,000<br>And then we can see there’s like one of a couple other go routines and we don’t really care about them.</p>
<p>142<br>00:14:39,000 –&gt; 00:14:48,000<br>And so, you know, this is a new hint that it’s just it’s really, really useful to look for stuck go routines by just going to this end point.</p>
<p>143<br>00:14:48,000 –&gt; 00:14:51,000<br>All right, so that was kind of the warm up.</p>
<p>144<br>00:14:51,000 –&gt; 00:14:56,000<br>Now I want to look at the first real concurrency pattern, which is a publish subscribe server.</p>
<p>145<br>00:14:57,000 –&gt; 00:15:05,000<br>So, publish subscribe is a way of structuring a program that you decouple the parts that are publishing interesting events from the things that are subscribing to them.</p>
<p>146<br>00:15:05,000 –&gt; 00:15:15,000<br>And there’s a publish subscriber pubs of server in the middle that connects those so that the individual publishers and the individual subscribers don’t have to be aware of exactly who the other ones are.</p>
<p>147<br>00:15:15,000 –&gt; 00:15:25,000<br>So, you know, I’m your Android phone and at might publish a make a phone call event and then the the dialer might subscribe to that and actually start and you know help dial.</p>
<p>148<br>00:15:25,000 –&gt; 00:15:33,000<br>And so in a real pubs of server there are ways to filter events based on like what kind they are so that when you publish a make a phone call event like it doesn’t go to your email program.</p>
<p>149<br>00:15:33,000 –&gt; 00:15:41,000<br>But you know, for now we’re just going to assume that the filtering is taken care of separately and we’re just worried about the actual publish and subscribe.</p>
<p>150<br>00:15:41,000 –&gt; 00:15:43,000<br>And the concurrency of that.</p>
<p>151<br>00:15:43,000 –&gt; 00:15:46,000<br>So, here’s an API we want to implement.</p>
<p>152<br>00:15:46,000 –&gt; 00:15:54,000<br>Any number of clients that can call subscribe with a channel and afterwards events that are published will be sent on that channel.</p>
<p>153<br>00:15:54,000 –&gt; 00:16:02,000<br>And then when a client is no longer interested, it can call cancel and pass in the same channel to say stop sending the events on that channel.</p>
<p>154<br>00:16:02,000 –&gt; 00:16:17,000<br>And the way that cancel will signal that it really is done sending events on that channel is it will close the channel so that the receive the caller can keep receiving events until it sees the channel get closed and then it knows that the cancel is taking effect.</p>
<p>155<br>00:16:18,000 –&gt; 00:16:37,000<br>So notice that the information is only flowing one way on the channel right you can send to the channel and then the receiver can receive from it and the information flows from the sender to the receiver and it never goes the other way so closing is also a signal from the sender to the receiver that all the sending is over.</p>
<p>156<br>00:16:37,000 –&gt; 00:16:44,000<br>And the receiver cannot close the channel to tell the sender like I don’t want you to send anymore because that’s information going the opposite direction.</p>
<p>157<br>00:16:44,000 –&gt; 00:17:05,000<br>And it’s just a lot easier to reason about if the information only goes one way and of course if you need communication in both directions you can use a pair of channels and it often turns out to be the case that those different directions may have different types of data flowing like before we saw that there were ruins going in one direction and status updates going in the other direction.</p>
<p>158<br>00:17:05,000 –&gt; 00:17:33,000<br>So how do we implement this API here’s a pretty basic implementation that you know it could be good enough we have a server and the server state is a map of registered subscriber channels protected by a lock we initialize the server by just allocating the map and then to publish the event we just send it to every registered channel to subscribe a new channel we just add it to the map and to cancel we take it out of the map.</p>
<p>159<br>00:17:33,000 –&gt; 00:17:39,000<br>Because these are all methods that might be called from multiple go routines.</p>
<p>160<br>00:17:39,000 –&gt; 00:17:52,000<br>We need to call lock and unlock around these to protect the map and notice that I wrote defer unlock right after the lock so I don’t have to remember to unlock it later.</p>
<p>161<br>00:17:52,000 –&gt; 00:18:03,000<br>I’ll see this you know it’s sort of a nice idiom to just do the lock unlock and then you know have a blank line and have that be its own kind of paragraph in the code.</p>
<p>162<br>00:18:03,000 –&gt; 00:18:19,000<br>One thing I want to point out is that using defer make sure that the mutex gets unlocked even if you have multiple returns from the function so you can’t forget but it also make sure that it gets unlocked if you have a panic like in subscribing cancel where there’s you know panics for misuse.</p>
<p>163<br>00:18:19,000 –&gt; 00:18:31,000<br>And there is a subtlety here about if you might not want to unlock the mutex if the panic happened while the thing that was locked is in some inconsistent state but I’m going to ignore that for now in general.</p>
<p>164<br>00:18:31,000 –&gt; 00:18:38,000<br>You try to avoid having the things that might panic happen while you’re you know potentially an inconsistent state.</p>
<p>165<br>00:18:39,000 –&gt; 00:18:54,000<br>And I shall also point out that the use of panic at all in subscribing and cancel implies that you really trust your clients not to misuse the interface that it is a program error worth you know tearing down the entire program potentially for that to happen.</p>
<p>166<br>00:18:54,000 –&gt; 00:18:58,000<br>And in a bigger program where other clients were using this API.</p>
<p>167<br>00:18:58,000 –&gt; 00:19:11,000<br>And I probably want to return an error instead and not have the possibility of taking down the whole program but panicking simplifies things for now and you know error handling in general is kind of not the topic today.</p>
<p>168<br>00:19:11,000 –&gt; 00:19:19,000<br>A more important concern with this code than than panics is what happens if a girl teen is slow to receive events.</p>
<p>169<br>00:19:19,000 –&gt; 00:19:26,000<br>So all the operations here are done holding the mutex which means all the clients kind of have to proceed in lockstep.</p>
<p>170<br>00:19:26,000 –&gt; 00:19:42,000<br>So during publish there’s a loop that’s sending on the channels sending the event to every channel and if one subscriber falls behind the next subscriber doesn’t get the event until that slow subscriber wakes up and actually gets the event off of that channel.</p>
<p>171<br>00:19:42,000 –&gt; 00:19:59,000<br>So the most subscriber can slow down everyone else and you know forcing them to proceed in lockstep this way is not always a problem if you’ve you know documented the restriction and for whatever reason you know how the clients are written and you know that they won’t ever fall too far behind this could be totally fine.</p>
<p>172<br>00:19:59,000 –&gt; 00:20:09,000<br>It’s a really simple implementation and and it has nice properties like on return from publish you know that the event has actually been handed off to each of the other girl routines.</p>
<p>173<br>00:20:09,000 –&gt; 00:20:16,000<br>You don’t know that they’ve started processing it but you know it’s been handed off and so you know maybe that’s good enough and you could stop here.</p>
<p>174<br>00:20:16,000 –&gt; 00:20:30,000<br>A second option is that if you need to tolerate just a little bit of slowness on the subscribers then you could say that they need to give you a buffer channel with room for a couple events in the buffer so that you know when you’re publishing.</p>
<p>175<br>00:20:30,000 –&gt; 00:20:45,000<br>You know as long as they’re not too far behind there always be room for the you know new event to go into the channel buffer and then the actual publish won’t walk for too long and again maybe that’s good enough if you’re sure that they won’t ever fall too far behind you get to stop there.</p>
<p>176<br>00:20:45,000 –&gt; 00:20:59,000<br>But in a really big program you do want to cope more gracefully with arbitrarily arbitrarily slow subscribers and so then the question is what do you do and so you know in general you have three options you can slow down the event generator with the number of people who are in the same way.</p>
<p>177<br>00:20:59,000 –&gt; 00:21:15,000<br>So you know what is the event generator which is what the previous solutions implicitly do because publish stops until the subscribers catch up or you can drop events or you can queue an arbitrary number of past events those are pretty much your only options.</p>
<p>178<br>00:21:15,000 –&gt; 00:21:20,000<br>So we talked about you know publish and slowing down the event generator.</p>
<p>179<br>00:21:20,000 –&gt; 00:21:38,000<br>So you know you can’t just go down where you coalesce the events or you drop them so that you know the subscriber might find out that you know hey you missed some events and I can’t tell you what they were because I didn’t save them but I’m at least going to tell you you missed five events and then maybe it can do something else to try to catch up.</p>
<p>180<br>00:21:38,000 –&gt; 00:22:00,000<br>So this is the kind of approach that that we take in the profiler so in the profiler if you’ve used it if there’s a go routine that fills the profile on a signal handler actually with profiling events and then there’s a separate go routine whose job is to read the data back out and like write it to disk or send it to a HTTP request or whatever it is you’re doing the profile data.</p>
<p>181<br>00:22:00,000 –&gt; 00:22:16,000<br>So the buffer in the middle and if the receiver from the profile data falls behind when the buffer fills up we start adding entries to a final profile entry that just has a single entry that’s a function called runtime dot lost profile data.</p>
<p>182<br>00:22:16,000 –&gt; 00:22:26,000<br>If you go look at the profile you see like hey the program spent five percent of its time and lost profile data that just means you know the the profile reader was too slow and it didn’t catch up.</p>
<p>183<br>00:22:26,000 –&gt; 00:22:40,000<br>And we lost some of the profile but we’re clear about exactly you know what the error rate is in the profile and you pretty much never see that because all the readers actually do keep up but just in case they didn’t you have a pretty clear signal.</p>
<p>184<br>00:22:40,000 –&gt; 00:22:54,000<br>An example of purely dropping the events is the OS signal package where you have to pass in a channel that will be ready to receive the signal signal like sighop or sig quit.</p>
<p>185<br>00:22:54,000 –&gt; 00:23:05,000<br>And when the signal comes in the runtime tries to send to each of the channels that subscribe to that signal and if it can’t send to it it just doesn’t it’s just gone because you know we’re in a signal handler we can’t wait.</p>
<p>186<br>00:23:05,000 –&gt; 00:23:32,000<br>And so what the callers have to do is they have to pass in a buffer channel and if they pass in a buffer channel that has you know length at least one buffer length at least one and they only register that channel to a single signal then you know that if a signal comes in you’re definitely going to get told about it if it comes in twice you might only get told about it once but that’s actually the same semantics that Unix gives to processes for signals anyway so that’s fine.</p>
<p>187<br>00:23:32,000 –&gt; 00:23:36,000<br>So those are both examples of dropping or coalescing events.</p>
<p>188<br>00:23:36,000 –&gt; 00:23:58,000<br>And then the third choice is that you might actually just really not want to lose any events it might just be really important that you never lose anything in which case you know you can queue an arbitrary number of events you can somehow arrange for the program to just save all the events that the slow subscriber hasn’t seen yet somewhere and give them to the subscriber later.</p>
<p>189<br>00:23:58,000 –&gt; 00:24:19,000<br>And it’s really important to think carefully before you do that because an distributed system you know there’s always slow computers always computers that we have fallen off line or whatever and they might be gone for a while and so you don’t want to introduce unbounded queuing in general you want to think very carefully before you do that and think well you know how unbounded is it really and can I tolerate that.</p>
<p>190<br>00:24:19,000 –&gt; 00:24:29,000<br>And so like that’s a reason why channels don’t have just an unbounded buffering it’s really almost never the right choice and if it is the right choice you probably want to build it very carefully.</p>
<p>191<br>00:24:31,000 –&gt; 00:24:34,000<br>And so but we’re going to build one just to see what it would look like.</p>
<p>192<br>00:24:35,000 –&gt; 00:24:48,000<br>And before we do that I just want to adjust the program a little bit so we have this mutex in the code and the mutex is an example of keeping the state whether you’re locked or not in a state variable.</p>
<p>193<br>00:24:49,000 –&gt; 00:24:55,000<br>But we can also move that into a program counter variable by putting it in a different go routine and so.</p>
<p>194<br>00:24:56,000 –&gt; 00:25:07,000<br>In this case we can start a new go routine that runs a program function called s dot loop and it handles requests sent on three new channels published subscribe and cancel.</p>
<p>195<br>00:25:08,000 –&gt; 00:25:18,000<br>And so in a knit we make the channels and then we kick off s dot loop and s dot loop is sort of the amalgamation of the previous method bodies and it just received.</p>
<p>196<br>00:25:19,000 –&gt; 00:25:35,000<br>From any of the three channels a request a publish of subscriber cancel request and it does whatever was asked and now that map the subscriber map can be just a local variable in s dot loop and and so you know it’s the same code.</p>
<p>197<br>00:25:36,000 –&gt; 00:25:42,000<br>But now that data is clearly owned by s dot loop nothing else could even get to it because it’s a local variable.</p>
<p>198<br>00:25:42,000 –&gt; 00:26:09,000<br>And then we just need to change the original methods to send the work over to the loop go routine so uppercase publish now sends on lowercase publish the channel the event that it wants to publish and similarly subscribe and cancel they create a request that has a channel that we want to subscribe and also a channel to get the answer back and they send that into the loop and then the loop sends back the answer.</p>
<p>199<br>00:26:12,000 –&gt; 00:26:24,000<br>And so I referred to transforming the program this way is like converting the mutex into a go routine because we took the data state of the mutex there’s like a lock bit inside it and now that lock bit is implicit in the program counter of the loop.</p>
<p>200<br>00:26:26,000 –&gt; 00:26:35,000<br>It’s very clear that you can’t ever have you know a publish and subscribe happening at the same time because it’s just single threaded code and just you know executes and sequence.</p>
<p>201<br>00:26:36,000 –&gt; 00:26:52,000<br>On the other hand the original version had a kind of like clarity of state where you could sort of inspect it and and reason about well this is the important state and it’s harder in the the go routine version to see like what’s important state and what’s kind of incidental state from just having a go routine.</p>
<p>202<br>00:26:53,000 –&gt; 00:27:18,000<br>And in a given situation you know one might be more important than the other so a couple years ago I did all the labs for the class when it first switched to go and and raft is a good example of where you probably prefer the state with the mutex is because raft is is so different from most concurrent programs and that like each replica is just kind of profoundly uncertain of its state right like the state transitions.</p>
<p>203<br>00:27:19,000 –&gt; 00:27:40,000<br>You know one moment you think you’re the leader and the next moment you’ve been deposed like one moment your log has 10 entries and next moment you find actually know it only has two entries and so being able to manipulate that state directly rather than having to you know somehow get it in an out of the program counter makes a lot more sense for raft but that’s pretty unique in most situations it cleans things up to the state in the program counter.</p>
<p>204<br>00:27:40,000 –&gt; 00:28:09,000<br>All right so in order to deal with the slow subscribers now we’re going to add some helper go routines and their job is to manage a particular subscribers backlog and keep the overall program from blocking and so this is the helper go routine and the main loop go routine will send the events to the helper which we then trust because we wrote it not to fall arbitrarily behind and then the helpers job is to this few events if needed and send them off to the subscriber.</p>
<p>205<br>00:28:11,000 –&gt; 00:28:28,000<br>All right so this actually has two problems the first is that if there’s nothing in the queue then the select is actually wrong to try to offer queue of zero and in fact just evaluating queue of zero at the start of the select panic because the queue is empty and so we can fix these.</p>
<p>206<br>00:28:28,000 –&gt; 00:28:39,000<br>By setting up the arguments separately from the select and in particular we need to make a channel send out that’s going to be nil which is never able to proceed in a select.</p>
<p>207<br>00:28:40,000 –&gt; 00:28:53,000<br>As we nil when we don’t want to send and it’s going to be the actual out channel when we do want to send and then we have to have a separate variable that holds the event that we’re going to send you will only you know actually read from queue of zero if there’s something in the queue.</p>
<p>208<br>00:28:54,000 –&gt; 00:29:05,000<br>The second thing that’s wrong is that we need to handle closing of the channel of the input channel because when the input channel closes we need to flush the rest of the queue and then we need to close the output channel.</p>
<p>209<br>00:29:06,000 –&gt; 00:29:19,000<br>So to check for that we change the select from just doing e equals receive from in to e comma OK equals receive from in in the comma OK will be told whether or not the channel is actually sending real data or else it’s closed.</p>
<p>210<br>00:29:19,000 –&gt; 00:29:27,000<br>And so when OK is false we can set into nil to say let’s stop trying to receive from in there’s nothing there we’re just going to keep getting told that it’s closed.</p>
<p>211<br>00:29:28,000 –&gt; 00:29:48,000<br>And then when the loop is fine when the queue is finally empty we can exit the loop and so we changed the four condition to say when we want to keep asking you to loop as long as there actually still is an input channel and there’s something to write back to the output channel and then once both of those are not true anymore it’s time to close it’s time to exit the loop and we close the output channel.</p>
<p>212<br>00:29:49,000 –&gt; 00:29:55,000<br>And we’re done and so now we’ve correctly propagated the closing of the input channel to the output channel.</p>
<p>213<br>00:29:56,000 –&gt; 00:30:00,000<br>So that was the helper and the server loop used to look like this.</p>
<p>214<br>00:30:01,000 –&gt; 00:30:09,000<br>And to update it we just changed the subscription map before it was a map from subscribe channels to bulls it was just basically a set.</p>
<p>215<br>00:30:09,000 –&gt; 00:30:24,000<br>And now it’s a map from subscribe channel to helper channel and every time we get a new subscription we make a helper channel we kick off a helper go routine and we record the helper channel in the subscription map instead of the actual channel.</p>
<p>216<br>00:30:25,000 –&gt; 00:30:31,000<br>And then the rest of the the loop actually barely changes at all.</p>
<p>217<br>00:30:31,000 –&gt; 00:31:00,000<br>So I do want to point out that like if you wanted to have a different strategy for you know what you do with clients that fall too far behind that can all go in the helper go routine the code on the screen right now is completely unchanged so we’ve completely separated the published subscribe maintaining the actual list of subscribers map from the what you do when things get too slow map or problem and so it’s really nice that you’ve got this clean separation of concerns into completely different ways of doing it.</p>
<p>218<br>00:31:01,000 –&gt; 00:31:07,000<br>So that’s a general hint is that you can use go routines a lot of the time to separate independent concerns.</p>
<p>219<br>00:31:09,000 –&gt; 00:31:10,000<br>All right.</p>
<p>220<br>00:31:12,000 –&gt; 00:31:15,000<br>So the second pattern for today is a work scheduler.</p>
<p>221<br>00:31:16,000 –&gt; 00:31:19,000<br>And you did one of these in lab one from app reviews and I’m just kind of you know build up to that.</p>
<p>222<br>00:31:19,000 –&gt; 00:31:27,000<br>And this doesn’t do all the RPC stuff it just kind of assumes that there’s kind of channel channel based interfaces to all the servers.</p>
<p>223<br>00:31:28,000 –&gt; 00:31:43,000<br>So you know we have this function scheduled it takes a fixed list of servers has a number of tasks to run and it has just this abstracted function call that you you call to run the task on a specific server and you can imagine it was doing the RPCs underneath.</p>
<p>224<br>00:31:43,000 –&gt; 00:31:48,000<br>So we’re going to need some way to keep track of which servers are available to execute tasks.</p>
<p>225<br>00:31:49,000 –&gt; 00:31:57,000<br>And so one option is to use our own stack or queue implementation but another option is to use a channel because it’s a good synchronized queue.</p>
<p>226<br>00:31:58,000 –&gt; 00:32:04,000<br>And so we can send into the channel to add to the queue and receive from it to pop something off.</p>
<p>227<br>00:32:04,000 –&gt; 00:32:12,000<br>And in this case we’ll make the queue be a queue of servers and we’ll start off it’s a queue of idle servers servers that aren’t doing any work for us right now.</p>
<p>228<br>00:32:13,000 –&gt; 00:32:17,000<br>And we’ll start off by just initializing it by sending all the known servers into the idle list.</p>
<p>229<br>00:32:19,000 –&gt; 00:32:28,000<br>And then we can loop over the tasks and for every task we kick off a go routine and its job is to pull a server off the idle list run the task and then put the server back on.</p>
<p>230<br>00:32:28,000 –&gt; 00:32:41,000<br>And this loop body is another example of the earlier to use go routines like independent things run independently because each task is running as a separate concern they’re all running in parallel.</p>
<p>231<br>00:32:42,000 –&gt; 00:32:45,000<br>Unfortunately, there are two problems with this program.</p>
<p>232<br>00:32:46,000 –&gt; 00:32:51,000<br>The first one is that the closure that’s running as a new go routine refers to the loop iteration variable which is task.</p>
<p>233<br>00:32:51,000 –&gt; 00:32:58,000<br>And so by the time the go routine starts exiting, you know, the loop has probably continued and done a task plus plus and so it’s actually getting the wrong value of task.</p>
<p>234<br>00:32:59,000 –&gt; 00:33:01,000<br>You’ve probably seen this by now.</p>
<p>235<br>00:33:02,000 –&gt; 00:33:05,000<br>And of course, the best way to catch this is to run the race detector.</p>
<p>236<br>00:33:06,000 –&gt; 00:33:17,000<br>And at Google we even encourage teams to set up the canary servers that run the race detector and split off something like 0.1% of their traffic to it just to catch races that might be in the production system.</p>
<p>237<br>00:33:17,000 –&gt; 00:33:23,000<br>And you know finding a bug with the race detector is way better than having to debug some corruption later.</p>
<p>238<br>00:33:24,000 –&gt; 00:33:26,000<br>So there are two ways to fix this race.</p>
<p>239<br>00:33:27,000 –&gt; 00:33:30,000<br>The first way is to give the closure an explicit parameter and pass it in.</p>
<p>240<br>00:33:31,000 –&gt; 00:33:44,000<br>And the go statement requires a function call specifically for this reason so that you can set specific arguments that get evaluated in the context of the original go routine and then get copied to the new go routine.</p>
<p>241<br>00:33:44,000 –&gt; 00:33:49,000<br>And so in this case, we can declare a new argument task two, we can pass task to it.</p>
<p>242<br>00:33:50,000 –&gt; 00:33:54,000<br>And then inside the go routine task two is a completely different copy of task.</p>
<p>243<br>00:33:55,000 –&gt; 00:33:58,000<br>And I only named it task two to make it easier to talk about.</p>
<p>244<br>00:33:59,000 –&gt; 00:34:06,000<br>But of course, there’s a bug here and the bug is that I forgot to update task inside the function to refer to task two instead of task.</p>
<p>245<br>00:34:06,000 –&gt; 00:34:19,000<br>And so we basically never do that. What we do instead is we just give it the same name so that it’s impossible now for the code inside the go routine to refer to the wrong copy of task.</p>
<p>246<br>00:34:20,000 –&gt; 00:34:27,000<br>That was the first way to fix the race. There’s a second way, which is sort of cryptic the first time you see it, but it amounts to the same thing.</p>
<p>247<br>00:34:28,000 –&gt; 00:34:31,000<br>And that is that you just make a copy of the variable inside the loop body.</p>
<p>248<br>00:34:31,000 –&gt; 00:34:36,000<br>So every time colon equals happens, that creates a new variable.</p>
<p>249<br>00:34:37,000 –&gt; 00:34:44,000<br>So in the for loop in the outer for loop, there’s a colon equals at the beginning and there’s not one the rest of the loop. So that’s all just one variable for the entire loop.</p>
<p>250<br>00:34:45,000 –&gt; 00:34:50,000<br>Whereas if we put a colon equals inside the body, every time we run an iteration of the loop, that’s a different variable.</p>
<p>251<br>00:34:51,000 –&gt; 00:34:56,000<br>So if the go if the go function closure captures that variable, those will all be distinct.</p>
<p>252<br>00:34:56,000 –&gt; 00:35:04,000<br>So we can do the same thing we do task two and this time I remember to update the body, but you know, just like before it’s too easy to forget to update the body.</p>
<p>253<br>00:35:05,000 –&gt; 00:35:10,000<br>And so typically you write task colon equals task, which looks kind of magical the first time you see it, but but that’s what it’s for.</p>
<p>254<br>00:35:11,000 –&gt; 00:35:16,000<br>All right, so I said there were two bugs in the program. The first one was this race on task.</p>
<p>255<br>00:35:17,000 –&gt; 00:35:24,000<br>And the second one is that we didn’t actually do anything after we skipped off all the tasks. We’re not waiting for them to be done.</p>
<p>256<br>00:35:25,000 –&gt; 00:35:37,000<br>And in particular, we’re kicking them off way too fast because you know, if there’s like a million tasks, you’re going to kick off a million guard teams and they’re all just going to sit waiting for one of the five servers, which is kind of inefficient.</p>
<p>257<br>00:35:37,000 –&gt; 00:35:45,000<br>And so what we can do is we can pull the fetching of the the next idle server up out of the go or team.</p>
<p>258<br>00:35:46,000 –&gt; 00:35:52,000<br>And we pull it up out of the go or team now will only kick off a go or team when there is a next server to use.</p>
<p>259<br>00:35:53,000 –&gt; 00:36:05,000<br>And then we can kick it off and and you know, use that server and put it back and the using the server and put it back runs concurrently, but doing the fetch of the idle server inside the loop slows things down so that you can get the server.</p>
<p>260<br>00:36:05,000 –&gt; 00:36:13,000<br>And then the server inside the loop slows things down so that there’s only ever now number of servers go or teams running instead of number of tasks.</p>
<p>261<br>00:36:14,000 –&gt; 00:36:19,000<br>And that receive is essentially creating some back pressure to slow down the loop so it doesn’t get too far ahead.</p>
<p>262<br>00:36:20,000 –&gt; 00:36:23,000<br>And then I mentioned we have to wait for the task to finish.</p>
<p>263<br>00:36:23,000 –&gt; 00:36:33,000<br>And so we can do that by just at the end of the loop going over the list again and pulling all the servers out when we’ve pulled, you know, the right number of servers out of the idle list, that means they’re all done.</p>
<p>264<br>00:36:33,000 –&gt; 00:36:36,000<br>So that’s the full program.</p>
<p>265<br>00:36:37,000 –&gt; 00:36:47,000<br>Now to me, the most important part of this is that you still get to write a for loop to iterate over the tasks. There’s lots of other languages where you have to do this with state machines or some sort of callbacks.</p>
<p>266<br>00:36:48,000 –&gt; 00:36:51,000<br>And you don’t get the luxury of encoding this in the control flow.</p>
<p>267<br>00:36:51,000 –&gt; 00:36:56,000<br>And so this is a much cleaner way where you can just use a regular loop.</p>
<p>268<br>00:36:56,000 –&gt; 00:36:59,000<br>And then we have to do some changes we can make some improvements.</p>
<p>269<br>00:36:59,000 –&gt; 00:37:06,000<br>And so one improvement is to notice that there’s only one go or team that makes requests of a server at a particular time.</p>
<p>270<br>00:37:06,000 –&gt; 00:37:15,000<br>So instead of having one go or team for task, maybe we should have one go or team per server because there are probably going to be fewer servers than tasks.</p>
<p>271<br>00:37:15,000 –&gt; 00:37:22,000<br>And to do that, we have to change from having a channel of idle servers to a channel of, you know, yet to be done tasks.</p>
<p>272<br>00:37:22,000 –&gt; 00:37:25,000<br>So we have to do an idle channel to work.</p>
<p>273<br>00:37:25,000 –&gt; 00:37:33,000<br>And then we also need a done channel to count, you know, how many tasks are done so that we know when we’re completely finished.</p>
<p>274<br>00:37:33,000 –&gt; 00:37:38,000<br>And so here, there’s a new function run tasks and that’s going to be the per server function.</p>
<p>275<br>00:37:38,000 –&gt; 00:37:49,000<br>And we kick off one of them for each server and run tasks as job is just to loop over the work channel, run the tasks. And when the server is done, we send true to done.</p>
<p>276<br>00:37:49,000 –&gt; 00:37:52,000<br>But, you know, the server tells us that, you know, it’s done.</p>
<p>277<br>00:37:52,000 –&gt; 00:37:58,000<br>And the server exits when the work channel gets closed. That’s what makes that for loop actually stop.</p>
<p>278<br>00:37:58,000 –&gt; 00:38:06,000<br>So then, you know, having kicked off the servers, we can then just sit there in a loop and send each task to the work channel.</p>
<p>279<br>00:38:06,000 –&gt; 00:38:11,000<br>Close the work channel and say, hey, there’s no more work coming. All the servers, you should finish and then, and then exit.</p>
<p>280<br>00:38:11,000 –&gt; 00:38:15,000<br>And then wait for all the servers to tell us that they’re done.</p>
<p>281<br>00:38:15,000 –&gt; 00:38:21,000<br>So in the lab, there were a couple of complications. One was that, you know, you might get new servers at any given time.</p>
<p>282<br>00:38:21,000 –&gt; 00:38:27,000<br>And so we could change that by saying the servers come in on a channel of strings.</p>
<p>283<br>00:38:27,000 –&gt; 00:38:36,000<br>And that actually fits pretty well into the current structure where, you know, when you get a new server, you just kick off a new run tasks go routine.</p>
<p>284<br>00:38:36,000 –&gt; 00:38:47,000<br>And so the only thing we have to change here is to put that loop into its own go routine so that while we’re sending tasks to servers, we can still accept new servers and kick off the helper go routines.</p>
<p>285<br>00:38:47,000 –&gt; 00:38:54,000<br>But now we have this problem that we don’t really have a good way to tell when all the servers are done because we don’t know how many servers there are.</p>
<p>286<br>00:38:54,000 –&gt; 00:39:00,000<br>And so we could try to like maintain that number as servers come in, but it’s a little tricky.</p>
<p>287<br>00:39:00,000 –&gt; 00:39:11,000<br>And so instead we can count the number of tasks that have finished. So we just move the done sending true to done up a line so that instead of doing it per server, we now do it per task.</p>
<p>288<br>00:39:11,000 –&gt; 00:39:17,000<br>And then the end of the loop or at the end of the function, we just have to wait for the right number of tasks to be done.</p>
<p>289<br>00:39:17,000 –&gt; 00:39:23,000<br>And so, so now again, we sort of know why these are going to finish.</p>
<p>290<br>00:39:23,000 –&gt; 00:39:37,000<br>And so, we have a lot of tasks still. And that is that if the number of tasks is is too big, actually, I think always, you’ll get a deadlock. And if you run this, you know, you get this nice thing where the door, it tells you like, hey, your go routines are stuck.</p>
<p>291<br>00:39:37,000 –&gt; 00:39:42,000<br>And the problem is that, you know, we have this run task server loop.</p>
<p>292<br>00:39:42,000 –&gt; 00:39:50,000<br>And the server loop is trying to say, hey, I’m done. And you’re trying to say, hey, like, here’s some more work. So if you have more than one task, you’ll run into this deadlock.</p>
<p>293<br>00:39:50,000 –&gt; 00:40:02,000<br>You’re trying to send the next task to a server. I guess it’s a few more tasks than servers. You’re trying to send the next task to a server and all the servers are trying to say, hey, I’m done with the previous task. But you’re not there to receive from the done channel.</p>
<p>294<br>00:40:02,000 –&gt; 00:40:10,000<br>And so again, you know, it’s really nice that the the go routines just hang around and wait for you to look at them. And we can fix this.</p>
<p>295<br>00:40:10,000 –&gt; 00:40:21,000<br>One way to fix this would be to add a separate loop that actually does a select that either sends some work or accounts for some of the work being done. That’s fine.</p>
<p>296<br>00:40:21,000 –&gt; 00:40:39,000<br>But a clear way to do this is to take the the work sending loop, the tasks sending loop and put it in its own go routine. So now it’s running independently of the counting loop and the counting loop can run and, you know, unblock servers that are done with certain tasks while other tasks are still being sent.</p>
<p>297<br>00:40:40,000 –&gt; 00:40:48,000<br>But the simplest possible fix for this is to just make the work channel big enough that you’re never going to run out of space.</p>
<p>298<br>00:40:48,000 –&gt; 00:41:00,000<br>Because we might decide that, you know, having a go routine for task is, you know, a couple kilobytes for task. But, you know, an extra into the channel is eight bytes. So probably you can spend eight bytes per task.</p>
<p>299<br>00:41:01,000 –&gt; 00:41:11,000<br>And so if you can, you just make the work channel big enough that you know that all the sends on work are going to never block and you’ll always get down to the counting loop at the end pretty quickly.</p>
<p>300<br>00:41:12,000 –&gt; 00:41:23,000<br>And so doing that actually sets us up pretty well for the other wrinkle in the lab, which is that sometimes calls can time out and here I’ve modeled it by the call returning a false, I just say it didn’t work.</p>
<p>301<br>00:41:24,000 –&gt; 00:41:45,000<br>And so, you know, in run task is really easy to say like if it’s really easy to say like if the call fails, then, or sorry, if the call succeeds, then you’re done. But if it fails, just put the task back on the work list. And because it’s a queue, not a stack, putting it back on the work list is very likely to hand it to some other server.</p>
<p>302<br>00:41:46,000 –&gt; 00:41:58,000<br>And so that will, you know, probably succeed because it’s some other server and this is all kind of hypothetical, but it’s a really, you know, it fits really well into the structure that we’ve created.</p>
<p>303<br>00:41:59,000 –&gt; 00:42:08,000<br>All right, and the final change is that because the server guratees are sending on work, we do have to wait to close it until we know that they’re done sending.</p>
<p>304<br>00:42:09,000 –&gt; 00:42:13,000<br>And because again, you can’t close before they finish sending.</p>
<p>305<br>00:42:14,000 –&gt; 00:42:18,000<br>And so we just have to move the close until after we’ve counted that all the tasks are done.</p>
<p>306<br>00:42:19,000 –&gt; 00:42:29,000<br>And you know, sometimes we get to this point and people ask like, why can’t you just kill guratees? Like why not just be able to say, look, hey, kill all the server guratees at this point, we know that they’re not needed anymore.</p>
<p>307<br>00:42:30,000 –&gt; 00:42:44,000<br>And the answer is that, you know, the gurateen has state and it’s interacting with the rest of the program. And if you don’t have a sudden just stops, it’s sort of like it hung right and maybe it was holding a lock, maybe it was in the middle of some sort of communication with some other gurateen that was kind of expecting an answer.</p>
<p>308<br>00:42:45,000 –&gt; 00:42:54,000<br>So we need to find some way to tear them down more gracefully and that’s by telling them explicitly, hey, you know, you’re done, you can go away and then they can clean up, however, they need to clean up.</p>
<p>309<br>00:42:55,000 –&gt; 00:43:16,000<br>You know, speaking of cleaning up, there’s actually one more thing we have to do, which is to shut down the loop that’s watching for new servers. And so we do have to put a select in here where, you know, the thing that’s waiting for new servers on the server channel, we have to tell it, okay, we’re done, just like stop watching for new servers because all the servers are gone.</p>
<p>310<br>00:43:18,000 –&gt; 00:43:21,000<br>And we could make this the colors problem, but this is actually fairly easy to do.</p>
<p>311<br>00:43:25,000 –&gt; 00:43:30,000<br>So here’s pattern number three, which is a client for a replicated server service.</p>
<p>312<br>00:43:32,000 –&gt; 00:43:38,000<br>So here’s the interface that we want to implement. We have some service that we want that is replicated for reliability.</p>
<p>313<br>00:43:39,000 –&gt; 00:43:53,000<br>And it’s okay for a client to talk to any one of these servers. And so the replicated client is given a list of servers, the arguments to init is a list of servers and a function that lets you call one of the servers.</p>
<p>314<br>00:43:54,000 –&gt; 00:43:57,000<br>And then it’s with a particular argument set and get a reply.</p>
<p>315<br>00:43:59,000 –&gt; 00:44:09,000<br>And then being given that during init, the replicated client then provides a call method that doesn’t tell you what server it’s going to use, it just finds a good server to use.</p>
<p>316<br>00:44:10,000 –&gt; 00:44:15,000<br>And it keeps the same keeps using the same server for as long as it can until it finds out that that server is no good.</p>
<p>317<br>00:44:16,000 –&gt; 00:44:19,000<br>So in this situation, there’s almost no shared state that you need to isolate.</p>
<p>318<br>00:44:19,000 –&gt; 00:44:25,000<br>And so like the only state that persists from one call to the next is what server did I use last time because I’m going to try to use that again.</p>
<p>319<br>00:44:26,000 –&gt; 00:44:33,000<br>So in this case, that’s totally fine for mutex. I’m just going to leave it there. It’s always okay to use mutex if that’s the cleanest way to write the code.</p>
<p>320<br>00:44:34,000 –&gt; 00:44:39,000<br>You know, some people get the wrong impression from how much we talk about channels, but it’s always okay to use a mutex if that’s all you need.</p>
<p>321<br>00:44:40,000 –&gt; 00:44:49,000<br>So now we need to implement this replicated call method whose job is to try sending to lots of different servers, right, but first to try the original server.</p>
<p>322<br>00:44:50,000 –&gt; 00:44:59,000<br>So what does it mean if you know the try fails? Well, there’s like no clear way for it to fail above. It just always returns a reply.</p>
<p>323<br>00:45:00,000 –&gt; 00:45:05,000<br>And so the only way it can fail is if it’s taking too long. So we’ll assume that if it takes too long, that means it failed.</p>
<p>324<br>00:45:06,000 –&gt; 00:45:13,000<br>So in order to deal with timeouts, we have to run that code in the background and a different go achieve. So we can do something like this.</p>
<p>325<br>00:45:15,000 –&gt; 00:45:31,000<br>Where we set a timeout, we create a timer, and then we use a go to send in the background. And then at the end, we wait and either we get the timeout or we get the actual reply. If we get the actual reply, we return it. And we get the timeout, we have to do something. We’ll have to figure out what to do.</p>
<p>326<br>00:45:32,000 –&gt; 00:45:41,000<br>It’s worth pointing out that you have to call t dot stop because otherwise the timer sits in a timer queue that you know it’s going to go off in one second.</p>
<p>327<br>00:45:42,000 –&gt; 00:45:53,000<br>And so you know if this call took a millisecond and you have this timer that’s going to sit there for the next second, and then you do this on a loop, you get a thousand timers sitting in that that that queue before they start actually, you know, disappearing.</p>
<p>328<br>00:45:54,000 –&gt; 00:45:59,000<br>And so this is kind of a war in the API, but it’s been there forever and we’ve never fixed it.</p>
<p>329<br>00:46:00,000 –&gt; 00:46:02,000<br>And so you just have to remember to call stop.</p>
<p>330<br>00:46:04,000 –&gt; 00:46:07,000<br>And then you know, now we have to figure out what do we do in the case of the timeout.</p>
<p>331<br>00:46:08,000 –&gt; 00:46:18,000<br>And so in the case of the timeout, we’re going to need to try a different server. So we’ll write a loop and we’ll start at the ID that ID zero, it says.</p>
<p>332<br>00:46:19,000 –&gt; 00:46:26,000<br>And you know, if your apply comes in, that’s great. And otherwise we’ll reset the timeout and go around the loop again and try sending to a different server.</p>
<p>333<br>00:46:27,000 –&gt; 00:46:35,000<br>And notice there’s only one done channel in this program. And so you know on the third iteration of the loop, we might be waiting.</p>
<p>334<br>00:46:36,000 –&gt; 00:46:40,000<br>And then finally the first server gives us a reply. That’s totally fine. We’ll take that reply. That’s great.</p>
<p>335<br>00:46:42,000 –&gt; 00:46:44,000<br>And so then we’ll stop and return it.</p>
<p>336<br>00:46:45,000 –&gt; 00:46:53,000<br>And but if we get all the way through the loop, it means that we sent the request to every single server. In which case, there’s no more timeouts. We just have to wait for one of them to come back.</p>
<p>337<br>00:46:53,000 –&gt; 00:46:56,000<br>And so that’s the plane receive and the return at the end.</p>
<p>338<br>00:46:58,000 –&gt; 00:47:08,000<br>And then it’s important to notice that the done channel is buffered now. So that if you know you’ve sent the result to three different servers, you’re going to take the first reply and return.</p>
<p>339<br>00:47:09,000 –&gt; 00:47:11,000<br>But the others are going to want to send responses to.</p>
<p>340<br>00:47:12,000 –&gt; 00:47:21,000<br>And we don’t want those go routines to just sit around forever trying to send to a channel that we’re not reading from. So we make the buffer big enough that they can send into the buffer and then go away. And then the channel just gets garbage collected.</p>
<p>341<br>00:47:24,000 –&gt; 00:47:26,000<br>We both question in the chat. Yeah. Yeah.</p>
<p>342<br>00:47:26,000 –&gt; 00:47:28,000<br>Sorry. I can’t give you the chat. Go ahead.</p>
<p>343<br>00:47:28,000 –&gt; 00:47:37,000<br>That says like, why can’t the timer just be garbage collected when nobody’s referencing it instead of having to wait when it goes off when you said that you have multiple waiting if it goes off in one one.</p>
<p>344<br>00:47:37,000 –&gt; 00:47:43,000<br>Yeah. The problem is the timer is referenced by the runtime. It’s in the list of active timers.</p>
<p>345<br>00:47:44,000 –&gt; 00:47:47,000<br>And so calling stop takes it out of the list of active timers.</p>
<p>346<br>00:47:47,000 –&gt; 00:47:56,000<br>And so like that’s arguably kind of a wart in that like in the specific case of a timer that’s like only going to ever get used in this channel way.</p>
<p>347<br>00:47:56,000 –&gt; 00:48:02,000<br>Like we could have special case that by like having the channel because inside the timer is this T.C. channel. Right.</p>
<p>348<br>00:48:02,000 –&gt; 00:48:08,000<br>So we could have had like a different kind of channel implementation that inside had a bit that’s an hey, I’m a timer channel right.</p>
<p>349<br>00:48:08,000 –&gt; 00:48:12,000<br>And and and then like the select on it would like know to just wait.</p>
<p>350<br>00:48:12,000 –&gt; 00:48:15,000<br>But if you just let go of it, it would just disappear.</p>
<p>351<br>00:48:15,000 –&gt; 00:48:21,000<br>We’ve kind of like thought about doing that for a while, but we never did. And so this is like the state of the world.</p>
<p>352<br>00:48:21,000 –&gt; 00:48:24,000<br>But but you know the garbage collector can’t distinguish between.</p>
<p>353<br>00:48:24,000 –&gt; 00:48:30,000<br>And so you know the reference inside the runtime and the reference and the rest of the program. It’s all just references.</p>
<p>354<br>00:48:30,000 –&gt; 00:48:38,000<br>And so until we like special case that channel in some way like we can’t actually get rid of that.</p>
<p>355<br>00:48:38,000 –&gt; 00:48:39,000<br>Thank you.</p>
<p>356<br>00:48:39,000 –&gt; 00:48:40,000<br>Sure.</p>
<p>357<br>00:48:40,000 –&gt; 00:48:48,000<br>So so then the only thing we have left is to have this preference where we try to use the same ID that we did the previous time.</p>
<p>358<br>00:48:48,000 –&gt; 00:48:51,000<br>And then we do that preference.</p>
<p>359<br>00:48:51,000 –&gt; 00:48:56,000<br>We had to serve ID coming back in the reply anyway in the result channel.</p>
<p>360<br>00:48:56,000 –&gt; 00:49:04,000<br>And so you know we do the same sort of loop, but we loop over an offset from the actual ID we’re going to use, which is the the preferred one.</p>
<p>361<br>00:49:04,000 –&gt; 00:49:10,000<br>And then when we get an answer, we set the preferred one to where we got the answer from and then we reply.</p>
<p>362<br>00:49:10,000 –&gt; 00:49:15,000<br>And you’ll notice that I used a go to statement that’s okay if you need to go to it’s fine.</p>
<p>363<br>00:49:15,000 –&gt; 00:49:18,000<br>So that’s what I’m going to do.</p>
<p>364<br>00:49:18,000 –&gt; 00:49:21,000<br>So I’m going to do that sort of there’s no zealotry here.</p>
<p>365<br>00:49:21,000 –&gt; 00:49:23,000<br>All right.</p>
<p>366<br>00:49:23,000 –&gt; 00:49:25,000<br>So the fourth one.</p>
<p>367<br>00:49:25,000 –&gt; 00:49:27,000<br>And then we’ll do some questions.</p>
<p>368<br>00:49:27,000 –&gt; 00:49:29,000<br>Is a protocol multiplexer.</p>
<p>369<br>00:49:29,000 –&gt; 00:49:32,000<br>And this is kind of the logic of a core of any RPC system.</p>
<p>370<br>00:49:32,000 –&gt; 00:49:33,000<br>And this comes up a lot.</p>
<p>371<br>00:49:33,000 –&gt; 00:49:37,000<br>I feel like I wrote a lot of these in grad school and sort of years after that.</p>
<p>372<br>00:49:37,000 –&gt; 00:49:44,000<br>And so the basic API of a protocol multiplexer is that it sits in front some service, which we’re going to pass to the init method.</p>
<p>373<br>00:49:44,000 –&gt; 00:49:51,000<br>And having been initialized with a service, you can call and you can call call and give it a message or request message.</p>
<p>374<br>00:49:51,000 –&gt; 00:49:54,000<br>And then it’ll give you back the reply message at some point.</p>
<p>375<br>00:49:54,000 –&gt; 00:50:03,000<br>And the things it needs from the service to do multiplexing is that given a message, it has to be able to pull out the tag that uniquely identifies the message.</p>
<p>376<br>00:50:03,000 –&gt; 00:50:07,000<br>And will identify the reply because it will come back in with a mask matching tag.</p>
<p>377<br>00:50:07,000 –&gt; 00:50:12,000<br>And then it needs to be able to send the message out and to receive, you know, a message.</p>
<p>378<br>00:50:12,000 –&gt; 00:50:17,000<br>And then we’ll send and receive our arbitrary messages that are not matched.</p>
<p>379<br>00:50:17,000 –&gt; 00:50:22,000<br>It’s the multiplexer job to actually match.</p>
<p>380<br>00:50:22,000 –&gt; 00:50:31,000<br>So to start with, we’ll have a go routine that’s in charge of calling send and another go routine that’s in charge of calling receive both in just a simple loop.</p>
<p>381<br>00:50:31,000 –&gt; 00:50:36,000<br>And so to initialize the service will set up the structure and then we’ll kick off the send loop and the receive loop.</p>
<p>382<br>00:50:36,000 –&gt; 00:50:48,000<br>And then we also have a map of pending requests and the map maps from the tag that we saw the ID number in the messages to a channel where the reply is supposed to go.</p>
<p>383<br>00:50:48,000 –&gt; 00:50:50,000<br>The send loop is fairly simple.</p>
<p>384<br>00:50:50,000 –&gt; 00:50:53,000<br>You just range over the things that need to be sent and you send them.</p>
<p>385<br>00:50:53,000 –&gt; 00:51:03,000<br>And this just has the effect of serializing the calls to send because we’re not going to force the service implementation to deal with us sending, you know, from multiple routines at once.</p>
<p>386<br>00:51:03,000 –&gt; 00:51:11,000<br>And then we’re going to use the same method that we’re going to use to serialize it so that it can just be thinking of sending one packet at a time.</p>
<p>387<br>00:51:11,000 –&gt; 00:51:15,000<br>And then the receive loop is a little bit more complicated.</p>
<p>388<br>00:51:15,000 –&gt; 00:51:18,000<br>It pulls a receive it pulls a reply off the service.</p>
<p>389<br>00:51:18,000 –&gt; 00:51:22,000<br>And again, they’re serialized so only reading one at a time.</p>
<p>390<br>00:51:22,000 –&gt; 00:51:25,000<br>And then it pulls the tag out of the reply.</p>
<p>391<br>00:51:25,000 –&gt; 00:51:28,000<br>And then it says, I need to find the channel to send this to.</p>
<p>392<br>00:51:28,000 –&gt; 00:51:34,000<br>It takes it out of the pending map so that, you know, if we accidentally get another one, we won’t try to send it.</p>
<p>393<br>00:51:34,000 –&gt; 00:51:37,000<br>And then it sends the reply.</p>
<p>394<br>00:51:37,000 –&gt; 00:51:43,000<br>And then to do a call, you just have to set yourself up in the map and then hand it to send and wait for the reply.</p>
<p>395<br>00:51:43,000 –&gt; 00:51:46,000<br>So we start off, we get the tag out.</p>
<p>396<br>00:51:46,000 –&gt; 00:51:48,000<br>We make our own done channel.</p>
<p>397<br>00:51:48,000 –&gt; 00:51:52,000<br>We insert the tag into the map after first checking for bugs.</p>
<p>398<br>00:51:52,000 –&gt; 00:51:56,000<br>And then we send the argument message to send.</p>
<p>399<br>00:51:56,000 –&gt; 00:51:58,000<br>And then we wait for the reply to come in on done.</p>
<p>400<br>00:51:58,000 –&gt; 00:51:59,000<br>It’s very, very simple.</p>
<p>401<br>00:51:59,000 –&gt; 00:52:05,000<br>I mean, like, I used to write these sort of things and see and it was much, much worse.</p>
<p>402<br>00:52:05,000 –&gt; 00:52:08,000<br>So that was all the patterns that I wanted to show.</p>
<p>403<br>00:52:08,000 –&gt; 00:52:14,000<br>And, you know, I hope that those end up being useful for you in whatever mutual program you’re writing.</p>
<p>404<br>00:52:14,000 –&gt; 00:52:19,000<br>And I hope that they’re, you know, just sort of good ideas, even in non-go programs.</p>
<p>405<br>00:52:19,000 –&gt; 00:52:24,000<br>And I hope that, you know, thinking about them and go can help you when you go to do other things as well.</p>
<p>406<br>00:52:24,000 –&gt; 00:52:26,000<br>So I’m going to put them all back up.</p>
<p>407<br>00:52:26,000 –&gt; 00:52:31,000<br>And then I have some questions that Fran said that were, you know, from all of you.</p>
<p>408<br>00:52:31,000 –&gt; 00:52:36,000<br>And we’ll probably have some time for, you know, questions from the chat as well.</p>
<p>409<br>00:52:36,000 –&gt; 00:52:39,000<br>I have no idea in zoom where the chat window is.</p>
<p>410<br>00:52:39,000 –&gt; 00:52:43,000<br>So when we get to that, people can just speak up.</p>
<p>411<br>00:52:43,000 –&gt; 00:52:47,000<br>I don’t use zoom on a daily basis, unfortunately.</p>
<p>412<br>00:52:47,000 –&gt; 00:52:55,000<br>And normally I know how to use zoom like regularly, but with the presentation, it’s like zoom is in this minimized thing that doesn’t have half the things I’m used to.</p>
<p>413<br>00:52:55,000 –&gt; 00:52:58,000<br>Anyway, someone asked how long go took.</p>
<p>414<br>00:52:58,000 –&gt; 00:53:01,000<br>And so far it’s been about 13 and a half years.</p>
<p>415<br>00:53:01,000 –&gt; 00:53:05,000<br>We started discussions in late September 2007.</p>
<p>416<br>00:53:05,000 –&gt; 00:53:09,000<br>I joined full time in August 2008 when I finished at MIT.</p>
<p>417<br>00:53:09,000 –&gt; 00:53:13,000<br>We did the initial open source launch November 2009.</p>
<p>418<br>00:53:13,000 –&gt; 00:53:18,000<br>We released go one, the sort of first stable version in October 2011.</p>
<p>419<br>00:53:18,000 –&gt; 00:53:22,000<br>Sorry, the plan was October 2011, go on itself was March 2012.</p>
<p>420<br>00:53:22,000 –&gt; 00:53:26,000<br>And then we’ve just been on, you know, a sort of regular schedule since then.</p>
<p>421<br>00:53:26,000 –&gt; 00:53:29,000<br>The next major change, of course, is going to be generics.</p>
<p>422<br>00:53:29,000 –&gt; 00:53:37,000<br>And adding generics. And that’s probably going to be go one 18, which is going to be next February.</p>
<p>423<br>00:53:37,000 –&gt; 00:53:42,000<br>So someone asked, you know, how big a team does it take to build a language like go.</p>
<p>424<br>00:53:42,000 –&gt; 00:53:45,000<br>And you know, for those first two years, there were just five of us.</p>
<p>425<br>00:53:45,000 –&gt; 00:53:52,000<br>And that was enough to get us to, you know, something that we released that actually could run in production.</p>
<p>426<br>00:53:52,000 –&gt; 00:53:54,000<br>But it was fairly primitive.</p>
<p>427<br>00:53:54,000 –&gt; 00:53:57,000<br>You know, it was it was a good prototype. It was a solid working prototype.</p>
<p>428<br>00:53:57,000 –&gt; 00:54:00,000<br>But it wasn’t like what it is today.</p>
<p>429<br>00:54:00,000 –&gt; 00:54:02,000<br>And over time, we’ve expanded a fair amount.</p>
<p>430<br>00:54:02,000 –&gt; 00:54:08,000<br>And we’ve got to something like 50 people employed directly, or employed by Google to work directly on go.</p>
<p>431<br>00:54:08,000 –&gt; 00:54:11,000<br>And then there’s tons of open source contributors.</p>
<p>432<br>00:54:11,000 –&gt; 00:54:15,000<br>I mean, there’s literal cast of thousands that have helped us over the last 13 years.</p>
<p>433<br>00:54:15,000 –&gt; 00:54:24,000<br>And there’s absolutely no way we could have done it, even with 50 people, without all the different contributions from the outside.</p>
<p>434<br>00:54:24,000 –&gt; 00:54:27,000<br>Someone asked about design priorities.</p>
<p>435<br>00:54:27,000 –&gt; 00:54:29,000<br>And motivations.</p>
<p>436<br>00:54:29,000 –&gt; 00:54:32,000<br>And so we built it for us, right?</p>
<p>437<br>00:54:32,000 –&gt; 00:54:35,000<br>The priority was to build something that was going to help Google.</p>
<p>438<br>00:54:35,000 –&gt; 00:54:37,000<br>And it just turned out that Google was like a couple years ahead.</p>
<p>439<br>00:54:37,000 –&gt; 00:54:41,000<br>We were just in a really lucky spot where Google was a couple years ahead of the rest of the industry.</p>
<p>440<br>00:54:41,000 –&gt; 00:54:43,000<br>On having to write distributed systems, right?</p>
<p>441<br>00:54:43,000 –&gt; 00:54:49,000<br>Now everyone using cloud software is writing programs that talk to other programs and sending messages.</p>
<p>442<br>00:54:49,000 –&gt; 00:54:53,000<br>And you know, there’s hardly any single machine programs anymore.</p>
<p>443<br>00:54:53,000 –&gt; 00:55:02,000<br>So, you know, we sort of locked into at some level, you know, building the language that we, that the rest of the world needed a couple years later.</p>
<p>444<br>00:55:02,000 –&gt; 00:55:07,000<br>And then the other thing that was really a priority was making it work for large numbers of programmers.</p>
<p>445<br>00:55:07,000 –&gt; 00:55:12,000<br>And because you know, Google had a very large number of programmers working in one code base.</p>
<p>446<br>00:55:12,000 –&gt; 00:55:19,000<br>And now we have open source where, you know, even if you’re a small team, you’re depending on code that’s written by a ton of other people usually.</p>
<p>447<br>00:55:19,000 –&gt; 00:55:25,000<br>And so a lot of the, the issues that come up with just having many programmers still come up in that context.</p>
<p>448<br>00:55:25,000 –&gt; 00:55:28,000<br>So those were really the things we were trying to solve.</p>
<p>449<br>00:55:28,000 –&gt; 00:55:35,000<br>And, you know, for all of these things, we took a long time before we were willing to actually commit to putting something in the language.</p>
<p>450<br>00:55:35,000 –&gt; 00:55:39,000<br>Like everyone basically had to agree in the core original group.</p>
<p>451<br>00:55:39,000 –&gt; 00:55:44,000<br>And, and so that meant that it took us a while to sort of get the pieces exactly the way we wanted them.</p>
<p>452<br>00:55:44,000 –&gt; 00:55:50,000<br>But once we got them there, they’ve actually been very stable and solid and really nice and they work together well.</p>
<p>453<br>00:55:50,000 –&gt; 00:55:57,000<br>And the same thing is kind of happening with generics now where we actually feel, I feel personally really good about generics.</p>
<p>454<br>00:55:57,000 –&gt; 00:56:09,000<br>I feel like it feels like the rest of go and that just wasn’t the case for the proposals that we had, you know, even a couple years ago, much less the early ones.</p>
<p>455<br>00:56:09,000 –&gt; 00:56:15,000<br>Someone said they really like defer, which is unique to language and I do too. Thank you.</p>
<p>456<br>00:56:15,000 –&gt; 00:56:20,000<br>But I wanted to point out that, you know, we did absolutely create defer over go.</p>
<p>457<br>00:56:20,000 –&gt; 00:56:29,000<br>But Swift has adopted it. And I think there’s a proposal for C++ to adopt it as well. So, you know, hopefully it kind of moves out a little bit.</p>
<p>458<br>00:56:29,000 –&gt; 00:56:34,000<br>There was a question about go and using capitalization for exporting.</p>
<p>459<br>00:56:34,000 –&gt; 00:56:40,000<br>And which I know is like something that, you know, sort of is jarring when you first see it.</p>
<p>460<br>00:56:40,000 –&gt; 00:56:44,000<br>And the story behind that is that well, we needed something and we knew that we would need something.</p>
<p>461<br>00:56:44,000 –&gt; 00:56:49,000<br>But like at the beginning, we just said, look, everything’s export everything’s publicly visible. We’ll deal with it later.</p>
<p>462<br>00:56:49,000 –&gt; 00:56:56,000<br>And after about a year, it was like clear that we needed some way to, you know, let programmers hide things from other programmers.</p>
<p>463<br>00:56:56,000 –&gt; 00:57:11,000<br>And, you know, C++ has this public colon and private colon. And in a large struct, it’s actually really annoying that like you’re looking, you’re looking at definitions and you have to scroll backwards and try to find where the like most recent public colon or private colon was.</p>
<p>464<br>00:57:11,000 –&gt; 00:57:17,000<br>And if it’s really big, it can be hard to find one. And so it’s like hard to tell whether a particular definition is public or private.</p>
<p>465<br>00:57:17,000 –&gt; 00:57:25,000<br>And then in Java, of course, it’s at the beginning of every single field. And that seemed kind of excessive too. It’s just too much typing.</p>
<p>466<br>00:57:25,000 –&gt; 00:57:32,000<br>And so we looked around some more and someone pointed out to us that well, Python has this convention where you put an underscore in front to make something hidden.</p>
<p>467<br>00:57:32,000 –&gt; 00:57:39,000<br>And that seemed interesting, but you probably don’t want the default to be not hidden. You want the default to be hidden.</p>
<p>468<br>00:57:39,000 –&gt; 00:57:44,000<br>And then we thought about well, we could put like a plus in front of names.</p>
<p>469<br>00:57:44,000 –&gt; 00:57:51,000<br>And then someone suggested, well, like what about uppercase could be exported. And it seemed like a dumb, terrible idea.</p>
<p>470<br>00:57:51,000 –&gt; 00:57:56,000<br>It really did. But as you think about it, like I really didn’t like this idea.</p>
<p>471<br>00:57:56,000 –&gt; 00:58:02,000<br>And I have like very clear memory of sitting of like the room and what I was staring at as we discussed this.</p>
<p>472<br>00:58:02,000 –&gt; 00:58:10,000<br>But I had no logical argument against it. And it turned out it was fantastic. It was like it seemed bad. It just like aesthetically.</p>
<p>473<br>00:58:10,000 –&gt; 00:58:17,000<br>But it is one of my favorite things now about go that when you look at a use of something, you can see immediately you get that bit of,</p>
<p>474<br>00:58:17,000 –&gt; 00:58:28,000<br>is this something that other people can access or not at every use? Because you know, you see code calling a function to do, you know, whatever it is that it does, you think, oh, wow, like can it can other people do that.</p>
<p>475<br>00:58:28,000 –&gt; 00:58:38,000<br>And you know, your brain sort of takes care of that. But now I go to C++ and I see calls like that. And I get really worried. I’m like, wait, is that is that something other classes can get at.</p>
<p>476<br>00:58:38,000 –&gt; 00:58:43,000<br>And having that data actually turns out to be really useful for reading code.</p>
<p>477<br>00:58:43,000 –&gt; 00:58:50,000<br>A couple of people asked about generics. If you don’t know, we have an active proposal for generics. We’re actively working on implementing it.</p>
<p>478<br>00:58:50,000 –&gt; 00:58:59,000<br>We hope that the release later in the year towards the end of the year will actually have, you know, a full version of generics that you can actually use.</p>
<p>479<br>00:58:59,000 –&gt; 00:59:11,000<br>The, that’ll be like a preview release. The real release that we hope it will be in is go on 18, which is February of next year. So maybe next class will actually get to use generics. We’ll see.</p>
<p>480<br>00:59:11,000 –&gt; 00:59:24,000<br>But I’m certainly looking forward to having like a generic minute max. The reason we don’t have those is that you’d have to pick which type they were for or you have like a whole suite of them and it just seem silly. It seemed like we should wait for generics.</p>
<p>481<br>00:59:24,000 –&gt; 00:59:35,000<br>Someone asked, is there any area of programming where go may not be the best language, but it’s still used. And, and the answer is like absolutely like that happens all the time with every language.</p>
<p>482<br>00:59:35,000 –&gt; 00:59:50,000<br>I think go is actually really good all around language. But you know, you might use it for something that’s not perfect for just because the rest of your program is written and go and you want to interoperate with the rest of the program. So, you know, there’s this website called the online encyclopedia of integer sequences.</p>
<p>483<br>00:59:50,000 –&gt; 00:59:55,000<br>It’s a search engine. You type in like two, three, five, seven, eleven and it tells you those are the primes.</p>
<p>484<br>00:59:55,000 –&gt; 01:00:05,000<br>And it turns out that the backend for that is all written and go. And if you type in a sequence, it doesn’t know it actually does some pretty sophisticated math on the numbers, all with big numbs and things like that.</p>
<p>485<br>01:00:05,000 –&gt; 01:00:15,000<br>And all of that is written and go to because it was too annoying to shell out to maple and math, and and sort of do that cross language thing, even though you’d much rather implement in those languages.</p>
<p>486<br>01:00:15,000 –&gt; 01:00:23,000<br>So, you know, you run into those sorts of compromises all the time and that’s fine.</p>
<p>487<br>01:00:23,000 –&gt; 01:00:36,000<br>And that’s the last about, you know, go is supposed to be simple. So that’s why there’s like no generics and those sets. But isn’t also for software developers and don’t software developers need all this stuff and you know, it’s silly to reconstruct it.</p>
<p>488<br>01:00:36,000 –&gt; 01:00:51,000<br>And I think that’s, it’s true that there’s someone intention, but but simplicity in the sense of leaving things out was not ever the goal. So like for sets, you know, it just seemed like maps are so close to sets. You just have a set a map where the value is empty or a Boolean.</p>
<p>489<br>01:00:51,000 –&gt; 01:01:03,000<br>So that’s a set. And for generics, like you have to remember that when we started go in 2007, Java was like just finishing a true fiasco of a rollout of generics.</p>
<p>490<br>01:01:03,000 –&gt; 01:01:14,000<br>And so like we were really scared of that. We knew that if we just tried to do it, you know, we would get it wrong. And we knew that we could write a lot of useful programs without generics. And so that was what we did.</p>
<p>491<br>01:01:14,000 –&gt; 01:01:24,000<br>And then we came back to it when you know, we felt like, okay, we’ve, you know, spent enough time writing other programs. We kind of know a lot more about what we need from from generics for go.</p>
<p>492<br>01:01:24,000 –&gt; 01:01:35,000<br>And we can take the time to talk to real experts. And I think that, you know, it would have been nice to have them five or 10 years ago, but we wouldn’t have had the really nice ones that we’re going to have now.</p>
<p>493<br>01:01:35,000 –&gt; 01:01:40,000<br>So I think it was probably the right decision.</p>
<p>494<br>01:01:40,000 –&gt; 01:01:47,000<br>So there was a question about go routines and the relation to the plan nine thread library, which, which was all cooperatively scheduled.</p>
<p>495<br>01:01:47,000 –&gt; 01:01:51,000<br>And whether go routines wherever corporally scheduled and like if that caused problems.</p>
<p>496<br>01:01:51,000 –&gt; 01:02:00,000<br>And it is absolutely the case that like go and the go routine runtime were sort of inspired by previous experience on plan nine.</p>
<p>497<br>01:02:00,000 –&gt; 01:02:08,000<br>There was actually a different language called aliph on an early version plan nine that was compiled. It had channels. It had select.</p>
<p>498<br>01:02:08,000 –&gt; 01:02:15,000<br>It had things we called tasks which were a little bit like go routines, but it didn’t have a garbage collector. And that made things really annoying in a lot of cases.</p>
<p>499<br>01:02:15,000 –&gt; 01:02:23,000<br>And also the way that tasks work, they were tied to a specific thread. So you might have three tasks in one thread and two tasks in another thread.</p>
<p>500<br>01:02:23,000 –&gt; 01:02:31,000<br>And in the three tasks in the first thread, they only won ever ran at a time and they could only rescheduled during a channel operation.</p>
<p>501<br>01:02:31,000 –&gt; 01:02:35,000<br>And so you would write code where those three tasks were all operating on the same data structure.</p>
<p>502<br>01:02:35,000 –&gt; 01:02:46,000<br>And you just knew because it was in your head when you wrote it that you know it was okay for these two different tasks to be scribbling over the same data structure because they could never be running at the same time.</p>
<p>503<br>01:02:46,000 –&gt; 01:02:51,000<br>And then you would be working while you know in the other thread, you’ve got the same situation going on with different data and different tasks.</p>
<p>504<br>01:02:51,000 –&gt; 01:02:57,000<br>And then you come back to the same program like six months later and you totally forget which tasks could write to different pieces of data.</p>
<p>505<br>01:02:57,000 –&gt; 01:03:08,000<br>And I’m sure that we had tons of races. I mean, it was just it was a nice model for small programs and it was a terrible model for for programming over a long period of time or having a big program that other people had to work on.</p>
<p>506<br>01:03:08,000 –&gt; 01:03:16,000<br>So, so that was never the model for go. The model for go was always it’s good to have these lightweight go routines, but they’re going to all be running independently.</p>
<p>507<br>01:03:16,000 –&gt; 01:03:23,000<br>And if they’re going to share anything they need to use locks and they need to use channels to communicate and coordinate explicitly.</p>
<p>508<br>01:03:23,000 –&gt; 01:03:28,000<br>And that that is definitely scaled a lot better than any of the plan nine stuff I ever did.</p>
<p>509<br>01:03:28,000 –&gt; 01:03:35,000<br>You know, sometimes people hear that go routines are cooperatively scheduled and they think, you know, something more like that.</p>
<p>510<br>01:03:35,000 –&gt; 01:03:41,000<br>It’s it’s true that early on the go routines were not as preemptively scheduled as you would like.</p>
<p>511<br>01:03:41,000 –&gt; 01:03:51,000<br>So in the very, very early days, the only preemption points when you called into the runtime shortly after that, the preemption points where anytime you enter to function.</p>
<p>512<br>01:03:51,000 –&gt; 01:03:59,000<br>And if you were in a tight loop for a very long time, that would never preempt and that would cause like garbage collector delays because garbage collector need to stop all the go routines.</p>
<p>513<br>01:03:59,000 –&gt; 01:04:04,000<br>And there be some go routines stuck in a tight loop and it would take forever to finish the loop.</p>
<p>514<br>01:04:04,000 –&gt; 01:04:12,000<br>And so actually in the last couple releases, we finally started, we figured out how to get unique signals to deliver to threads and just the right way so that.</p>
<p>515<br>01:04:12,000 –&gt; 01:04:17,000<br>And we can have the right bookkeeping to actually be able to use that as a preemption mechanism.</p>
<p>516<br>01:04:17,000 –&gt; 01:04:31,000<br>And so now things are, I think, I think the preemption delays for garbage collection are actually bounded finally, but from the start, the model has been that, you know, they’re running preemptively and they don’t get control over when they get preempted.</p>
<p>517<br>01:04:31,000 –&gt; 01:04:38,000<br>As a sort of follow on questions, someone else asked, you know, where they can look to in the source tree to learn more about go routines.</p>
<p>518<br>01:04:38,000 –&gt; 01:04:49,000<br>And the go routine scheduler. And the answer is that this is basically a little operating system, like it’s a little operating system that sits on top of the other operating system, instead of on top of CPUs.</p>
<p>519<br>01:04:49,000 –&gt; 01:05:03,000<br>And so the first thing to do is like take 6828, which is like, I mean, I worked on 6828 and an XV6, like literally like the year or two before I went and did the go runtime. And so like there’s a huge amount of 6828 in the go runtime.</p>
<p>520<br>01:05:03,000 –&gt; 01:05:11,000<br>And in the actual go runtime directory, there’s a file called proc.go, which is, you know, proc stands for process because like that’s what it is in the operating systems.</p>
<p>521<br>01:05:11,000 –&gt; 01:05:18,000<br>And I would start there like that’s the file to start with and then sort of pull on strings.</p>
<p>522<br>01:05:18,000 –&gt; 01:05:27,000<br>Someone asked about Python sort of negative indexing where you can write X of minus one. And that comes up a lot, especially from Python programmers.</p>
<p>523<br>01:05:27,000 –&gt; 01:05:34,000<br>And it seems like a really great idea. You write these like really nice elegant programs where like you want to get the last element, you just say X of minus one.</p>
<p>524<br>01:05:34,000 –&gt; 01:05:41,000<br>But the real problem is that like you have X of I and you have a loop that’s like counting down from, you know, end to zero.</p>
<p>525<br>01:05:41,000 –&gt; 01:05:51,000<br>And you have an off by one somewhere and like now X of minus one instead of being, you know, X of I when I is minus one instead of being an error where you see like immediately say, hey, there’s a bug. I need to find that.</p>
<p>526<br>01:05:51,000 –&gt; 01:05:58,000<br>It just like silently grabs the element off the other end of the array. And and that’s where you know that sort of Python.</p>
<p>527<br>01:05:58,000 –&gt; 01:06:10,000<br>And so that’s why we left it out because it was it was going to hide bugs too much we bought.</p>
<p>528<br>01:06:10,000 –&gt; 01:06:17,000<br>You know, you could imagine something where you say like X of dollar minus one or lend minus one not lend of X, but just lend.</p>
<p>529<br>01:06:17,000 –&gt; 01:06:22,000<br>But you know, it seemed like too much of a special case and it really it doesn’t come up enough.</p>
<p>530<br>01:06:22,000 –&gt; 01:06:27,000<br>So I don’t want to ask about, you know, what aspect of go was hardest to implement.</p>
<p>531<br>01:06:27,000 –&gt; 01:06:36,000<br>And honestly, like a lot of this is not very hard. We’ve done most of this before we’ve written operating systems and writing libraries and channel implementations.</p>
<p>532<br>01:06:36,000 –&gt; 01:06:39,000<br>And so like doing all of that again was fairly straightforward.</p>
<p>533<br>01:06:39,000 –&gt; 01:06:42,000<br>The hardest thing was probably the garbage collector.</p>
<p>534<br>01:06:42,000 –&gt; 01:06:48,000<br>But go is unique among garbage collected languages in that it gets programmers a lot more control over memory layout.</p>
<p>535<br>01:06:48,000 –&gt; 01:06:53,000<br>So if you want to have a struct with two different other structs inside it, that’s just one big chunk of memory.</p>
<p>536<br>01:06:53,000 –&gt; 01:06:56,000<br>It’s not a struct with pointers to two other chunks of memory.</p>
<p>537<br>01:06:56,000 –&gt; 01:07:01,000<br>And because of that and you can take the address of like the second field in the struct and pass that around.</p>
<p>538<br>01:07:01,000 –&gt; 01:07:07,000<br>And that means the garbage collector has to be able to deal with a pointer that could point into the middle of an allocated object.</p>
<p>539<br>01:07:07,000 –&gt; 01:07:11,000<br>And that’s just something that Java and list and other things just don’t do.</p>
<p>540<br>01:07:11,000 –&gt; 01:07:16,000<br>And so that makes the garbage collector a lot more complicated in how it maintains its data structures.</p>
<p>541<br>01:07:16,000 –&gt; 01:07:22,000<br>And we also knew from the start that you really want low latency because if you’re handling network requests.</p>
<p>542<br>01:07:22,000 –&gt; 01:07:29,000<br>You can’t, you know, just pause for 200 milliseconds while and block all of those in progress requests to do a garbage collection.</p>
<p>543<br>01:07:29,000 –&gt; 01:07:33,000<br>It really needs to be in, you know, low latency and not stop things.</p>
<p>544<br>01:07:33,000 –&gt; 01:07:39,000<br>And we thought that multi core would be a good, the good opportunity there because we could have the garbage collector sort of doing one core.</p>
<p>545<br>01:07:39,000 –&gt; 01:07:45,000<br>And the go program using the other cores and that might work really well. And that actually did turn out to work really well.</p>
<p>546<br>01:07:45,000 –&gt; 01:07:52,000<br>But it required hiring a real expert in garbage collection to like figure out how to do it.</p>
<p>547<br>01:07:52,000 –&gt; 01:07:56,000<br>And make it work. But but now it’s really great.</p>
<p>548<br>01:07:56,000 –&gt; 01:07:58,000<br>I have a quick question. Yeah.</p>
<p>549<br>01:07:58,000 –&gt; 01:08:03,000<br>You said like if a struct like is declared inside another struct.</p>
<p>550<br>01:08:03,000 –&gt; 01:08:06,000<br>It actually is all a big chunk of memory.</p>
<p>551<br>01:08:06,000 –&gt; 01:08:11,000<br>Yeah. Why did why did you implement it like that? What’s the reason behind that?</p>
<p>552<br>01:08:11,000 –&gt; 01:08:20,000<br>Um, I, well, so there’s a couple reasons one is for a garbage collector. Right. It’s a service and the load on the garbage collector is proportional to the number of objects you allocate.</p>
<p>553<br>01:08:20,000 –&gt; 01:08:24,000<br>And so if you have, you know, a struct with five things in it and you can make that one allocation.</p>
<p>554<br>01:08:24,000 –&gt; 01:08:29,000<br>That’s like a fifth of the load on the garbage collector and that turns out to be really important.</p>
<p>555<br>01:08:29,000 –&gt; 01:08:32,000<br>But the other thing that’s really important is casual quality.</p>
<p>556<br>01:08:32,000 –&gt; 01:08:38,000<br>Like if you have the processor is pulling in chunks of memory in like, you know, 64 byte chunks or whatever it is.</p>
<p>557<br>01:08:38,000 –&gt; 01:08:42,000<br>And it’s much better reading memory that’s altogether than reading memory that’s scattered.</p>
<p>558<br>01:08:42,000 –&gt; 01:08:48,000<br>And so, you know, we have a get server at Google called Garrett that is written Java.</p>
<p>559<br>01:08:48,000 –&gt; 01:08:52,000<br>And it was just starting at the time that that go was, you know, so just coming out.</p>
<p>560<br>01:08:52,000 –&gt; 01:08:57,000<br>And we just missed like Garrett being written and go, I think, by like a year.</p>
<p>561<br>01:08:57,000 –&gt; 01:09:05,000<br>And he said that the guy who had written Garrett and he said that like one of the biggest problems in Garrett was like, you have really shot one hashes.</p>
<p>562<br>01:09:05,000 –&gt; 01:09:09,000<br>And just having the idea of 20 bytes is like impossible to have in Java.</p>
<p>563<br>01:09:09,000 –&gt; 01:09:11,000<br>You can’t just have 20 bytes in a struct.</p>
<p>564<br>01:09:11,000 –&gt; 01:09:13,000<br>You have to have a pointer to an object.</p>
<p>565<br>01:09:13,000 –&gt; 01:09:17,000<br>And the object like, you know, you can’t even have 20 bytes in the object, right.</p>
<p>566<br>01:09:17,000 –&gt; 01:09:21,000<br>You have to declare like five different ins or something like that to get 20 bytes.</p>
<p>567<br>01:09:21,000 –&gt; 01:09:29,000<br>And so, you know, no good way to do it. And it’s just the overhead of just a simple thing like that really adds up.</p>
<p>568<br>01:09:29,000 –&gt; 01:09:36,000<br>And so, you know, we thought giving programmers control over memory was really important.</p>
<p>569<br>01:09:36,000 –&gt; 01:09:41,000<br>So another question was about automatic parallelization like for loops and things like that.</p>
<p>570<br>01:09:41,000 –&gt; 01:09:44,000<br>We don’t do anything like that in the standard go tool chain.</p>
<p>571<br>01:09:44,000 –&gt; 01:09:48,000<br>So we start go compilers for go front ends for GCC and LLVM.</p>
<p>572<br>01:09:48,000 –&gt; 01:09:55,000<br>And so to the extent that those do those kind of loop optimizations and see, I think, you know, we get the same from the go friends for those.</p>
<p>573<br>01:09:55,000 –&gt; 01:09:59,000<br>But it’s not the kind of parallelization that we typically need at Google.</p>
<p>574<br>01:09:59,000 –&gt; 01:10:03,000<br>It’s more, you know, lots of servers running different things.</p>
<p>575<br>01:10:03,000 –&gt; 01:10:09,000<br>And so, you know, that sort of, you know, like the sort of big vector math kind of stuff doesn’t come up as much.</p>
<p>576<br>01:10:09,000 –&gt; 01:10:13,000<br>So it just hasn’t been that important to us.</p>
<p>577<br>01:10:13,000 –&gt; 01:10:21,000<br>And then the last question I have written down is that someone asked about like how do you decide when to acquire release locks and why don’t you have reentered locks.</p>
<p>578<br>01:10:21,000 –&gt; 01:10:25,000<br>And for that, I want to go back a slide. Let me see.</p>
<p>579<br>01:10:25,000 –&gt; 01:10:33,000<br>Yeah, here. So like, you know, during the lecture, I said things like the lock, like new protects the map or protects the data.</p>
<p>580<br>01:10:33,000 –&gt; 01:10:41,000<br>But what we really mean at that point is that we’re saying that the lock protects some collection of invariants that apply to the data or that are true of the data.</p>
<p>581<br>01:10:41,000 –&gt; 01:10:51,000<br>And the reason that we have a lock is to protect the operations that depend on the invariants and that sometimes temporarily invalidate the invariants from each other.</p>
<p>582<br>01:10:51,000 –&gt; 01:10:57,000<br>And so when you call lock, what you’re saying is I need to make use of the invariants that this lock protects.</p>
<p>583<br>01:10:57,000 –&gt; 01:11:00,000<br>And when you call unlock what you’re saying is I don’t need them anymore.</p>
<p>584<br>01:11:00,000 –&gt; 01:11:09,000<br>And if I temporarily invalid invalidated them, I have put them back so that the next person who calls lock will see, you know, correct invariants.</p>
<p>585<br>01:11:09,000 –&gt; 01:11:15,000<br>So in the mux, you know, we want the invariant that each registered pending channel gets it most one reply.</p>
<p>586<br>01:11:15,000 –&gt; 01:11:21,000<br>And so to do that, when we take done out of the map, we also delete it from the map before we unlock it.</p>
<p>587<br>01:11:21,000 –&gt; 01:11:29,000<br>And if there was some separate kind of cancel operation that was directly implying the map as well, it could lock the, it could call lock.</p>
<p>588<br>01:11:29,000 –&gt; 01:11:32,000<br>It could take the thing out, call unlock.</p>
<p>589<br>01:11:32,000 –&gt; 01:11:38,000<br>And then, you know, if it actually found one, it would know, no one is going to send to that anymore because I took it out.</p>
<p>590<br>01:11:38,000 –&gt; 01:11:56,000<br>Whereas if you know, we had written this code to have, you know, an extra unlock and re lock between the done equals pending of tag and the delete, then you wouldn’t have that, you know, protection of the invariants anymore because you would have put things back, you unlock and re locked while the invariants were broken.</p>
<p>591<br>01:11:56,000 –&gt; 01:12:02,000<br>And so it’s really important to, you know, correctness to think about locks is protecting invariants.</p>
<p>592<br>01:12:02,000 –&gt; 01:12:16,000<br>And, and so if you have reentrant locks, all that goes out the window without the reentrant lock, when you call lock on the next line, you know, okay, the lock just got acquired all the invariants are true.</p>
<p>593<br>01:12:16,000 –&gt; 01:12:25,000<br>If you have a reentrant lock, all you know is, well, all the invariants were true for whoever locked this the first time, who like might be way up here on my call stack.</p>
<p>594<br>01:12:25,000 –&gt; 01:12:27,000<br>And, and you really know nothing.</p>
<p>595<br>01:12:27,000 –&gt; 01:12:31,000<br>And so that makes it a lot harder to reason about like, what can you assume?</p>
<p>596<br>01:12:31,000 –&gt; 01:12:36,000<br>And, and so I think reentrant locks are like a really unfortunate part of Java’s legacy.</p>
<p>597<br>01:12:36,000 –&gt; 01:12:46,000<br>And another big problem with reentrant locks is that if you have code where, you know, you call something and it is depending on a reentrant lock for, you know, something where you’ve acquired the lock up above.</p>
<p>598<br>01:12:46,000 –&gt; 01:12:54,000<br>And, and then at some point you say, you know what, actually, I want to like have a time out on this or I want to do it, you know, in some other go routine while I wait for something else.</p>
<p>599<br>01:12:54,000 –&gt; 01:13:02,000<br>When you move that code to a different go routine, reentrant always means locked on the same stack. That’s like the only plausible thing it could possibly mean.</p>
<p>600<br>01:13:02,000 –&gt; 01:13:13,000<br>And so if you move the code that was doing the reentrant lock onto a different stack, then it’s going to deadlock because it’s going to the lock is now actually going to be a real lock acquire and it’s going to be waiting for you to let go of the lock.</p>
<p>601<br>01:13:13,000 –&gt; 01:13:17,000<br>And you’re not going to let go of it because you know you think that code needs to finish running.</p>
<p>602<br>01:13:17,000 –&gt; 01:13:24,000<br>So it’s actually like completely fundamentally incompatible with restructuring where you take code and run it in different threads or different routines.</p>
<p>603<br>01:13:24,000 –&gt; 01:13:36,000<br>And so anyway, like my advice there is to just think about locks protecting invariants and then you just avoid depending on reentrant locks. It really just doesn’t scale well to real programs.</p>
<p>604<br>01:13:36,000 –&gt; 01:13:42,000<br>So I’ll put this list back up. Actually, you know, we have that up long enough. I can try to figure out how to stop presenting.</p>
<p>605<br>01:13:42,000 –&gt; 01:13:47,000<br>And then I can take a few more questions.</p>
<p>606<br>01:13:47,000 –&gt; 01:13:50,000<br>I had a question.</p>
<p>607<br>01:13:50,000 –&gt; 01:13:59,000<br>And I mean, I think coming from Python, like it’s very useful, right? It’s very common to use like standard functional operations, right?</p>
<p>608<br>01:13:59,000 –&gt; 01:14:06,000<br>Like map or filter stuff like that, like list comprehension.</p>
<p>609<br>01:14:06,000 –&gt; 01:14:18,000<br>And when you know I switch over to go and started programming, it’s use I looked it up and people say like you shouldn’t do this. Do this with no right? I was wondering why?</p>
<p>610<br>01:14:18,000 –&gt; 01:14:24,000<br>Well, I mean, one is that you can’t do it the other way. So you might as well do the way you can do it.</p>
<p>611<br>01:14:24,000 –&gt; 01:14:28,000<br>But you know, a bigger issue is that.</p>
<p>612<br>01:14:28,000 –&gt; 01:14:42,000<br>So that was one answer. The other answer is that, you know, if you do it that way, you actually end up creating a lot of garbage. And if you care about like not putting too much load on the garbage collector, that kind of is another way to avoid that.</p>
<p>613<br>01:14:42,000 –&gt; 01:14:54,000<br>You know, so if you’ve got like a map and then a filter and then another map, like you can make that one loop over the data instead of three loops over the data each of which generate a new piece of garbage.</p>
<p>614<br>01:14:54,000 –&gt; 01:15:04,000<br>So now that we have generic coming, you’ll actually be able to write those functions like you couldn’t actually write what the types of those functions were before. And so like you literally couldn’t write them.</p>
<p>615<br>01:15:04,000 –&gt; 01:15:17,000<br>And Python gets away with this because there’s no, you know, static types. But now we’re actually going to have a way to do that. And I totally expect that once new arcs go in, there will be a package slices and if you import slices, you can do slices that map and slices that filter.</p>
<p>616<br>01:15:17,000 –&gt; 01:15:26,000<br>And if you want to make a leak or something like that. And I think those will all happen. And you know, if if that’s the right thing, then that’s great.</p>
<p>617<br>01:15:26,000 –&gt; 01:15:30,000<br>Thanks.</p>
<p>618<br>01:15:30,000 –&gt; 01:15:40,000<br>But one of the hints that you had, it was about running go routines that are independent, like concurrently.</p>
<p>619<br>01:15:40,000 –&gt; 01:15:45,000<br>And some of the examples of the code, I think I couldn’t understand.</p>
<p>620<br>01:15:45,000 –&gt; 01:15:53,000<br>It seemed to me like you can just like call the function in the same thread rather than in different thread.</p>
<p>621<br>01:15:53,000 –&gt; 01:15:57,000<br>And I was not sure why you would call it in a different thread.</p>
<p>622<br>01:15:57,000 –&gt; 01:16:11,000<br>Usually it’s because you want them to proceed independently. So, so in one of the, one of the examples we had, like, the, there was a loop that was sending, you know, tasks to the work queue.</p>
<p>623<br>01:16:11,000 –&gt; 01:16:21,000<br>But there was the servers were running in different go routines and reading from the work you and doing work. But then when they were done, they would send, you know, hey, I’m done now to the done channel.</p>
<p>624<br>01:16:21,000 –&gt; 01:16:34,000<br>But ascending go doesn’t complete until they receive actually matches with it. And so if the thing that’s sending on the work queue is not going to start receiving from the done channel until it’s done sending to all the work cues.</p>
<p>625<br>01:16:34,000 –&gt; 01:16:44,000<br>Or sending all the work into all the tasks and to work you. Then now you have a deadlock because the main thread, the main goal routine is trying to send new work to the servers.</p>
<p>626<br>01:16:44,000 –&gt; 01:16:58,000<br>The servers are not taking new work. They’re trying to tell the main thread that they’re done. But the main thread’s not going to actually start at like reading from the done channel until it finishes giving out all the work. And so there’s just they’re just staring at each other waiting for different things to happen.</p>
<p>627<br>01:16:58,000 –&gt; 01:17:05,000<br>Whereas if we take that loop that if we just put the little go routine around the loop that’s sending the work, then that can go somewhere else.</p>
<p>628<br>01:17:05,000 –&gt; 01:17:17,000<br>And then it can proceed independently. And while it’s stuck waiting for the servers to send to take more work, the servers are stuck waiting for the main go routine to, you know, acknowledge that it finished some work.</p>
<p>629<br>01:17:17,000 –&gt; 01:17:25,000<br>And now the main go routine actually gets down to the loop that you know pulls that finishes that actually acknowledges that it finished the work that reads from the done channel.</p>
<p>630<br>01:17:25,000 –&gt; 01:17:31,000<br>And so it’s just a way to separate out, you know, these are two different things that logically they didn’t have to happen one after the other.</p>
<p>631<br>01:17:31,000 –&gt; 01:17:38,000<br>And because they were happening one after the other that caused a deadlock and by taking one out and moving it, let it run independently.</p>
<p>632<br>01:17:38,000 –&gt; 01:17:42,000<br>That removes the deadlock.</p>
<p>633<br>01:17:42,000 –&gt; 01:17:44,000<br>Thank you so much.</p>
<p>634<br>01:17:44,000 –&gt; 01:17:45,000<br>Sure.</p>
<p>635<br>01:17:45,000 –&gt; 01:17:49,000<br>So let’s talk a little bit about how it goes, race, sector is implemented.</p>
<p>636<br>01:17:49,000 –&gt; 01:17:52,000<br>Sure, it is the LVM race detector.</p>
<p>637<br>01:17:52,000 –&gt; 01:17:58,000<br>And so I probably doesn’t help, but but it is exactly the thing that LVM calls thread sanitizer.</p>
<p>638<br>01:17:58,000 –&gt; 01:18:05,000<br>And so we actually have a little binary blob that you know we link against because we don’t want to depend on all of the M.</p>
<p>639<br>01:18:05,000 –&gt; 01:18:07,000<br>But it’s the LVM race detector.</p>
<p>640<br>01:18:07,000 –&gt; 01:18:12,000<br>And the way the LVM race detector works is that it allocates a ton of extra virtual memory.</p>
<p>641<br>01:18:12,000 –&gt; 01:18:26,000<br>And then based on the address of the thing being read or written, it has this other, you know, spot in virtual memory where it records information about like the last thread, you know, it thinks of threats, but they’re go routines.</p>
<p>642<br>01:18:26,000 –&gt; 01:18:36,000<br>And then also every time a synchronizing event happens like you know a communication from one go routine to another.</p>
<p>643<br>01:18:36,000 –&gt; 01:18:40,000<br>That counts as establishing a happens before edge between two different go routines.</p>
<p>644<br>01:18:40,000 –&gt; 01:18:45,000<br>And if you ever get something where you have a read and a write.</p>
<p>645<br>01:18:45,000 –&gt; 01:18:53,000<br>And they’re not properly sequenced right like so if you have a read and then it happens before something in another go routine, which then you know later does the right that’s fine.</p>
<p>646<br>01:18:53,000 –&gt; 01:18:57,000<br>So reading a right and there’s no happens before sequence that connects them.</p>
<p>647<br>01:18:57,000 –&gt; 01:18:59,000<br>Then that’s a race.</p>
<p>648<br>01:18:59,000 –&gt; 01:19:07,000<br>And it actually has some pretty clever ways to dynamically figure out quickly, you know, did this read happen.</p>
<p>649<br>01:19:07,000 –&gt; 01:19:10,000<br>Is there happens before path between this reading straight as they happen.</p>
<p>650<br>01:19:10,000 –&gt; 01:19:13,000<br>And it slows down the program by like maybe 10X.</p>
<p>651<br>01:19:13,000 –&gt; 01:19:18,000<br>But you know if you just divert a small amount of traffic there, that’s probably fine.</p>
<p>652<br>01:19:18,000 –&gt; 01:19:24,000<br>And it’s it’s way better than like not finding out about the races. So it’s totally worth it.</p>
<p>653<br>01:19:24,000 –&gt; 01:19:32,000<br>And honestly, 10 or 20X is fantastic. The original thread sanitizer was more like 100 or 1000 X and that was not good enough.</p>
<p>654<br>01:19:32,000 –&gt; 01:19:35,000<br>What’s the race detector called LRVN?</p>
<p>655<br>01:19:35,000 –&gt; 01:19:45,000<br>It’s called thread sanitizer, but it’s part of LLVM, which is the Clang C compiler, the one that almost everyone uses now.</p>
<p>656<br>01:19:45,000 –&gt; 01:19:55,000<br>And it’s part of the LLVM project.</p>
<p>657<br>01:19:55,000 –&gt; 01:20:02,000<br>Can you talk about slices and like the design choices having them as views on a race, which like confused me at first.</p>
<p>658<br>01:20:02,000 –&gt; 01:20:06,000<br>Yeah, yeah, it is a little confusing at first.</p>
<p>659<br>01:20:06,000 –&gt; 01:20:14,000<br>The main thing is that you want it to be efficient to kind of walk through an array or to like, you know, if you couldn’t quick sort or merge sort or something where you have an array of things.</p>
<p>660<br>01:20:14,000 –&gt; 01:20:17,000<br>And now you want to say, well, now sort this half and sort the other half.</p>
<p>661<br>01:20:17,000 –&gt; 01:20:23,000<br>You want to be able to efficiently say like here, this is half of the previous one, like, you know, sort that.</p>
<p>662<br>01:20:23,000 –&gt; 01:20:30,000<br>And so in C, the way you do that is you just pass in, you know, the pointer to the first element and the number of elements.</p>
<p>663<br>01:20:30,000 –&gt; 01:20:32,000<br>And that’s basically all a slice is.</p>
<p>664<br>01:20:32,000 –&gt; 01:20:39,000<br>And then the other pattern that comes up a lot when you’re, you know, trying to be efficient with arrays is you have to grow them.</p>
<p>665<br>01:20:39,000 –&gt; 01:20:45,000<br>And so you don’t want to read call realloc on every single new element, you want to amortize that.</p>
<p>666<br>01:20:45,000 –&gt; 01:20:53,000<br>And so the way you do that in in C again is that you have a base pointer, you have the length that you’re using right now and you have the length that you allocated.</p>
<p>667<br>01:20:53,000 –&gt; 01:20:58,000<br>And then to add one you check and see if the length is bigger than the amount you allocated.</p>
<p>668<br>01:20:58,000 –&gt; 01:21:01,000<br>And otherwise you just keep bumping it forward.</p>
<p>669<br>01:21:01,000 –&gt; 01:21:08,000<br>And slices are really just an encoding of those idioms because those are kind of the most efficient way to manage the memory.</p>
<p>670<br>01:21:08,000 –&gt; 01:21:14,000<br>And so in any kind of like C++ vector or sort of thing like that, that’s what’s going on underneath.</p>
<p>671<br>01:21:14,000 –&gt; 01:21:23,000<br>But it makes it a lot harder to like the C++ vector because of ownership reasons, you know, the vector is tied to the actual underlying memory.</p>
<p>672<br>01:21:23,000 –&gt; 01:21:29,000<br>And it’s a lot harder to get like a sub vector that’s just the view on to like the second half for merge sort.</p>
<p>673<br>01:21:29,000 –&gt; 01:21:36,000<br>So that’s sort of the ideas that it just like there are all these patterns for accessing memory officially that came from C.</p>
<p>674<br>01:21:36,000 –&gt; 01:21:43,000<br>And we tried to make them fit into go in an idiomatic way in a safe way.</p>
<p>675<br>01:21:43,000 –&gt; 01:21:51,000<br>So look at how you decided to implement the go like remote module system where you import directly from a URL.</p>
<p>676<br>01:21:51,000 –&gt; 01:21:53,000<br>Yeah.</p>
<p>677<br>01:21:53,000 –&gt; 01:22:00,000<br>I mean, I just didn’t want to run a service and like, like, you know, a lot of the things like Ruby gems and those like we’re not as.</p>
<p>678<br>01:22:00,000 –&gt; 01:22:04,000<br>For the front of my mind at the time, just because they were newer.</p>
<p>679<br>01:22:04,000 –&gt; 01:22:07,000<br>But like I used Pearl for a while and like C pan.</p>
<p>680<br>01:22:07,000 –&gt; 01:22:12,000<br>And I just thought it was it was insane that like everyone was fighting over these short names like DB, you know.</p>
<p>681<br>01:22:12,000 –&gt; 01:22:18,000<br>There probably shouldn’t be an argument over like who gets to make the DB package.</p>
<p>682<br>01:22:18,000 –&gt; 01:22:22,000<br>And so putting domain names in the front seemed like a good way to decentralize it.</p>
<p>683<br>01:22:22,000 –&gt; 01:22:30,000<br>And it was also a good way for us not to run any server because you know, we could just say while we don’t recognize the host name and then and then go grab it from source control.</p>
<p>684<br>01:22:30,000 –&gt; 01:22:32,000<br>From someone else’s server.</p>
<p>685<br>01:22:32,000 –&gt; 01:22:35,000<br>And that turned out to be a really great idea, I think.</p>
<p>686<br>01:22:35,000 –&gt; 01:22:40,000<br>Because we just we don’t have that kind of same infrastructure that other things depend on.</p>
<p>687<br>01:22:40,000 –&gt; 01:22:44,000<br>Like in the Java world, it’s actually really problematic. There are multiple.</p>
<p>688<br>01:22:44,000 –&gt; 01:22:48,000<br>There’s no sort of standard registry, but they all use these short names.</p>
<p>689<br>01:22:48,000 –&gt; 01:22:54,000<br>And so like Maven can be configured to build from multiple different registries.</p>
<p>690<br>01:22:54,000 –&gt; 01:23:00,000<br>And you if you’re an open source software package provider, you actually have to go around and be sure that you uploaded to all the different registries.</p>
<p>691<br>01:23:00,000 –&gt; 01:23:05,000<br>Because if you don’t if you miss one and it becomes popular, someone else will upload different code to that one.</p>
<p>692<br>01:23:05,000 –&gt; 01:23:09,000<br>And and then like Maven actually just takes which everyone comes back first.</p>
<p>693<br>01:23:09,000 –&gt; 01:23:12,000<br>It just like sends a request to all of them and whatever comes back first.</p>
<p>694<br>01:23:12,000 –&gt; 01:23:18,000<br>So like, you know, if someone wants to make a malicious copy of your package, all I do is find some registry other people use that you forgot to upload it to.</p>
<p>695<br>01:23:18,000 –&gt; 01:23:21,000<br>And like, you know, they get to win the race sometimes.</p>
<p>696<br>01:23:21,000 –&gt; 01:23:29,000<br>So it’s like, it’s a real problem. Like I think having the domain name there really helps split up the ownership in a really important way.</p>
<p>697<br>01:23:29,000 –&gt; 01:23:30,000<br>Thank you.</p>
<p>698<br>01:23:30,000 –&gt; 01:23:35,000<br>Sure.</p>
<p>699<br>01:23:35,000 –&gt; 01:23:38,000<br>So what the name is you take a quick pause here.</p>
<p>700<br>01:23:38,000 –&gt; 01:23:42,000<br>I was people that have to go and go. I’m sure Russ is willing to stick around for a little bit longer.</p>
<p>701<br>01:23:42,000 –&gt; 01:23:43,000<br>Yeah.</p>
<p>702<br>01:23:43,000 –&gt; 01:23:47,000<br>And answer any questions. But I do want to think Russ for giving this lecture.</p>
<p>703<br>01:23:47,000 –&gt; 01:23:52,000<br>Hopefully this will help you running more good per go programs.</p>
<p>704<br>01:23:52,000 –&gt; 01:23:56,000<br>DC patterns and so thank you Russ.</p>
<p>705<br>01:23:56,000 –&gt; 01:24:00,000<br>Welcome. It’s nice to be here.</p>
<p>706<br>01:24:00,000 –&gt; 01:24:03,000<br>And then more questions feel free to ask questions.</p>
<p>707<br>01:24:03,000 –&gt; 01:24:04,000<br>Yeah.</p>
<p>708<br>01:24:04,000 –&gt; 01:24:07,000<br>Oh, just a little logistical thing.</p>
<p>709<br>01:24:07,000 –&gt; 01:24:13,000<br>The slides that are on the 6824 website are not the exactly the same as Russ’s slides.</p>
<p>710<br>01:24:13,000 –&gt; 01:24:14,000<br>People.</p>
<p>711<br>01:24:14,000 –&gt; 01:24:16,000<br>Yeah, well, I’ll get friends and new PDF.</p>
<p>712<br>01:24:16,000 –&gt; 01:24:19,000<br>Yeah.</p>
<p>713<br>01:24:19,000 –&gt; 01:24:26,000<br>So I have a question about when is writing a new language like the best solution to a phone.</p>
<p>714<br>01:24:26,000 –&gt; 01:24:31,000<br>That’s a great question. It’s almost never the best solution.</p>
<p>715<br>01:24:31,000 –&gt; 01:24:38,000<br>But you know, at the time we had just an enormous number of programmers like thousands of programmers working in one code base.</p>
<p>716<br>01:24:38,000 –&gt; 01:24:47,000<br>And the compilations were just taking forever because C++ was just not not meant for, you know, efficient incremental compilation.</p>
<p>717<br>01:24:47,000 –&gt; 01:24:53,000<br>And so, and furthermore, at the time, like threading libraries were really awful.</p>
<p>718<br>01:24:53,000 –&gt; 01:24:54,000<br>Like people just didn’t use threads.</p>
<p>719<br>01:24:54,000 –&gt; 01:24:57,000<br>I remember the like one of the first days I was at MIT and talking to Robert.</p>
<p>720<br>01:24:57,000 –&gt; 01:25:03,000<br>And Robert said to me, like in 2001, he said to me, like, well, we don’t use threads here because threads are slow.</p>
<p>721<br>01:25:03,000 –&gt; 01:25:08,000<br>And that was like totally normal. Like that was just the way the world at the time.</p>
<p>722<br>01:25:08,000 –&gt; 01:25:14,000<br>And at Google, we were having a lot of trouble because it was all event based, like little callbacks and C++.</p>
<p>723<br>01:25:14,000 –&gt; 01:25:22,000<br>And there were these multi core machines. And we actually didn’t know how to get things to work on them because like Linux threads were not something you could really rely on to work.</p>
<p>724<br>01:25:22,000 –&gt; 01:25:31,000<br>And so we ended up like, if you had a four core machine, you just run four different process into completely independent processes of the web server and just treat it as like four machines.</p>
<p>725<br>01:25:31,000 –&gt; 01:25:39,000<br>And that was clearly like not very efficient. So like there were a lot of good reasons to like try something.</p>
<p>726<br>01:25:39,000 –&gt; 01:25:46,000<br>But you know, it’s a huge amount of work to get to the point where go is today. And I think that so much is not the language, right.</p>
<p>727<br>01:25:46,000 –&gt; 01:25:51,000<br>Like there were important things that we made didn’t the language that enabled other considerations.</p>
<p>728<br>01:25:51,000 –&gt; 01:26:00,000<br>But so much of the successful languages, the egos and like I built up around it and the tooling that we built and the go command and like all these like not the language things.</p>
<p>729<br>01:26:00,000 –&gt; 01:26:15,000<br>So, you know, programming language, people who are like focus on the language itself. I think sometimes get distracted by all the stuff around it.</p>
<p>730<br>01:26:15,000 –&gt; 01:26:25,000<br>Can I ask a full often that I was wondering how it’s working on go different now since it’s more mature than it was before.</p>
<p>731<br>01:26:25,000 –&gt; 01:26:37,000<br>Oh, that’s a great question. You know, in the early days, it was so easy to make changes. And now it’s really hard to make changes. I think that’s the number one thing.</p>
<p>732<br>01:26:37,000 –&gt; 01:26:52,000<br>You know, in the early days, like everything was in one source code repository, literally all the go code in the world was in one source code repository. And so like there were days where we changed the syntax like you used to have a star before Chan every time you set a channel, because it was a pointer underneath and it was all kind of exposed.</p>
<p>733<br>01:26:52,000 –&gt; 01:27:01,000<br>So you’d always say star Chan int instead of Chan int and similarly for maps. And at some point we realized like this is done. Like you have to say the star. Let’s just take it out.</p>
<p>734<br>01:27:01,000 –&gt; 01:27:17,000<br>And so like we made the change to the compiler. And I opened up literally like the couple hundred go source files in the world in my editor and like the entire team stood behind me and like I typed some regular expressions and we looked at the effect on the files. If you have that looks right, save it, you know, compile it. We’re done.</p>
<p>735<br>01:27:17,000 –&gt; 01:27:35,000<br>And like today, you know, we can’t make backwards, but the compatible changes at all. And even making new changes like it affects a lot of people. And so, you know, you sort of propose something and you know, people, well, this won’t work for me and you try to like adjust that maybe.</p>
<p>736<br>01:27:35,000 –&gt; 01:27:44,000<br>It’s just it’s a lot harder. We estimate there’s at least a million, maybe two million go programmers in the world and is very different from when they were four or five.</p>
<p>737<br>01:27:47,000 –&gt; 01:27:58,000<br>And so, you know, I’m sure if this is a valid question, but what languages go written in? Is it written in go also or no?</p>
<p>738<br>01:27:58,000 –&gt; 01:28:04,000<br>Now it is. Now it is. The original compiler runtime or written C, but a few years ago we went through a big.</p>
<p>739<br>01:28:04,000 –&gt; 01:28:18,000<br>We actually wrote a program to translate C to go that only worked for our C code, but still it was good enough so that we wouldn’t lose kind of all the sort of encoded knowledge in that code about why things were the way they were and like how things works. We got to start from scratch.</p>
<p>740<br>01:28:18,000 –&gt; 01:28:28,000<br>But now it’s all written in go and you know, a little bit of assembly. And that means that people can, you know, people who know go can help on the go project.</p>
<p>741<br>01:28:28,000 –&gt; 01:28:43,000<br>That’s before like, if you wanted to work on the compiler or the runtime, you had to know C really well and like, we weren’t getting a lot of people new C really well, like there’s not actually that many of them proportionally and and furthermore like aren’t our user bases go programmers not see programmers so moving to go with.</p>
<p>742<br>01:28:43,000 –&gt; 01:28:46,000<br>It was a really big deal.</p>
<p>743<br>01:28:46,000 –&gt; 01:28:56,000<br>I was wondering how do you prioritize what features to have to link with that like this point like an all generate sort of like a lot of where we’re like asking for that like.</p>
<p>744<br>01:28:56,000 –&gt; 01:28:59,000<br>You don’t know like how you choose what to work on.</p>
<p>745<br>01:28:59,000 –&gt; 01:29:05,000<br>I mean, we’ve considered language mostly frozen for a while and and so we haven’t been adding much.</p>
<p>746<br>01:29:05,000 –&gt; 01:29:16,000<br>There was a long period where we said we were not anything and then we added a little bit of things in the last couple years to lead up to Jericho’s kind of shake the rust off. I’m like all the like what breaks when you change something in the language.</p>
<p>747<br>01:29:16,000 –&gt; 01:29:21,000<br>So like you can put underscores between digits and long numbers now things like that.</p>
<p>748<br>01:29:21,000 –&gt; 01:29:27,000<br>But you know generics has clearly been the next thing that needed to happen and we just had to figure out how.</p>
<p>749<br>01:29:27,000 –&gt; 01:29:33,000<br>In general, we try to only add things that don’t have weird kind of interference with other features.</p>
<p>750<br>01:29:33,000 –&gt; 01:29:50,000<br>And we try to add things that are really important that will help a lot of people for the kinds of programs that we’re trying to target with go which is like distributed systems and that sort of thing.</p>
<p>751<br>01:29:50,000 –&gt; 01:29:52,000<br>Cool.</p>
<p>752<br>01:29:52,000 –&gt; 01:29:56,000<br>Oh, I had a question actually.</p>
<p>753<br>01:29:56,000 –&gt; 01:30:04,000<br>So I noticed that like, you know, go doesn’t have like basic functions like men or max for like.</p>
<p>754<br>01:30:04,000 –&gt; 01:30:11,000<br>Yeah, so is that like something that you’re considering like say adding with like the generic stuff. Maybe is that why you didn’t.</p>
<p>755<br>01:30:11,000 –&gt; 01:30:13,000<br>Yeah, exactly right. Because like you can’t have a man.</p>
<p>756<br>01:30:13,000 –&gt; 01:30:18,000<br>You’d have min and then you could have minimum date, but those that have different names and that was kind of annoying.</p>
<p>757<br>01:30:18,000 –&gt; 01:30:23,000<br>So now we can light just a generic name over any type that has a less than operator.</p>
<p>758<br>01:30:23,000 –&gt; 01:30:28,000<br>Yeah, that’ll be good. And you know, honestly, like for the specific case of min and max.</p>
<p>759<br>01:30:28,000 –&gt; 01:30:30,000<br>It’s not that hard to call that.</p>
<p>760<br>01:30:30,000 –&gt; 01:30:38,000<br>I know I was going to say I’m starting to feel like we should just make them built in like like you know print things like that so that you know you can just always have them.</p>
<p>761<br>01:30:38,000 –&gt; 01:30:42,000<br>But even if we don’t like you’ll be math thought man and that’ll be there at least.</p>
<p>762<br>01:30:42,000 –&gt; 01:30:49,000<br>Yeah, we really didn’t want to make them built in until we could like express their types and we couldn’t do that until generics happen.</p>
<p>763<br>01:30:49,000 –&gt; 01:30:52,000<br>Because there is actually a min for like floating points actually.</p>
<p>764<br>01:30:52,000 –&gt; 01:30:59,000<br>Yeah, I know it’s kind of weird. It’s because it’s because the math library is basically copied from the C math dot H set of things.</p>
<p>765<br>01:30:59,000 –&gt; 01:31:05,000<br>Yeah, so that’s a good point like we can’t actually put them in math because they’re already there.</p>
<p>766<br>01:31:05,000 –&gt; 01:31:12,000<br>Okay, but yeah, we’ll figure it out. Like I think we should probably just put them in the language, but we have to get generic through first.</p>
<p>767<br>01:31:12,000 –&gt; 01:31:18,000<br>And another thing actually noticed that you did usaco like competitive programming to actually.</p>
<p>768<br>01:31:18,000 –&gt; 01:31:25,000<br>Oh, yeah, so how did you so actually I included this in one of the questions that I submitted. Let me pull it up.</p>
<p>769<br>01:31:25,000 –&gt; 01:31:45,000<br>So my question was like, how did how was like how did you go from doing competitive programming to like doing what you you’re doing now at Google looking on going how’s the transition between competitive programming to systems also finally what made you decide to go into systems and how did it really.</p>
<p>770<br>01:31:45,000 –&gt; 01:31:46,000<br>Programming company.</p>
<p>771<br>01:31:46,000 –&gt; 01:31:59,000<br>I mean, competitive program at the time that I did it was not as all consuming as I gather it is now like, you know, you could just like be able to implement a simple dynamic programming like little two for loops and that was fine.</p>
<p>772<br>01:31:59,000 –&gt; 01:32:03,000<br>And now you have to go like complex hall algorithms and all that stuff that I can’t do.</p>
<p>773<br>01:32:03,000 –&gt; 01:32:07,000<br>So like, at some point like some of them like it was different.</p>
<p>774<br>01:32:07,000 –&gt; 01:32:16,000<br>You know, I was actually more interested in the sort of systems you kind of stuff from the start and the program concepts were just like something fun to do on the side.</p>
<p>775<br>01:32:16,000 –&gt; 01:32:18,000<br>So there wasn’t like a huge transition there.</p>
<p>776<br>01:32:18,000 –&gt; 01:32:24,000<br>I was never into like implementing complex hall algorithms and that max flow and all those sorts of things.</p>
<p>777<br>01:32:24,000 –&gt; 01:32:31,000<br>On the other hand, like when you start a new language, you actually if you get to write a lot of core things, right.</p>
<p>778<br>01:32:31,000 –&gt; 01:32:36,000<br>Like someone has to write the sort function and has to be a good general sort function.</p>
<p>779<br>01:32:36,000 –&gt; 01:32:44,000<br>Like I spent a while last month like looking into dip algorithms and that’s like, you know, sort of matches that background pretty well.</p>
<p>780<br>01:32:44,000 –&gt; 01:32:46,000<br>So it does come up.</p>
<p>781<br>01:32:46,000 –&gt; 01:32:49,000<br>But you know, it’s just it’s just a different kind of program.</p>
<p>782<br>01:32:49,000 –&gt; 01:32:56,000<br>Oh, so you thought of it as more of a side thing back then not like it was definitely not the sort of main thing I did when I was writing programs.</p>
<p>783<br>01:32:56,000 –&gt; 01:32:59,000<br>Yeah, because like today it’s effectively like the main thing.</p>
<p>784<br>01:32:59,000 –&gt; 01:33:03,000<br>If you don’t do it full time like there’s just no way you can.</p>
<p>785<br>01:33:03,000 –&gt; 01:33:08,000<br>If you they just want that many people who cared you know in 1995.</p>
<p>786<br>01:33:08,000 –&gt; 01:33:15,000<br>Well, yeah, 20 years later.</p>
<p>787<br>01:33:15,000 –&gt; 01:33:18,000<br>I’m going to ask her later question to that.</p>
<p>788<br>01:33:18,000 –&gt; 01:33:24,000<br>So how’d you decide to go from from like academic work into.</p>
<p>789<br>01:33:24,000 –&gt; 01:33:32,000<br>And I was your work is still like a little bit more different than like the usual like software and anything but still.</p>
<p>790<br>01:33:32,000 –&gt; 01:33:34,000<br>Yeah, yeah.</p>
<p>791<br>01:33:34,000 –&gt; 01:33:35,000<br>You know, I got lucky.</p>
<p>792<br>01:33:35,000 –&gt; 01:33:43,000<br>I grew up near Bell Labs in New Jersey. And so like that was how I ended up working on playing the eye in a little bit in high school in college.</p>
<p>793<br>01:33:43,000 –&gt; 01:33:51,000<br>And so, you know, I sort of knew I was going to go to grad school and you know, the plan was to go back to Bell Labs, but it kind of imploded while I was in grad school.</p>
<p>794<br>01:33:51,000 –&gt; 01:33:54,000<br>And you have to focus</p>
<p>795<br>01:33:54,000 –&gt; 01:33:56,000<br>ไป, like, online or proprietary or fly example?</p>
<p>796<br>01:33:56,000 –&gt; 01:33:58,000<br>ada. com boom and the. com crash.</p>
<p>797<br>01:33:58,000 –&gt; 01:34:00,000<br>And so like, you know Google was sort of a,</p>
<p>798<br>01:34:00,000 –&gt; 01:34:11,000<br>just vacuuming up PhDs systems PhDs of the time.</p>
<p>799<br>01:34:11,000 –&gt; 01:34:13,000<br>And and doing really interesting things.</p>
<p>800<br>01:34:13,000 –&gt; 01:34:14,000<br>I mean, it’s probably.</p>
<p>801<br>01:34:14,000 –&gt; 01:34:17,000<br>There’s things like Spanner and.</p>
<p>802<br>01:34:17,000 –&gt; 01:34:18,680<br>to be able to go to that too.</p>
<p>803<br>01:34:20,680 –&gt; 01:34:25,720<br>And at the time I graduated, I was also looking at industrial research labs like Microsoft Research</p>
<p>804<br>01:34:25,720 –&gt; 01:34:32,039<br>and places like that. So there’s definitely an opportunity there for researchy things but not</p>
<p>805<br>01:34:32,039 –&gt; 01:34:37,159<br>in academia if that’s what you want. It’s a little harder to find now. I mean, most of the places</p>
<p>806<br>01:34:37,159 –&gt; 01:34:45,319<br>that like Microsoft Research imploded to a couple years later. But it’s still an option.</p>
<p>807<br>01:34:45,319 –&gt; 01:34:52,679<br>And it’s just a slightly different path. The differences I see from academia is you end up</p>
<p>808<br>01:34:52,679 –&gt; 01:34:57,399<br>carrying a ton more about actually making things work a hundred percent time and supporting them</p>
<p>809<br>01:34:57,399 –&gt; 01:35:01,960<br>for a decade or more. Whereas you finish your paper and you get to put it off to the side.</p>
<p>810<br>01:35:01,960 –&gt; 01:35:09,799<br>And that’s really nice actually at some level. It’s definitely strange to me to be editing</p>
<p>811<br>01:35:09,800 –&gt; 01:35:16,920<br>source files that I wrote. In some cases, actually 20 years ago, because I used a bunch of code</p>
<p>812<br>01:35:16,920 –&gt; 01:35:21,640<br>that I’d already written when we started go. And it’s very weird to think that I’ve been keeping</p>
<p>813<br>01:35:21,640 –&gt; 01:35:42,680<br>this program running for 20 years. Thank you.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>MIT6824 P10Lecture10 GuestLectureonGo RussCox</div>
      <div>http://example.com/2025/10/24/MIT6824 P10Lecture10-GuestLectureonGo-RussCox/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月24日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/24/MIT6824%20P12Lecture12-CacheConsistency-Frangipani/" title="MIT6824 P12Lecture12 CacheConsistency Frangipani">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">MIT6824 P12Lecture12 CacheConsistency Frangipani</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/24/CMU15445%20P8F202307-HashTables/" title="CMU15445 P8F202307 HashTables">
                        <span class="hidden-mobile">CMU15445 P8F202307 HashTables</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
