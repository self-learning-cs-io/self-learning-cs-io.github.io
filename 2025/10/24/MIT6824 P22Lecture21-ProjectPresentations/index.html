

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:16,000So, it’s 105. So, feel free to get started whenever you want to be ready. 200:00:16,000 –&gt; 00:00:24,000All right, should we start then? Please. 300:00:24,000 –&gt; 0">
<meta property="og:type" content="article">
<meta property="og:title" content="MIT6824 P22Lecture21 ProjectPresentations">
<meta property="og:url" content="http://example.com/2025/10/24/MIT6824%20P22Lecture21-ProjectPresentations/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:16,000So, it’s 105. So, feel free to get started whenever you want to be ready. 200:00:16,000 –&gt; 00:00:24,000All right, should we start then? Please. 300:00:24,000 –&gt; 0">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-24T12:02:19.371Z">
<meta property="article:modified_time" content="2025-10-24T12:06:28.574Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>MIT6824 P22Lecture21 ProjectPresentations - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="MIT6824 P22Lecture21 ProjectPresentations"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-24 20:02" pubdate>
          2025年10月24日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.8k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          57 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">MIT6824 P22Lecture21 ProjectPresentations</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:16,000<br>So, it’s 105. So, feel free to get started whenever you want to be ready.</p>
<p>2<br>00:00:16,000 –&gt; 00:00:24,000<br>All right, should we start then? Please.</p>
<p>3<br>00:00:24,000 –&gt; 00:00:34,000<br>All right. Hey, everyone. My name is Felipe. I’m working with Catalina. And today we’re going to be presenting on our project on distributed private electronic voting.</p>
<p>4<br>00:00:34,000 –&gt; 00:00:44,000<br>So, motivating this project was, you know, actually sort of sort of easy given the current events and elections that have to happen with COVID restrictions.</p>
<p>5<br>00:00:44,000 –&gt; 00:00:59,000<br>So, we asked the question, you know, how would internet voting work? And we’re focusing specifically on maintaining voter privacy or keeping votes private.</p>
<p>6<br>00:00:59,000 –&gt; 00:01:14,000<br>And so, here’s a sketch of how a voting system might work. You have a bunch of voters, in this case, you know, five, and then a vote counter. And the voters send the votes to the vote counter.</p>
<p>7<br>00:01:14,000 –&gt; 00:01:28,000<br>And the vote counter is, you know, maybe they sent them encrypted or some sort of security vote counter decrypts them, make sure that each voter votes at most ones and computer winner.</p>
<p>8<br>00:01:28,000 –&gt; 00:01:44,000<br>And so, you know, the key thing to notice here is that in order for the vote counter to determine that every voter votes at most ones, each vote has to be in some way linked to the voter, which is dangerous.</p>
<p>9<br>00:01:44,000 –&gt; 00:02:05,000<br>And so, we’re going to explain our threat model here, which is we’re giving the attacker two sort of capacity or two sort of powers. The first is to create fell stop failures, but but not visiting failure. So the attacker can crash server, but it cannot sort of make make it miss behave.</p>
<p>10<br>00:02:05,000 –&gt; 00:02:16,000<br>And, you know, whether it is a reasonable assumption is a question for another day, but we think there are other protocols that deal with this issues. We’re not dealing with visiting failures.</p>
<p>11<br>00:02:16,000 –&gt; 00:02:35,000<br>The second power we give them is to passively spy on a vote counter. And so this is problematic because as we said, votes are linked with their voters. And so a passive attacker that’s that’s spying on the server can sort of de-anonymize these votes.</p>
<p>12<br>00:02:35,000 –&gt; 00:02:57,000<br>And so here’s where we come in and present our distributed voting design. We’re first going to deal with the first problem, which is, you know, the the adversary crashing the servers. And so we are going to have several vote counters. And the idea is the each voter will send their votes to all the vote counters.</p>
<p>13<br>00:02:57,000 –&gt; 00:03:06,000<br>And the vote counters will use the same protocols before and compute winners, the winners. Sorry.</p>
<p>14<br>00:03:06,000 –&gt; 00:03:19,000<br>And it’s this is good because an other certain crash sort of like N minus one vote counters as long as one of them is up and running will be able to compute a winner.</p>
<p>15<br>00:03:19,000 –&gt; 00:03:38,000<br>However, it’s very, you know, arguably more unsafe for the second type of attack, which was like passively spying because as long as, you know, as the as the adversary or the attacker can compromise it even one server, you know, it can de-anonymize all the votes.</p>
<p>16<br>00:03:38,000 –&gt; 00:03:49,000<br>And so that’s where we’re going to introduce Shemir secret sharing for Shemir secret sharing. We have a voter that’s going to, you know, choose a vote at zero or one.</p>
<p>17<br>00:03:49,000 –&gt; 00:03:59,000<br>And we’re going to, you know, I’m not going to explain how Shemir actually works. It’s a cryptographic protocol. But we’re going to just, you know, show what it allows us to do.</p>
<p>18<br>00:03:59,000 –&gt; 00:04:11,000<br>And you pass a vote through Shemir, where you give it two parameters, N and K, and it’s going to create n parts, which allow you to recompute that the vote.</p>
<p>19<br>00:04:11,000 –&gt; 00:04:22,000<br>The n parts completely random. And in fact, what is sort of powerful, but Shemir is that even K minus one shares give you no information about the original vote.</p>
<p>20<br>00:04:22,000 –&gt; 00:04:30,000<br>But given K or more shares, you can use Shemir to recompute that vote.</p>
<p>21<br>00:04:30,000 –&gt; 00:04:33,000<br>So we’re going to go into Shemir voting scheme.</p>
<p>22<br>00:04:33,000 –&gt; 00:04:45,000<br>So, you know, for the Shemir voting scheme, voting scheme. So first, all the voters are going to choose their vote and share parts to the vote countries not the complete vote on the different parts.</p>
<p>23<br>00:04:45,000 –&gt; 00:04:55,000<br>And so the vote countries are going to receive the parts and when they have the parts of all the voters, they’re going to sum this parts and share the sum with the vote countries.</p>
<p>24<br>00:04:55,000 –&gt; 00:05:08,000<br>So here it’s important to know that the sum it looks completely at random. And so by sharing it with the vote countries, the other vote countries they cannot learn anything about the parts that a received.</p>
<p>25<br>00:05:08,000 –&gt; 00:05:14,000<br>So this can show us that the privacy of the voters is maintained.</p>
<p>26<br>00:05:14,000 –&gt; 00:05:25,000<br>So they exchange their votes. And when a vote country has received K sums from other voters, including their part, they can finally compute the winner.</p>
<p>27<br>00:05:25,000 –&gt; 00:05:39,000<br>So using Shemir’s secret sharing again, that box, it will like recompute the sum. And if we get like something that is greater than half of the number of voters, then the winner is one. And if it is less than the winner would be zero.</p>
<p>28<br>00:05:39,000 –&gt; 00:05:42,000<br>And yes, so we finally have a winner.</p>
<p>29<br>00:05:42,000 –&gt; 00:05:54,000<br>Now some of the assumptions of our scheme are first at the voters and the vote countries all are well behave and follow the protocol and their parts some to what they say some, you know, like good intentions.</p>
<p>30<br>00:05:54,000 –&gt; 00:06:00,000<br>And we only handle a fail stop failures with this scheme.</p>
<p>31<br>00:06:00,000 –&gt; 00:06:18,000<br>So yeah, now to handle some of the scenarios first, if we have a unreliable network, a scenario, all of the RPC that we send in our servers are going to be sent periodically until we receive an acknowledgement that it has been received.</p>
<p>32<br>00:06:18,000 –&gt; 00:06:27,000<br>And to handle vote failures, so we need to persist all of the voters like persist the parts that they computed and their vote.</p>
<p>33<br>00:06:27,000 –&gt; 00:06:35,000<br>Because if we like recompute parts and then the vote countries had different parts, then the correctness of the scheme will be done and they would not be able to correct the sum.</p>
<p>34<br>00:06:35,000 –&gt; 00:06:43,000<br>So it’s important to like always share like parts from the same computation and not like change parts.</p>
<p>35<br>00:06:43,000 –&gt; 00:06:50,000<br>Finally, to handle the vote counter failures, here we rely on Shamir secret sharing scheme.</p>
<p>36<br>00:06:50,000 –&gt; 00:06:55,000<br>And so as we mentioned before, we only need K servers to compute the winner.</p>
<p>37<br>00:06:55,000 –&gt; 00:07:01,000<br>So the system is a resilient to N minus K crashes of vote countries.</p>
<p>38<br>00:07:01,000 –&gt; 00:07:09,000<br>And now it is demo time. So I’ll stop sharing screen and share another screen.</p>
<p>39<br>00:07:09,000 –&gt; 00:07:19,000<br>So here is our demo. Basically, we have five voters here. So we have three vote countries, five voters and K is equal to two.</p>
<p>40<br>00:07:19,000 –&gt; 00:07:27,000<br>This means that the network is unreliable. And now if we run it.</p>
<p>41<br>00:07:27,000 –&gt; 00:07:35,000<br>So we got three and we get that the winner is one. We can also crash one of the servers since K is equal to two.</p>
<p>42<br>00:07:35,000 –&gt; 00:07:45,000<br>We can still compute a winner by having only two servers up. And so now if we run it, we get the winner of election is the one again.</p>
<p>43<br>00:07:45,000 –&gt; 00:07:50,000<br>And this is the end of our presentation. Thank you very much for listening and we’ll take some questions.</p>
<p>44<br>00:07:57,000 –&gt; 00:08:12,000<br>Hopefully for you, we ask questions.</p>
<p>45<br>00:08:12,000 –&gt; 00:08:23,000<br>I’m curious how extensively you tested this system. Like do you have you try in a much different field of configurations? Do you have performance numbers?</p>
<p>46<br>00:08:23,000 –&gt; 00:08:37,000<br>Sure. So we did have like different sizes of we create a whole test suite and make sure to test like voter failures, server failures have different like sizes.</p>
<p>47<br>00:08:37,000 –&gt; 00:08:56,000<br>And we don’t have performance numbers. We didn’t test that. But in terms of like failures and different like numbers of voters of vote counters. Yeah, we have a full test suite and that’s we should have put the link and get a forget up, but we can send it to you if you want.</p>
<p>48<br>00:08:56,000 –&gt; 00:09:00,000<br>So you can check like look over implementation.</p>
<p>49<br>00:09:00,000 –&gt; 00:09:10,000<br>And testing.</p>
<p>50<br>00:09:10,000 –&gt; 00:09:13,000<br>And there are no more.</p>
<p>51<br>00:09:13,000 –&gt; 00:09:21,000<br>Can you say something maybe a little bit about like what I do some 6824 where you’re able to apply in the system.</p>
<p>52<br>00:09:21,000 –&gt; 00:09:25,000<br>Other than using the testing framework.</p>
<p>53<br>00:09:25,000 –&gt; 00:09:28,000<br>I kind of do want to take this one or should I say?</p>
<p>54<br>00:09:28,000 –&gt; 00:09:48,000<br>So yeah, here I guess that this is came actually comes from a piece of it from the cryptography class. And so it was fun to look at it from a different perspective. So now we’re not like focusing that much on the security and it but more like, oh, what happens if the individual like servers if they fail.</p>
<p>55<br>00:09:48,000 –&gt; 00:10:04,000<br>So both like handling vote, voter failures handling a vote counter failures problems with the network. I guess we didn’t address specifically partitions because it would work similar to a vote country crashed.</p>
<p>56<br>00:10:04,000 –&gt; 00:10:06,000<br>But yeah, it was.</p>
<p>57<br>00:10:06,000 –&gt; 00:10:12,000<br>Yeah, it was fun to look at this from that perspective.</p>
<p>58<br>00:10:12,000 –&gt; 00:10:15,000<br>Yeah, thanks.</p>
<p>59<br>00:10:15,000 –&gt; 00:10:18,000<br>Yeah, something to say we’re out of time a bit. So.</p>
<p>60<br>00:10:18,000 –&gt; 00:10:22,000<br>Yeah, cool. Awesome. One nice job. Thanks for sharing.</p>
<p>61<br>00:10:22,000 –&gt; 00:10:29,000<br>Okay, actually, we have a presentation on private analytics.</p>
<p>62<br>00:10:29,000 –&gt; 00:10:34,000<br>If Kevin is ready to share it. Awesome. Take it away. Everybody.</p>
<p>63<br>00:10:34,000 –&gt; 00:10:38,000<br>Okay, you guys can hear me and you guys can see my winner. Yes.</p>
<p>64<br>00:10:38,000 –&gt; 00:10:40,000<br>Right. Okay, cool.</p>
<p>65<br>00:10:40,000 –&gt; 00:10:50,000<br>Hello, everyone. I’m Kevin and today I’m going to be presenting this very creative reading system called sis. And this is a system for collecting aggregate statistics in a privacy preserving way.</p>
<p>66<br>00:10:50,000 –&gt; 00:11:01,000<br>And so the last presentation was good leading to my project. So for the most part in 684, we’ve talked about how we can build reliable systems in the presence of visiting or fail stop failures.</p>
<p>67<br>00:11:01,000 –&gt; 00:11:15,000<br>So servers can crash and clients are generally will behave. But from this talk, I hope you learned some new concepts on how you can build systems with stronger entities in the presence of visiting failures on behalf of both clients and serving the system.</p>
<p>68<br>00:11:15,000 –&gt; 00:11:27,000<br>And the main tools that we’re going to use to achieve these guarantees are traffic primitives such as multi party competition and zero knowledge proofs and also distributed computing primitives such as broadcast.</p>
<p>69<br>00:11:27,000 –&gt; 00:11:38,000<br>Okay, so for simplicity, let’s say we just want to build a system that computes songs. So we’re going to have an aggregation server that stores a key value store. So the keys are just going to be indices for some statistics.</p>
<p>70<br>00:11:38,000 –&gt; 00:11:41,000<br>And then the values are going to be tuples of sums.</p>
<p>71<br>00:11:41,000 –&gt; 00:11:52,000<br>And then we’re going to have a bunch of clients. So each client is going to have some identity say it’s client IP address. It’s going to have index of the statistic they want to bump. And then it’s also going to have its private inputs.</p>
<p>72<br>00:11:52,000 –&gt; 00:11:59,000<br>So the most straightforward thing to do is we can just have all the clients send their inputs to the server as is and it can compete the sums.</p>
<p>73<br>00:11:59,000 –&gt; 00:12:09,000<br>That is this is bad because now this leaks everything right the server will learn the clients identity. It’ll learn the index being bumped and learn their private input.</p>
<p>74<br>00:12:09,000 –&gt; 00:12:15,000<br>So we can do a little bit better. We can compete these sums privately if we deploy to non colluding servers.</p>
<p>75<br>00:12:15,000 –&gt; 00:12:20,000<br>And then we’re going to have each client secret share their input to each of these servers.</p>
<p>76<br>00:12:20,000 –&gt; 00:12:27,000<br>So as I said, been the previous presentation. So each server of each secret share alone leaks no information about the clients private input.</p>
<p>77<br>00:12:27,000 –&gt; 00:12:34,000<br>But still the servers can add up these shares and compute a local version of the key value store.</p>
<p>78<br>00:12:34,000 –&gt; 00:12:42,000<br>And the later when the servers want to recover the actual sums, they can combine their local key value stores to reconstruct the global key value store.</p>
<p>79<br>00:12:42,000 –&gt; 00:12:48,000<br>And this is a little bit better. At least if one of these servers is honest and the servers are still going to learn the clients identity.</p>
<p>80<br>00:12:48,000 –&gt; 00:12:57,000<br>They’re still going to learn the clients index. But now instead of learning each individual clients input, they’re going to learn the sums of all clients and inputs.</p>
<p>81<br>00:12:57,000 –&gt; 00:13:04,000<br>Okay, so that’s better. But still a problem, namely that this identity index relation can still leak a lot of information.</p>
<p>82<br>00:13:04,000 –&gt; 00:13:10,000<br>So how can you fix this? We can make things anonymous. So we’re still going to adapt the setup from before.</p>
<p>83<br>00:13:10,000 –&gt; 00:13:14,000<br>But now we’re going to give each server a public key for encryption.</p>
<p>84<br>00:13:14,000 –&gt; 00:13:18,000<br>And that each client is going to encrypt each of their shares.</p>
<p>85<br>00:13:18,000 –&gt; 00:13:25,000<br>And instead of having the client send their shares directly to the servers, now we’re going to have a layer of forwarding proxies in between.</p>
<p>86<br>00:13:25,000 –&gt; 00:13:32,000<br>And so what’s going to happen is the client’s going to send their encrypted shares via broadcast to these are these proxies.</p>
<p>87<br>00:13:32,000 –&gt; 00:13:41,000<br>And the proxies will route each share to the respective servers. And then the aggregation can go as explain.</p>
<p>88<br>00:13:41,000 –&gt; 00:13:43,000<br>And so what are the privacy guarantees here?</p>
<p>89<br>00:13:43,000 –&gt; 00:13:52,000<br>If at least one of these proxies is honest, then the proxy will still learn the clients identity and it’ll learn some timing information based on when the client sent the share.</p>
<p>90<br>00:13:52,000 –&gt; 00:13:58,000<br>But nothing else because these encrypt shares are encrypted to the servers so they’ll learn nothing from that.</p>
<p>91<br>00:13:58,000 –&gt; 00:14:05,000<br>And then if at least one of the servers is honest, then the servers will also learn some timing information based on when the proxy forwarded it.</p>
<p>92<br>00:14:05,000 –&gt; 00:14:09,000<br>It’ll certainly learn the index of the statistic and it’ll learn the sum.</p>
<p>93<br>00:14:09,000 –&gt; 00:14:20,000<br>But most importantly, as long as not both a proxy and a server are compromised at the same time, then this design unlinks the identity from the index being dumped, which is exactly what we wanted.</p>
<p>94<br>00:14:20,000 –&gt; 00:14:30,000<br>So this is great, but this also leads to another problem mainly that now clients can hide behind the privacy and anonymity guarantees of the system to send bad inputs.</p>
<p>95<br>00:14:30,000 –&gt; 00:14:36,000<br>Right. So let’s say the system expected client inputs to be zero and once will behind this real privacy.</p>
<p>96<br>00:14:36,000 –&gt; 00:14:39,000<br>Now the client can send the secret share of like a billion through the system.</p>
<p>97<br>00:14:39,000 –&gt; 00:14:45,000<br>And now it can undetectively skew this sum. So clearly this is bad.</p>
<p>98<br>00:14:45,000 –&gt; 00:14:57,000<br>And fix this we want to make the system more robust. So what we’re going to do is we’re going to have each client generate what’s called a zero knowledge proof or their shares and send these to the servers.</p>
<p>99<br>00:14:57,000 –&gt; 00:15:09,000<br>And then when the servers collect these zero and proofs, they can interactively check that the clients inputs actually the client shares actually reconstruct to some well formed input.</p>
<p>100<br>00:15:09,000 –&gt; 00:15:16,000<br>And because this proof is in zero knowledge, it leaks nothing about the input other than that it’s well formed.</p>
<p>101<br>00:15:16,000 –&gt; 00:15:22,000<br>And so again, our privacy properties stay the same. The proxy still learns that clients identity is still learning some timing information.</p>
<p>102<br>00:15:22,000 –&gt; 00:15:26,000<br>The server learns timing information to learn index and learns the sums.</p>
<p>103<br>00:15:26,000 –&gt; 00:15:32,000<br>But now we’ve protected the system against malicious clients because it’ll only accept well formed inputs.</p>
<p>104<br>00:15:32,000 –&gt; 00:15:43,000<br>And this is great. Still, there’s another problem, which is that servers can crash and we can lose data. So we obviously need both servers to be online in order to reconstruct the global key value store.</p>
<p>105<br>00:15:43,000 –&gt; 00:15:48,000<br>And so if we want to make this system more reliable, we can do what we know best, which is to replicate the servers.</p>
<p>106<br>00:15:48,000 –&gt; 00:15:53,000<br>And so we can use a rast cyber application or we can also use primary backup style of the patient.</p>
<p>107<br>00:15:53,000 –&gt; 00:16:01,000<br>And now the question is, okay, with all this replication, all this cryptographic machinery and all this message ready can we still achieve good throughput.</p>
<p>108<br>00:16:01,000 –&gt; 00:16:08,000<br>And it turns out that we can actually paralyze the server step here that does proof checking aggregation, which is likely to be the bottleneck of the system.</p>
<p>109<br>00:16:08,000 –&gt; 00:16:13,000<br>And so what’s going to happen is the proxies are going to hash partition inputs to each of these servers.</p>
<p>110<br>00:16:13,000 –&gt; 00:16:21,000<br>And then each of these servers in a sort of reduced step will combine their intermediate key value stores to reconstruct the global key value store containing all the sums.</p>
<p>111<br>00:16:21,000 –&gt; 00:16:23,000<br>Okay.</p>
<p>112<br>00:16:23,000 –&gt; 00:16:27,000<br>And so now the final question is, did I implement all of this before the due date?</p>
<p>113<br>00:16:27,000 –&gt; 00:16:35,000<br>Unfortunately, no, but I did make it much of the way there. So I’m going to show a quick demo of the non replicated and non-polliver in a bit.</p>
<p>114<br>00:16:35,000 –&gt; 00:16:43,000<br>So I’m going to quickly switch to my other laptop.</p>
<p>115<br>00:16:43,000 –&gt; 00:16:47,000<br>I get to stop sharing this one first.</p>
<p>116<br>00:16:47,000 –&gt; 00:16:52,000<br>Yes.</p>
<p>117<br>00:16:52,000 –&gt; 00:16:55,000<br>Cool. Okay. So great.</p>
<p>118<br>00:16:55,000 –&gt; 00:17:00,000<br>So on these right two terminals are going to be the servers. I’m going to run them.</p>
<p>119<br>00:17:00,000 –&gt; 00:17:07,000<br>This is implemented in Rust. Now I’m going to hook up these two proxies in the middle.</p>
<p>120<br>00:17:07,000 –&gt; 00:17:12,000<br>And then on the left terminal, I’m just going to simulate a thousand honest clients.</p>
<p>121<br>00:17:12,000 –&gt; 00:17:18,000<br>And so what’s happening is all the clients are generating their input share and generating zero knowledge proofs and send them to the proxies.</p>
<p>122<br>00:17:18,000 –&gt; 00:17:21,000<br>And the proxies are simply forwarding them to the servers.</p>
<p>123<br>00:17:21,000 –&gt; 00:17:25,000<br>And then here, finally, on the server side, they’re going to be checking all of the proofs.</p>
<p>124<br>00:17:25,000 –&gt; 00:17:30,000<br>And if the invaders are in fact, well, for them, it’s going to add it to its local key value store.</p>
<p>125<br>00:17:30,000 –&gt; 00:17:37,000<br>And then at some time later, when these servers want to reconstruct the final statistics, they can just combine their key value source to recover the sums.</p>
<p>126<br>00:17:37,000 –&gt; 00:17:46,000<br>And that’s it for my presentation. And happy to take any questions.</p>
<p>127<br>00:17:46,000 –&gt; 00:17:54,000<br>Any questions from the audience?</p>
<p>128<br>00:17:54,000 –&gt; 00:18:06,000<br>I guess I have a question. So like with what you implemented so far, what sort of like what point do you accept or what point do tolerate failures and like stuff like that?</p>
<p>129<br>00:18:06,000 –&gt; 00:18:12,000<br>Like can you talk about the reliability of your current implementation?</p>
<p>130<br>00:18:12,000 –&gt; 00:18:19,000<br>The reliability of the current implementation is not great mostly because the servers aren’t complicated.</p>
<p>131<br>00:18:19,000 –&gt; 00:18:27,000<br>So for the proxies, because the client’s broadcast the proxies, all we require is that one of the proxies is up.</p>
<p>132<br>00:18:27,000 –&gt; 00:18:34,000<br>So if we have two proxies, we have we can tolerate one failure of the proxies and we’ll still get the messages to the servers.</p>
<p>133<br>00:18:34,000 –&gt; 00:18:42,000<br>And if any of the servers goes down, then you’re just not going to be able to reconstruct on the data for that.</p>
<p>134<br>00:18:42,000 –&gt; 00:18:50,000<br>Is that only for sums or did you implemented for like any general function that operates on all those inputs?</p>
<p>135<br>00:18:50,000 –&gt; 00:18:59,000<br>Yeah, for now. I’ve only implemented it for sums, but basically with this added a secret sharing scheme, you can compute any linear confunction you want.</p>
<p>136<br>00:18:59,000 –&gt; 00:19:04,000<br>And maybe more complex ones are possible, but still haven’t explored those yet.</p>
<p>137<br>00:19:04,000 –&gt; 00:19:11,000<br>Turns out, at least in practice, it sounds probably get you like 90% of the way there.</p>
<p>138<br>00:19:11,000 –&gt; 00:19:22,000<br>So what do you, some of the numbers looked like performance numbers. Yeah. So the main things we want to measure are for the client side client on computation and client bandwidth.</p>
<p>139<br>00:19:22,000 –&gt; 00:19:31,000<br>So I have some numbers at least for client computation, generating these shares and these proofs takes like less than a few milliseconds. So it’s very lightweight.</p>
<p>140<br>00:19:31,000 –&gt; 00:19:44,000<br>The bandwidth is just a few kilobytes. And then for the throughput on the server side, I actually ran on EC2, but I only allocated four cores to each server because I only had 64 cores and I wanted most of them to be on the client.</p>
<p>141<br>00:19:44,000 –&gt; 00:20:04,000<br>So I could remove that bottleneck. And so with four cores, I think, what is that? Probably like 1000 queries per second. And then estimating, I guess, if you parallelize by 20 servers for each logic machine, they can probably achieve close to 22,000 queries per second.</p>
<p>142<br>00:20:04,000 –&gt; 00:20:12,000<br>But this is all around run on the same data center. So it doesn’t factor into latency. So like the actual numbers will probably be a little bit lower than that.</p>
<p>143<br>00:20:12,000 –&gt; 00:20:22,000<br>I had a question about your implementation. How did you do? So how do you actually implement your knowledge proofs and code like non theoretical?</p>
<p>144<br>00:20:22,000 –&gt; 00:20:29,000<br>Yeah, that’s a great question. I can send you the paper that I implemented it out of.</p>
<p>145<br>00:20:29,000 –&gt; 00:20:38,000<br>But it’s not too complicated. Basically, it’s just a bunch of finite field operations. And so if you find your finite field library, just follow the paper and follow the steps.</p>
<p>146<br>00:20:38,000 –&gt; 00:20:44,000<br>It’s a somewhat straightforward from that point, as long as you can decrypt the paper.</p>
<p>147<br>00:20:44,000 –&gt; 00:20:52,000<br>Okay. And is that and if it possible, it’s like test that. Like, how would you know that if working or not working?</p>
<p>148<br>00:20:52,000 –&gt; 00:21:03,000<br>Yeah, so I guess yeah, I only showed the simulation with honest clients, but you could also generate a submission with that with clients that are submit like bad proofs. And then you can see them being rejected.</p>
<p>149<br>00:21:03,000 –&gt; 00:21:05,000<br>Okay, yeah, that makes sense.</p>
<p>150<br>00:21:11,000 –&gt; 00:21:13,000<br>Thanks for your speed.</p>
<p>151<br>00:21:13,000 –&gt; 00:21:18,000<br>Is the next group ready to go?</p>
<p>152<br>00:21:18,000 –&gt; 00:21:21,000<br>Awesome.</p>
<p>153<br>00:21:23,000 –&gt; 00:21:33,000<br>Hello, I’m Shannon and I’m making you on here. So your on ticket away.</p>
<p>154<br>00:21:33,000 –&gt; 00:21:43,000<br>Thank you, Shannon. So what we talking about book at ox. Look at ox is a descriptive collaborative editor. It’s similar to good ox, but just a little bit better.</p>
<p>155<br>00:21:43,000 –&gt; 00:21:46,000<br>So I’m going to come from next.</p>
<p>156<br>00:21:46,000 –&gt; 00:21:48,000<br>Can you like next.</p>
<p>157<br>00:21:48,000 –&gt; 00:21:54,000<br>Okay. So as you have seen in this class, achieving consistency is very hard to do in a district system.</p>
<p>158<br>00:21:54,000 –&gt; 00:22:07,000<br>There are many ways that consistency could go wrong. So a very simple example is if the order that you received RBC is different in each peer, you might end up with an inconsistent state.</p>
<p>159<br>00:22:07,000 –&gt; 00:22:27,000<br>There’s a data structure called CRDT’s which we use in our system to mitigate this issue. CRDT’s achieve eventual consistency by making every single operation that you make on the document globally unique, not just unique to every single peer, but globally unique.</p>
<p>160<br>00:22:27,000 –&gt; 00:22:34,000<br>So if I press the letter A on my editor, it’s different from Shannon or lip pressing the letter A on their editor.</p>
<p>161<br>00:22:34,000 –&gt; 00:22:55,000<br>So for example, here, even if the bottom tier, for example, here, as a new turtle to a document, even if they receive remove requests from the other two gears, they will never remove the golden turtle because the operation is different from remove.</p>
<p>162<br>00:22:55,000 –&gt; 00:23:00,000<br>But remove green turtle is different from remove golden turtle.</p>
<p>163<br>00:23:00,000 –&gt; 00:23:11,000<br>And this, this is how we achieve eventual consistency. So from here, I believe Nick is going to talk a little bit more about what a serial how we implement certainties.</p>
<p>164<br>00:23:12,000 –&gt; 00:23:21,000<br>So for who could box we chose to use a CRDT called LC, which represents a sequence of elements with variable length keys.</p>
<p>165<br>00:23:21,000 –&gt; 00:23:28,000<br>So the goal is let’s say we want a sequence that represents the alphabet and so far we have the letters A and C.</p>
<p>166<br>00:23:28,000 –&gt; 00:23:37,000<br>So one editor might choose to try adding the letter B between them and another editor may choose to try adding the letter D after see.</p>
<p>167<br>00:23:37,000 –&gt; 00:23:42,000<br>So that with eventual consistency, we’ll eventually reach the state ADCD.</p>
<p>168<br>00:23:42,000 –&gt; 00:23:47,000<br>So the way that LC achieves this is by using a start and an end token.</p>
<p>169<br>00:23:47,000 –&gt; 00:23:53,000<br>And then it gives every character in the document, an individual token that is between the start and the end.</p>
<p>170<br>00:23:53,000 –&gt; 00:23:56,000<br>So we can insert H between certain end.</p>
<p>171<br>00:23:56,000 –&gt; 00:24:02,000<br>And if we want the letter I after age, then we can insert that at seven, which is between four and eight.</p>
<p>172<br>00:24:02,000 –&gt; 00:24:06,000<br>So we can insert an exclamation point between I and the end of the document.</p>
<p>173<br>00:24:06,000 –&gt; 00:24:15,000<br>We can insert it with the keys seven comma to to increase key link or to to create a key between two other keys that are adjacent.</p>
<p>174<br>00:24:15,000 –&gt; 00:24:23,000<br>So in this way, we can always create a key between any two other keys. So we can always insert.</p>
<p>175<br>00:24:23,000 –&gt; 00:24:31,000<br>And I’ll seek forms well in that it reaches eventual consistency with very little effort for coordination.</p>
<p>176<br>00:24:31,000 –&gt; 00:24:37,000<br>And it has some optimizations that cause the length of the keys to grow relatively slowly.</p>
<p>177<br>00:24:37,000 –&gt; 00:24:46,000<br>However, some cons are that in order to support deletion of these elements, it relies on causal delivery and exactly once delivery.</p>
<p>178<br>00:24:46,000 –&gt; 00:24:50,000<br>And we didn’t really want to implement this since it was based off a number of other works.</p>
<p>179<br>00:24:50,000 –&gt; 00:24:54,000<br>So these are slightly simpler approach, which was a deletion set.</p>
<p>180<br>00:24:54,000 –&gt; 00:25:04,000<br>So this is a grow only set where we add in elements. So for instance, to delete letters H and I, we would add in 4 set and into this deletion set.</p>
<p>181<br>00:25:04,000 –&gt; 00:25:15,000<br>Then this whole state becomes equivalent to just having the start and end tokens and the acclamation point at key seven to.</p>
<p>182<br>00:25:15,000 –&gt; 00:25:32,000<br>So we build the book of the service similar to how we implemented KV raft. We have multiple servers multiple clients and multiple clients. They only talk to one server at a time and they continuously try the operations until they get a successful reply from the server.</p>
<p>183<br>00:25:32,000 –&gt; 00:25:34,000<br>Okay.</p>
<p>184<br>00:25:34,000 –&gt; 00:25:43,000<br>Clients and servers both maintain an AVL tree of characters in the document as well as our own deletion set of removed keys.</p>
<p>185<br>00:25:43,000 –&gt; 00:25:50,000<br>We chose to store characters in AVL tree for I guess performance reasons.</p>
<p>186<br>00:25:50,000 –&gt; 00:25:56,000<br>The chain of events gives something like this. So the client will send an insertion and deletion to the server.</p>
<p>187<br>00:25:56,000 –&gt; 00:26:01,000<br>A server will update its own AVL tree and deletion set and persist that.</p>
<p>188<br>00:26:01,000 –&gt; 00:26:08,000<br>And for those updates to all the other servers and clients and then the server will respond success to the light.</p>
<p>189<br>00:26:08,000 –&gt; 00:26:16,000<br>So we’re going to demo it. We build a very simple UI for it here.</p>
<p>190<br>00:26:16,000 –&gt; 00:26:19,000<br>So, you know,</p>
<p>191<br>00:26:19,000 –&gt; 00:26:27,000<br>Johan and Nick are also accessing this from different lines right now. So you can see them typing.</p>
<p>192<br>00:26:27,000 –&gt; 00:26:35,000<br>You can type something else. I’m typing here.</p>
<p>193<br>00:26:35,000 –&gt; 00:26:42,000<br>I think Johan is typing high. Nick is typing something here.</p>
<p>194<br>00:26:42,000 –&gt; 00:26:56,000<br>We can edit each other’s.</p>
<p>195<br>00:26:56,000 –&gt; 00:27:06,000<br>We can edit each other’s.</p>
<p>196<br>00:27:06,000 –&gt; 00:27:14,000<br>We can edit each other’s.</p>
<p>197<br>00:27:14,000 –&gt; 00:27:23,000<br>So, I’m going to type in the text.</p>
<p>198<br>00:27:23,000 –&gt; 00:27:31,000<br>I’m going to type in the text.</p>
<p>199<br>00:27:31,000 –&gt; 00:27:38,000<br>I’m going to type in the text.</p>
<p>200<br>00:27:38,000 –&gt; 00:27:48,000<br>So, I’m going to type in the text.</p>
<p>201<br>00:27:48,000 –&gt; 00:27:56,000<br>I’m going to type in the text.</p>
<p>202<br>00:27:56,000 –&gt; 00:28:06,000<br>I’m going to type in the text.</p>
<p>203<br>00:28:06,000 –&gt; 00:28:14,000<br>I’m going to type in the text.</p>
<p>204<br>00:28:14,000 –&gt; 00:28:21,000<br>I’m going to type in the text.</p>
<p>205<br>00:28:21,000 –&gt; 00:28:31,000<br>I’m going to type in the text.</p>
<p>206<br>00:28:31,000 –&gt; 00:28:39,000<br>I’m going to type in the text.</p>
<p>207<br>00:28:39,000 –&gt; 00:28:49,000<br>I’m going to type in the text.</p>
<p>208<br>00:28:49,000 –&gt; 00:28:57,000<br>I’m going to type in the text.</p>
<p>209<br>00:28:57,000 –&gt; 00:29:07,000<br>I’m going to type in the text.</p>
<p>210<br>00:29:07,000 –&gt; 00:29:15,000<br>I’ll see mainly just because it was one of the first ones we found and we wanted to get started.</p>
<p>211<br>00:29:15,000 –&gt; 00:29:25,000<br>So, I’m going to type in the text.</p>
<p>212<br>00:29:25,000 –&gt; 00:29:33,000<br>So, I’m going to type in the text.</p>
<p>213<br>00:29:33,000 –&gt; 00:29:43,000<br>I’m going to type in the text.</p>
<p>214<br>00:29:43,000 –&gt; 00:29:51,000<br>I’m going to type in the text.</p>
<p>215<br>00:29:51,000 –&gt; 00:30:01,000<br>I’m going to type in the text.</p>
<p>216<br>00:30:01,000 –&gt; 00:30:09,000<br>I’m going to type in the text.</p>
<p>217<br>00:30:09,000 –&gt; 00:30:19,000<br>I’m going to type in the text.</p>
<p>218<br>00:30:19,000 –&gt; 00:30:27,000<br>I’m going to type in the text.</p>
<p>219<br>00:30:27,000 –&gt; 00:30:37,000<br>I’m going to type in the text.</p>
<p>220<br>00:30:37,000 –&gt; 00:30:45,000<br>I’m going to type in the text.</p>
<p>221<br>00:30:45,000 –&gt; 00:30:55,000<br>I’m going to type in the text.</p>
<p>222<br>00:30:55,000 –&gt; 00:31:03,000<br>I’m going to type in the text.</p>
<p>223<br>00:31:03,000 –&gt; 00:31:25,000<br>I’m going to type in the text.</p>
<p>224<br>00:31:25,000 –&gt; 00:31:35,000<br>I’m going to type in the text.</p>
<p>225<br>00:31:35,000 –&gt; 00:31:43,000<br>I’m going to type in the text.</p>
<p>226<br>00:31:43,000 –&gt; 00:31:53,000<br>I’m going to type in the text.</p>
<p>227<br>00:31:53,000 –&gt; 00:32:01,000<br>I’m going to type in the text.</p>
<p>228<br>00:32:01,000 –&gt; 00:32:19,000<br>I’m going to type in the text.</p>
<p>229<br>00:32:19,000 –&gt; 00:32:39,000<br>I’m going to type in the text.</p>
<p>230<br>00:32:39,000 –&gt; 00:32:49,000<br>I’m going to type in the text.</p>
<p>231<br>00:32:49,000 –&gt; 00:32:57,000<br>I’m going to type in the text.</p>
<p>232<br>00:32:57,000 –&gt; 00:33:07,000<br>I’m going to type in the text.</p>
<p>233<br>00:33:07,000 –&gt; 00:33:15,000<br>I’m going to type in the text.</p>
<p>234<br>00:33:15,000 –&gt; 00:33:25,000<br>I’m going to type in the text.</p>
<p>235<br>00:33:25,000 –&gt; 00:33:33,000<br>I’m going to type in the text.</p>
<p>236<br>00:33:33,000 –&gt; 00:33:51,000<br>I’m going to type in the text.</p>
<p>237<br>00:33:51,000 –&gt; 00:34:01,000<br>I’m going to type in the text.</p>
<p>238<br>00:34:01,000 –&gt; 00:34:09,000<br>I’m going to type in the text.</p>
<p>239<br>00:34:09,000 –&gt; 00:34:19,000<br>I’m going to type in the text.</p>
<p>240<br>00:34:19,000 –&gt; 00:34:27,000<br>I’m going to type in the text.</p>
<p>241<br>00:34:27,000 –&gt; 00:34:37,000<br>I’m going to type in the text.</p>
<p>242<br>00:34:37,000 –&gt; 00:34:45,000<br>I’m going to type in the text.</p>
<p>243<br>00:34:45,000 –&gt; 00:35:03,000<br>I’m going to type in the text.</p>
<p>244<br>00:35:03,000 –&gt; 00:35:13,000<br>I’m going to type in the text.</p>
<p>245<br>00:35:13,000 –&gt; 00:35:21,000<br>I’m going to type in the text.</p>
<p>246<br>00:35:21,000 –&gt; 00:35:31,000<br>I’m going to type in the text.</p>
<p>247<br>00:35:31,000 –&gt; 00:35:39,000<br>I’m going to type in the text.</p>
<p>248<br>00:35:39,000 –&gt; 00:35:49,000<br>I’m going to type in the text.</p>
<p>249<br>00:35:49,000 –&gt; 00:35:57,000<br>I’m going to type in the text.</p>
<p>250<br>00:35:57,000 –&gt; 00:36:07,000<br>I’m going to type in the text.</p>
<p>251<br>00:36:07,000 –&gt; 00:36:15,000<br>I’m going to type in the text.</p>
<p>252<br>00:36:15,000 –&gt; 00:36:25,000<br>I’m going to type in the text.</p>
<p>253<br>00:36:25,000 –&gt; 00:36:33,000<br>I’m going to type in the text.</p>
<p>254<br>00:36:33,000 –&gt; 00:36:43,000<br>I’m going to type in the text.</p>
<p>255<br>00:36:43,000 –&gt; 00:36:51,000<br>I’m going to type in the text.</p>
<p>256<br>00:36:51,000 –&gt; 00:37:01,000<br>I’m going to type in the text.</p>
<p>257<br>00:37:01,000 –&gt; 00:37:09,000<br>I’m going to type in the text.</p>
<p>258<br>00:37:09,000 –&gt; 00:37:19,000<br>I’m going to type in the text.</p>
<p>259<br>00:37:19,000 –&gt; 00:37:27,000<br>I’m going to type in the text.</p>
<p>260<br>00:37:27,000 –&gt; 00:37:37,000<br>I’m going to type in the text.</p>
<p>261<br>00:37:37,000 –&gt; 00:37:45,000<br>I’m going to type in the text.</p>
<p>262<br>00:37:45,000 –&gt; 00:37:55,000<br>I’m going to type in the text.</p>
<p>263<br>00:37:55,000 –&gt; 00:38:03,000<br>I’m going to type in the text.</p>
<p>264<br>00:38:03,000 –&gt; 00:38:13,000<br>I’m going to type in the text.</p>
<p>265<br>00:38:13,000 –&gt; 00:38:21,000<br>I’m going to type in the text.</p>
<p>266<br>00:38:21,000 –&gt; 00:38:31,000<br>I’m going to type in the text.</p>
<p>267<br>00:38:31,000 –&gt; 00:38:39,000<br>I’m going to type in the text.</p>
<p>268<br>00:38:39,000 –&gt; 00:38:49,000<br>I’m going to type in the text.</p>
<p>269<br>00:38:49,000 –&gt; 00:38:57,000<br>I’m going to type in the text.</p>
<p>270<br>00:38:57,000 –&gt; 00:39:07,000<br>I’m going to type in the text.</p>
<p>271<br>00:39:07,000 –&gt; 00:39:15,000<br>I’m going to type in the text.</p>
<p>272<br>00:39:15,000 –&gt; 00:39:25,000<br>I’m going to type in the text.</p>
<p>273<br>00:39:25,000 –&gt; 00:39:33,000<br>I’m going to type in the text.</p>
<p>274<br>00:39:33,000 –&gt; 00:39:43,000<br>I’m going to type in the text.</p>
<p>275<br>00:39:43,000 –&gt; 00:39:51,000<br>I’m going to type in the text.</p>
<p>276<br>00:39:51,000 –&gt; 00:40:01,000<br>I’m going to type in the text.</p>
<p>277<br>00:40:01,000 –&gt; 00:40:09,000<br>I’m going to type in the text.</p>
<p>278<br>00:40:09,000 –&gt; 00:40:19,000<br>I’m going to type in the text.</p>
<p>279<br>00:40:19,000 –&gt; 00:40:27,000<br>I’m going to type in the text.</p>
<p>280<br>00:40:27,000 –&gt; 00:40:37,000<br>I’m going to type in the text.</p>
<p>281<br>00:40:37,000 –&gt; 00:40:45,000<br>I’m going to type in the text.</p>
<p>282<br>00:40:45,000 –&gt; 00:40:55,000<br>I’m going to type in the text.</p>
<p>283<br>00:40:55,000 –&gt; 00:41:03,000<br>I’m going to type in the text.</p>
<p>284<br>00:41:03,000 –&gt; 00:41:13,000<br>I’m going to type in the text.</p>
<p>285<br>00:41:13,000 –&gt; 00:41:21,000<br>I’m going to type in the text.</p>
<p>286<br>00:41:21,000 –&gt; 00:41:31,000<br>I’m going to type in the text.</p>
<p>287<br>00:41:31,000 –&gt; 00:41:39,000<br>I’m going to type in the text.</p>
<p>288<br>00:41:39,000 –&gt; 00:41:49,000<br>I’m going to type in the text.</p>
<p>289<br>00:41:49,000 –&gt; 00:41:57,000<br>I’m going to type in the text.</p>
<p>290<br>00:41:57,000 –&gt; 00:42:07,000<br>I’m going to type in the text.</p>
<p>291<br>00:42:07,000 –&gt; 00:42:15,000<br>I’m going to type in the text.</p>
<p>292<br>00:42:15,000 –&gt; 00:42:25,000<br>I’m going to type in the text.</p>
<p>293<br>00:42:25,000 –&gt; 00:42:33,000<br>I’m going to type in the text.</p>
<p>294<br>00:42:33,000 –&gt; 00:42:43,000<br>I’m going to type in the text.</p>
<p>295<br>00:42:43,000 –&gt; 00:42:51,000<br>I’m going to type in the text.</p>
<p>296<br>00:42:51,000 –&gt; 00:43:11,000<br>I’m going to type in the text.</p>
<p>297<br>00:43:11,000 –&gt; 00:43:21,000<br>I’m going to type in the text.</p>
<p>298<br>00:43:21,000 –&gt; 00:43:29,000<br>I’m going to type in the text.</p>
<p>299<br>00:43:29,000 –&gt; 00:43:39,000<br>I’m going to type in the text.</p>
<p>300<br>00:43:39,000 –&gt; 00:43:47,000<br>I’m going to type in the text.</p>
<p>301<br>00:43:47,000 –&gt; 00:43:57,000<br>I’m going to type in the text.</p>
<p>302<br>00:43:57,000 –&gt; 00:44:07,000<br>I’m going to type in the text.</p>
<p>303<br>00:44:07,000 –&gt; 00:44:15,000<br>I’m going to type in the text.</p>
<p>304<br>00:44:15,000 –&gt; 00:44:25,000<br>I’m going to type in the text.</p>
<p>305<br>00:44:25,000 –&gt; 00:44:33,000<br>I’m going to type in the text.</p>
<p>306<br>00:44:33,000 –&gt; 00:44:43,000<br>I’m going to type in the text.</p>
<p>307<br>00:44:43,000 –&gt; 00:44:51,000<br>I’m going to type in the text.</p>
<p>308<br>00:44:51,000 –&gt; 00:45:01,000<br>I’m going to type in the text.</p>
<p>309<br>00:45:01,000 –&gt; 00:45:09,000<br>I’m going to type in the text.</p>
<p>310<br>00:45:09,000 –&gt; 00:45:19,000<br>I’m going to type in the text.</p>
<p>311<br>00:45:19,000 –&gt; 00:45:27,000<br>I’m going to type in the text.</p>
<p>312<br>00:45:27,000 –&gt; 00:45:37,000<br>I’m going to type in the text.</p>
<p>313<br>00:45:37,000 –&gt; 00:45:45,000<br>I’m going to type in the text.</p>
<p>314<br>00:45:45,000 –&gt; 00:45:55,000<br>I’m going to type in the text.</p>
<p>315<br>00:45:55,000 –&gt; 00:46:03,000<br>I’m going to type in the text.</p>
<p>316<br>00:46:03,000 –&gt; 00:46:13,000<br>I’m going to type in the text.</p>
<p>317<br>00:46:13,000 –&gt; 00:46:21,000<br>I’m going to type in the text.</p>
<p>318<br>00:46:21,000 –&gt; 00:46:31,000<br>I’m going to type in the text.</p>
<p>319<br>00:46:31,000 –&gt; 00:46:39,000<br>I’m going to type in the text.</p>
<p>320<br>00:46:39,000 –&gt; 00:46:49,000<br>I’m going to type in the text.</p>
<p>321<br>00:46:49,000 –&gt; 00:46:57,000<br>I’m going to type in the text.</p>
<p>322<br>00:46:57,000 –&gt; 00:47:07,000<br>I’m going to type in the text.</p>
<p>323<br>00:47:07,000 –&gt; 00:47:15,000<br>I’m going to type in the text.</p>
<p>324<br>00:47:15,000 –&gt; 00:47:25,000<br>I’m going to type in the text.</p>
<p>325<br>00:47:25,000 –&gt; 00:47:33,000<br>I’m going to type in the text.</p>
<p>326<br>00:47:33,000 –&gt; 00:47:43,000<br>I’m going to type in the text.</p>
<p>327<br>00:47:43,000 –&gt; 00:47:51,000<br>I’m going to type in the text.</p>
<p>328<br>00:47:51,000 –&gt; 00:48:01,000<br>I’m going to type in the text.</p>
<p>329<br>00:48:01,000 –&gt; 00:48:09,000<br>I’m going to type in the text.</p>
<p>330<br>00:48:09,000 –&gt; 00:48:19,000<br>I’m going to type in the text.</p>
<p>331<br>00:48:19,000 –&gt; 00:48:27,000<br>I’m going to type in the text.</p>
<p>332<br>00:48:27,000 –&gt; 00:48:37,000<br>I’m going to type in the text.</p>
<p>333<br>00:48:37,000 –&gt; 00:48:45,000<br>I’m going to type in the text.</p>
<p>334<br>00:48:45,000 –&gt; 00:48:55,000<br>I’m going to type in the text.</p>
<p>335<br>00:48:55,000 –&gt; 00:49:03,000<br>I’m going to type in the text.</p>
<p>336<br>00:49:03,000 –&gt; 00:49:13,000<br>I’m going to type in the text.</p>
<p>337<br>00:49:13,000 –&gt; 00:49:21,000<br>I’m going to type in the text.</p>
<p>338<br>00:49:21,000 –&gt; 00:49:31,000<br>I’m going to type in the text.</p>
<p>339<br>00:49:31,000 –&gt; 00:49:39,000<br>I’m going to type in the text.</p>
<p>340<br>00:49:39,000 –&gt; 00:49:49,000<br>I’m going to type in the text.</p>
<p>341<br>00:49:49,000 –&gt; 00:49:57,000<br>I’m going to type in the text.</p>
<p>342<br>00:49:57,000 –&gt; 00:50:07,000<br>I’m going to type in the text.</p>
<p>343<br>00:50:07,000 –&gt; 00:50:15,000<br>This is actually connecting to an s3 bucket that we have.</p>
<p>344<br>00:50:15,000 –&gt; 00:50:29,000<br>If I want to create a new key, or I need to do is say cat.</p>
<p>345<br>00:50:29,000 –&gt; 00:50:43,000<br>Instead of having to use AWS’s custom library in order to write a file system or do a file system operation to create a file and write to it.</p>
<p>346<br>00:50:43,000 –&gt; 00:50:53,000<br>Then an s3 should show up as a new key now.</p>
<p>347<br>00:50:53,000 –&gt; 00:51:01,000<br>Where does the fault tolerance part come in here?</p>
<p>348<br>00:51:01,000 –&gt; 00:51:11,000<br>The fault tolerance part comes in here.</p>
<p>349<br>00:51:11,000 –&gt; 00:51:25,000<br>We can slice it this 9p interface to replicate and modify services.</p>
<p>350<br>00:51:25,000 –&gt; 00:51:35,000<br>If I am able to replicate all these operations to different instances of service, then the service gets replicated pretty without having to modify it at all.</p>
<p>351<br>00:51:35,000 –&gt; 00:51:45,000<br>I use the name D as configuration service.</p>
<p>352<br>00:51:45,000 –&gt; 00:51:47,000<br>You can think this is a kind of zookeeper.</p>
<p>353<br>00:51:47,000 –&gt; 00:51:59,000<br>I replicate two different services without any modification and in memory file system and a service which exposes durable storage from local machines.</p>
<p>354<br>00:51:59,000 –&gt; 00:52:11,000<br>I’ll quickly show them that.</p>
<p>355<br>00:52:11,000 –&gt; 00:52:33,000<br>For example, I can start off a bunch of replicas.</p>
<p>356<br>00:52:33,000 –&gt; 00:52:45,000<br>If I look into the 9p namespace, you see this mammothized replica.</p>
<p>357<br>00:52:45,000 –&gt; 00:52:59,000<br>I can see that we have five replicas up.</p>
<p>358<br>00:52:59,000 –&gt; 00:53:13,000<br>I can read from another one of the replicas and we should get the same result out.</p>
<p>359<br>00:53:13,000 –&gt; 00:53:23,000<br>I can even crash in replicas.</p>
<p>360<br>00:53:23,000 –&gt; 00:53:33,000<br>Let’s kill one of these guys.</p>
<p>361<br>00:53:33,000 –&gt; 00:53:43,000<br>We can see that there are only four replicas left now in the name space.</p>
<p>362<br>00:53:43,000 –&gt; 00:53:53,000<br>I can then write a difference to this file.</p>
<p>363<br>00:53:53,000 –&gt; 00:54:03,000<br>I can see that there are only three replicas left.</p>
<p>364<br>00:54:03,000 –&gt; 00:54:13,000<br>I can see that there are only three replicas left.</p>
<p>365<br>00:54:13,000 –&gt; 00:54:23,000<br>I think that’s sort of concludes my presentation.</p>
<p>366<br>00:54:23,000 –&gt; 00:54:33,000<br>I’d be happy to say any more questions.</p>
<p>367<br>00:54:33,000 –&gt; 00:54:37,000<br>Evergrette not wearing my plan nine shirt this time.</p>
<p>368<br>00:54:37,000 –&gt; 00:54:47,000<br>I’m curious though.</p>
<p>369<br>00:54:47,000 –&gt; 00:54:53,000<br>I worked on something that was similar earlier this semester, except there was no replication.</p>
<p>370<br>00:54:53,000 –&gt; 00:55:01,000<br>I imagine there are other replication schemes that are available for this sort of a thing.</p>
<p>371<br>00:55:01,000 –&gt; 00:55:11,000<br>I think there are other replicas over the same namespace that look like a small machine.</p>
<p>372<br>00:55:11,000 –&gt; 00:55:21,000<br>I just did chain replication because it seemed like a simple starting point, I guess.</p>
<p>373<br>00:55:21,000 –&gt; 00:55:31,000<br>I could also throw this on top of a rough computation like the F from class or anything like that.</p>
<p>374<br>00:55:31,000 –&gt; 00:55:37,000<br>Does your system support adding additional replicas after it started?</p>
<p>375<br>00:55:37,000 –&gt; 00:55:45,000<br>Yeah, great question. So currently no, that’s a working progress.</p>
<p>376<br>00:55:45,000 –&gt; 00:55:57,000<br>But yeah, currently we don’t support adding additional replicas out of box.</p>
<p>377<br>00:55:57,000 –&gt; 00:56:06,000<br>This is an open question. It’s sort of like that you may not have this is this wasn’t the express intended the purpose, but one of the things that’s really cool about plan nine and 9 p is that you treat network connections like their files as well.</p>
<p>378<br>00:56:06,000 –&gt; 00:56:14,000<br>So you’re like you have like my my best you have from what I saw a scheduler to you that was implemented to set a files.</p>
<p>379<br>00:56:14,000 –&gt; 00:56:22,000<br>Do you and this is sort of an open question because the question of whether network stuff over file interfaces is scalable is difficult to answer.</p>
<p>380<br>00:56:22,000 –&gt; 00:56:33,000<br>But do you also implement this in sort of that way or do you use more traditional positive in devices to like when the clients use this thing they presume they use traditional sockets and things to communicate.</p>
<p>381<br>00:56:33,000 –&gt; 00:56:44,000<br>Yeah, yeah, yeah, no good question. So yeah, everything. So all the clients and services communicate over TCP at the moment.</p>
<p>382<br>00:56:44,000 –&gt; 00:56:51,000<br>And yeah, it is a good question as to whether the 9 p interface is actually going to be performed enough for what we’re going to do with it.</p>
<p>383<br>00:56:51,000 –&gt; 00:56:55,000<br>As far as we can see now there’s not.</p>
<p>384<br>00:56:55,000 –&gt; 00:57:05,000<br>So we’ve done some performance benchmarking to see how well like we’ve written a scheduler over 9 p.</p>
<p>385<br>00:57:05,000 –&gt; 00:57:20,000<br>And we’ve done some performance benchmarking to see how it performs and it seems to not add a ton of overhead at the moment, but a we can imagine those trade off changing for different types of services and as the scheduler becomes more less of a subscriber.</p>
<p>386<br>00:57:21,000 –&gt; 00:57:43,000<br>I guess I guess to clarify so sorry I’m taking up some take it up a lot of your time, but just briefly the whole 9 p if you if you were able to and this is again very open, but if you were able to treat network connections as files you have replicas right you could have something for each card and then shard network traffic over those network cards, which I guess this is serverless anyway, so probably doesn’t make that much difference.</p>
<p>387<br>00:57:43,000 –&gt; 00:57:46,000<br>Yeah, forget it.</p>
<p>388<br>00:57:46,000 –&gt; 00:57:51,000<br>Because you already have the handles for you.</p>
<p>389<br>00:57:51,000 –&gt; 00:57:53,000<br>Thank you.</p>
<p>390<br>00:57:53,000 –&gt; 00:57:55,000<br>Thank you.</p>
<p>391<br>00:57:55,000 –&gt; 00:58:00,000<br>All right, so let’s hear about some verification stuff.</p>
<p>392<br>00:58:00,000 –&gt; 00:58:03,000<br>If you’re ready.</p>
<p>393<br>00:58:03,000 –&gt; 00:58:05,000<br>Can you guys hear me?</p>
<p>394<br>00:58:05,000 –&gt; 00:58:06,000<br>Yes.</p>
<p>395<br>00:58:06,000 –&gt; 00:58:08,000<br>All right, excellent.</p>
<p>396<br>00:58:08,000 –&gt; 00:58:15,000<br>So indeed, I’m going to talk to you about my project which is focused on modular verification for distributed systems.</p>
<p>397<br>00:58:15,000 –&gt; 00:58:21,000<br>Let’s start by answering the obvious question, which is why bother with any other stuff.</p>
<p>398<br>00:58:21,000 –&gt; 00:58:29,000<br>And I think anyone that’s worked on the labs for eight to four must have discovered at some point that getting distributed systems right is hard.</p>
<p>399<br>00:58:29,000 –&gt; 00:58:33,000<br>There’s a lot of non-atermism caused by concurrency and network failure.</p>
<p>400<br>00:58:33,000 –&gt; 00:58:44,000<br>And that makes it very difficult to exhaust the test to make sure that there’s no corner case bugs verification is an alternative to you know alternative approaches testing to try and get correctness.</p>
<p>401<br>00:58:44,000 –&gt; 00:58:48,000<br>And in principle, it can entirely rule out bugs with verification.</p>
<p>402<br>00:58:48,000 –&gt; 00:58:54,000<br>You basically mathematically model your system and improve some theorem about that model.</p>
<p>403<br>00:58:54,000 –&gt; 00:59:03,000<br>And you know, one of the the downs of the verification is that it’s quite a lot of work during these formal proofs is by no means easy.</p>
<p>404<br>00:59:03,000 –&gt; 00:59:09,000<br>And even if it was easy verification still wouldn’t be a perfect silver bullet for one in verification.</p>
<p>405<br>00:59:09,000 –&gt; 00:59:12,000<br>You have to make sure that you get your specification right.</p>
<p>406<br>00:59:12,000 –&gt; 00:59:20,000<br>If the mathematical theorem you’re proving by your system doesn’t actually say what you really wanted it to say, then what you’ve proved is useless.</p>
<p>407<br>00:59:20,000 –&gt; 00:59:25,000<br>And relatedly, you have to make sure that the model that you have to your system is also complete.</p>
<p>408<br>00:59:25,000 –&gt; 00:59:35,000<br>If you fail to model some execution that can happen reality, but that you don’t consider, then your theorem won’t apply to to the real world.</p>
<p>409<br>00:59:35,000 –&gt; 00:59:42,000<br>And some of you that are familiar with some distributed verification work might say, oh, don’t we already know how to do this.</p>
<p>410<br>00:59:42,000 –&gt; 00:59:51,000<br>Indeed, distributed systems have always been hard and people have recently worked on projects to try to verify actual implementation of the service systems.</p>
<p>411<br>00:59:51,000 –&gt; 00:59:54,000<br>So some of these projects include iron fleets and birdie.</p>
<p>412<br>00:59:54,000 –&gt; 01:00:04,000<br>However, these projects didn’t focus much on modularity or trying to prove reusable specifications for components of systems, try to build more complicated systems out of them.</p>
<p>413<br>01:00:05,000 –&gt; 01:00:09,000<br>And I’d argue that that’s the way that distributed systems are actually built.</p>
<p>414<br>01:00:09,000 –&gt; 01:00:25,000<br>The way you build a distributed system is by oftentimes using building blocks like key value services and lock services or zookeeper and putting them together with some added code and novel functionality to build your more interesting and more useful system.</p>
<p>415<br>01:00:25,000 –&gt; 01:00:32,000<br>And our sort of thesis, if you will, is that verification can and should exploit this compositionality.</p>
<p>416<br>01:00:33,000 –&gt; 01:00:50,000<br>As one sort of target goal, we aim to prove specifications for clients of systems prior work like iron fleets and birdie, simply a reason about what the behavior of the actual server side to school, like, and don’t explicitly model or prove anything about what the client programs actually do.</p>
<p>417<br>01:00:50,000 –&gt; 01:00:55,000<br>And oftentimes there’s a bit of logic in the client that’s crucial for getting correctness.</p>
<p>418<br>01:00:55,000 –&gt; 01:01:10,000<br>The approach we use is to use advances in concurrent separation logic, which is a compositional means of reasoning about concurrent programs that’s lately become popular for popular and then demonstrate to be successful at the reason about real code.</p>
<p>419<br>01:01:10,000 –&gt; 01:01:15,000<br>So the first example that we worked on was verifying a charted key value system.</p>
<p>420<br>01:01:15,000 –&gt; 01:01:23,000<br>The keys in this are, you know, statically split up into shards and shards themselves can be moved between the shard servers.</p>
<p>421<br>01:01:23,000 –&gt; 01:01:32,000<br>So it’s very similar to lab four of eight to four, except that it’s not replicated so there’s no, there’s no raft ring in this and it’s purely in memory.</p>
<p>422<br>01:01:32,000 –&gt; 01:01:45,000<br>And besides that our system also has shard servers and a coordinator server and the coordinator is the one that tells other shard servers to move shard between themselves as you know what to join or as you need to read balance.</p>
<p>423<br>01:01:45,000 –&gt; 01:02:03,000<br>The top of a library that we provide and that we want to prove a specification for is you know we call it a key to clerk, which is to client object that one can use and can call these three functions on to actually interact with the server so that you know there’s a put you say what value what put in the key there’s a get which will return the current value in the key.</p>
<p>424<br>01:02:03,000 –&gt; 01:02:11,000<br>And then there’s a conditional put which will only put the new value if the old value is the expected one.</p>
<p>425<br>01:02:11,000 –&gt; 01:02:26,000<br>And we aim to basically implement and implement a linearizable key value service and the proof a specification that shows it’s linearizable and the way you do this and the separation logic style is basically by right amount specification to look a lot like this.</p>
<p>426<br>01:02:26,000 –&gt; 01:02:49,000<br>This basically says that if you know the object CK is a key value clerk, then you have you know specifications for the put and get functions that say, for example, if you start running the put function with the precondition that K key has value w then by the end of it you’ll know that K key has K as value V.</p>
<p>427<br>01:02:49,000 –&gt; 01:02:59,000<br>Similarly, if you do a get and you know that key K has value V at the beginning, then that’s the thing that’s going to be returned and you’re still going to know that that’s the value of the key.</p>
<p>428<br>01:02:59,000 –&gt; 01:03:18,000<br>And these specifications look pretty simple and like you know I think like of course that’s what the key value service does and that’s sort of the point that these top level client specifications are as simple as they can be and and basically hide all the details of the fact that there’s multiple sharp servers and that this clerk library might need to talk to servers multiple times.</p>
<p>429<br>01:03:18,000 –&gt; 01:03:35,000<br>If I need to refresh its information about which server owns the you know which keys and we basically you know prove the spec that allows you to forget all that and use the key values service just by calling these puts and gets and having this idealized notion of what the key value mapping actually looks like.</p>
<p>430<br>01:03:35,000 –&gt; 01:03:39,000<br>So I won’t talk too much more in detail about what the actual proof looks like.</p>
<p>431<br>01:03:39,000 –&gt; 01:03:47,000<br>And instead of focused to should focus towards the next thing we were just doing, which is actually doing something with a bit of false tolerance to this.</p>
<p>432<br>01:03:47,000 –&gt; 01:04:01,000<br>So like I mentioned the key value service itself is not replicated and isn’t false tolerant and so we started by trying to figure out how to verify the simplest possible false tolerance sort of protocol and we basically started with single degree packs.</p>
<p>433<br>01:04:01,000 –&gt; 01:04:05,000<br>Single degree back so as a classic protocol for getting concepts on a single value.</p>
<p>434<br>01:04:05,000 –&gt; 01:04:17,000<br>So whereas with a raft you can get you replicate entire log and you keep upending new entries to log single degree packs is the the crux of multi packs and basically functions of right once register.</p>
<p>435<br>01:04:17,000 –&gt; 01:04:29,000<br>If you want to set the value to something you can attempt to to write to it and if someone else beat you then you know that’s too bad for you and now the values already been decided and it’s never going to change again.</p>
<p>436<br>01:04:29,000 –&gt; 01:04:38,000<br>So we implemented and partially verified a single degree packs of simple notation and basically prove a specification that shows that it’s a right once register.</p>
<p>437<br>01:04:38,000 –&gt; 01:04:54,000<br>And the key idea in the specification and the proof is that when you commit value in single degree packs you get irrevocable knowledge of what that committed value is and you basically know that from here on out if anybody else ever sees any committed value.</p>
<p>438<br>01:04:54,000 –&gt; 01:04:58,000<br>And the same thing that you see right now.</p>
<p>439<br>01:04:58,000 –&gt; 01:05:02,000<br>And thinking about this a little bit after we worked on the proof a bit.</p>
<p>440<br>01:05:02,000 –&gt; 01:05:12,000<br>We started thinking that we sort of notice that there’s a slight generalization you can do to single degree packs which we call monotone packs for lack of a better name.</p>
<p>441<br>01:05:12,000 –&gt; 01:05:25,000<br>So the idea is rather than gaining knowledge about the exact value upon a commit you instead can we modify the protocol so that you only gain a knowledge about a lower bound on value.</p>
<p>442<br>01:05:25,000 –&gt; 01:05:40,000<br>So basically when you commit a value for example if you commit the number 15 to this right once register rather than knowing that 15 is the only value anybody else in the future is ever going to see you’ll know that any value that people see in the future as committed is going to be at least 15.</p>
<p>443<br>01:05:40,000 –&gt; 01:05:46,000<br>And so of course doing this requires having some notion of what larger than actually means for the value type.</p>
<p>444<br>01:05:46,000 –&gt; 01:06:02,000<br>And the key idea is a replica can always find out with the latest committed value is and choose to increase it and other replicas can continually find out larger and larger lower bounds on basically what the value so far is.</p>
<p>445<br>01:06:02,000 –&gt; 01:06:27,000<br>And once we sort of came up with this idea of monotone packs we realized immediately that we can do log replication with this so the set of values V we can choose to simply be all the logs that you might want to replicate your logs of operations and we can define one log to be bigger than another one if the smaller one is a prefix of you know it’s all one of the prefix about to.</p>
<p>446<br>01:06:27,000 –&gt; 01:06:45,000<br>And this basically allows us to you know this sort of yields a protocol which you’ll sort of have to trust me to not really showing you the code for it in which you can gain information about what the prefix of the log is and over time you can add new things to log by making it larger and larger and that’s pretty much exactly what we mean when we say long replication.</p>
<p>447<br>01:06:46,000 –&gt; 01:07:14,000<br>The problem with this exact protocol is that naively if we sort of implement the most naive version of this monotone taxes thing you would need to send around the full log and every single RPC in single degree taxes you send around the full value on all the RPCs and the you know trivial generalization of it to monotone taxes would have you send around the full log that’s not really useful to log and get larger and larger and larger and you know the beginning of log is no longer relevant by the time everybody’s agreed to commit it and and all that.</p>
<p>448<br>01:07:14,000 –&gt; 01:07:32,000<br>So you could try to optimize this by only passing around a suffix of the log and indeed there’s a whole you know sequence of optimizations you can make to this monotone taxos based long replication and as you start doing more and more of this you’ll realize that this looked exactly like ratch and in fact.</p>
<p>449<br>01:07:32,000 –&gt; 01:08:01,000<br>We aim basically to use our idea of monotone taxes not to implement a new replication protocol but rather to verify a raft like system so you know we have this proof for single degree taxes we have this clear generalization to this monotone taxes thing and our hope is that we can use the idea of monotone taxes to basically verify raft directly as opposed to relying on the much more complicated correctness arguments for raft that have been described in sort of other state machine type styles.</p>
<p>450<br>01:08:02,000 –&gt; 01:08:20,000<br>So this is sort of our future work and the key takeaway I sort of want to leave leave you guys with is that reasoning both formal and informal about distributed systems should be as compositional as writing code is the way you scale writing code is modularity and that’s the way reasoning should also scale.</p>
<p>451<br>01:08:22,000 –&gt; 01:08:26,000<br>And that’s all for my presentation i’m happy to take questions.</p>
<p>452<br>01:08:33,000 –&gt; 01:08:45,000<br>If the answer is too long you cannot like link me in the chat but I was curious I know there’s a class in this but do you have any resources for somebody interested in getting into at the from a software perspective like any brief recommendations.</p>
<p>453<br>01:08:46,000 –&gt; 01:09:01,000<br>Are you so yeah I guess i’m not quite sure what the so are you interested in like I should mess with the effort but like if you’re interested I guess in the sort of most lightweight version of verification I think daffney is a great tool to learn because it’s.</p>
<p>454<br>01:09:02,000 –&gt; 01:09:20,000<br>A pretty simple starting point you can write sort of real code and get a feel for things I think a lot of it a lot of verification is pretty academic and not super close to being really useful really verification like this so i’m not sure how useful it really would be for real software during just yet so the hope is that one day it will be.</p>
<p>455<br>01:09:20,000 –&gt; 01:09:21,000<br>Thanks.</p>
<p>456<br>01:09:24,000 –&gt; 01:09:29,000<br>Did you implement this version of taxes you’re talking about.</p>
<p>457<br>01:09:30,000 –&gt; 01:09:32,000<br>This monotone taxes thing.</p>
<p>458<br>01:09:32,000 –&gt; 01:09:57,000<br>So yeah I implemented rather than implementing like a generic monotone taxes thing which wouldn’t really make sense and go anyways I implemented directly the log replication over monotone taxes so in you know in this monotone this monotone log replication thing all the rpc center on the full log so if you run it for a long time it’s going to get way too slow because the rpc’s are sending too much stuff but yeah I did implement it and I think we’re working on actually trying to reason about it.</p>
<p>459<br>01:09:57,000 –&gt; 01:10:05,000<br>Basically did you manage to fear how forward actions that being or how well works in practice.</p>
<p>460<br>01:10:06,000 –&gt; 01:10:12,000<br>So I think the exact code that we have right now is not code you want to run and my.</p>
<p>461<br>01:10:12,000 –&gt; 01:10:21,000<br>In a sense it’s it ought to be as performant as raft sort of is and we don’t really have an optimization it’s all I haven’t actually bothered getting performance numbers for it at all.</p>
<p>462<br>01:10:22,000 –&gt; 01:10:24,000<br>It’s probably pretty slow not really sure.</p>
<p>463<br>01:10:28,000 –&gt; 01:10:30,000<br>Great thank you.</p>
<p>464<br>01:10:30,000 –&gt; 01:10:40,000<br>Yeah even if we verify my programs and sure all this will lock somewhere but that’s here from pp2 now.</p>
<p>465<br>01:10:40,000 –&gt; 01:10:47,000<br>All right number one C.</p>
<p>466<br>01:10:47,000 –&gt; 01:11:02,000<br>Great so we are the pigeon protocol to me and me and Jay to me and we are we present a simple distributed file system.</p>
<p>467<br>01:11:02,000 –&gt; 01:11:12,000<br>And the reason we selected a distributed file system is that users oftentimes want to sort data privately in a really accessible way without the implications of using the cloud company where you don’t own your own data.</p>
<p>468<br>01:11:13,000 –&gt; 01:11:20,000<br>So we wanted to create a solution where you self host your data in a fault tolerant distributed manner on commodity hardware.</p>
<p>469<br>01:11:21,000 –&gt; 01:11:29,000<br>And our file system is really similar to frangipani except that it uses raft and sort of pedal and the file system is on the servers instead of the clients.</p>
<p>470<br>01:11:29,000 –&gt; 01:11:36,000<br>In terms of files and parameters we also have a 44,096 byte block size and a two megabyte maximum file size.</p>
<p>471<br>01:11:37,000 –&gt; 01:11:43,000<br>We theoretically have a 32 gigabyte maximum disk capacity however this is actually constrained by your RAM so if you only have eight gigabytes of RAM.</p>
<p>472<br>01:11:44,000 –&gt; 01:11:49,000<br>You would have however much is left over after your after whatever your system takes up.</p>
<p>473<br>01:11:50,000 –&gt; 01:12:03,000<br>And we support as many servers and clients as we can within reason obviously the more servers and clients that you add due to locking contention there will be less performance as you start to access the same file over and over again.</p>
<p>474<br>01:12:04,000 –&gt; 01:12:18,000<br>And in terms of performance while we were very heavily focused on availability and crash recovery so we didn’t we didn’t measure performance and we think it’s probably pretty bad because our system is built on top of raft which is not known to be the most performant of systems.</p>
<p>475<br>01:12:20,000 –&gt; 01:12:22,000<br>So over to Jay.</p>
<p>476<br>01:12:23,000 –&gt; 01:12:35,000<br>So again for performance is not the biggest thing that we have but we do have very very strong consistency guarantees in particular we enforce positive consistency which is a form of strong consistency you usually see on local file systems.</p>
<p>477<br>01:12:35,000 –&gt; 01:12:45,000<br>So we enforce the invariant that after a file right after you do a successful file right any read of your previously written bytes from anywhere will return the data specified by that previous right.</p>
<p>478<br>01:12:45,000 –&gt; 01:12:52,000<br>Similarly any new rights over that data will be will result in visible over rights of that data from the perspective of other readers.</p>
<p>479<br>01:12:53,000 –&gt; 01:13:08,000<br>So in order to achieve this we have a data mode journal that is built into this sort of block layer that is again distributed with raft and replicated and which is effectively a right ahead log that guarantees the adamacy of rights strong semantics and the presence of crashes the same as raft pretty much.</p>
<p>480<br>01:13:08,000 –&gt; 01:13:19,000<br>And also the concurrent the consistency model that we offer above so servers also in order to help with this we issued distributed blocking so we can have this very primitive block cache as you would see in a local file system.</p>
<p>481<br>01:13:19,000 –&gt; 01:13:24,000<br>And also you have you know we’ve leases to make sure that there’s mutually exclusive access to all of these blocks.</p>
<p>482<br>01:13:25,000 –&gt; 01:13:44,000<br>Right so to allow our clients to use our file system we created a positive like interface where users can interact with files we mainly have four functions open closed read and write open and close our pretty explanatory they just open and close file descriptors on our file system.</p>
<p>483<br>01:13:44,000 –&gt; 01:14:02,000<br>Read it just takes a file descriptor and read the fixed number of bytes at the current file position right also takes a file descriptor and read and flushes sorry right takes a file descriptor and just writes the data to the file notice.</p>
<p>484<br>01:14:02,000 –&gt; 01:14:12,000<br>But it’s in a different way than a normal posics right because a instead flushes the buffer copy of the file and then depends the new data on this.</p>
<p>485<br>01:14:12,000 –&gt; 01:14:28,000<br>So instead of a normal posics right where we just write to a file descriptor with a buffer and the number of bytes to write it does what I just said instead and we have a demo to represent clients interactable to system.</p>
<p>486<br>01:14:28,000 –&gt; 01:14:42,000<br>So this is just a quick demonstration of our files has been being run both serially and concurrently so what’s going to happen is console one or I should say left console is going to open up a file called TT just testing thing.</p>
<p>487<br>01:14:42,000 –&gt; 01:14:55,000<br>It’s going to write something to the file and then the console on the right is going to read from it afterwards per the consistency model they should see the same thing as the left console wrote and indeed after a minute.</p>
<p>488<br>01:14:56,000 –&gt; 01:15:14,000<br>We see that okay so the next thing that’s going to happen is both console one and console two are going to try to flush their local copies of this file at the same time this is not a traditional posics right they’re both taking the copies of the file they have and trying to put them on to disk at the same time.</p>
<p>489<br>01:15:14,000 –&gt; 01:15:38,000<br>So it’s sort of like two rights from offset zero one of these is going to win and we can look at the log on the left console as it commits and actually see after a moment that both transactions run concurrently they both take up different parts of the log but at the end of the day the left consoles transaction is going to win so they was completely atomic everything works.</p>
<p>490<br>01:15:44,000 –&gt; 01:16:12,000<br>So I think you got muted sorry I muted due to time there are more there’s some limitations and features we can add to our file system so firstly we only have one route directory so adding more will definitely be a plus next we only we should persist blocks to disk rather than RAM because that’s what we’re currently doing.</p>
<p>491<br>01:16:12,000 –&gt; 01:16:37,000<br>That what we’re doing has a lot of rights so it could be pretty bad if we just keep writing doing having a lot of rights for just one operation we also only have direct I know blocks rather than having direct and indirect I know so that would be a plus to add those and secondly there should be a better way for clients to interact with this file system so there could be a fuse layer or they could just be better pauses compliance in general.</p>
<p>492<br>01:16:38,000 –&gt; 01:16:40,000<br>That concludes our presentation.</p>
<p>493<br>01:16:42,000 –&gt; 01:16:52,000<br>You want to talk a little bit about how you tested this.</p>
<p>494<br>01:16:52,000 –&gt; 01:17:09,000<br>Sure so we had a pretty at your recommendation we had a pretty broad set of tests we had so it’s been in each component so each you know the block layer regular individual graph Q values we had the journal and we had all these things we basically mocked every layer underneath each layer we were testing and tested.</p>
<p>495<br>01:17:09,000 –&gt; 01:17:13,000<br>Did sort of unit testing you can’t really call unit testing once you get high enough.</p>
<p>496<br>01:17:13,000 –&gt; 01:17:36,000<br>Because you’re so rely on time lower layers being correct but we did as best we could from there we did integration testing and you know wrote out a set of partitions one of those partitions is sort of what you just saw the most interesting of them there were five of them you can see them in our get repository and then we also to what degree we could some this didn’t necessarily entirely work just some because of some of like the time limitations that we had but.</p>
<p>497<br>01:17:36,000 –&gt; 01:17:42,000<br>We also attempted to do some stress testing obviously performance numbers aren’t great because it’s not supposed to be great but.</p>
<p>498<br>01:17:42,000 –&gt; 01:17:46,000<br>I’m just best we could so we’re pretty sure this is at least correct this is verified here.</p>
<p>499<br>01:17:46,000 –&gt; 01:18:15,000<br>So one interesting thing is that you’re basically shooting for actually slightly stronger consistently properly to positive texture required that there’s two processes ready to single file there’s actually not much that actually the right texture they have to do.</p>
<p>500<br>01:18:15,000 –&gt; 01:18:27,000<br>Yes, that was kind of accidental but we were so it’s kind of stronger yeah it was accidental but it happened so we’re like cool it worked.</p>
<p>501<br>01:18:27,000 –&gt; 01:18:43,000<br>The sort of I mean I think the part of the so what sort of happened was that we guarantee we I’d possibly say guarantees I talked about but we also make the guarantee that the block rights are all time and I think that’s why we get this sort of stronger consistency because of the whole journaling thing yes you could be.</p>
<p>502<br>01:18:43,000 –&gt; 01:18:51,000<br>Right over written if you do it some of the same time but it’s always going to be clean.</p>
<p>503<br>01:18:51,000 –&gt; 01:18:56,000<br>If you have a gratitude cash you might run in and don’t write immediately to the.</p>
<p>504<br>01:18:56,000 –&gt; 01:19:00,000<br>Log then you might get different behaviors right.</p>
<p>505<br>01:19:00,000 –&gt; 01:19:05,000<br>Right this is why we don’t aggressively cash we have a flock cash of size one.</p>
<p>506<br>01:19:05,000 –&gt; 01:19:11,000<br>This is.</p>
<p>507<br>01:19:11,000 –&gt; 01:19:22,000<br>Awesome thank you very cool right our last group is presenting a game framework remember you’re ready take it away.</p>
<p>508<br>01:19:22,000 –&gt; 01:19:40,000<br>So we’re sure that many of you have played multiplayer games in quarantine when you’re bored so let’s imagine that you are a small indie game company and you’re trying to develop a most player game possibly that has either several different rooms something like chat penguin where you might interact with other people.</p>
<p>509<br>01:19:40,000 –&gt; 01:19:47,000<br>So you might have to have other people in the same room or perhaps it’s like matchmaking based where you’re in the lobby with several other players.</p>
<p>510<br>01:19:47,000 –&gt; 01:20:04,000<br>Well so traditionally how these work is that everything goes against process on one central server but that central server is a bottleneck if every single player has to connect to that server to handle the game logic that server to get a bottleneck by the number of requests that comes through.</p>
<p>511<br>01:20:04,000 –&gt; 01:20:14,000<br>So what we’re proposing is to create a distributed game framework that instead of that’s also fault.</p>
<p>512<br>01:20:14,000 –&gt; 01:20:22,000<br>So instead of having all the processing being on that central server we actually distribute the game logic processing to several different worker servers.</p>
<p>513<br>01:20:22,000 –&gt; 01:20:33,000<br>So to be fall tarant so one of these like worker servers goes down we need to be able to handle that game logic and further move players to some other server workers.</p>
<p>514<br>01:20:33,000 –&gt; 01:20:46,000<br>So as part of that we need to actually balance latency with fault tolerance because if we make everything strictly fault tolerance we might run into like each move taking a long time to process.</p>
<p>515<br>01:20:46,000 –&gt; 01:20:59,000<br>So that’s why we’re introducing can we know which is our fault tarant game framework that addresses all of the previous issues with.</p>
<p>516<br>01:20:59,000 –&gt; 01:21:09,000<br>So to dive into the system of our framework let’s imagine the game club penguin so in club penguin a user that is assigned into one room or one region.</p>
<p>517<br>01:21:09,000 –&gt; 01:21:19,000<br>It only really cares about talking and interacting with other users and the objects in that one room and they don’t really need to care about anything else that’s having in another room.</p>
<p>518<br>01:21:19,000 –&gt; 01:21:25,000<br>So there’s no reason to have the request of every user be processed by one centralized servers.</p>
<p>519<br>01:21:25,000 –&gt; 01:21:35,000<br>So instead we decided that we will have all of these requests be processed across multiple workers in order to do this we have workers that are assigned to different region.</p>
<p>520<br>01:21:35,000 –&gt; 01:21:48,000<br>So if a player is in one region of they might be talking with the worker that is assigned to that region. So for example in here the penguin that is in worker that is assigned to the region for worker to talk with worker to only.</p>
<p>521<br>01:21:48,000 –&gt; 01:21:52,000<br>But then the one in the worker and will talk with worker and.</p>
<p>522<br>01:21:52,000 –&gt; 01:22:03,000<br>So we mentioned we decided that this wouldn’t the the relation between worker and regions doesn’t necessarily have to be one to one mapping for some rooms that might be less popular and have less traffic.</p>
<p>523<br>01:22:03,000 –&gt; 01:22:11,000<br>It’s possible that a worker can handle multiple of those so there’s that type of relation that we need to keep track of.</p>
<p>524<br>01:22:11,000 –&gt; 01:22:16,000<br>So in order to keep track of this we do need one centralized server, which is the coordinator.</p>
<p>525<br>01:22:16,000 –&gt; 01:22:28,000<br>So the coordinator will be keeping track of all these mappings and some of the mapping includes the region to worker relation as well as region the worker to their replica.</p>
<p>526<br>01:22:28,000 –&gt; 01:22:46,000<br>So for the fall time aspect we have that the workers will have to replica each and surely will talk talk a little bit more about what kind of information is sent to the workers from the like to their local later.</p>
<p>527<br>01:22:46,000 –&gt; 01:23:00,000<br>Additionally, the coordinator because it is that one centralized server it is also a possible failure point so we have a coordinator backup and in here the coordinator’s main role is just to keep track of all of these relations of the game states.</p>
<p>528<br>01:23:00,000 –&gt; 01:23:11,000<br>So information about the coordinator that changes for those relations will be sent to the coordinator backup before being process completely completely.</p>
<p>529<br>01:23:11,000 –&gt; 01:23:34,000<br>So now with this although we have that one server of the bulk of the traffic for games usually is players making moves and sending requests to process those move and those are now divided across multiple workers and the coordinator is in charge of just the mapping and sending heartbeat to ensure that the workers are still alive and can handle any failure cases.</p>
<p>530<br>01:23:34,000 –&gt; 01:23:58,000<br>So the case that a worker goes down we have the coordinator handling the reassignment of the players who are in that worker and because the corner manages only the region mappings is also easy for us to move around regions when one of say like one worker gets overloaded this levels to perform some amount of load balancing as we mentioned earlier.</p>
<p>531<br>01:23:58,000 –&gt; 01:24:08,000<br>So we are going to talk about the developer API looks like because another key feature that we wanted was for the framework to be used for a developer trying to code and you game in it.</p>
<p>532<br>01:24:08,000 –&gt; 01:24:16,000<br>So we treat the game as a state machine essentially and so any move that the player makes actually fit into one of two different types of moves.</p>
<p>533<br>01:24:16,000 –&gt; 01:24:29,000<br>So in order to provide a sort of choice for the developer we have two separate commands that we expose to the developer.</p>
<p>534<br>01:24:29,000 –&gt; 01:24:40,000<br>The first is send fast move so this fast move makes sure that the move gets to the replica of as soon as possible so the move gets process as fast as possible on the worker.</p>
<p>535<br>01:24:40,000 –&gt; 01:24:53,000<br>And we have sensible move which actually is a more fall torrent move that we expose to the developer and this ensures this is mainly used for game critical logic changes such as say trans action.</p>
<p>536<br>01:24:53,000 –&gt; 01:25:01,000<br>So if you’re buying something you don’t want like if you’ve already spent that money you want to make sure that you get like wherever you spent that money on in your game.</p>
<p>537<br>01:25:01,000 –&gt; 01:25:21,000<br>And so we guarantee that if that move gets fully processed and on the game it’s it’s stored on both of the replicas which ensures that if the worker that you’re talking to goes down and the player gets transferred to a new worker that new worker will be able to reconstruct the game including that transaction.</p>
<p>538<br>01:25:21,000 –&gt; 01:25:26,000<br>Guarantee isn’t done for a fast move which prioritizes the latency of my site.</p>
<p>539<br>01:25:26,000 –&gt; 01:25:44,000<br>But you can also see here the move structs that the developers define are pretty general so in the game that will be that we kind of built as a toy demo for our framework is kind of a chat penguin like interface so each player is in several different.</p>
<p>540<br>01:25:45,000 –&gt; 01:26:07,000<br>Room and so within each room there’s a chat window that you can talk to to interact with another player so the two type of main move that you can make in this game are first like a move so a developer would just define like the x y and the user name of the player moving and so the chat message is kind of the same words just like a chat message that you send into the window.</p>
<p>541<br>01:26:07,000 –&gt; 01:26:33,000<br>And so we in our game we made chat messages a stable move and move as a fast move so even if like say one move gets dropped it’s okay if you’re like saying new kind of teleports but we don’t want chat messages to randomly disappear because they could be important messages so with that I move on to the demo which is a little bare bones but should show off the functionality.</p>
<p>542<br>01:26:38,000 –&gt; 01:26:42,000<br>So we have our spring minimalist front end.</p>
<p>543<br>01:26:43,000 –&gt; 01:26:58,000<br>And so when we move around the penguin we can see that it’s first sends a fast move and replica that same move gets sent to the other replicas assigned to the main worker so right now we’re on worker zero it gets replicated to work a one and two so we have to copy.</p>
<p>544<br>01:26:58,000 –&gt; 01:27:26,000<br>And the game server then receives that change and so then it can process that locally and then if we send a chat message we also have the player username identified with the chat message is sent but this is actually a stable move so it’s not visible on the blogs but stable moves wait until those move are actually replicated to the workers and it’s not easy to see here because normally there might be some amount of lag.</p>
<p>545<br>01:27:29,000 –&gt; 01:27:33,000<br>But when we do introduce some of my flag into the network that same one would take longer.</p>
<p>546<br>01:27:35,000 –&gt; 01:27:39,000<br>And now let’s move it back to some future work that we want to implement.</p>
<p>547<br>01:27:44,000 –&gt; 01:27:56,000<br>In terms of the back end one additional thing that we would like to do is to allow the users to move across different rooms so right now upon a user joining the game and it being initialized there are assigned to one room.</p>
<p>548<br>01:27:57,000 –&gt; 01:28:11,000<br>But ideally if they want to move across to it if they want to move to a different room then they should be able to talk to the coordinator to be like hey i’m going to go to this region now can you load up the information of the game state from that region and then also now i’m going to start talking to a new worker.</p>
<p>549<br>01:28:12,000 –&gt; 01:28:25,000<br>And additionally we hinted at this earlier where we wanted to deal with region based worker load balancing so the reason why we had that why we did not go for once one mapping with worker to region was to allow for this.</p>
<p>550<br>01:28:26,000 –&gt; 01:28:33,000<br>And we hope to be able to do that in order to control how much load each worker will be based with.</p>
<p>551<br>01:28:34,000 –&gt; 01:28:37,000<br>Thank you.</p>
<p>552<br>01:28:43,000 –&gt; 01:28:44,000<br>Oh, I have a.</p>
<p>553<br>01:28:44,000 –&gt; 01:28:49,000<br>Sorry, I have a question so are you are.</p>
<p>554<br>01:28:49,000 –&gt; 01:28:58,000<br>I guess you have two actions sending a message and moving so those actions are all atomic right are they like.</p>
<p>555<br>01:28:59,000 –&gt; 01:29:00,000<br>Yeah.</p>
<p>556<br>01:29:01,000 –&gt; 01:29:13,000<br>They get to partially processed and since they’re like individual moves they most of the time they only modify like some variables and they acquire the walk on those variables.</p>
<p>557<br>01:29:16,000 –&gt; 01:29:25,000<br>So you said earlier that you have the coordinator and coordinator backup and the replica is going to talk to either of them.</p>
<p>558<br>01:29:25,000 –&gt; 01:29:35,000<br>What happens if you have a network partition that separates the coordinator and some set of replicas from the coordinator backup and some others that are replicas.</p>
<p>559<br>01:29:38,000 –&gt; 01:29:49,000<br>So the coordinator backup indicates of a network partition the workers will be kind of lost like the coordinator is not a matter of the worker being able to talk to either the coordinator or the coordinator backup.</p>
<p>560<br>01:29:49,000 –&gt; 01:29:57,000<br>They’ll only be able to talk to the coordinator and if a coordinator goes down then the backup get brought up to actually start processing.</p>
<p>561<br>01:29:57,000 –&gt; 01:30:10,000<br>So in that case of a network partition, I don’t think we will be like the workers that are isolated and away from that coordinator will not be able to be processed with the like the coordinator itself.</p>
<p>562<br>01:30:10,000 –&gt; 01:30:16,000<br>In terms of the user side like it can still be processed because the player just need to continue talking to that worker.</p>
<p>563<br>01:30:16,000 –&gt; 01:30:23,000<br>It’s just that if there’s any changes in the region like the state of the game as a whole that will be processed yet.</p>
<p>564<br>01:30:23,000 –&gt; 01:30:32,000<br>Yeah, additionally I want to know if we have like a partition the coordinator backup essentially acts as a coordinator for all the workers that it can talk to.</p>
<p>565<br>01:30:32,000 –&gt; 01:30:39,000<br>And this is fine because we want the game to be like still running for all of the regions in the workers that the coordinator backup is talking to.</p>
<p>566<br>01:30:39,000 –&gt; 01:31:01,000<br>This family becomes a problem when they do reunite and in this case the coordinator backup then takes all of its like data and it can send it to the coordinator and the coordinator can locally resolve it because there is kind of an original coordinator and a coordinator backup and they know that the backup was a backup of the coordinator because it’s towards local.</p>
<p>567<br>01:31:02,000 –&gt; 01:31:24,000<br>But if the coordinator backup becomes a coordinator then wouldn’t it, for example, say, oh, I need to make sure that we have active replicas for all these rooms that the that are inside the partition wouldn’t you have the same room host on both sides of the partition and be able to beverage.</p>
<p>568<br>01:31:24,000 –&gt; 01:31:47,000<br>No, because each room belongs only to like one worker. So like so I guess like each room like can’t like the replicas for the rooms would get abandoned so essentially what happens is like if a worker like in the case of a partition the coordinator wouldn’t be able to access like a worker that’s in the other partition so what happens is it.</p>
<p>569<br>01:31:47,000 –&gt; 01:31:54,000<br>Oh, I think I’ll like move the replicas over but because the players also can’t contact a worker.</p>
<p>570<br>01:31:54,000 –&gt; 01:32:05,000<br>None of the moves would be processed and so the more recent replicas after the partition heals would be prioritized when healing that network.</p>
<p>571<br>01:32:08,000 –&gt; 01:32:16,000<br>Why did you decide on that API with move and sending a message.</p>
<p>572<br>01:32:16,000 –&gt; 01:32:27,000<br>So specifically for this API we wanted to different types of moves to distinct types of moves to demonstrate one with the fast move and one with the stable move.</p>
<p>573<br>01:32:27,000 –&gt; 01:32:37,000<br>Ideally stable move is used more like rarely and use more for transactions that where it’s okay for it to take longer but we wanted to not be dropped at all.</p>
<p>574<br>01:32:37,000 –&gt; 01:32:52,000<br>The easiest way to replicate this in a like a simple front end was with a chat package. It was kind of arbitrary but moves for sure should be fast because like we don’t want it to be like we can players with a lot.</p>
<p>575<br>01:32:52,000 –&gt; 01:33:00,000<br>Thank you.</p>
<p>576<br>01:33:00,000 –&gt; 01:33:05,000<br>Thanks so much. That concludes the presentation. It’s pretty job everyone. This was this is pretty exciting.</p>
<p>577<br>01:33:05,000 –&gt; 01:33:11,000<br>I have one more question for an old presentation. That’s possible.</p>
<p>578<br>01:33:11,000 –&gt; 01:33:13,000<br>Yeah, go ahead.</p>
<p>579<br>01:33:13,000 –&gt; 01:33:20,000<br>So for the leader, I’m sorry for the distributed election system.</p>
<p>580<br>01:33:20,000 –&gt; 01:33:29,000<br>I’m not familiar a lot with photography but I guess the system where you sum up all the results of the election.</p>
<p>581<br>01:33:29,000 –&gt; 01:33:49,000<br>I have a vote on a counter server. This wouldn’t that hide group attacks. For example, if I have two servers and then I vote for different people on both servers but then I coordinate with someone else to also vote in the other way around will eventually get the same vote vector.</p>
<p>582<br>01:33:49,000 –&gt; 01:33:59,000<br>I guess in this case to change the vote result or like the election result but I guess I would have acted incorrectly.</p>
<p>583<br>01:33:59,000 –&gt; 01:34:04,000<br>So are there checks to make sure everybody voted correctly at each server?</p>
<p>584<br>01:34:04,000 –&gt; 01:34:07,000<br>Yeah.</p>
<p>585<br>01:34:07,000 –&gt; 01:34:15,000<br>Sorry. So we actually don’t handle malicious voting, which was which is which is pretty big.</p>
<p>586<br>01:34:15,000 –&gt; 01:34:21,000<br>And you know, arguably pretty important for a real world voting system.</p>
<p>587<br>01:34:21,000 –&gt; 01:34:28,000<br>But yeah, I think like you know the scope of the project that we had and that we set out.</p>
<p>588<br>01:34:28,000 –&gt; 01:34:31,000<br>It was just a little like too complicated.</p>
<p>589<br>01:34:31,000 –&gt; 01:34:33,000<br>So we.</p>
<p>590<br>01:34:33,000 –&gt; 01:35:01,000<br>Yeah, I think with focus more like on the distributed systems part, but if we wanted to like provide more security like in for security using for example, like an idea that we thought but then decided to not do was having like a public ledger where you can like give us your knowledge proofs that they what you’re posting like adds up and is what you’re saying that it is and things of this things to handle malicious participants.</p>
<p>591<br>01:35:01,000 –&gt; 01:35:04,000<br>Yeah.</p>
<p>592<br>01:35:04,000 –&gt; 01:35:07,000<br>So we’re running a little bit late.</p>
<p>593<br>01:35:07,000 –&gt; 01:35:09,000<br>Let me end the class in principle.</p>
<p>594<br>01:35:09,000 –&gt; 01:35:12,000<br>Anybody wants to take a round of course, you know, feel free to stick around.</p>
<p>595<br>01:35:12,000 –&gt; 01:35:16,000<br>I just wanted to say one or two things before closing since this is our last class meeting.</p>
<p>596<br>01:35:16,000 –&gt; 01:35:20,000<br>First of all, I want to thank all of you for participating, even though it’s another COVID semester.</p>
<p>597<br>01:35:20,000 –&gt; 01:35:23,000<br>I feel I’ve interacted with many of you.</p>
<p>598<br>01:35:23,000 –&gt; 01:35:29,000<br>Either for email or indirectly and exchange lots of information and I’d love to see you at some point in person.</p>
<p>599<br>01:35:29,000 –&gt; 01:35:32,000<br>I know who you are.</p>
<p>600<br>01:35:32,000 –&gt; 01:35:35,000<br>But I appreciate all the participation.</p>
<p>601<br>01:35:35,000 –&gt; 01:35:38,000<br>The second thing I want to thank the TAs.</p>
<p>602<br>01:35:38,000 –&gt; 01:35:40,000<br>It’s an awesome set of TAs.</p>
<p>603<br>01:35:40,000 –&gt; 01:35:42,000<br>You should probably have realized.</p>
<p>604<br>01:35:42,000 –&gt; 01:35:47,000<br>Probably for many of you, they figured out some bugs and helped you get through the labs.</p>
<p>605<br>01:35:47,000 –&gt; 01:35:50,000<br>And so I ran a plot for the TAs.</p>
<p>606<br>01:35:50,000 –&gt; 01:35:55,000<br>I’m being very fortunate with this kind of quality.</p>
<p>607<br>01:35:55,000 –&gt; 01:36:00,000<br>And I guess the last thing I want to say is I guess good luck and find.</p>
<p>608<br>01:36:00,000 –&gt; 01:36:02,000<br>Hopefully not too bad.</p>
<p>609<br>01:36:02,000 –&gt; 01:36:07,000<br>And I hope you learned something in six or four and enjoyed it at the same time.</p>
<p>610<br>01:36:07,000 –&gt; 01:36:13,000<br>And anybody wants to stick around please stick around and you know, more questions you want to ask to the different teams.</p>
<p>611<br>01:36:13,000 –&gt; 01:36:18,000<br>If the teams can stick around to that would be wonderful. Otherwise, well, this is the end.</p>
<p>612<br>01:36:18,000 –&gt; 01:36:21,000<br>At least for the class meeting to a two four.</p>
<p>613<br>01:36:21,000 –&gt; 01:36:24,000<br>Thank you all.</p>
<p>614<br>01:36:24,000 –&gt; 01:36:27,000<br>Thank you.</p>
<p>615<br>01:36:27,000 –&gt; 01:36:30,000<br>Thank you so much.</p>
<p>616<br>01:36:30,000 –&gt; 01:36:32,000<br>Thank you.</p>
<p>617<br>01:36:32,000 –&gt; 01:36:38,000<br>Thank you so much.</p>
<p>618<br>01:36:38,000 –&gt; 01:36:41,000<br>Um.</p>
<p>619<br>01:36:41,000 –&gt; 01:36:45,000<br>Sorry, quick question.</p>
<p>620<br>01:36:45,000 –&gt; 01:36:48,000<br>One last question now.</p>
<p>621<br>01:36:48,000 –&gt; 01:36:50,000<br>For real.</p>
<p>622<br>01:36:50,000 –&gt; 01:36:55,000<br>I was wondering actually for logistics for the exam.</p>
<p>623<br>01:36:55,000 –&gt; 01:36:58,000<br>I emailed you.</p>
<p>624<br>01:36:58,000 –&gt; 01:37:02,000<br>Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah.</p>
<p>625<br>01:37:02,000 –&gt; 01:37:04,000<br>I haven’t gotten to the point yet.</p>
<p>626<br>01:37:04,000 –&gt; 01:37:06,000<br>We’re dealing with logistics of the exam.</p>
<p>627<br>01:37:06,000 –&gt; 01:37:07,000<br>Okay.</p>
<p>628<br>01:37:07,000 –&gt; 01:37:08,000<br>A couple of.</p>
<p>629<br>01:37:08,000 –&gt; 01:37:11,000<br>I’m aware of you and two free Alex.</p>
<p>630<br>01:37:11,000 –&gt; 01:37:13,000<br>We have an extra good idea.</p>
<p>631<br>01:37:13,000 –&gt; 01:37:15,000<br>We’re shared in details.</p>
<p>632<br>01:37:15,000 –&gt; 01:37:16,000<br>Okay.</p>
<p>633<br>01:37:16,000 –&gt; 01:37:18,000<br>But we’ll have it.</p>
<p>634<br>01:37:18,000 –&gt; 01:37:19,000<br>Sounds good.</p>
<p>635<br>01:37:19,000 –&gt; 01:37:22,000<br>I’m sure you’ll reach out.</p>
<p>636<br>01:37:22,000 –&gt; 01:37:24,000<br>Yeah.</p>
<p>637<br>01:37:24,000 –&gt; 01:37:25,000<br>All right.</p>
<p>638<br>01:37:25,000 –&gt; 01:37:26,000<br>Perfect.</p>
<p>639<br>01:37:26,000 –&gt; 01:37:31,000<br>Thank you so much for everything for the class and, you know, the TAs.</p>
<p>640<br>01:37:31,000 –&gt; 01:37:34,000<br>Thank you very much for.</p>
<p>641<br>01:37:34,000 –&gt; 01:37:36,000<br>All the class.</p>
<p>642<br>01:37:36,000 –&gt; 01:37:37,000<br>Very fun.</p>
<p>643<br>01:37:37,000 –&gt; 01:37:39,000<br>I learned a lot.</p>
<p>644<br>01:37:39,000 –&gt; 01:37:41,000<br>Thank you for participating.</p>
<p>645<br>01:37:41,000 –&gt; 01:37:42,000<br>Asking over questions.</p>
<p>646<br>01:37:42,000 –&gt; 01:37:44,000<br>Appreciate it.</p>
<p>647<br>01:37:44,000 –&gt; 01:37:45,000<br>Yes, thank you.</p>
<p>648<br>01:37:45,000 –&gt; 01:37:46,000<br>This was this was an awesome class.</p>
<p>649<br>01:37:46,000 –&gt; 01:37:48,000<br>I really appreciate it.</p>
<p>650<br>01:37:48,000 –&gt; 01:37:54,000<br>I think we’re being active doing the class.</p>
<p>651<br>01:37:54,000 –&gt; 01:37:55,000<br>All right.</p>
<p>652<br>01:37:55,000 –&gt; 01:37:56,000<br>I guess that’s probably it.</p>
<p>653<br>01:37:56,000 –&gt; 01:38:00,000<br>So I guess what’s the stop the recording.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>MIT6824 P22Lecture21 ProjectPresentations</div>
      <div>http://example.com/2025/10/24/MIT6824 P22Lecture21-ProjectPresentations/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月24日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/24/MIT6824%20P5Lecture5FaultToleranceRaft1/" title="MIT6824 P5Lecture5FaultToleranceRaft1">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">MIT6824 P5Lecture5FaultToleranceRaft1</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/24/MIT6824%20P3Lecture3GFS/" title="MIT6824 P3Lecture3GFS">
                        <span class="hidden-mobile">MIT6824 P3Lecture3GFS</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
