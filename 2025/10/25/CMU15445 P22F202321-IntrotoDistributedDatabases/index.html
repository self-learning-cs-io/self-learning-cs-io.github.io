

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:22,839a 200:00:22,839 –&gt; 00:00:24,379A 300:00:24,379 –&gt; 00:00:26,379Hey, let’s get started! 400:00:26,379 –&gt; 00:00:29,379Give it up, two bass locking. 500:00:29,379">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU15445 P22F202321 IntrotoDistributedDatabases">
<meta property="og:url" content="http://example.com/2025/10/25/CMU15445%20P22F202321-IntrotoDistributedDatabases/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:22,839a 200:00:22,839 –&gt; 00:00:24,379A 300:00:24,379 –&gt; 00:00:26,379Hey, let’s get started! 400:00:26,379 –&gt; 00:00:29,379Give it up, two bass locking. 500:00:29,379">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-25T05:03:39.736Z">
<meta property="article:modified_time" content="2025-10-25T05:03:39.736Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>CMU15445 P22F202321 IntrotoDistributedDatabases - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CMU15445 P22F202321 IntrotoDistributedDatabases"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-25 13:03" pubdate>
          2025年10月25日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          9.2k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          77 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CMU15445 P22F202321 IntrotoDistributedDatabases</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:22,839<br>a</p>
<p>2<br>00:00:22,839 –&gt; 00:00:24,379<br>A</p>
<p>3<br>00:00:24,379 –&gt; 00:00:26,379<br>Hey, let’s get started!</p>
<p>4<br>00:00:26,379 –&gt; 00:00:29,379<br>Give it up, two bass locking.</p>
<p>5<br>00:00:29,379 –&gt; 00:00:32,379<br>I’m back.</p>
<p>6<br>00:00:32,379 –&gt; 00:00:33,379<br>Yeah.</p>
<p>7<br>00:00:33,379 –&gt; 00:00:35,379<br>Yeah guys, I’ve been going for a while.</p>
<p>8<br>00:00:35,379 –&gt; 00:00:36,379<br>How you doing?</p>
<p>9<br>00:00:36,379 –&gt; 00:00:37,379<br>I’m doing well for you.</p>
<p>10<br>00:00:37,379 –&gt; 00:00:39,379<br>My first wife gave me COVID.</p>
<p>11<br>00:00:39,379 –&gt; 00:00:41,379<br>She betrayed me, so that sucked.</p>
<p>12<br>00:00:41,379 –&gt; 00:00:47,379<br>But while Jines was teaching, we spent a lot of time writing papers and grants and things like that.</p>
<p>13<br>00:00:47,379 –&gt; 00:00:50,379<br>So your show has been crushing us and I’ve been hearing.</p>
<p>14<br>00:00:50,379 –&gt; 00:00:51,379<br>Yeah.</p>
<p>15<br>00:00:51,379 –&gt; 00:00:52,379<br>And how was your girlfriend?</p>
<p>16<br>00:00:52,380 –&gt; 00:00:58,380<br>She was the last taken show that she wanted to find out who was giving flowers and was abby matter.</p>
<p>17<br>00:00:58,380 –&gt; 00:00:59,380<br>And I also met her.</p>
<p>18<br>00:00:59,380 –&gt; 00:01:00,380<br>She’s still pissed?</p>
<p>19<br>00:01:00,380 –&gt; 00:01:01,380<br>Yeah.</p>
<p>20<br>00:01:01,380 –&gt; 00:01:03,380<br>I know she’s trying to get to the bottom of it.</p>
<p>21<br>00:01:03,380 –&gt; 00:01:04,379<br>Yeah.</p>
<p>22<br>00:01:04,379 –&gt; 00:01:05,379<br>I mean, it’s on you, you have to handle it.</p>
<p>23<br>00:01:05,379 –&gt; 00:01:08,379<br>What do you mean it’s on me?</p>
<p>24<br>00:01:08,379 –&gt; 00:01:11,379<br>I mean, it’s on you, gave me this gig sometimes.</p>
<p>25<br>00:01:11,379 –&gt; 00:01:12,379<br>Okay, there’s that.</p>
<p>26<br>00:01:12,379 –&gt; 00:01:13,379<br>Yeah, yeah, yeah.</p>
<p>27<br>00:01:13,379 –&gt; 00:01:15,379<br>All right guys, let’s get started.</p>
<p>28<br>00:01:15,379 –&gt; 00:01:17,379<br>I’m going to get the right slides.</p>
<p>29<br>00:01:17,379 –&gt; 00:01:19,379<br>So, again, administrative stuff.</p>
<p>30<br>00:01:19,379 –&gt; 00:01:20,379<br>Homework 5 is out.</p>
<p>31<br>00:01:20,379 –&gt; 00:01:23,379<br>It’s going to be due on December 3rd.</p>
<p>32<br>00:01:23,379 –&gt; 00:01:25,379<br>And then, so that’s in two weeks.</p>
<p>33<br>00:01:25,379 –&gt; 00:01:26,379<br>Project 4 is out.</p>
<p>34<br>00:01:26,379 –&gt; 00:01:28,379<br>That’ll be due on December 10th.</p>
<p>35<br>00:01:28,379 –&gt; 00:01:35,379<br>And we’ll be announcing the info session for that on PSO, I think, this week.</p>
<p>36<br>00:01:35,379 –&gt; 00:01:38,379<br>And then, on the last week of class, it’s going to be two special lectures.</p>
<p>37<br>00:01:38,379 –&gt; 00:01:41,379<br>So we’re going to have Sunday from single store, come on over in Zoom.</p>
<p>38<br>00:01:41,379 –&gt; 00:01:44,379<br>I’m going to talk about the single store database system.</p>
<p>39<br>00:01:45,379 –&gt; 00:01:50,379<br>They’re going to have a heavy emphasis on LLM’s or vector database stuff that they’re building in single store.</p>
<p>40<br>00:01:50,379 –&gt; 00:01:51,379<br>Again, that’ll be over Zoom.</p>
<p>41<br>00:01:51,379 –&gt; 00:01:53,379<br>So we don’t have to come here for that.</p>
<p>42<br>00:01:53,379 –&gt; 00:01:54,379<br>So please, please attend that.</p>
<p>43<br>00:01:54,379 –&gt; 00:02:00,379<br>And then, on the very last day of the class on Wednesday, December 6th, we’re going to do the final exam review.</p>
<p>44<br>00:02:00,379 –&gt; 00:02:04,379<br>But then we’re also going to do something we’ll call the system speed run.</p>
<p>45<br>00:02:04,379 –&gt; 00:02:12,379<br>So I’ll post a form on Piazza, go select or go put in what are some like some databases that we don’t really cover during this semester that you want to learn about.</p>
<p>46<br>00:02:13,379 –&gt; 00:02:19,379<br>We’re trying to cover 10, maybe like, it’s 120 minutes, we’ll cover like one database in 10 minutes or like a crash course.</p>
<p>47<br>00:02:19,379 –&gt; 00:02:20,379<br>Here’s what the system does.</p>
<p>48<br>00:02:20,379 –&gt; 00:02:21,379<br>Here’s why it’s interesting.</p>
<p>49<br>00:02:21,379 –&gt; 00:02:23,379<br>Here’s why it matters or here’s why it’s stupid.</p>
<p>50<br>00:02:23,379 –&gt; 00:02:25,379<br>We’re trying to get through as many systems as we can.</p>
<p>51<br>00:02:25,379 –&gt; 00:02:26,379<br>Okay?</p>
<p>52<br>00:02:26,379 –&gt; 00:02:30,379<br>So every year, it’s always like Mongo’s number one, Spanners number two.</p>
<p>53<br>00:02:30,379 –&gt; 00:02:38,379<br>But if you guys want to do something we’re challenging, again, we’ll look at, I’ll send a link to the DBVIO, pick any random stuff that you want.</p>
<p>54<br>00:02:38,379 –&gt; 00:02:39,379<br>Okay?</p>
<p>55<br>00:02:39,379 –&gt; 00:02:41,379<br>And then the final exam has been scheduled.</p>
<p>56<br>00:02:41,379 –&gt; 00:02:45,379<br>I don’t know where, but it’s going to be on Tuesday, December 12th at 8.30 a.m.</p>
<p>57<br>00:02:45,379 –&gt; 00:02:52,379<br>Again, if you need any accommodations or if you have three exams scheduled in a 25 hour period, according to your super-politees,</p>
<p>58<br>00:02:52,379 –&gt; 00:02:56,379<br>email, jignesh, and myself, and we’ll re-scatch you for the makeup exam.</p>
<p>59<br>00:02:56,379 –&gt; 00:02:57,379<br>Okay?</p>
<p>60<br>00:02:57,379 –&gt; 00:02:59,379<br>Any questions about any of these things?</p>
<p>61<br>00:03:01,379 –&gt; 00:03:05,379<br>All right. So then for the seminar series to have this semester, we have two last talks.</p>
<p>62<br>00:03:05,379 –&gt; 00:03:09,379<br>The talk today is actually super exciting. We’re going to have somebody from Amazon talk about PG Vector.</p>
<p>63<br>00:03:09,379 –&gt; 00:03:15,379<br>PG Vector is the most popular vector extension for Postgres.</p>
<p>64<br>00:03:15,379 –&gt; 00:03:20,379<br>So you don’t need to use VBA or Millevis or Pine Cone.</p>
<p>65<br>00:03:20,379 –&gt; 00:03:23,379<br>You can do some of those operations directly inside of Postgres.</p>
<p>66<br>00:03:23,379 –&gt; 00:03:24,379<br>So they’ll talk about how that works.</p>
<p>67<br>00:03:24,379 –&gt; 00:03:30,379<br>And then next week will be a, the last talk will be a new database startup at a San Francisco called Chroma.</p>
<p>68<br>00:03:30,379 –&gt; 00:03:33,379<br>That is again, it was one of these specialized vector databases.</p>
<p>69<br>00:03:33,379 –&gt; 00:03:36,379<br>Okay? Again, all that’s over zoom.</p>
<p>70<br>00:03:36,379 –&gt; 00:03:47,379<br>All right. So at this point in this semester, we’ve covered everything you need to know at a high level of how to build a single known database system.</p>
<p>71<br>00:03:47,379 –&gt; 00:03:52,379<br>Right? We covered, like, if the lowest level at the storage layer, we talked about how to bring things in that memory.</p>
<p>72<br>00:03:52,379 –&gt; 00:03:58,379<br>We talked about how to actually run queries, do query planning, take a SQL query, and turn it into an actual physical plan.</p>
<p>73<br>00:03:58,379 –&gt; 00:04:02,379<br>And then we went back across the entire stack and now then we add a recovery.</p>
<p>74<br>00:04:02,379 –&gt; 00:04:10,379<br>So we’re going to have to handle through Redhead logging or other methods to be able to recover the database after a crash.</p>
<p>75<br>00:04:10,379 –&gt; 00:04:15,379<br>We’re talking about how to have multiple transactions run at the same time and update the database through concurrency troll.</p>
<p>76<br>00:04:15,379 –&gt; 00:04:18,379<br>All that, everything, you know, these topics here.</p>
<p>77<br>00:04:18,379 –&gt; 00:04:25,379<br>Again, we didn’t go too deep in any one thing, but this is basically what you need to build a single node database system.</p>
<p>78<br>00:04:25,379 –&gt; 00:04:30,379<br>So at this point in this semester, we’re going to build on public we’ve done so far and now we’re talking about distributed databases.</p>
<p>79<br>00:04:30,379 –&gt; 00:04:35,379<br>Right? It’s hard enough to build a single node database by itself. It’s even harder to build a distributed one.</p>
<p>80<br>00:04:35,379 –&gt; 00:04:41,379<br>All right? And there’s be a bunch of these different design traditions we’re going to have to make about how we want these different notes to coordinate with each other.</p>
<p>81<br>00:04:41,379 –&gt; 00:04:47,379<br>How they’re going to talk to each other and how they’re going to work together to execute queries, execution, actions.</p>
<p>82<br>00:04:48,379 –&gt; 00:04:52,379<br>And so like, you know, you could have things come from the top and coordinate some messages to the top.</p>
<p>83<br>00:04:52,379 –&gt; 00:04:59,379<br>You can go through the bottom, you can go through the middle, right? There’s all these different design choices you could have of how you had a build a distributed database system.</p>
<p>84<br>00:04:59,379 –&gt; 00:05:04,379<br>But at its core, it’s been doing all the things that we talked about this semester.</p>
<p>85<br>00:05:04,379 –&gt; 00:05:08,379<br>Right? There’s still going to be a disk. You still got to read things, you know, in a buffer pool.</p>
<p>86<br>00:05:08,379 –&gt; 00:05:13,379<br>But now when you run a query, are you going to send messages to another node to run part of the query over there?</p>
<p>87<br>00:05:13,379 –&gt; 00:05:18,379<br>Should you pull data from that they have or is there a central location you can go get data from?</p>
<p>88<br>00:05:18,379 –&gt; 00:05:24,379<br>And so we only have three classes to discuss distributed databases. So obviously this is going to be a crash course in this topic.</p>
<p>89<br>00:05:24,379 –&gt; 00:05:36,379<br>But again, hopefully what you’ll get out of this is a way to assess real-world systems because you understand the vernacular vocabulary of what these systems are talking about and how they’re implemented.</p>
<p>90<br>00:05:36,379 –&gt; 00:05:42,379<br>And that’ll help you make different design decisions when you, you know, if you ever want to build one yourself or need to start using one in the real world.</p>
<p>91<br>00:05:42,379 –&gt; 00:05:54,379<br>Okay? So we showed this slide early in the semester where we discussed parallel query execution that we made this distinction between parallel database systems and distributed databases.</p>
<p>92<br>00:05:54,379 –&gt; 00:05:59,379<br>Right? We said the parallel databases are ones where the nodes are physically close to each other.</p>
<p>93<br>00:05:59,379 –&gt; 00:06:11,379<br>Like think of like different CPUs, sockets of different CPUs that are running different different different the sort of the running separate instances of the database system and they communicate over some high speed interconnect.</p>
<p>94<br>00:06:11,379 –&gt; 00:06:17,379<br>Or they’re running in like the same rack and it looks like just one giant shared machine. Right?</p>
<p>95<br>00:06:17,379 –&gt; 00:06:25,379<br>So the big thing about in a parallel database system is that we’re going to assume that the communication cost is going to be small.</p>
<p>96<br>00:06:25,379 –&gt; 00:06:30,379<br>Like nanoseconds or microseconds to send a message from one worker to another.</p>
<p>97<br>00:06:30,379 –&gt; 00:06:34,379<br>And they’re also going to assume that the communication is reliable.</p>
<p>98<br>00:06:34,379 –&gt; 00:06:43,379<br>Meaning like if I send a message to another thread, that thread is going to get that you can modulo any like software errors, but like it’s not the message that it’s not going to get disappeared.</p>
<p>99<br>00:06:43,379 –&gt; 00:06:48,379<br>Right? But now in the distributed database system world, we can’t make those assumptions.</p>
<p>100<br>00:06:48,379 –&gt; 00:06:55,379<br>We can’t assume that the nodes are going to be close to each other. We can’t assume that one node or one worker talking to another worker is cheap.</p>
<p>101<br>00:06:55,379 –&gt; 00:07:03,379<br>Right? Because you can either be in, you know, ideally in the same rack, but maybe you’re in the same data center, but the same different availability zone.</p>
<p>102<br>00:07:03,379 –&gt; 00:07:09,379<br>Or the worst case scenario is that you’re in completely two different data centers and one database node is on the other opposite and the planet.</p>
<p>103<br>00:07:09,379 –&gt; 00:07:16,379<br>Now you’re, you’re restricted by speed of light issues, which you can’t, you know, there’s no magic want to make that go away.</p>
<p>104<br>00:07:16,379 –&gt; 00:07:24,379<br>So the other, so in addition to the communication between nodes being expensive, communication could be unreliable.</p>
<p>105<br>00:07:24,379 –&gt; 00:07:34,379<br>Right? TCP IP will help a bunch of things make sure that the pack is end up in order, but there’s no guarantee that if we send a message that the other side actually going to get it.</p>
<p>106<br>00:07:34,379 –&gt; 00:07:41,379<br>Right? Or it might get it in different orders. Right? Not because the network is severed, but like say the node itself starts doing something weird.</p>
<p>107<br>00:07:41,379 –&gt; 00:07:45,379<br>Like it says it’s a Java based database system and then the garbage collector kicks in.</p>
<p>108<br>00:07:45,379 –&gt; 00:07:49,379<br>So there’s like, you know, a 30 second pause because it’s cleaning up the heat.</p>
<p>109<br>00:07:49,379 –&gt; 00:07:52,379<br>But now the node looks on, on, on available.</p>
<p>110<br>00:07:52,379 –&gt; 00:07:56,379<br>And now messages might, and when it flips back on messages might show up in different orders.</p>
<p>111<br>00:07:56,379 –&gt; 00:08:01,379<br>So all these reasons, you know, that we have to account for all these things in our, in our distributed database system.</p>
<p>112<br>00:08:01,379 –&gt; 00:08:08,379<br>We can assume the hardware is going to hide it for us in the same way we can for parallel databases.</p>
<p>113<br>00:08:08,379 –&gt; 00:08:15,379<br>So this is just repeating what I said before, but we can use all the building blocks of a single data system that we, that we’ve constructed so far.</p>
<p>114<br>00:08:15,379 –&gt; 00:08:24,379<br>And now we can, we can layer on top of that and say, OK, here’s how we want to distribute the execution across multiple physical nodes.</p>
<p>115<br>00:08:24,379 –&gt; 00:08:30,379<br>Right? And we can do this for all TV systems, like running transactional workloads and for analytical workloads.</p>
<p>116<br>00:08:30,379 –&gt; 00:08:33,379<br>So today’s class is going to be a high level of like, here’s what a distributed database looks like.</p>
<p>117<br>00:08:33,379 –&gt; 00:08:35,379<br>Here’s the things that you have to worry about.</p>
<p>118<br>00:08:35,379 –&gt; 00:08:41,379<br>Then next class after the break will be entirely about distributed transaction systems.</p>
<p>119<br>00:08:41,379 –&gt; 00:08:44,379<br>And then we’ll cover distributed old lab systems or analytical systems.</p>
<p>120<br>00:08:44,379 –&gt; 00:08:48,379<br>And 721 next semester will be entirely on analytical systems.</p>
<p>121<br>00:08:48,379 –&gt; 00:08:52,379<br>So in a distributed environment, everything is just harder.</p>
<p>122<br>00:08:52,379 –&gt; 00:08:55,379<br>Optization and query planning, that was hard enough on a single note.</p>
<p>123<br>00:08:55,379 –&gt; 00:09:02,379<br>It’s even harder in a distributed system because now you have, you may not be sure what data is actually at another node.</p>
<p>124<br>00:09:02,379 –&gt; 00:09:05,379<br>Or how, how fast can you communicate between them?</p>
<p>125<br>00:09:05,379 –&gt; 00:09:08,379<br>Currents you told will be the hardest part of all this.</p>
<p>126<br>00:09:08,379 –&gt; 00:09:14,379<br>How do we make sure that the different nodes that are involved in a transaction, all the grids that a transaction can commit.</p>
<p>127<br>00:09:14,379 –&gt; 00:09:18,379<br>Then when we say yes, let’s go commit, they all actually did that.</p>
<p>128<br>00:09:18,379 –&gt; 00:09:25,379<br>Right? It’s basically a distributed state machine if you take in distributed algorithms, distributed systems.</p>
<p>129<br>00:09:25,379 –&gt; 00:09:34,379<br>And then logging recovery again, how do we make sure that if a, if one of our nodes in our system crashes, ideally we don’t want that, that to take down our entire system.</p>
<p>130<br>00:09:34,379 –&gt; 00:09:42,379<br>Right? For distributed databases like 20 nodes and one of them goes down, we don’t want the other 19 to be completely locked until that thing comes back up.</p>
<p>131<br>00:09:42,379 –&gt; 00:09:45,379<br>Because it might never come back up. Right?</p>
<p>132<br>00:09:45,379 –&gt; 00:09:48,379<br>So again, we’ll touch on all these things as we go along.</p>
<p>133<br>00:09:48,379 –&gt; 00:09:50,379<br>We won’t really talk about query optimization too much.</p>
<p>134<br>00:09:50,379 –&gt; 00:09:53,379<br>We’ll talk a little bit about it next week.</p>
<p>135<br>00:09:53,379 –&gt; 00:10:00,379<br>All right. So for today’s class, we’re going to first talk about the high level overview of what the other distributed system architecture could look like in a context of databases.</p>
<p>136<br>00:10:00,379 –&gt; 00:10:04,379<br>Then we’ll talk about the design issues we have to worry about when we actually implement one of these things.</p>
<p>137<br>00:10:04,379 –&gt; 00:10:10,379<br>Then we’ll talk about how we want to partition our database so we can split it up across multiple nodes.</p>
<p>138<br>00:10:10,379 –&gt; 00:10:13,379<br>Again, we talked a little bit about that when we talked about parallel execution.</p>
<p>139<br>00:10:13,379 –&gt; 00:10:17,379<br>And then we’ll give a preview of why the shipping concurrentials hard.</p>
<p>140<br>00:10:17,379 –&gt; 00:10:21,379<br>And that’ll be a segue into what we discuss next week.</p>
<p>141<br>00:10:21,379 –&gt; 00:10:24,379<br>Okay? Okay.</p>
<p>142<br>00:10:24,379 –&gt; 00:10:26,379<br>So let’s start from the basics.</p>
<p>143<br>00:10:26,379 –&gt; 00:10:37,379<br>So, a distributed database in architecture is going to basically define where the resources are that are going to be available to the CPUs.</p>
<p>144<br>00:10:37,379 –&gt; 00:10:40,379<br>Again, we’re assuming a bottom-known architecture.</p>
<p>145<br>00:10:40,379 –&gt; 00:10:46,379<br>There’s things on disk, we bring it to the memory, and then there’s a CPU that uses that memory to execute instructions and process data.</p>
<p>146<br>00:10:46,379 –&gt; 00:10:50,379<br>So the discussion really, when you just designed a distributed database system,</p>
<p>147<br>00:10:50,379 –&gt; 00:10:57,379<br>where’s the memory and where’s the disk, and who’s allowed to read and write to it at any given time.</p>
<p>148<br>00:10:57,379 –&gt; 00:11:02,379<br>And this is going to determine how the CPUs are going to coordinate and talk to each other.</p>
<p>149<br>00:11:02,379 –&gt; 00:11:09,379<br>Like, what kind of messages are they going to send and when do they send them, and then who’s going to be involved in deciding when certain things should happen.</p>
<p>150<br>00:11:09,379 –&gt; 00:11:15,379<br>Again, if it’s a transactional system, somebody’s got to decide, okay, it’s time to commit this transaction.</p>
<p>151<br>00:11:15,379 –&gt; 00:11:22,379<br>And then, can everybody agree to that? And someone has to be in charge of making that decision.</p>
<p>152<br>00:11:22,379 –&gt; 00:11:34,379<br>So the architecture we’ve been mostly discussing so far, actually entirely discussing the semester, is what is known in the sort of the database literature as a shared everything system.</p>
<p>153<br>00:11:34,379 –&gt; 00:11:45,379<br>There’s a single box and single node, it has a local disk, it has a local memory, and that database system can access all those things equally.</p>
<p>154<br>00:11:45,379 –&gt; 00:11:50,379<br>And there’s no other node, right? This is basically what a single node database system is.</p>
<p>155<br>00:11:50,379 –&gt; 00:11:57,379<br>This is what bus tub is, a postgres for my sequel. Ignoring replication for now.</p>
<p>156<br>00:11:57,379 –&gt; 00:12:02,379<br>And when most people think of a distributed database system, they think of something like this, what is known as a shared nothing system.</p>
<p>157<br>00:12:02,379 –&gt; 00:12:07,379<br>This is what is a term invented in the 1980s by the guy who then a postgres Mike Snowbroker.</p>
<p>158<br>00:12:07,379 –&gt; 00:12:18,379<br>And this again, this is what most people think about when you think of a distributed system, right? That there’s individual nodes, and those nodes have CPUs, and those CPUs can access memory, can access local disk.</p>
<p>159<br>00:12:18,379 –&gt; 00:12:37,379<br>But anytime you want to communicate with any other node in the distributed database, it has to go through some network protocol, again, for our purposes, as soon as TCP IP, and it sends messages to the different, to the different nodes to coordinate with each other.</p>
<p>160<br>00:12:37,379 –&gt; 00:12:42,379<br>What is more common now, especially in the cloud is what is known as a shared disk system.</p>
<p>161<br>00:12:42,379 –&gt; 00:12:47,379<br>And the idea here is that there’s still individual nodes that have CPUs and have local memory.</p>
<p>162<br>00:12:47,379 –&gt; 00:12:52,379<br>They may even have direct attached SSDs that could use for caching.</p>
<p>163<br>00:12:52,379 –&gt; 00:12:57,379<br>But the primary storage location of the database is going to be on some shared disk, right?</p>
<p>164<br>00:12:57,379 –&gt; 00:13:11,379<br>If you think of a giant Nause appliance, like some shared storage server, or if you’re in the cloud, into S3, or whatever the one for Azure, GCP is, that’s the resting place, the primary location of the database.</p>
<p>165<br>00:13:11,379 –&gt; 00:13:23,379<br>In the case of a shared nothing system, the database could be replicated on every single node, or we could partition it or break it up to subsets and have each node be responsible for that.</p>
<p>166<br>00:13:24,379 –&gt; 00:13:31,379<br>But in the shared disk system, it looks like a single logical disk that every node can communicate with.</p>
<p>167<br>00:13:31,379 –&gt; 00:13:35,379<br>I’ll go through each of these more details with examples.</p>
<p>168<br>00:13:35,379 –&gt; 00:13:42,379<br>And just to be complete in the research literature, there’s also a category system called shared memory systems.</p>
<p>169<br>00:13:42,379 –&gt; 00:13:55,379<br>And the idea here is that the disk and memory is shared across some kind of fabric, and the CPU nodes, or the database nodes, can only coordinate or communicate through some kind of network.</p>
<p>170<br>00:13:55,379 –&gt; 00:13:59,379<br>Again, this looks a lot like shared everything.</p>
<p>171<br>00:13:59,379 –&gt; 00:14:04,379<br>I’ll show this in a slide in a second, but like, as far as I know, nobody actually does shared memory, right?</p>
<p>172<br>00:14:04,379 –&gt; 00:14:16,379<br>This architecture mostly exists in high performance computing, where you want to have a single, just aggregate memory pool, and all the nodes can coordinate through that.</p>
<p>173<br>00:14:16,379 –&gt; 00:14:19,379<br>But again, as far as I know, node database has been actually implemented.</p>
<p>174<br>00:14:19,379 –&gt; 00:14:25,379<br>So we’re going to spend most of our time focusing on shared nothing and shared disk.</p>
<p>175<br>00:14:25,379 –&gt; 00:14:30,379<br>So as I said, the term shared nothing dates into 1986.</p>
<p>176<br>00:14:30,379 –&gt; 00:14:37,379<br>The first shared nothing database system that was actually commercially available was TerraData, which I think is like 82, 83.</p>
<p>177<br>00:14:37,379 –&gt; 00:14:41,379<br>There were some academic prototypes that predate that.</p>
<p>178<br>00:14:41,379 –&gt; 00:14:45,379<br>But those were actually never actually implemented in the use.</p>
<p>179<br>00:14:45,379 –&gt; 00:14:47,379<br>But TerraData was the first one.</p>
<p>180<br>00:14:47,379 –&gt; 00:15:01,379<br>Again, the idea here is that each node can’t view the memory or disk of any other node in the cluster, and they can only communicate through the through some network.</p>
<p>181<br>00:15:01,379 –&gt; 00:15:15,379<br>So the conventional wisdom is that in a shared nothing system, this is maybe better performance and better efficiency, because now, if I chart or partition my database across these different nodes,</p>
<p>182<br>00:15:15,379 –&gt; 00:15:33,379<br>then I can distribute it query, break it up into smaller pieces, have each node basically run full-blast, and all its local storage, local copy of the database, and then I somehow aggregate the results together, and the same way we did for parallel execution using like an exchange operator.</p>
<p>183<br>00:15:33,379 –&gt; 00:15:42,379<br>So this gets the best performance because you’re not bottlenecked for any as you’ll know, you’re not bottlenecking any other node because you’re only accessing data that’s local to you.</p>
<p>184<br>00:15:42,379 –&gt; 00:15:51,379<br>As we know, in the real world, you may have to talk to other nodes to get data that you’re missing, and that becomes a problem.</p>
<p>185<br>00:15:51,379 –&gt; 00:16:05,379<br>The challenge, though, and we’ll see this in contrast with a shared disk system, is that in a shared nothing system, it’s hard to scale capacity because the data that’s stored in the local disk is tied to each node.</p>
<p>186<br>00:16:05,379 –&gt; 00:16:13,379<br>If I want to add a new node in my cluster, I got a copy data from other nodes to be able to spread it out.</p>
<p>187<br>00:16:13,379 –&gt; 00:16:29,379<br>It’s also going to be harder to ensure consistency because again, since every node has their own local portion of the database, copied the database, they can’t see the memory of other nodes, then they got to send messages to ask, hey, what are you doing for this transaction, or what are you doing for this query?</p>
<p>188<br>00:16:29,379 –&gt; 00:16:41,379<br>So there’s a lot of databases that use this architecture, and I said this was the conventional wisdom of how you build a scalable distributed database system up until maybe the last 10 years or so.</p>
<p>189<br>00:16:41,379 –&gt; 00:16:49,379<br>The cloud changes, but if you’ve been about distributed database in the 80s or 90s, early 2000s, you would use this approach.</p>
<p>190<br>00:16:49,379 –&gt; 00:16:50,379<br>Yes.</p>
<p>191<br>00:16:50,379 –&gt; 00:16:54,379<br>So each of these disks, do they have a portion of the database?</p>
<p>192<br>00:16:54,379 –&gt; 00:16:57,379<br>Potentially, yes. Depends on how you want to partition it. We’ll get that in a second.</p>
<p>193<br>00:16:57,379 –&gt; 00:17:04,380<br>So if the first thing you want to get something from the third disk, you’re going to go through the network and bring it over.</p>
<p>194<br>00:17:04,380 –&gt; 00:17:11,380<br>Yeah. His question is assuming, say the database, we’ll talk about how to do partition in a second.</p>
<p>195<br>00:17:11,380 –&gt; 00:17:17,380<br>You literally just take one column, hash it the value, and then you distribute it out across the different nodes.</p>
<p>196<br>00:17:17,380 –&gt; 00:17:22,380<br>You make a face. That’s very common. And it’s actually a good idea.</p>
<p>197<br>00:17:22,380 –&gt; 00:17:28,380<br>We’ll see that. So basically, this node one has some range.</p>
<p>198<br>00:17:28,380 –&gt; 00:17:31,380<br>Next node has the next range. I’ll actually show the next slide.</p>
<p>199<br>00:17:31,380 –&gt; 00:17:37,380<br>If my node here needs to get the data that this node has, I can’t just peek over to the disk.</p>
<p>200<br>00:17:37,380 –&gt; 00:17:40,380<br>I got to send a message and say, hey, send the data you have.</p>
<p>201<br>00:17:40,380 –&gt; 00:17:44,380<br>So it’s a query goes to all the CPUs?</p>
<p>202<br>00:17:44,380 –&gt; 00:17:50,380<br>His question is, is a query goes to all the CPUs? If you need all the data and all the CPUs, yes.</p>
<p>203<br>00:17:50,380 –&gt; 00:17:55,380<br>We’ll get in a second. There’s going to be something. There’s some intelligence to say, okay, you look at the query and it’s declarative.</p>
<p>204<br>00:17:55,380 –&gt; 00:18:02,380<br>So I know what you’re trying to do. Find me the middle remember nodes that has the data that I need.</p>
<p>205<br>00:18:02,380 –&gt; 00:18:05,380<br>Next slide.</p>
<p>206<br>00:18:05,380 –&gt; 00:18:09,380<br>So say we have a really simple distributed database, two node clusters shared nothing.</p>
<p>207<br>00:18:09,380 –&gt; 00:18:13,380<br>Again, so on each node, there’s a local CPU, local memory, local disk.</p>
<p>208<br>00:18:13,380 –&gt; 00:18:20,380<br>And then what I’m showing here is that I’ve taken a single table and I’ve partitioned it based on the value of an ID column.</p>
<p>209<br>00:18:21,380 –&gt; 00:18:29,380<br>So it’s the primary key. And so the first partition at the top is going to have all the two pulls where ID equals one to 150.</p>
<p>210<br>00:18:29,380 –&gt; 00:18:34,380<br>And the one at the bottom has all two pulls where ID is one fifty one to three hundred.</p>
<p>211<br>00:18:34,380 –&gt; 00:18:39,380<br>This is an example of range partitioning. I said, patch partition is another approach. We’ll see that in a second.</p>
<p>212<br>00:18:39,380 –&gt; 00:18:49,380<br>But now, depending what my query is, depending on what data I need access, I would use this information to figure out what these nodes I need to go to.</p>
<p>213<br>00:18:49,380 –&gt; 00:18:55,380<br>And the way I’m going to figure out what what what node I need to go to is through some kind of catalog or metadata service.</p>
<p>214<br>00:18:55,380 –&gt; 00:19:08,380<br>And I’m showing this as a cloud because it could be on the actual nodes themselves or it could be like a third party external service on the side says, okay, what direction you need to get this data.</p>
<p>215<br>00:19:08,380 –&gt; 00:19:11,380<br>Right. Different systems do different things.</p>
<p>216<br>00:19:11,380 –&gt; 00:19:18,380<br>So I’m just saying this is a more for its thing is somehow is going to tell us their application where should we go.</p>
<p>217<br>00:19:18,380 –&gt; 00:19:24,380<br>Now, say my query is get get ID equals 200 based on the information I’ve gotten from the catalog.</p>
<p>218<br>00:19:24,380 –&gt; 00:19:33,380<br>I know that this node at the bottom has the all the two pulls where ID is one fifty one to three hundred ID equals 200 is in that range.</p>
<p>219<br>00:19:33,380 –&gt; 00:19:36,380<br>So I know I want to come here and get the data that I need.</p>
<p>220<br>00:19:36,380 –&gt; 00:19:44,380<br>Now, when I actually this query on this node down here, I don’t need to communicate with the node at the top because it doesn’t have any of the data that I need.</p>
<p>221<br>00:19:44,380 –&gt; 00:19:47,380<br>Everything is down here.</p>
<p>222<br>00:19:47,380 –&gt; 00:19:55,380<br>Right. Then at the same time, I mean other query comes along and say this one wants to get ID equals 100 and ID equals 200.</p>
<p>223<br>00:19:55,380 –&gt; 00:20:07,380<br>So we’ll talk about data transparency in a second, but ideally, we don’t want the application server to be aware in charge of deciding how to get the data that needs for a particular query.</p>
<p>224<br>00:20:07,380 –&gt; 00:20:19,380<br>Meaning I just want to send my query request for these two IDs to this node and then have this node figure out so they want to the top figure out how to get the data that it needs to process this query.</p>
<p>225<br>00:20:19,380 –&gt; 00:20:25,380<br>And so it could be the case that the in this example here, I send a message from the top node to the bottom node.</p>
<p>226<br>00:20:25,380 –&gt; 00:20:29,380<br>Hey, I have a query up here that needs needs get ID equals 200.</p>
<p>227<br>00:20:29,380 –&gt; 00:20:33,380<br>Send me that data up send that data up to me.</p>
<p>228<br>00:20:33,380 –&gt; 00:20:38,380<br>Okay, so.</p>
<p>229<br>00:20:38,380 –&gt; 00:20:44,380<br>Right. And then I can return the response to the server.</p>
<p>230<br>00:20:44,380 –&gt; 00:20:46,380<br>Is this clear? Yes.</p>
<p>231<br>00:20:46,380 –&gt; 00:20:55,380<br>If we do an aggregation for example, so we don’t want the application to do a lot of the thing that’s working in the two.</p>
<p>232<br>00:20:55,380 –&gt; 00:20:58,380<br>Yeah, so say it is.</p>
<p>233<br>00:20:58,380 –&gt; 00:21:04,380<br>If you’re doing aggregation where you just in a table, you need such data at both partitions or both nodes.</p>
<p>234<br>00:21:04,380 –&gt; 00:21:08,380<br>You want the data server to do that for you, not the applications are right. Yes.</p>
<p>235<br>00:21:08,380 –&gt; 00:21:16,380<br>So we’ll see the second you could have something in front of this, a middleware or coordinator that the query shows up there and then it knows here’s the data that I need.</p>
<p>236<br>00:21:16,380 –&gt; 00:21:23,380<br>And if I have to line combine results, it can decide, okay, well, most of the data I need is on the node here.</p>
<p>237<br>00:21:23,380 –&gt; 00:21:28,380<br>So I want to I want to maybe just pull a small amount of data from the bottom to the top because that’s me cheaper.</p>
<p>238<br>00:21:28,380 –&gt; 00:21:31,380<br>We’ll see this push for support in a second.</p>
<p>239<br>00:21:31,380 –&gt; 00:21:36,380<br>Another question?</p>
<p>240<br>00:21:36,380 –&gt; 00:21:42,380<br>Yeah, so like this question is should the top node also talk to this metadata service? Yes, like it has to be.</p>
<p>241<br>00:21:42,380 –&gt; 00:21:46,380<br>And it’s going to have to be ideally well.</p>
<p>242<br>00:21:46,380 –&gt; 00:21:49,380<br>Yeah, no, I yes, ideally, you want this already basically transactional.</p>
<p>243<br>00:21:49,380 –&gt; 00:22:01,380<br>So like if something gets added or new data changes or the range is changes, I want to do this in a transactional safe manner because then I can guarantee that any party comes along and looks for an ID from start moving things around.</p>
<p>244<br>00:22:01,380 –&gt; 00:22:03,380<br>It gets the right answer.</p>
<p>245<br>00:22:03,380 –&gt; 00:22:08,380<br>We’ll see how Mongo did it wrong in a second. Yes.</p>
<p>246<br>00:22:08,380 –&gt; 00:22:15,380<br>Right. So now let’s say I want to add, I got a lot of activity on my database node.</p>
<p>247<br>00:22:15,380 –&gt; 00:22:20,380<br>I need to add more, you know, more servers because I’m, you know, my latency is too high.</p>
<p>248<br>00:22:20,380 –&gt; 00:22:24,380<br>I’m getting too many queries. I want to scale up or sorry, scale out.</p>
<p>249<br>00:22:24,380 –&gt; 00:22:30,380<br>So I want to add a new new node here. But again, when it boots up, there’s no data inside of it.</p>
<p>250<br>00:22:30,380 –&gt; 00:22:37,380<br>So now I need to start getting data from the other nodes toward a fill in the, you know, fill in the desk and start being able to process queries.</p>
<p>251<br>00:22:37,380 –&gt; 00:22:41,380<br>So in this case here, you have to have the top guy and the bottom guy for simplicity.</p>
<p>252<br>00:22:41,380 –&gt; 00:22:45,380<br>Soon they’re going to put this rate in half by equally.</p>
<p>253<br>00:22:45,380 –&gt; 00:22:55,380<br>So ID from 150, 150, 150 down here and from, what was before?</p>
<p>254<br>00:22:55,380 –&gt; 00:22:58,380<br>Sorry.</p>
<p>255<br>00:22:58,380 –&gt; 00:23:03,380<br>It was 151, 300. So we’ll move 151 and 200 up here. Right.</p>
<p>256<br>00:23:03,380 –&gt; 00:23:07,380<br>And then to this question over here, I update the catalog surface.</p>
<p>257<br>00:23:07,380 –&gt; 00:23:11,380<br>There’s data, you know, there’s new node exists. Here’s the ranges that it has.</p>
<p>258<br>00:23:11,380 –&gt; 00:23:15,380<br>So any new query comes along. It says, where can I find the data I’m looking for?</p>
<p>259<br>00:23:15,380 –&gt; 00:23:19,380<br>We’ll see a consistent view of the catalog.</p>
<p>260<br>00:23:19,380 –&gt; 00:23:23,380<br>Now it’s said before that MongoDB did it wrong.</p>
<p>261<br>00:23:23,380 –&gt; 00:23:29,380<br>So MongoDB had this auto scaling thing and, and I think they still have an early version of MongoDB.</p>
<p>262<br>00:23:29,380 –&gt; 00:23:33,380<br>One of the big selling points is that they could do auto scaling.</p>
<p>263<br>00:23:33,380 –&gt; 00:23:37,380<br>So if your, if your partitions or nodes are getting too hot, it can split the ranges up for you automatically.</p>
<p>264<br>00:23:37,380 –&gt; 00:23:41,380<br>But they didn’t, they didn’t move data around in a transaction-safe manner.</p>
<p>265<br>00:23:41,380 –&gt; 00:23:44,380<br>So they would do this copying that I’m showing here.</p>
<p>266<br>00:23:44,380 –&gt; 00:23:49,380<br>But it couldn’t guarantee that the catalog would be synchronized when this change occurred.</p>
<p>267<br>00:23:49,380 –&gt; 00:23:53,380<br>So there may be a small window where you can actually have a false negative where</p>
<p>268<br>00:23:53,380 –&gt; 00:23:55,380<br>the catalog wasn’t updated yet.</p>
<p>269<br>00:23:55,380 –&gt; 00:23:59,380<br>Your query goes up here to the top node because you’re looking for ID150.</p>
<p>270<br>00:23:59,380 –&gt; 00:24:01,380<br>But the data hasn’t moved yet.</p>
<p>271<br>00:24:01,380 –&gt; 00:24:05,380<br>Or I’m sorry, the data was moved, but you didn’t have the catalog.</p>
<p>272<br>00:24:05,380 –&gt; 00:24:07,380<br>So it points you to the top one.</p>
<p>273<br>00:24:07,380 –&gt; 00:24:11,380<br>And then that node says it’s not there.</p>
<p>274<br>00:24:11,380 –&gt; 00:24:17,380<br>So the reason I’m highlighting this metadata stuff is because it’s just another transaction.</p>
<p>275<br>00:24:17,380 –&gt; 00:24:19,380<br>We want to have a consistent view of the database.</p>
<p>276<br>00:24:19,380 –&gt; 00:24:24,380<br>And that does mean, not just mean what data is, sorry, what the data looks like on each individual node.</p>
<p>277<br>00:24:24,380 –&gt; 00:24:28,380<br>But the metadata itself that tells you where that data is located.</p>
<p>278<br>00:24:28,380 –&gt; 00:24:32,380<br>We want that to be transactional as well.</p>
<p>279<br>00:24:32,380 –&gt; 00:24:42,380<br>All right, so shared disk, as I said, the cloud has really made this the most popular way to build a database system now.</p>
<p>280<br>00:24:42,380 –&gt; 00:24:48,380<br>Share disk and this architecture was first designed in the 1980s.</p>
<p>281<br>00:24:48,380 –&gt; 00:24:54,380<br>But a lot of the systems that were based on this architecture didn’t pin out.</p>
<p>282<br>00:24:54,380 –&gt; 00:24:58,380<br>It was huge pain to build and became very unreliable.</p>
<p>283<br>00:24:58,380 –&gt; 00:25:00,380<br>The cloud changes that now.</p>
<p>284<br>00:25:00,380 –&gt; 00:25:06,380<br>So again, because the shared disk isn’t just going to be something that we as the data system developer have to build.</p>
<p>285<br>00:25:06,380 –&gt; 00:25:08,380<br>Although some systems choose to do that.</p>
<p>286<br>00:25:08,380 –&gt; 00:25:12,380<br>We just rely on the massive infrastructure of the cloud vendors.</p>
<p>287<br>00:25:12,380 –&gt; 00:25:16,380<br>And use that as our backing storage.</p>
<p>288<br>00:25:16,380 –&gt; 00:25:22,380<br>Right, so like you could use Amazon S3, right, that’s basically infinite disk.</p>
<p>289<br>00:25:22,380 –&gt; 00:25:26,380<br>Right, so you never know where about scaling or provision new new new storage.</p>
<p>290<br>00:25:26,380 –&gt; 00:25:29,380<br>Amazon has infinite storage for you.</p>
<p>291<br>00:25:29,380 –&gt; 00:25:34,380<br>Right, or basically infinite like you get to the point where you start running out of space on S3.</p>
<p>292<br>00:25:34,380 –&gt; 00:25:37,380<br>You’re going to call some Amazon way before that even happens, right?</p>
<p>293<br>00:25:37,380 –&gt; 00:25:39,380<br>Your credit card is going to get denied.</p>
<p>294<br>00:25:39,380 –&gt; 00:25:41,380<br>All right, you can distribute a file system.</p>
<p>295<br>00:25:41,380 –&gt; 00:25:44,380<br>HGFS is a bad example, but that’s something you could use.</p>
<p>296<br>00:25:44,380 –&gt; 00:25:47,380<br>But there’s better ones now that you could use it as the backing store.</p>
<p>297<br>00:25:47,380 –&gt; 00:25:50,380<br>But it’s not just in this architecture.</p>
<p>298<br>00:25:50,380 –&gt; 00:25:56,380<br>It’s not enough just to say, okay, let me take my single node bus to every single postgres and make it stick it on a distributed file system.</p>
<p>299<br>00:25:56,380 –&gt; 00:26:00,380<br>The database system itself needs to be aware that it’s talking distributed file system.</p>
<p>300<br>00:26:00,380 –&gt; 00:26:02,380<br>Because there are some optimization you can do.</p>
<p>301<br>00:26:02,380 –&gt; 00:26:08,380<br>And there’s some obviously some logic and make sure that you don’t have two guys trying to write to the same file at the same time.</p>
<p>302<br>00:26:08,380 –&gt; 00:26:13,380<br>Because they’re doing transactions that because they don’t, but they don’t know about each other.</p>
<p>303<br>00:26:13,380 –&gt; 00:26:21,380<br>Right, so it’s not just enough to say, I’m going to file system, you have to have the the compute nodes be aware that they are part of a larger system.</p>
<p>304<br>00:26:21,380 –&gt; 00:26:27,380<br>So the nice advantage of using this approach is that you can now scale the two, the two parts of the data system independently.</p>
<p>305<br>00:26:27,380 –&gt; 00:26:32,380<br>So if I need more compute, I just add new compute notes and the compute knows they’re stateless.</p>
<p>306<br>00:26:32,380 –&gt; 00:26:36,380<br>So it’s not like I need to copy data between the different nodes as I did in this for nothing system.</p>
<p>307<br>00:26:36,380 –&gt; 00:26:39,380<br>There was a pool data from the shared disk.</p>
<p>308<br>00:26:39,380 –&gt; 00:26:45,380<br>Now, I still need update my metadata to say who’s responsible for what portion of the database.</p>
<p>309<br>00:26:45,380 –&gt; 00:26:52,380<br>Especially if it’s a transactional system, but that’s way easier than a shared nothing system.</p>
<p>310<br>00:26:52,380 –&gt; 00:26:55,380<br>We can still use direct attack storage.</p>
<p>311<br>00:26:55,380 –&gt; 00:27:00,380<br>So even though I’m not showing it in the boxes here at the top, pointer.</p>
<p>312<br>00:27:00,380 –&gt; 00:27:03,380<br>Sorry, new clicker.</p>
<p>313<br>00:27:04,380 –&gt; 00:27:06,380<br>So we can’t even see.</p>
<p>314<br>00:27:06,380 –&gt; 00:27:11,380<br>Right, so even though the nodes themselves, I’m not showing a disk, they can have a local SSD as well.</p>
<p>315<br>00:27:11,380 –&gt; 00:27:13,380<br>And we can just use that as a bigger, slower cache.</p>
<p>316<br>00:27:13,380 –&gt; 00:27:19,380<br>So like right now, your buffer pool basically writes out the disk in bus tub and that the disk is the final location of the database.</p>
<p>317<br>00:27:19,380 –&gt; 00:27:31,380<br>But I could have another stage in my buffer pool where I could write things out to the SSD and then manage that as if it was just DRAM and do a Viction and throw things out of that as well.</p>
<p>318<br>00:27:32,380 –&gt; 00:27:37,380<br>So when people talk about data lakes, they tip, they mean this architecture.</p>
<p>319<br>00:27:37,380 –&gt; 00:27:47,380<br>The data lake stuff is interesting or we can cover this next week because the idea is that instead of all the right path for all updates to the database going through the database system.</p>
<p>320<br>00:27:47,380 –&gt; 00:27:53,380<br>I can just write things out to s3 and then there’s some metadata service like the high meta store.</p>
<p>321<br>00:27:53,380 –&gt; 00:27:56,380<br>I think Databricks calls there’s unity, right?</p>
<p>322<br>00:27:56,380 –&gt; 00:28:07,380<br>There’s some catalog service that you can update and say, hey, by the way, I have a bunch of these CSV files or parquet files on disk and then it now knows how to incorporate them or use them when you actually queries.</p>
<p>323<br>00:28:07,380 –&gt; 00:28:11,380<br>But it’s still going to be a shared disk architecture.</p>
<p>324<br>00:28:11,380 –&gt; 00:28:15,380<br>Or when people say they have a serverless database, it typically means this as well.</p>
<p>325<br>00:28:15,380 –&gt; 00:28:17,380<br>Because again, the compute nodes are stateless.</p>
<p>326<br>00:28:17,380 –&gt; 00:28:23,380<br>The final resting place in the database, which is what we care about, is here on the shared disk on s3 or whatever it is.</p>
<p>327<br>00:28:23,380 –&gt; 00:28:31,380<br>So now if I spin up my database system, I haven’t executed any queries on the database system for an hour.</p>
<p>328<br>00:28:31,380 –&gt; 00:28:34,380<br>I can just shut off the compute nodes.</p>
<p>329<br>00:28:34,380 –&gt; 00:28:42,380<br>And in the shared disk system, or sorry, in a shared nothing system, the database would go away because again, the disk was attached to each node.</p>
<p>330<br>00:28:42,380 –&gt; 00:28:43,380<br>So I turned the node off.</p>
<p>331<br>00:28:43,380 –&gt; 00:28:46,380<br>The database is, you know, that portion of the data isn’t among available.</p>
<p>332<br>00:28:46,380 –&gt; 00:28:49,380<br>But in the shared disk system, I shut the compute node off.</p>
<p>333<br>00:28:49,380 –&gt; 00:28:52,380<br>And s3, you know, all my data is still in s3.</p>
<p>334<br>00:28:52,380 –&gt; 00:29:00,380<br>And then an hour later, I’ve, I’ve wanted to execute another query, then I spin up another compute node and start pulling data from the shared disk storage.</p>
<p>335<br>00:29:00,380 –&gt; 00:29:06,380<br>Basically how a serverless database works.</p>
<p>336<br>00:29:06,380 –&gt; 00:29:11,380<br>So there’s a lot of systems that implement this as well, both for transactional systems and for OLAP systems.</p>
<p>337<br>00:29:11,380 –&gt; 00:29:19,380<br>And as I said, most of the newer database systems design in the, probably less five years, are using this architecture.</p>
<p>338<br>00:29:19,380 –&gt; 00:29:31,380<br>And then a bunch of systems that were maybe originally shared nothing have since come around and actually retrofitted or refactor their code to become a shared disk system.</p>
<p>339<br>00:29:31,380 –&gt; 00:29:33,380<br>All right, so here’s that same mark.</p>
<p>340<br>00:29:33,380 –&gt; 00:29:34,380<br>Yes, question.</p>
<p>341<br>00:29:34,380 –&gt; 00:29:45,380<br>So this question is, do these systems rewrite the entire server backend like for storage or?</p>
<p>342<br>00:29:45,380 –&gt; 00:29:48,380<br>Yeah, I mean, so, so.</p>
<p>343<br>00:29:48,380 –&gt; 00:29:57,380<br>If you’re relying on s3, you don’t have to, you know, you don’t have to build something that reads and writes a disk like a good.</p>
<p>344<br>00:29:57,380 –&gt; 00:30:01,380<br>You still need a disk manager, right, but that disk manager isn’t writing to local storage.</p>
<p>345<br>00:30:01,380 –&gt; 00:30:04,380<br>It’s just coding writing data to s3.</p>
<p>346<br>00:30:04,380 –&gt; 00:30:07,380<br>Now, I made a big deal of beginning this messer said like, oh, that OS is terrible.</p>
<p>347<br>00:30:07,380 –&gt; 00:30:11,380<br>We don’t trust the OS for anything, but now I’m saying we’re going to trust Amazon, right?</p>
<p>348<br>00:30:11,380 –&gt; 00:30:13,380<br>Yes.</p>
<p>349<br>00:30:13,380 –&gt; 00:30:20,380<br>So you can think of s3 as just being, it’s just from our perspective, it’s just another disk.</p>
<p>350<br>00:30:20,380 –&gt; 00:30:23,380<br>It’s bigger, slower.</p>
<p>351<br>00:30:23,380 –&gt; 00:30:27,380<br>It’s not directly attached, but from the Davison perspective, it’s just another disk.</p>
<p>352<br>00:30:27,380 –&gt; 00:30:34,380<br>Now, the some things you can do with like using s3 as an example that you can’t do it with a regular disk, you can do some predicate push down.</p>
<p>353<br>00:30:34,380 –&gt; 00:30:47,380<br>So in s3, for example, you can actually run select queries on s3 and it’ll s3 can natively like parse scsv or json file and run part of your query down there.</p>
<p>354<br>00:30:47,380 –&gt; 00:30:56,380<br>So it’s a little more sophisticated than a dumb disk, but from our perspective on the Davison system, it’s just a disk.</p>
<p>355<br>00:30:56,380 –&gt; 00:30:57,380<br>Right?</p>
<p>356<br>00:30:57,380 –&gt; 00:31:03,380<br>We’re still going to be responsible for deciding when things get written out, what gets brought into memory.</p>
<p>357<br>00:31:03,380 –&gt; 00:31:06,380<br>If we have a multi-stage cache, where does that go?</p>
<p>358<br>00:31:06,380 –&gt; 00:31:12,380<br>How do we decide how to split all the data up? All that we have to manage ourselves. That doesn’t go away.</p>
<p>359<br>00:31:12,380 –&gt; 00:31:15,380<br>Yes.</p>
<p>360<br>00:31:15,380 –&gt; 00:31:19,380<br>Question, is there any benefit to doing this on your own versus using s3?</p>
<p>361<br>00:31:19,380 –&gt; 00:31:23,380<br>Oh, yes. Could you get better than s3? Absolutely, yes.</p>
<p>362<br>00:31:23,380 –&gt; 00:31:27,380<br>And some systems do that.</p>
<p>363<br>00:31:27,380 –&gt; 00:31:32,380<br>There’s like, do I want to run my own, just distribute a disk or distribute a file system?</p>
<p>364<br>00:31:32,380 –&gt; 00:31:37,380<br>And then that’s one aspect of what you can rewrite.</p>
<p>365<br>00:31:37,380 –&gt; 00:31:39,380<br>Very few people will do that.</p>
<p>366<br>00:31:39,380 –&gt; 00:31:44,380<br>Because again, Amazon is Amazon. They have hundreds of engineers working on this.</p>
<p>367<br>00:31:44,380 –&gt; 00:31:47,380<br>And like I said, it’s infinite disk. You don’t have the provision in themselves.</p>
<p>368<br>00:31:47,380 –&gt; 00:31:54,380<br>You pay more for it. Right? And the latency can be like 50 to 200 milliseconds. Sometimes. That’s a lot.</p>
<p>369<br>00:31:54,380 –&gt; 00:31:58,380<br>But they handle replication for you.</p>
<p>370<br>00:31:58,380 –&gt; 00:32:04,380<br>Right? Which can be good or bad. Right? Again, the Davison is aware that it’s written to s3 and s3 is going to replicate itself.</p>
<p>371<br>00:32:04,380 –&gt; 00:32:08,380<br>Then you maybe you don’t have the Davison to sub-disount through replication.</p>
<p>372<br>00:32:08,380 –&gt; 00:32:16,380<br>That’s one aspect of this. Then the do you want to rely on Amazon’s libraries to talk to s3?</p>
<p>373<br>00:32:16,380 –&gt; 00:32:22,380<br>And there’s one data is yellow brick. They gave a talk a few years ago where they were like,</p>
<p>374<br>00:32:22,380 –&gt; 00:32:25,380<br>we tried all the Amazon libraries. They’re all crap. They rewrote everything themselves.</p>
<p>375<br>00:32:25,380 –&gt; 00:32:32,380<br>And they did kernel bypass to make, you know, reason rights puts and gets s3 faster than what Amazon will give you.</p>
<p>376<br>00:32:32,380 –&gt; 00:32:40,380<br>So there’s various levels of my optimization you can do before like, okay, let me run my own s3.</p>
<p>377<br>00:32:40,380 –&gt; 00:32:49,380<br>But I think they having the ability to do predicate pushdown in s3. I don’t think I think Microsoft supports that.</p>
<p>378<br>00:32:49,380 –&gt; 00:32:54,380<br>I don’t think Google does one of them supports it. But like be able to do some predicate pushdown.</p>
<p>379<br>00:32:54,380 –&gt; 00:33:01,380<br>That’s a big win as well. Because now I can be more selective on bringing back data that maybe they don’t need.</p>
<p>380<br>00:33:01,380 –&gt; 00:33:09,380<br>What are the downsides of this to share nothing?</p>
<p>381<br>00:33:09,380 –&gt; 00:33:16,380<br>Well, see this in a second. Let me go next slide. The big challenge is going to be,</p>
<p>382<br>00:33:16,380 –&gt; 00:33:24,380<br>you almost always have to pull data from from disk into the computer.</p>
<p>383<br>00:33:25,380 –&gt; 00:33:30,380<br>To the computer. Again, it’s called pushing the query to the data or pulling the data to the query.</p>
<p>384<br>00:33:30,380 –&gt; 00:33:37,380<br>And it’s shared nothing system. You can make that decision and you always can push the query to the data.</p>
<p>385<br>00:33:37,380 –&gt; 00:33:45,380<br>So even if you can’t push the entire query, I can use some predicate pushdown. That’s better than just blindly grabbing blocks and fetching them.</p>
<p>386<br>00:33:45,380 –&gt; 00:33:52,380<br>That’s the key difference, right? But the not having to worry about how to do replication and all these other things</p>
<p>387<br>00:33:53,380 –&gt; 00:34:04,380<br>that Amazon takes here for you, that’s a big enough win. And the speeds have gotten so much faster that like it’s just worth paying that company.</p>
<p>388<br>00:34:04,380 –&gt; 00:34:13,380<br>All right, so let’s go back to our example here. Right. So now my application server runs a query says gets ID 101.</p>
<p>389<br>00:34:13,380 –&gt; 00:34:17,380<br>The node can go into the catalog service and figure out where to find that data.</p>
<p>390<br>00:34:18,380 –&gt; 00:34:26,380<br>Again, what bucket of S3 has the data that need? And then now when it accesses storage, it’s not.</p>
<p>391<br>00:34:26,380 –&gt; 00:34:37,380<br>It’s like a four and a couple manager, if the convert the record you’re looking for to a page number or block number or a bucket number or segment or whatever you want to call it to go out to the disk and go get it.</p>
<p>392<br>00:34:37,380 –&gt; 00:34:43,380<br>And then it copies it into the local memory of this node who then compute the query and produce the answer to once.</p>
<p>393<br>00:34:44,380 –&gt; 00:34:53,380<br>Same thing with this guy down here. Again, he can go get the ID you can want to do goes that page and then processes the query.</p>
<p>394<br>00:34:53,380 –&gt; 00:34:58,380<br>So now if I want to add new capacity, I want to add a new compute node. Again, these nodes are stateless.</p>
<p>395<br>00:34:58,380 –&gt; 00:35:04,380<br>Meaning the primary location of the database is not in the compute nodes. It’s only on shared disk.</p>
<p>396<br>00:35:04,380 –&gt; 00:35:12,380<br>So even though these nodes may have cash copies of pages, you do want to do because you pay money every time you look things up on Amazon.</p>
<p>397<br>00:35:13,380 –&gt; 00:35:17,380<br>It’s, you know, they’re not, you know, it’s a temporary lease, temporary ownership.</p>
<p>398<br>00:35:17,380 –&gt; 00:35:25,380<br>So I could spin up this new node, not have to copy any data between my, my other nodes potentially.</p>
<p>399<br>00:35:25,380 –&gt; 00:35:30,380<br>And then a new query from the show up and then this thing gets the data that it needs.</p>
<p>400<br>00:35:30,380 –&gt; 00:35:36,380<br>And then if I want to add more disk, what do I do? Well, actually, I was doing update first.</p>
<p>401<br>00:35:37,380 –&gt; 00:35:46,380<br>So if I do an update here, 101, so since this node here has a copy of it, I have to make the modification to the, to the shared disk.</p>
<p>402<br>00:35:46,380 –&gt; 00:35:52,380<br>But then I maybe have to update everyone else say, oh, by the way, I know you have a cash copy of this, of this tuple.</p>
<p>403<br>00:35:52,380 –&gt; 00:36:00,380<br>Here’s the new version of it. Or it’s, you know, when a version you have now has been invalidated, go back to the shared disk and go get the new version.</p>
<p>404<br>00:36:00,380 –&gt; 00:36:01,380<br>Yes.</p>
<p>405<br>00:36:02,380 –&gt; 00:36:08,380<br>So question, how does the top node that the, how does the top node, the bottom two nodes have a cash copy of this?</p>
<p>406<br>00:36:08,380 –&gt; 00:36:14,380<br>So, what’s the second, in the shared disk, we’re doing that partitioning, but it’s logical.</p>
<p>407<br>00:36:14,380 –&gt; 00:36:22,380<br>And we’re just saying that the, the, a one node is going to be responsible for handling the rights to another node.</p>
<p>408<br>00:36:23,380 –&gt; 00:36:38,380<br>And then if another node wants to get it, you know, also get a copy of it, it could either go to, it has to tell somebody, hey, by the way, I’m, you know, I know you have a copy, you’re the owner for this, for this record or this partition.</p>
<p>409<br>00:36:38,380 –&gt; 00:36:43,380<br>Give me a copy what you have. And then now this guy knows that the bottom guy has a copy of it and get updated.</p>
<p>410<br>00:36:44,380 –&gt; 00:36:52,380<br>Or you could tell the met the catalog server, hey, by the way, like, I need a copy or you broadcast to everyone, like a gossip protocol and say, hey, go, go get, we’re going to the latest version.</p>
<p>411<br>00:36:52,380 –&gt; 00:36:57,380<br>And then now we, we target isolation levels, we’ll talk about, you know, it’s the same idea.</p>
<p>412<br>00:36:57,380 –&gt; 00:37:03,380<br>You know, this is actually the C in acid, which we sort of danced over before.</p>
<p>413<br>00:37:03,380 –&gt; 00:37:07,380<br>Do you want to have a consistent view of the entire database? Yes or no?</p>
<p>414<br>00:37:07,380 –&gt; 00:37:13,380<br>If you want a consistent view, then you got to make sure that anyone about possibly have a copy gets this update. Here’s a new version.</p>
<p>415<br>00:37:13,380 –&gt; 00:37:18,380<br>Or if you’re okay with things having stale reads, then I do my update.</p>
<p>416<br>00:37:18,380 –&gt; 00:37:25,380<br>But then I eventually tell everyone I was, hey, by the way, a version of it. And it may be the case that me query that goes here and reads the old version.</p>
<p>417<br>00:37:25,380 –&gt; 00:37:29,380<br>That’s okay. For some applications, that’s okay. For others not, it’s not.</p>
<p>418<br>00:37:29,380 –&gt; 00:37:33,380<br>Okay, we’ll cover that more next week.</p>
<p>419<br>00:37:34,380 –&gt; 00:37:38,380<br>All right, if I want to add new storage capacity, again, if it’s S3, it’s easy.</p>
<p>420<br>00:37:38,380 –&gt; 00:37:42,380<br>You just give them some more money, right? And they’re gladly take it.</p>
<p>421<br>00:37:42,380 –&gt; 00:37:47,380<br>And you just get more storage capacity. Or even it was managed by yourself, right?</p>
<p>422<br>00:37:47,380 –&gt; 00:37:54,380<br>I can add new disks to my distributed file system. And because these guys are stateless, it doesn’t matter.</p>
<p>423<br>00:37:54,380 –&gt; 00:37:58,380<br>I don’t, I don’t have to do any coordination that.</p>
<p>424<br>00:37:59,380 –&gt; 00:38:05,380<br>All right, so I’m not going to say much about shared memory. Again, this is sort of like the.</p>
<p>425<br>00:38:05,380 –&gt; 00:38:08,380<br>It’s it’s almost like a not theoretical because you could build one.</p>
<p>426<br>00:38:08,380 –&gt; 00:38:12,380<br>And there’s people have have dance around betting prototypes in the 80s and 90s.</p>
<p>427<br>00:38:12,380 –&gt; 00:38:16,380<br>But there’s again, as far as I know, there’s no real system that actually does this.</p>
<p>428<br>00:38:16,380 –&gt; 00:38:19,380<br>And again, the idea here is that you have these stateless compute nodes.</p>
<p>429<br>00:38:19,380 –&gt; 00:38:24,380<br>And then there’s some kind of shared disk thing. But then the memory is also shared as well.</p>
<p>430<br>00:38:25,380 –&gt; 00:38:30,380<br>So any time I want to go send messages to another node, I just write to some memory address.</p>
<p>431<br>00:38:30,380 –&gt; 00:38:35,380<br>And there’s some hardware that magically make sure that everyone gets the update.</p>
<p>432<br>00:38:35,380 –&gt; 00:38:41,380<br>It looks a lot like shared everything. Just the distinction is that I’m saying there’s there’s there’s separate physical notes.</p>
<p>433<br>00:38:41,380 –&gt; 00:38:47,380<br>And there’s some interconnect like RdMA or something like that or a thin band so that they can talk to each other.</p>
<p>434<br>00:38:49,380 –&gt; 00:38:52,380<br>But again, nobody actually does this as far as I know.</p>
<p>435<br>00:38:54,380 –&gt; 00:39:01,380<br>So I sort of mentioned this before, but there’s a the attribute idea of a distributed basis old goes back to the 1970s.</p>
<p>436<br>00:39:01,380 –&gt; 00:39:08,380<br>So as far as I know, the first two prototypes of distributed databases were this thing called muffin.</p>
<p>437<br>00:39:08,380 –&gt; 00:39:11,380<br>It stands for multiple or something or something of ingress.</p>
<p>438<br>00:39:11,380 –&gt; 00:39:14,380<br>It’s the guy that built ingress and postgres Sturmberger.</p>
<p>439<br>00:39:14,380 –&gt; 00:39:20,380<br>They have a sort of tech report paper at a Berkeley that describes here’s how you could build a distributed version of ingress.</p>
<p>440<br>00:39:20,380 –&gt; 00:39:23,380<br>The more famous one is SDD1 by Phil Bernstein.</p>
<p>441<br>00:39:23,380 –&gt; 00:39:29,380<br>Phil Bernstein did a lot of the great initial work on how to do concurred control and distributed data.</p>
<p>442<br>00:39:29,380 –&gt; 00:39:33,380<br>But he gave a talk once at a workshop up his running.</p>
<p>443<br>00:39:33,380 –&gt; 00:39:41,380<br>We talked about SDD1 actually wasn’t a real system. There’s a much of scripts that could build a prototype so they could like not trick the government.</p>
<p>444<br>00:39:41,380 –&gt; 00:39:45,380<br>Like show the government, hey, we can we can actually do this and they got money from it.</p>
<p>445<br>00:39:45,380 –&gt; 00:39:48,380<br>They actually never build the real system.</p>
<p>446<br>00:39:48,380 –&gt; 00:39:58,380<br>IBM built a version of a version of system R the first relational system they were building because R star gamma is a</p>
<p>447<br>00:39:58,380 –&gt; 00:40:05,380<br>was the early prototype of a distributed database at university was constant from the 1980s.</p>
<p>448<br>00:40:05,380 –&gt; 00:40:08,380<br>It was built by a jignesh’s PC advisor at Wisconsin.</p>
<p>449<br>00:40:08,380 –&gt; 00:40:13,380<br>But the only one of these that actually still around today is this thing called nonstop sequel from tandem.</p>
<p>450<br>00:40:13,380 –&gt; 00:40:17,380<br>That was Jim Gray’s one of projects that Jim Gray worked on at tandem.</p>
<p>451<br>00:40:17,380 –&gt; 00:40:24,380<br>Jim Gray again won the touring world for databases in the 1980s. He made a two days locking up a bunch of other stuff we’ve discussed this semester.</p>
<p>452<br>00:40:24,380 –&gt; 00:40:31,380<br>He left IBM to go to tandem, but he had a non-copy clause where he wasn’t allowed to work on databases for five years or something like that.</p>
<p>453<br>00:40:31,380 –&gt; 00:40:36,380<br>And then nonstop was building this super fault tolerant hardware.</p>
<p>454<br>00:40:36,380 –&gt; 00:40:43,380<br>Think of like NASA level fault tolerance like there’s like two CPUs running and they’re running the same computation and they check to see whether they get the same result.</p>
<p>455<br>00:40:43,380 –&gt; 00:40:47,380<br>This is obviously big in banks in the 80s even today.</p>
<p>456<br>00:40:47,380 –&gt; 00:40:57,380<br>But tandem nonstop sequel is still around today. If you ever use an ATM machine, changes are your transaction going to go through nonstop or IMS from IBM.</p>
<p>457<br>00:40:57,380 –&gt; 00:40:59,380<br>But you’re going through some old systems.</p>
<p>458<br>00:40:59,380 –&gt; 00:41:06,380<br>Muffin was multiple faster, faster ingress.</p>
<p>459<br>00:41:06,380 –&gt; 00:41:10,380<br>And I asked Mike once, Mike said, yeah, that’s what they had to put in the paper.</p>
<p>460<br>00:41:10,380 –&gt; 00:41:14,380<br>But he really said that they’re ruining it with ingress. So they called it muffin.</p>
<p>461<br>00:41:14,380 –&gt; 00:41:19,380<br>Mike doesn’t curse that much. I was surprised when he said that.</p>
<p>462<br>00:41:19,380 –&gt; 00:41:28,380<br>Anyway, all right. So you guys had too much of these questions and we’ve been sort of dancing around these things and now it’s time to talk about how are we actually going to do these things?</p>
<p>463<br>00:41:28,380 –&gt; 00:41:34,380<br>So we know what the high level architecture looks like. So now we’re going to talk about how we’re going to actually run queries and execute transactions.</p>
<p>464<br>00:41:34,380 –&gt; 00:41:38,380<br>So one of the first things that came out was like, okay, how’s the application find the data?</p>
<p>465<br>00:41:38,380 –&gt; 00:41:41,380<br>In my examples, I said there was this catalog service.</p>
<p>466<br>00:41:41,380 –&gt; 00:41:46,380<br>That’s one way to do it. And then the application decide where to actually want to go themselves.</p>
<p>467<br>00:41:46,380 –&gt; 00:41:51,380<br>Or we can see another approach where there’s just a single coordinator, a single URL that everybody talks to.</p>
<p>468<br>00:41:51,380 –&gt; 00:41:54,380<br>And that thing is knows where all the data needs.</p>
<p>469<br>00:41:55,380 –&gt; 00:41:58,380<br>Likewise, where does it actually send the data? So I said send the queries.</p>
<p>470<br>00:41:58,380 –&gt; 00:42:01,380<br>Do I send it to that coordinator? Do I send it to individual nodes?</p>
<p>471<br>00:42:01,380 –&gt; 00:42:06,380<br>Does the application even aware of those individual nodes? Ideally, no.</p>
<p>472<br>00:42:06,380 –&gt; 00:42:14,380<br>And then we want to act to queries and say the data that we need is not on a single disk or single node, what do we do?</p>
<p>473<br>00:42:14,380 –&gt; 00:42:21,380<br>Right? And again, the two approaches are doing a push the query to the data or some portion of the query to the data where it resides.</p>
<p>474<br>00:42:21,380 –&gt; 00:42:24,380<br>So I’m processing and get back a subset of the results.</p>
<p>475<br>00:42:24,380 –&gt; 00:42:30,380<br>Or I want to pull all the data that I need from a node to another node and process the query there.</p>
<p>476<br>00:42:30,380 –&gt; 00:42:35,380<br>How are we going to make sure that if we execute transactions that update data at multiple locations.</p>
<p>477<br>00:42:35,380 –&gt; 00:42:38,380<br>And then we say commit that it actually commits.</p>
<p>478<br>00:42:38,380 –&gt; 00:42:44,380<br>And everyone’s in sync at the same time about, you know, and agrees what these are the changes that are getting made.</p>
<p>479<br>00:42:44,380 –&gt; 00:42:48,380<br>And then how are we going to decide if we want to split the database across different resources?</p>
<p>480<br>00:42:48,380 –&gt; 00:42:51,380<br>Is it the partition stuff I was saying before?</p>
<p>481<br>00:42:51,380 –&gt; 00:42:56,380<br>So as always, in all parts of the systems, especially in databases, we’re not going to make trade-offs.</p>
<p>482<br>00:42:56,380 –&gt; 00:43:00,380<br>Because we’re not going to be able to guarantee that our database system is going to be online all the time,</p>
<p>483<br>00:43:00,380 –&gt; 00:43:06,380<br>and can answer any possible query, especially if nodes start going down and messages start getting lost and we can’t communicate between nodes.</p>
<p>484<br>00:43:06,380 –&gt; 00:43:09,380<br>We have to make a decision on what should we do?</p>
<p>485<br>00:43:09,380 –&gt; 00:43:15,380<br>Should we produce incorrect results or should we just stop everything until we can get back online?</p>
<p>486<br>00:43:16,380 –&gt; 00:43:18,380<br>So next class, we’re going to focus on this.</p>
<p>487<br>00:43:18,380 –&gt; 00:43:20,380<br>Again, how do we ensure correctness?</p>
<p>488<br>00:43:20,380 –&gt; 00:43:23,380<br>How do we make sure that we can coordinate transactions across multiple nodes?</p>
<p>489<br>00:43:23,380 –&gt; 00:43:30,380<br>The TLDR is going to be something like Paxos or two-phase commit or raft if you’re familiar with those protocols.</p>
<p>490<br>00:43:30,380 –&gt; 00:43:35,380<br>But then we have to handle replication and other things.</p>
<p>491<br>00:43:35,380 –&gt; 00:43:40,380<br>All right, so the first decision we’ve got to make is what should the nodes actually do?</p>
<p>492<br>00:43:40,380 –&gt; 00:43:44,380<br>And the two approaches are you have home and genius nodes or heterogeneous nodes.</p>
<p>493<br>00:43:44,380 –&gt; 00:43:53,380<br>And so what I’ve shown so far are more or less home and genius nodes where every node in our database system cluster can do any task.</p>
<p>494<br>00:43:53,380 –&gt; 00:43:59,380<br>I mean, I can send a query to any node and that node can then figure out, okay, where’s the data that I need?</p>
<p>495<br>00:43:59,380 –&gt; 00:44:05,380<br>How do I send it to that location or get the data that I need to put it back together?</p>
<p>496<br>00:44:05,380 –&gt; 00:44:15,380<br>And what is nice about this approach is that it makes provisioning the resources you need for your database cluster easy.</p>
<p>497<br>00:44:15,380 –&gt; 00:44:23,380<br>And if a node goes down and you spin up a new one, it just replaces the, you know, fits in with the rest of the system, the rest of the nodes.</p>
<p>498<br>00:44:23,380 –&gt; 00:44:28,380<br>And you don’t have to worry about rebalancing who’s doing what?</p>
<p>499<br>00:44:28,380 –&gt; 00:44:33,380<br>And a homogeneous architecture, you have nodes be assigned to specific tasks.</p>
<p>500<br>00:44:33,380 –&gt; 00:44:37,380<br>I’ve already alluded to this already. You could say you could have this catalog service at the separate node.</p>
<p>501<br>00:44:37,380 –&gt; 00:44:41,380<br>You could have a coordinator node or middleware is a separate node.</p>
<p>502<br>00:44:41,380 –&gt; 00:44:45,380<br>And then you make decisions about what’s going to be stateless, what’s going to be stable.</p>
<p>503<br>00:44:45,380 –&gt; 00:44:52,380<br>And should I have multiple sort of virtual nodes assigned to a single physical node so that, you know, one box can do multiple things.</p>
<p>504<br>00:44:52,380 –&gt; 00:45:02,380<br>But now that box goes down, which it will in a real system, then how do I decide where to place the new tasks or fail over to the new task?</p>
<p>505<br>00:45:02,380 –&gt; 00:45:05,380<br>Again, different systems do different things.</p>
<p>506<br>00:45:05,380 –&gt; 00:45:14,380<br>I would say in the cloud architecture, the heterogeneous approach is more common now with a coordinator or middleware sitting in front of the rest of the compute nodes.</p>
<p>507<br>00:45:14,380 –&gt; 00:45:19,380<br>Like this is what snowflake will give you, data bricks and others.</p>
<p>508<br>00:45:19,380 –&gt; 00:45:25,380<br>But some of the no-seqal systems like Cassandra, for example, or these just should be key value stores.</p>
<p>509<br>00:45:25,380 –&gt; 00:45:29,380<br>There’ll be homogeneous nodes.</p>
<p>510<br>00:45:29,380 –&gt; 00:45:37,380<br>I don’t actually want to give me a question that like if you’re no-seqal, you’re homogeneous, if you’re sequel or relational, you’re heterogeneous, everybody does something different.</p>
<p>511<br>00:45:37,380 –&gt; 00:45:42,380<br>And I’m not saying one approach is better than another.</p>
<p>512<br>00:45:42,380 –&gt; 00:45:54,380<br>All right, we’re going to talk about data transparency. Again, the idea is that we don’t want our application to be aware of where the data is actually located and where the physical nodes are.</p>
<p>513<br>00:45:54,380 –&gt; 00:46:00,380<br>Now, in some ways that are high level, you kind of need to be aware of where your data actually is.</p>
<p>514<br>00:46:00,380 –&gt; 00:46:11,380<br>Like if I’m going to run an expensive query, I don’t want to do a two petabyte join between data that’s in, you know, across the country and a data center in my local data center.</p>
<p>515<br>00:46:11,380 –&gt; 00:46:15,380<br>Because that’s going to be super expensive. Now, if it’s on a void, well, sure, right?</p>
<p>516<br>00:46:15,380 –&gt; 00:46:21,380<br>But, you know, you don’t want people to be too loosey goosey with sending whatever query that they want.</p>
<p>517<br>00:46:21,380 –&gt; 00:46:31,380<br>Some high level understanding of where things are, but like the exact physical address of what data is at what partition, ideally we want all that to be hidden.</p>
<p>518<br>00:46:31,380 –&gt; 00:46:45,380<br>So that the same SQL query that someone builds, you know, that runs today could run the next day, even though the physical nodes have been reorganized or data moved, has moved around because I’ve re re rebalanced.</p>
<p>519<br>00:46:45,380 –&gt; 00:46:55,380<br>So again, I don’t want ideally not to have specific hints or physical location of where hints or keywords inside my SQL queries.</p>
<p>520<br>00:46:55,380 –&gt; 00:47:04,380<br>I want to have all that abstract away and let the data system decide the best way to handle all that.</p>
<p>521<br>00:47:04,380 –&gt; 00:47:07,380<br>So now let’s talk about having, we want to split our database up.</p>
<p>522<br>00:47:07,380 –&gt; 00:47:20,380<br>So, again, it’s just like in a parallel database, so we talk before where we want to divide our database across into disjoint subsets so that I can take advantage of, the system can take advantage of all the additional hardware that’s available to us.</p>
<p>523<br>00:47:20,380 –&gt; 00:47:28,380<br>I don’t want to pay for 100 machines in my database system, my distributed data system, but then only be able to use one of them or two of them.</p>
<p>524<br>00:47:28,380 –&gt; 00:47:31,380<br>That would be stupid and a waste of money.</p>
<p>525<br>00:47:31,380 –&gt; 00:47:36,380<br>So I’m going to use the term partitioning in the relational database world or an academic world that’s the term we use.</p>
<p>526<br>00:47:36,380 –&gt; 00:47:43,380<br>If you ever read documentation about the no-seqal systems or other open source distributed databases, they might say the term sharding.</p>
<p>527<br>00:47:43,380 –&gt; 00:47:52,380<br>The idea is basically the same. We’re going to break the database into disjoint subsets and we’re going to store them on those subsets into different locations.</p>
<p>528<br>00:47:52,380 –&gt; 00:48:06,380<br>And then now, just like in a parallel database, a query shows up, I may want to break it up into the query plan into query fragments and distribute those fragments to the different compute nodes and have them execute on the partitions that they have.</p>
<p>529<br>00:48:06,380 –&gt; 00:48:11,380<br>And then there’ll be some exchange operator some way to coalesce results and produce a single answer back to the application.</p>
<p>530<br>00:48:11,380 –&gt; 00:48:18,380<br>So because again, I don’t want to have, I don’t want to read my SQL query if I add new nodes or take away nodes.</p>
<p>531<br>00:48:18,380 –&gt; 00:48:27,380<br>The same SQL query that works on that machine, you know, distributed database with 10 nodes, should work on also with 100 nodes without having to make any changes.</p>
<p>532<br>00:48:28,380 –&gt; 00:48:41,380<br>So the database system is going to be able to partition the data, the data is physically, if it’s shared nothing, because again, we have to physically divide it up across different nodes or logically in a shared disk system, because again, those compute nodes are technically sort of stateless.</p>
<p>533<br>00:48:41,380 –&gt; 00:48:53,380<br>And they’re pulling data from the shared disk, shared disk layer. But I would still want to know who’s responsible what portion or what partition of the shared disk.</p>
<p>534<br>00:48:54,380 –&gt; 00:49:02,380<br>So we’ll talk about different ways to do partitioning. So the most naive approach or the simplest approach is called simple table partitioning.</p>
<p>535<br>00:49:02,380 –&gt; 00:49:13,380<br>This is not that common. I know Mongo does this. I don’t know what other systems do. But the idea here is you basically just say, all right, this table, it’s entire town tense goes to this node and this other table goes to this other node.</p>
<p>536<br>00:49:13,380 –&gt; 00:49:23,380<br>And this works great if you don’t do joins across those two tables. And most operations on the tables are very fast and only touching the small amount of data.</p>
<p>537<br>00:49:23,380 –&gt; 00:49:29,380<br>Because then you can make sure that you’re the load of the application is spread across the different the different nodes.</p>
<p>538<br>00:49:29,380 –&gt; 00:49:42,380<br>So let’s see really simple example. I have two tables. So I’m going to take color code them all the rows or two pulls from partition table one goes the first partition, all the two pulls from table two goes the second partition.</p>
<p>539<br>00:49:42,380 –&gt; 00:49:55,380<br>And then my idea scenario of any query that just looks at only one of those tables, no joins, this will be okay. Again, assuming that there’s could be hot spots and other issues, but for simplicity, we can ignore that.</p>
<p>540<br>00:49:55,380 –&gt; 00:50:11,380<br>So in the case of Mongo, the example they told me the reason why they supported this is that they had some customers where they had the they wanted to do horizontal partitioning. We’ll see in a second across most of the tables, but they had one table that was like almost like an application log.</p>
<p>541<br>00:50:11,380 –&gt; 00:50:31,380<br>So anytime there was a change, they would write in sort of new record into that table. And you never actually read it, you just want to write it. So they to ensure that that right operation in the fear of other partitions, it would just all go to a single single node for them that worked.</p>
<p>542<br>00:50:32,380 –&gt; 00:50:52,380<br>A vertical partition is like a way to do a poor man’s column store. The idea here is that we’re going to split the table based on the actual attributes in itself, but not the values of them, but rather just the entire column and the entire, you know, all the all the values are given attribute.</p>
<p>543<br>00:50:52,380 –&gt; 00:51:05,380<br>So let’s say in this case here, we have a table that has four columns, the first three columns are 30-bit integers so that they’re small, they’re cheap. But then I have a fourth attribute that’s a text field. And maybe this is like 10 megabytes or something like that.</p>
<p>544<br>00:51:05,380 –&gt; 00:51:18,380<br>But most my queries only when access the first three attributes. So instead of having to again, assuming I’m a row store, pollute my buffer pool and bring much data in for this attribute.</p>
<p>545<br>00:51:18,380 –&gt; 00:51:33,380<br>I could just do vertical partitioning where I split it up, almost stored as a virtual table, if you will, and then have that be stored as a separate partition and manage separately in my cluster.</p>
<p>546<br>00:51:33,380 –&gt; 00:51:51,380<br>So you could do this, but you still want to do like, you know, to separate the two portions of the table, but you still want to do horizontal partition, which seemed the next slide, because maybe I want to distribute the two pulls across different partitions as well.</p>
<p>547<br>00:51:51,380 –&gt; 00:52:04,380<br>I still hope horizontal partition, I think we covered also what propellated basis earlier, but this is what most people think about when they think about distributed data is how to divide things up. And again, if you say, sharding, this is what people mean.</p>
<p>548<br>00:52:05,380 –&gt; 00:52:23,380<br>The idea here is that we’re going to choose some column in our table that is going to be a going to distinguish the two pulls enough and distribute across our partitions so that we get even load across the across across our compute notes.</p>
<p>549<br>00:52:23,380 –&gt; 00:52:35,380<br>There’s no one hotspot partition ideally. It doesn’t always work if you have, if everyone is going to get, you know, updating a single key, you can’t distribute that, that’s going to be within the single partition.</p>
<p>550<br>00:52:35,380 –&gt; 00:52:45,380<br>But that’s not always the case. So the three ways to handle partitioning are, there’s actually four, there’s round robin, we could ignore that.</p>
<p>551<br>00:52:46,380 –&gt; 00:52:55,380<br>Hashing is pretty common, you basically pick some column, take the value of every single two pull, actually buy something, but you’re hash able, and then you decide what partition is going to go to.</p>
<p>552<br>00:52:56,380 –&gt; 00:53:05,380<br>Range partition, we’ve seen before, we set some kind of some some continuous range of values, and you say that that’s all goes one partition, the range goes to another partition.</p>
<p>553<br>00:53:06,380 –&gt; 00:53:13,380<br>Predicate partition is where you basically put a wear clause expression to determine what partition something’s going to go to.</p>
<p>554<br>00:53:14,380 –&gt; 00:53:23,380<br>It’s like mainly assigning say, you know, where where name equals Andy and age equals something, go to partition one, where name equals Andy and age equals something else, go to another partition.</p>
<p>555<br>00:53:25,380 –&gt; 00:53:29,380<br>That’s not as common as hashing and range partitioning.</p>
<p>556<br>00:53:30,380 –&gt; 00:53:35,380<br>Hatch partitioning is probably the most common one, and most of the no SQL systems are going to do this.</p>
<p>557<br>00:53:37,380 –&gt; 00:53:44,380<br>So go back to example here, so first we’ve got to do partition, we’ve got to pick a partition key, and let’s say for every reason this one is the one we want to use.</p>
<p>558<br>00:53:46,380 –&gt; 00:53:58,380<br>And so if we’re doing hash partitioning, we then take the value of every single two pull, hash it by some hash function, and it might have by the number of partitions that we have, and that’s just going to determine where the different two pulls go.</p>
<p>559<br>00:54:00,380 –&gt; 00:54:13,380<br>And so the ideal query for this scenario here is if you’re doing a look up with an exact value on the partitioning key, because now I can take whatever value passed into this query, hash it using the same hash function, and bottom by the number of parts.</p>
<p>560<br>00:54:14,380 –&gt; 00:54:18,380<br>And then I know exactly where the data you need, the data that query needs.</p>
<p>561<br>00:54:19,380 –&gt; 00:54:38,380<br>So that’s the sample here going back, this is physical partitioning, because I’m like taking, well, it’s all PowerPoint slides, but I’m saying the echo date itself is going to some physical location.</p>
<p>562<br>00:54:38,380 –&gt; 00:54:58,380<br>But again, in shared disk, we don’t really have that, right, we have these stateless nodes. So the idea is here is that we would just do, we would logically assign different values or different hash values, or in this case, a range of two pulls within our table or database, and they would assign them to the different nodes.</p>
<p>563<br>00:54:59,380 –&gt; 00:55:12,380<br>So now when a query shows up, like get ID equals one, my catalog service would tell me, okay, this node is responsible for that ID value, and it knows how to go get the data that it needs, and same thing for ID equals three.</p>
<p>564<br>00:55:14,380 –&gt; 00:55:21,380<br>And then if I want to get multiple ones, again, I can then potentially go up to the one at top, and it can get the data for me.</p>
<p>565<br>00:55:23,380 –&gt; 00:55:24,380<br>Yes.</p>
<p>566<br>00:55:24,380 –&gt; 00:55:27,380<br>So the main benefit of the logical partition of the actual quality?</p>
<p>567<br>00:55:27,380 –&gt; 00:55:34,380<br>So the question is the main benefit of logical partition and cache locality, as opposed to what physical partitioning?</p>
<p>568<br>00:55:34,380 –&gt; 00:55:44,380<br>So like, so you have to do, in a shared disk system, you have to do this because the resting place of the location of the data isn’t these nodes here.</p>
<p>569<br>00:55:45,380 –&gt; 00:55:53,380<br>It’s over here. So you got it aside. Okay, well if I query shows up, get ID equals three, get ID equals two, what node should be responsible for going at that data?</p>
<p>570<br>00:55:53,380 –&gt; 00:56:03,380<br>Because you, yeah, to your point, like, if you just make it random, then anybody’s reading any data, and then like, you’re just fetching from shared disk over and over again, and it costs more, and it’s going to be slower.</p>
<p>571<br>00:56:03,380 –&gt; 00:56:13,380<br>But by doing this logical partitioning, you’re potentially pinning the data here on this node to any query that shows up, you’re more likely to have it already in your cache, not pay the penalty going to disk again.</p>
<p>572<br>00:56:14,380 –&gt; 00:56:28,380<br>Yes. So I’m going to say a time, I’m going to skip, we’ve already discussed physical partitioning a bit. It’s basically the same idea that you keep track of like, you know, where the data actually physically is located on the nodes.</p>
<p>573<br>00:56:28,380 –&gt; 00:56:34,380<br>All right, so go back to my example here. What’s the problem with this approach? If you’re doing cache partitioning?</p>
<p>574<br>00:56:34,380 –&gt; 00:56:40,380<br>Yes. He said, he said scratch screen. Yes, that’s one, right?</p>
<p>575<br>00:56:40,380 –&gt; 00:56:52,380<br>If I have a range scan, you know, get start select from table where partition key between this and this, if it’s has partition, you can’t do that.</p>
<p>576<br>00:56:52,380 –&gt; 00:56:57,380<br>What’s another problem?</p>
<p>577<br>00:56:57,380 –&gt; 00:57:01,380<br>How do I scale out with this?</p>
<p>578<br>00:57:01,380 –&gt; 00:57:05,380<br>Right? Add a new node. What I need to do now.</p>
<p>579<br>00:57:05,380 –&gt; 00:57:16,380<br>I need it on my hashing to now mod by five. And that sucks because that’s going to move data from from, you know, basically re-shuffles the entire data system.</p>
<p>580<br>00:57:16,380 –&gt; 00:57:27,380<br>So that is one advantage of range partitioning, but now how to figure out the range, that’s not true, not, not trivial as well.</p>
<p>581<br>00:57:27,380 –&gt; 00:57:33,380<br>So there’s actually a way to handle this, which is really clever. Who here has heard of consistent hashing before?</p>
<p>582<br>00:57:33,380 –&gt; 00:57:39,380<br>No, okay. About half of it is more than previous years.</p>
<p>583<br>00:57:39,380 –&gt; 00:57:43,380<br>So because this is a partition, this is a hashing, it’s a really neat technique.</p>
<p>584<br>00:57:43,380 –&gt; 00:57:49,380<br>It was invented by in the early 2000s at MIT in this project called cord.</p>
<p>585<br>00:57:49,380 –&gt; 00:57:59,380<br>And basically what’s going to allow us to do is, because allows you incremental addition and removal of nodes in our cluster using has partitioning without having to rebalance everything.</p>
<p>586<br>00:57:59,380 –&gt; 00:58:03,380<br>And a bunch of different database systems are going to take advantage of this.</p>
<p>587<br>00:58:03,380 –&gt; 00:58:14,380<br>So the basic idea is that you have this, say, this ring of locations of where a key might exist in your database.</p>
<p>588<br>00:58:14,380 –&gt; 00:58:27,380<br>So let’s say I have three partitions, P1, P2, P3. So now if I’m going to do a lookup, say, find me key one, I would hash it and produce a value of 0 and 1, and I would end up with some location in my ring.</p>
<p>589<br>00:58:27,380 –&gt; 00:58:40,380<br>And now all I need to do is just have some kind of metadata, some lookup table, and say, okay, for this range for on my ring, what’s the, if I go clockwise, what’s the next partition I’m going to find?</p>
<p>590<br>00:58:40,380 –&gt; 00:58:47,380<br>So if I land in the middle here, then I know that the data, the partition is going to have the data I need is on P1.</p>
<p>591<br>00:58:47,380 –&gt; 00:58:55,380<br>So that’s why I hash key two, I landed this part of the ring, then I know the slide around clockwise, and I find P3.</p>
<p>592<br>00:58:55,380 –&gt; 00:59:10,380<br>So the way I think about it is that these colors here correspond to the range of hash values that these P3, P3, is from P3, here, all the way back to P2 and so forth.</p>
<p>593<br>00:59:10,380 –&gt; 00:59:18,380<br>So far that’s nice, but that doesn’t solve our problem of how do we actually add new partitions.</p>
<p>594<br>00:59:18,380 –&gt; 00:59:35,380<br>So what the ring provides for us, because it’s circular, is that we can introduce a new partition somewhere in the ring, in this case here we add P4, and the only thing we need to reshuffle is any data that is now managed by this partition here along the ring.</p>
<p>595<br>00:59:35,380 –&gt; 00:59:50,380<br>So it’s only has to do with P3. So now all the data from P4 over here to P2 and the ring that used to be on P3, P3 has to send over here, and I don’t need to move any other data in any other partition.</p>
<p>596<br>00:59:51,380 –&gt; 01:00:02,380<br>Likewise, I get to add P5 here, and P6 here, and it just changes the range of the values that correspond to a given node.</p>
<p>597<br>01:00:03,380 –&gt; 01:00:11,380<br>So now what’s interesting about this next week is that you can actually use this ring also to replication.</p>
<p>598<br>01:00:11,380 –&gt; 01:00:24,380<br>Meaning if I save a replication of factor 3, I want to have three copies of any key or any two-by-write database, I want three copies on different partitions.</p>
<p>599<br>01:00:25,380 –&gt; 01:00:35,380<br>So if I do a write to P1, I just follow along the ring and find the next two partitions along that range, and I’ll make sure I write the data there.</p>
<p>600<br>01:00:35,380 –&gt; 01:00:50,380<br>So now if a query shows up, say I want to find key 1, again I could get actually data from either P1, P6, or P2, because they’re the three closest ones clockwise in my ring.</p>
<p>601<br>01:00:51,380 –&gt; 01:01:17,380<br>Now there’s a bunch of games you can play about like, okay if I do a write, and I do a replication factor 3, should I wait for all three nodes to respond with the correct answer or acknowledgement that I did the right or maybe I can just maybe just get a majority, because if I do a read, should I wait for all three nodes in my ring, or is one of them coming back, is that good enough for me?</p>
<p>602<br>01:01:17,380 –&gt; 01:01:29,380<br>Again, this is how we’ll see this next week, when we do transactions, like we don’t have to have full consistency or shrunk consistency, we may be okay with things eventually getting propagated across different nodes.</p>
<p>603<br>01:01:29,380 –&gt; 01:01:32,380<br>And again, this is the new SQL guys do.</p>
<p>604<br>01:01:32,380 –&gt; 01:01:51,380<br>So there’s a bunch of systems here that use this. This actually technique for data bases, the original idea was developed at MIT in 2000s, and they had sort of a distributed hash table called Cored, but this famously was using databases and Amazon in this key value store called Dynamo.</p>
<p>605<br>01:01:51,380 –&gt; 01:02:04,380<br>It’s a paper 2007 that took the hell they were using this approach. In the fallout paper in 2022, they didn’t say, okay, when we took the research system, Dynamo, and made the commercial version, Dynamo DB, they dropped consistent hashing.</p>
<p>606<br>01:02:05,380 –&gt; 01:02:10,380<br>And then they use a the higher call replication scheme that we’ll see next class.</p>
<p>607<br>01:02:11,380 –&gt; 01:02:24,380<br>But a bunch of these systems use this and actually react was a no SQL system, they went under six, seven years ago, we can kind of see in the logo here, like there’s the dots of the ring and the replication stuff because they’re using consistent hashing.</p>
<p>608<br>01:02:24,380 –&gt; 01:02:37,380<br>Snowflake doesn’t do this for the catalog, they use Foundation DB, which is a fully transactional key value store for the catalog, but they use consistent hashing for caching of, and they’re shared disc architecture.</p>
<p>609<br>01:02:37,380 –&gt; 01:02:43,380<br>They’re using consistent hashing to do logical partition of the metadata where things are located.</p>
<p>610<br>01:02:43,380 –&gt; 01:02:48,380<br>And Cassandra is probably the most widely one that does this as well as catchphrase.</p>
<p>611<br>01:02:52,380 –&gt; 01:03:05,380<br>So we’ll talk more about transactions next class, but the basic big challenge is going to be transaction shows up, we look at a metadata service, a catalog service, and try to figure out what data they’re going to need access.</p>
<p>612<br>01:03:06,380 –&gt; 01:03:16,380<br>And then we’re going to use that to figure out whether it’s a single node transaction or like touching one partition, which is the best case scenario because we only have to check data within that single node.</p>
<p>613<br>01:03:17,380 –&gt; 01:03:31,380<br>Or if it’s a distributed transaction meaning we’re touching data multiple nodes, multiple locations, then we’ve got to run distributed concurrency troll and a consensus protocol to make sure that everyone agrees that this transaction is allowed to commit, allow them to make the changes that it made.</p>
<p>614<br>01:03:32,380 –&gt; 01:03:37,380<br>So we’ll ignore replication for today and the next class will cover how we actually want to handle that as well.</p>
<p>615<br>01:03:37,380 –&gt; 01:03:47,380<br>I showed replication and consistent hashing. I do a right to my database. I don’t have like some number of copies to make sure that my data is always available even if there’s a crash.</p>
<p>616<br>01:03:48,380 –&gt; 01:04:01,380<br>So for if we want to support multiple operations on different nodes, then we need some way to coordinate the execution that turns actually.</p>
<p>617<br>01:04:02,380 –&gt; 01:04:12,380<br>And the basic two approaches that you could have a sort of centralized coordinator that acts as a global traffic cop that has a complete view of what’s going on at any time in our database system.</p>
<p>618<br>01:04:13,380 –&gt; 01:04:22,380<br>Or it would be decentralized and let the nodes organize amongst themselves and talk amongst themselves to figure out what’s actually going to be running and who’s allowed to commit at what time.</p>
<p>619<br>01:04:23,380 –&gt; 01:04:38,380<br>Most distributed data, this is going to use a hybrid approach where it’s going to be decentralized meaning that there isn’t going to be one dedicated machine or node that’s going to be the traffic cop.</p>
<p>620<br>01:04:39,380 –&gt; 01:04:51,380<br>But since it’s slow to do distributed or decentralized concurrent control, they’re going to elect the leader that’s going to temporarily be the traffic cop coordinator and decide whether transaction allowed to commit.</p>
<p>621<br>01:04:51,380 –&gt; 01:04:56,380<br>But if now that that node goes down, then you do a new leader election and somebody else can take over.</p>
<p>622<br>01:04:56,380 –&gt; 01:05:01,380<br>And again, the spoiler is going to be we’re going to use raft or Paxos to do that election.</p>
<p>623<br>01:05:02,380 –&gt; 01:05:13,380<br>So I’m going to go through two different approaches, different examples of how you do these decentralized decentralized approaches and then that’ll segue into how to be then coordinate transactions next class.</p>
<p>624<br>01:05:15,380 –&gt; 01:05:23,380<br>So the first example of the early examples of doing distributed transactions was a centralized approach using what is called a TP monitor.</p>
<p>625<br>01:05:24,380 –&gt; 01:05:38,380<br>So most of you have not heard of a TP monitor. I think the original T, the original, you know, what it stood for was, I think, originally, the outcome processing monitor, but that nobody refers through it as an hour.</p>
<p>626<br>01:05:38,380 –&gt; 01:05:40,380<br>So now you say it’s a transaction processing monitor.</p>
<p>627<br>01:05:40,380 –&gt; 01:05:47,380<br>But think of it as like it’s a separate server or separate demon running somewhere that can coordinate transactions across different nodes.</p>
<p>628<br>01:05:48,380 –&gt; 01:06:01,380<br>And this is built in the 1970s, 1980s because there wasn’t really, as I said in the early days, there wasn’t a single distributed data system that was aware of different nodes and things like that.</p>
<p>629<br>01:06:01,380 –&gt; 01:06:03,380<br>People sort of cobbled things together.</p>
<p>630<br>01:06:03,380 –&gt; 01:06:13,380<br>And so they would build this TP monitor as a separate system that then could then coordinate transactions across different disparate database systems that didn’t know that they were doing transactions and distributed way.</p>
<p>631<br>01:06:13,380 –&gt; 01:06:19,380<br>It just saw something that they thought was a client telling it, you know, whether to commit or run a query and so forth.</p>
<p>632<br>01:06:19,380 –&gt; 01:06:32,380<br>So the most famous one of these TP monitors is a system called Saber. This is built by American Airlines back in the 1970s for all like running transactions across different different databases for doing airline reservations.</p>
<p>633<br>01:06:32,380 –&gt; 01:06:36,380<br>And there’s a bunch of airlines that all still use Saber today.</p>
<p>634<br>01:06:36,380 –&gt; 01:06:42,380<br>For one of us really slow to book airline stuff because there’s running one shit from the 70s, right?</p>
<p>635<br>01:06:42,380 –&gt; 01:06:48,380<br>In the 1990s, there was a movement to try to standardize the protocol for what the healthy TP monitors to talk different things.</p>
<p>636<br>01:06:48,380 –&gt; 01:06:51,380<br>So this is called OpenXA or X Open.</p>
<p>637<br>01:06:51,380 –&gt; 01:07:02,380<br>And again, most of the enterprise systems that none of us in this room can afford a good Oracle and Teradata and nonstop, they’re all going to support this protocol.</p>
<p>638<br>01:07:02,380 –&gt; 01:07:06,380<br>I think actually Postgres might be a little support some subset of it.</p>
<p>639<br>01:07:06,380 –&gt; 01:07:14,380<br>But this is how they were going to have a standard API to have these, to have me to coordinate these TV monitors.</p>
<p>640<br>01:07:14,380 –&gt; 01:07:16,380<br>So let’s see example here.</p>
<p>641<br>01:07:16,380 –&gt; 01:07:20,380<br>Again, I’m not saying whether there’s a shared desk or a shared nothing system. It doesn’t matter at this point.</p>
<p>642<br>01:07:20,380 –&gt; 01:07:24,380<br>Matters like, okay, we have these partitions assumed that they can’t talk directly to each other.</p>
<p>643<br>01:07:24,380 –&gt; 01:07:27,380<br>How do we actually coordinate transactions?</p>
<p>644<br>01:07:27,380 –&gt; 01:07:31,380<br>So, say if I want to have a transaction, I want to touch data of these three partitions.</p>
<p>645<br>01:07:31,380 –&gt; 01:07:40,380<br>Again, assuming we know how to go to our metadata service to figure out what data we want to touch, the application server goes to the coordinator and says, hey, I want to lock data at this partition.</p>
<p>646<br>01:07:40,380 –&gt; 01:07:43,380<br>And the coordinator is going to have its own local lock table.</p>
<p>647<br>01:07:43,380 –&gt; 01:07:50,380<br>Just like you have on a single node system that knows about all the different partitions that are in the distributed database.</p>
<p>648<br>01:07:50,380 –&gt; 01:07:54,380<br>And assuming now we just do, of course, the entire partition.</p>
<p>649<br>01:07:54,380 –&gt; 01:08:03,380<br>So it’ll go ahead and, you know, say, running two phase locking just before and acquire the locks on that data gets back an acknowledgement to the application server.</p>
<p>650<br>01:08:03,380 –&gt; 01:08:08,380<br>Now the application server can send whatever queries it wants to the different partitions to do whatever it wants to do.</p>
<p>651<br>01:08:08,380 –&gt; 01:08:15,380<br>And then when it’s done doing those updates or look ups, it goes to the coordinator, says, hey, I want to commit this transaction.</p>
<p>652<br>01:08:15,380 –&gt; 01:08:17,380<br>The coordinator then communicates the different partitions.</p>
<p>653<br>01:08:17,380 –&gt; 01:08:23,380<br>This says, hey, is this thing saved to commit? Yes or no? Then if yes, then we get back an acknowledgement.</p>
<p>654<br>01:08:23,380 –&gt; 01:08:33,380<br>Right? So as I said, there was a bunch of old systems that are still predicated or used this technology.</p>
<p>655<br>01:08:33,380 –&gt; 01:08:40,380<br>The B.E.A. had this thing called Tuxedo from the 1980s that Oracle bought 10 years ago or 15 years ago.</p>
<p>656<br>01:08:40,380 –&gt; 01:08:46,380<br>That was a TV monitor. Trans Arc was a, came out of the A.F.S. projects here at CMU.</p>
<p>657<br>01:08:46,380 –&gt; 01:08:51,380<br>And then they did it, they did it, spin it off as a startup. It was acquired by IBM.</p>
<p>658<br>01:08:51,380 –&gt; 01:08:56,380<br>You know, Jeff Eppinger in the software engineering department. He was the, he was the founder of that company.</p>
<p>659<br>01:08:56,380 –&gt; 01:09:01,380<br>This is a, it’s hard to read, but it says omid, omid.</p>
<p>660<br>01:09:01,380 –&gt; 01:09:05,380<br>This is a, it’s a TV, they don’t call it a TV monitor because that’s a data term.</p>
<p>661<br>01:09:05,380 –&gt; 01:09:09,380<br>But it’s a, it’s a centralized transaction coordinator. They run HBASE transactions.</p>
<p>662<br>01:09:09,380 –&gt; 01:09:15,380<br>That was developed by Yahoo Labs a few years ago. And still around today.</p>
<p>663<br>01:09:15,380 –&gt; 01:09:25,380<br>All right. What is more common is to use this middleware approach where the, there’s some software, some service running in between the application server and the database system itself.</p>
<p>664<br>01:09:25,380 –&gt; 01:09:31,380<br>And so the application communicate directly with the, the partitions of the nodes. Everything has to go through the coordinator.</p>
<p>665<br>01:09:31,380 –&gt; 01:09:38,380<br>Right. So you send query requests. The middleware maintains its own lock table, just like the, the TV monitor.</p>
<p>666<br>01:09:38,380 –&gt; 01:09:43,380<br>And then it’s responsible for sending the, acquiring lock sending queries to the different partitions.</p>
<p>667<br>01:09:43,380 –&gt; 01:09:49,380<br>And then it’s done. You get the commit request. You know, it’s responsible. We’re going to the, to the different partitions.</p>
<p>668<br>01:09:49,380 –&gt; 01:09:58,380<br>And say, hey, am I allowed to commit yes or no? Right. So, I mean, there’s a lot of commercial systems that, that do this now.</p>
<p>669<br>01:09:58,380 –&gt; 01:10:02,380<br>But this is, this is how Facebook scaled out my sequel back in the day. Right.</p>
<p>670<br>01:10:02,380 –&gt; 01:10:06,380<br>Because my sequel couldn’t do to search his actions. They put a middleware thing in front of it.</p>
<p>671<br>01:10:06,380 –&gt; 01:10:11,380<br>Or Google did the same thing with, with using my sequel for ads.</p>
<p>672<br>01:10:11,380 –&gt; 01:10:19,380<br>If you’re familiar with the tests or the, there’s a startup called Planet scale. That’s how they did transactions on my sequel for YouTube.</p>
<p>673<br>01:10:19,380 –&gt; 01:10:26,380<br>I say YouTube runs on something like this. Right. This is very common.</p>
<p>674<br>01:10:26,380 –&gt; 01:10:32,380<br>And the last one is a distributed decentralized approach. Again, where there is no bit of where there is no global transaction coordinator.</p>
<p>675<br>01:10:32,380 –&gt; 01:10:38,380<br>Query shows up or request to start a transaction shows up some partition.</p>
<p>676<br>01:10:38,380 –&gt; 01:10:46,380<br>How that, how we decided to go to the air versus another one, you can depends on what’s in the metadata.</p>
<p>677<br>01:10:46,380 –&gt; 01:10:51,380<br>So as the leader node for this transaction, and then you may create requests to different partitions.</p>
<p>678<br>01:10:51,380 –&gt; 01:10:56,380<br>Then at some point it’s going to go to the leader says, hey, I want to commit.</p>
<p>679<br>01:10:56,380 –&gt; 01:11:05,380<br>And then leaders are as responsible for coordinating with other other other node deciding whether this is a lot of commit or not. Yes or no.</p>
<p>680<br>01:11:05,380 –&gt; 01:11:12,380<br>Again, we’ll go in more detail this next week.</p>
<p>681<br>01:11:12,380 –&gt; 01:11:20,380<br>All right. So I’m going to show you a, I’m going to expose you to this idea of federated databases. I don’t think it’s actually pie is in the textbook.</p>
<p>682<br>01:11:20,380 –&gt; 01:11:32,380<br>It’s an old idea. I just want to show this to you again to see that as an example of like you can start doing some really interesting thing with distributed databases where it may not, may not be the case of the, the,</p>
<p>683<br>01:11:32,380 –&gt; 01:11:37,380<br>that all the nodes your database are from running the same software from the same database system.</p>
<p>684<br>01:11:37,380 –&gt; 01:11:47,380<br>I sort of mentioned that with the the TP monitor stuff was like these disparate systems were being coupled together and using TP monitor decide how to coordinate transactions on them.</p>
<p>685<br>01:11:47,380 –&gt; 01:11:59,380<br>But the idea with federated databases is that it’s almost like the middleware approach where you put something in front of the database systems that can make it look like it’s all a single type of database system, but underneath the coverage it’s rewriting queries for you.</p>
<p>686<br>01:11:59,380 –&gt; 01:12:07,380<br>Right. And the reason why we want to do this is because in a lot of organizations when you guys got in the real world, a lot of companies have a ton of different databases.</p>
<p>687<br>01:12:07,380 –&gt; 01:12:14,380<br>Right. Because some guy in some corner of the company that nobody’s paying attention to, but a little app internally using mango or whatever.</p>
<p>688<br>01:12:14,380 –&gt; 01:12:21,380<br>Because they thought it was cool because they saw on hacker news and it was fine when he was just using it, but then his, his buddy started using it and other things started using it before you know it.</p>
<p>689<br>01:12:21,380 –&gt; 01:12:25,380<br>Half the company has to use this application and now the company has to support mango.</p>
<p>690<br>01:12:25,380 –&gt; 01:12:31,380<br>But nevermind, they’ve been using Oracle or Postgres for years and now you know they have a bunch of new databases that support.</p>
<p>691<br>01:12:31,380 –&gt; 01:12:37,380<br>So at large companies, it’s never homogenous. People choose different databases all the time.</p>
<p>692<br>01:12:37,380 –&gt; 01:12:48,380<br>And now you have these different data silos and ideally you want to have a single view of all your data and federated. This is our one way to do this.</p>
<p>693<br>01:12:48,380 –&gt; 01:12:53,380<br>Right. So the idea is it’s going to be distributed architecture using a middleware approach.</p>
<p>694<br>01:12:53,380 –&gt; 01:13:05,380<br>That can expose to the application a single logical view of the database. Even though underneath the covers, you know, maybe something stores stuff as JSON, something storing stuff as as relational tables or whatever.</p>
<p>695<br>01:13:05,380 –&gt; 01:13:11,380<br>But ideally you want your application only at the right queries against one, one data map.</p>
<p>696<br>01:13:11,380 –&gt; 01:13:18,380<br>So as I said, this is an old idea because back to the 1990s, nobody does this really well.</p>
<p>697<br>01:13:18,380 –&gt; 01:13:26,380<br>And nobody does this as efficiently as you possibly can because it’s sort of like the lowest common denominator to support one system well.</p>
<p>698<br>01:13:26,380 –&gt; 01:13:32,380<br>You want to be able to push down as much of the computations you can the query itself to that to that single system.</p>
<p>699<br>01:13:32,380 –&gt; 01:13:36,380<br>But you may not be able to be able to do that based on queries and antics and other issues.</p>
<p>700<br>01:13:36,380 –&gt; 01:13:41,380<br>So you got to pull a bunch of data to the centralized coordinator, then you’re joined there do whatever you need to do.</p>
<p>701<br>01:13:41,380 –&gt; 01:13:46,380<br>Right. Because the different database systems can’t talk directly to each other. You always have to go through the coordinator.</p>
<p>702<br>01:13:46,380 –&gt; 01:13:58,380<br>So let me go through an example here. So I have four different databases. My query goes to this middleware and the middleware is responsible for sending, dividing that query up into the corresponding queries that need a different database systems.</p>
<p>703<br>01:13:58,380 –&gt; 01:14:02,380<br>And then they get results back on the middleware and I put it all together.</p>
<p>704<br>01:14:02,380 –&gt; 01:14:11,380<br>Right. But again, the key ideas that we have a single logical view to the application of the data is even though it’s spread across different machines.</p>
<p>705<br>01:14:11,380 –&gt; 01:14:20,380<br>So again, it’s like a distributed database that’s doing partitioning. It’s just that we now have to do some extra work to make it look like it’s all unified, even though it’s not.</p>
<p>706<br>01:14:21,380 –&gt; 01:14:27,380<br>So if you were looking at Davis literature, these are going to call connectors usually. Postgres farm data wrappers can be used for this.</p>
<p>707<br>01:14:27,380 –&gt; 01:14:37,380<br>There’s this distributed or that system called presto. There’s a fork of it called Treno that came out of Facebook because people don’t like Facebook or something.</p>
<p>708<br>01:14:37,380 –&gt; 01:14:46,380<br>But they have a bunch of connected different type of systems. And again, in some cases, they can do complete query push down. They can take a query, push it down, tie to the database system that has the data you need.</p>
<p>709<br>01:14:46,380 –&gt; 01:14:53,380<br>In other cases, they have to copy one to the data back up, then do processing there to produce the answer that you need.</p>
<p>710<br>01:14:53,380 –&gt; 01:14:56,380<br>Okay.</p>
<p>711<br>01:14:56,380 –&gt; 01:15:02,380<br>All right. Last two slides. Can quick preview of what’s what’s your store store for us next week.</p>
<p>712<br>01:15:02,380 –&gt; 01:15:07,380<br>So we write it this multiple times. We may need a lot of multiple transactions to execute.</p>
<p>713<br>01:15:07,380 –&gt; 01:15:24,380<br>Some of the things that cross different nodes in our system. And we need to make sure that when they go to commit that we make sure that everyone agrees that this is allowed to happen and that it looks ideally that the changes are happening atomically, even though there’s spread across different machines.</p>
<p>714<br>01:15:24,380 –&gt; 01:15:33,380<br>It was hard enough to do this on a single box. Now we have to do this on multiple machines across different data centers. That’s challenging.</p>
<p>715<br>01:15:33,380 –&gt; 01:15:41,380<br>So replication will talk about next week. How do we, if we have the data in different copies of it in different locations, how to make sure that they’re all in sync.</p>
<p>716<br>01:15:41,380 –&gt; 01:16:01,380<br>The communication also expensive nodes could go down and it can be permanent like the machine catches on fire and it’s never coming back or like this is a pause because you know the GC kicks in or the the disk starts defragging something stupid and then messages get delayed or something stupid like someone trips over a wire and pulls it out and they plug it back in.</p>
<p>717<br>01:16:01,380 –&gt; 01:16:07,380<br>It comes back online and that’s a forget what’s going on. And now maybe even this the last like 30 seconds of transactions. What should we do?</p>
<p>718<br>01:16:07,380 –&gt; 01:16:18,380<br>And then clock skew will be a big issue when we start about time stamp ordering because how do we make sure that everyone agrees that this is the right time stamp or when transaction wants to commit.</p>
<p>719<br>01:16:18,380 –&gt; 01:16:24,380<br>Because again you can’t use a logical counter always because now like you know how do you make sure that everyone’s you know plus one at the same time.</p>
<p>720<br>01:16:24,380 –&gt; 01:16:32,380<br>You can’t maybe use a physical clock because the you know there’s there’s going to be drifting skew on the actual hardware itself.</p>
<p>721<br>01:16:32,380 –&gt; 01:16:37,380<br>So it’s really hard to make sure that clocks are actually in sync.</p>
<p>722<br>01:16:37,380 –&gt; 01:16:47,380<br>And the split is going to be the way Google handles handles this with with Spanner is that they put a time of clocks in the data center and they use that to get the time make sure everything’s in sync or they get the time from the GPS satellites.</p>
<p>723<br>01:16:47,380 –&gt; 01:16:53,380<br>They use that for you know when they run transactions in in their database which is amazing.</p>
<p>724<br>01:16:53,380 –&gt; 01:16:56,380<br>Nobody does that.</p>
<p>725<br>01:16:56,380 –&gt; 01:17:02,380<br>So again we’ll cover Spanner next week. Spanner is probably the might be one of the most advanced transactions from the systems.</p>
<p>726<br>01:17:02,380 –&gt; 01:17:05,380<br>Google did a lot of amazing things in that.</p>
<p>727<br>01:17:05,380 –&gt; 01:17:15,380<br>Took them a lot to get there right like they did a bunch of no SQL crap before but when they actually build a you know fully transaction system they were well ahead of everyone else.</p>
<p>728<br>01:17:15,380 –&gt; 01:17:17,380<br>It’s really fascinating.</p>
<p>729<br>01:17:17,380 –&gt; 01:17:19,380<br>All right so let’s see why this is hard.</p>
<p>730<br>01:17:19,380 –&gt; 01:17:22,380<br>Here’s how we want to do. See we’re going to use two phase locking.</p>
<p>731<br>01:17:22,380 –&gt; 01:17:29,380<br>So say we have two different application servers and our database is partitioned to two pieces here.</p>
<p>732<br>01:17:29,380 –&gt; 01:17:36,380<br>So applications number one once it’s set 80 equal to two application server over there once set B to equal to seven.</p>
<p>733<br>01:17:36,380 –&gt; 01:17:40,380<br>That’s fine because I can take locks on those those that data.</p>
<p>734<br>01:17:40,380 –&gt; 01:17:45,380<br>And for this first transaction here he doesn’t need any.</p>
<p>735<br>01:17:45,380 –&gt; 01:17:48,380<br>48 and vice versa going the other way.</p>
<p>736<br>01:17:48,380 –&gt; 01:17:53,380<br>But then the challenge is going to be if I want to start in my same transaction.</p>
<p>737<br>01:17:53,380 –&gt; 01:17:58,380<br>The first guy wants to update B another guy wants to update a now what’s the problem.</p>
<p>738<br>01:17:58,380 –&gt; 01:18:02,380<br>The deadlock right but now it’s a deadlock over a wider network potentially.</p>
<p>739<br>01:18:02,380 –&gt; 01:18:07,380<br>And I have to figure out who’s going to kill what to break the deadlock.</p>
<p>740<br>01:18:07,380 –&gt; 01:18:11,380<br>Well I can’t wait for a graph as we did before but where’s this located.</p>
<p>741<br>01:18:11,380 –&gt; 01:18:16,380<br>Is every node maintaining some weights or graph is a centralized coordinator.</p>
<p>742<br>01:18:16,380 –&gt; 01:18:18,380<br>And what if one of those nodes goes down.</p>
<p>743<br>01:18:18,380 –&gt; 01:18:23,380<br>You know say I decide oh this one’s the younger one I want to kill this this transaction to break the deadlock.</p>
<p>744<br>01:18:23,380 –&gt; 01:18:25,380<br>But then that no goes down doesn’t get the message.</p>
<p>745<br>01:18:25,380 –&gt; 01:18:27,380<br>And it comes back up and still think it has the locks.</p>
<p>746<br>01:18:27,380 –&gt; 01:18:29,380<br>What do we do.</p>
<p>747<br>01:18:29,380 –&gt; 01:18:31,380<br>All right.</p>
<p>748<br>01:18:31,380 –&gt; 01:18:34,380<br>There’s going to be no magical ball at the hand the handle this.</p>
<p>749<br>01:18:34,380 –&gt; 01:18:37,380<br>It made it oftentimes just like okay I waited long enough.</p>
<p>750<br>01:18:37,380 –&gt; 01:18:39,380<br>You know full steam head let’s go.</p>
<p>751<br>01:18:39,380 –&gt; 01:18:42,380<br>Or maybe the case of like okay well I.</p>
<p>752<br>01:18:42,380 –&gt; 01:18:47,380<br>The majority of nodes I can’t read I can’t talk to so I’m assuming I have a split brain meaning I can’t see the other side.</p>
<p>753<br>01:18:47,380 –&gt; 01:18:50,380<br>So I’m going to stop running any queries.</p>
<p>754<br>01:18:50,380 –&gt; 01:18:54,380<br>Until things get resolved and I come back.</p>
<p>755<br>01:18:54,380 –&gt; 01:18:56,380<br>Right.</p>
<p>756<br>01:18:56,380 –&gt; 01:19:00,380<br>So this is what we just cost next week after the break.</p>
<p>757<br>01:19:00,380 –&gt; 01:19:04,380<br>Again the main takeaway from all this should be that this is all very very hard to do.</p>
<p>758<br>01:19:04,380 –&gt; 01:19:09,380<br>And that in most cases people do not need most people don’t need a distributed database.</p>
<p>759<br>01:19:09,380 –&gt; 01:19:12,380<br>Repetition is a separate issue will handle that next class.</p>
<p>760<br>01:19:12,380 –&gt; 01:19:15,380<br>But most people don’t need to scale horizontally.</p>
<p>761<br>01:19:15,380 –&gt; 01:19:18,380<br>99% of the databases are like 10 gigs 20 gigs maybe 100 gigs.</p>
<p>762<br>01:19:18,380 –&gt; 01:19:22,380<br>But even then it’s not going to be that big.</p>
<p>763<br>01:19:22,380 –&gt; 01:19:25,380<br>And the cases that you do need a distributed database.</p>
<p>764<br>01:19:25,380 –&gt; 01:19:31,380<br>Well there’s a lot of these cloud services like snowflake or BigQuery or whatever like they’ll handle all this for you.</p>
<p>765<br>01:19:31,380 –&gt; 01:19:35,380<br>And you don’t have to manage yourself.</p>
<p>766<br>01:19:35,380 –&gt; 01:19:39,380<br>Transaction stuff is still very hard for OLAP because it’s.</p>
<p>767<br>01:19:39,380 –&gt; 01:19:41,380<br>There’s other challenges but coordinate the concurrent.</p>
<p>768<br>01:19:41,380 –&gt; 01:19:48,380<br>Virtual stuff is less than issue there right because you’re not making a bunch updates all the time.</p>
<p>769<br>01:19:48,380 –&gt; 01:19:55,380<br>All right so next class distribute O2Systems replication, cat theorem and then we’ll talk a little about some real limitations.</p>
<p>770<br>01:19:55,380 –&gt; 01:19:59,380<br>Okay question yes.</p>
<p>771<br>01:19:59,380 –&gt; 01:20:10,380<br>Is question is in a shared system given that these charges far away from the computer.</p>
<p>772<br>01:20:10,380 –&gt; 01:20:15,380<br>Do we still use a lot of pages for all to be absolutely yes.</p>
<p>773<br>01:20:15,380 –&gt; 01:20:17,380<br>All of the stuff we talked about doesn’t go away.</p>
<p>774<br>01:20:17,380 –&gt; 01:20:19,380<br>Yes. Okay.</p>
<p>775<br>01:20:19,380 –&gt; 01:20:21,380<br>All right hit it.</p>
<p>776<br>01:20:22,380 –&gt; 01:20:23,380<br>Yeah.</p>
<p>777<br>01:20:23,380 –&gt; 01:20:25,380<br>Yeah.</p>
<p>778<br>01:20:25,380 –&gt; 01:20:28,380<br>I’m the poppy with the mother fucking.</p>
<p>779<br>01:20:28,380 –&gt; 01:20:31,380<br>28 gram the pen and on if it’s good.</p>
<p>780<br>01:20:31,380 –&gt; 01:20:33,380<br>You ain’t hit them all yet.</p>
<p>781<br>01:20:33,380 –&gt; 01:20:34,380<br>Still got your sugar.</p>
<p>782<br>01:20:34,380 –&gt; 01:20:37,380<br>I smack you with the bottom of the clip to tell you.</p>
<p>783<br>01:20:37,380 –&gt; 01:20:38,380<br>Look up.</p>
<p>784<br>01:20:38,380 –&gt; 01:20:39,380<br>Show me what it’s safe.</p>
<p>785<br>01:20:40,380 –&gt; 01:20:43,380<br>I got a block on tap.</p>
<p>786<br>01:20:43,380 –&gt; 01:20:45,380<br>The feds can’t trace that.</p>
<p>787<br>01:20:45,380 –&gt; 01:20:46,380<br>Style is like temp or proof.</p>
<p>788<br>01:20:46,380 –&gt; 01:20:47,380<br>You can’t lace that.</p>
<p>789<br>01:20:47,380 –&gt; 01:20:50,380<br>The Dominic and oh you could call me Dominican.</p>
<p>790<br>01:20:50,380 –&gt; 01:20:51,380<br>Black Skelly.</p>
<p>791<br>01:20:51,380 –&gt; 01:20:52,380<br>Black.</p>
<p>792<br>01:20:52,380 –&gt; 01:20:53,380<br>Another black sweat.</p>
<p>793<br>01:20:53,380 –&gt; 01:20:54,380<br>Timberlands.</p>
<p>794<br>01:20:54,380 –&gt; 01:20:55,380<br>My whole black 38 is sent you to the perigates.</p>
<p>795<br>01:20:55,380 –&gt; 01:20:58,380<br>You get the slumber trying to skate and that’s your first mistake.</p>
<p>796<br>01:20:58,380 –&gt; 01:21:00,380<br>I ain’t lying for that cake.</p>
<p>797<br>01:21:00,380 –&gt; 01:21:02,380<br>If you’re not a fan of the same thing, you can’t do it.</p>
<p>798<br>01:21:02,380 –&gt; 01:21:04,380<br>I’m not a fan of the same thing.</p>
<p>799<br>01:21:04,380 –&gt; 01:21:05,380<br>I’m not a fan of the same thing.</p>
<p>800<br>01:21:05,380 –&gt; 01:21:06,380<br>I’m not a fan of the same thing.</p>
<p>801<br>01:21:06,380 –&gt; 01:21:07,380<br>I’m not a fan of the same thing.</p>
<p>802<br>01:21:07,380 –&gt; 01:21:09,380<br>I ain’t lying for that cake.</p>
<p>803<br>01:21:09,380 –&gt; 01:21:10,380<br>If you’re not a fan of the same thing, you can’t do it.</p>
<p>804<br>01:21:10,380 –&gt; 01:21:11,380<br>I ain’t lying for that cake.</p>
<p>805<br>01:21:11,380 –&gt; 01:21:12,380<br>If you’re not a fan of the same thing, you can’t do it.</p>
<p>806<br>01:21:12,380 –&gt; 01:21:13,380<br>I ain’t lying for that cake.</p>
<p>807<br>01:21:13,380 –&gt; 01:21:14,380<br>If you’re not a fan of the same thing, you can’t do it.</p>
<p>808<br>01:21:14,380 –&gt; 01:21:15,380<br>I ain’t lying for that cake.</p>
<p>809<br>01:21:15,380 –&gt; 01:21:16,380<br>If you’re not a fan of the same thing, you can’t do it.</p>
<p>810<br>01:21:16,380 –&gt; 01:21:17,380<br>I ain’t lying for that cake.</p>
<p>811<br>01:21:17,380 –&gt; 01:21:18,380<br>If you’re not a fan of the same thing, you can’t do it.</p>
<p>812<br>01:21:18,380 –&gt; 01:21:19,380<br>I ain’t lying for that cake.</p>
<p>813<br>01:21:19,380 –&gt; 01:21:20,380<br>My grand’s is heavy weight.</p>
<p>814<br>01:21:20,380 –&gt; 01:21:21,380<br>The grand’s through every state.</p>
<p>815<br>01:21:21,380 –&gt; 01:21:22,380<br>When they ask how I’m living, tell them I’m living great.</p>
<p>816<br>01:21:22,380 –&gt; 01:21:23,380<br>I ain’t lying for that cake.</p>
<p>817<br>01:21:23,380 –&gt; 01:21:24,380<br>I ain’t lying for that cake.</p>
<p>818<br>01:21:24,380 –&gt; 01:21:25,380<br>I ain’t lying for that cake.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CMU15445 P22F202321 IntrotoDistributedDatabases</div>
      <div>http://example.com/2025/10/25/CMU15445 P22F202321-IntrotoDistributedDatabases/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/25/CMU15445%20P26F202325-PotpourriRedisCockroachDBSnowflakeMangoDBTabDB/" title="CMU15445 P26F202325 PotpourriRedisCockroachDBSnowflakeMangoDBTabDB">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CMU15445 P26F202325 PotpourriRedisCockroachDBSnowflakeMangoDBTabDB</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/25/CMU15445%20P23F202322-DistributedTransactionProcessingDatabases/" title="CMU15445 P23F202322 DistributedTransactionProcessingDatabases">
                        <span class="hidden-mobile">CMU15445 P23F202322 DistributedTransactionProcessingDatabases</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
