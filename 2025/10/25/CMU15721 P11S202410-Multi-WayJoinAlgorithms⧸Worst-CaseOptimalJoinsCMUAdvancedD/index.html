

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:06,000Carnegie Mellon University’s Advanced Database Systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio audience. 300:00:09,000 –&gt; 00:00:11,0">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU15721 P11S202410 Multi WayJoinAlgorithms⧸Worst CaseOptimalJoinsCMUAdvancedD">
<meta property="og:url" content="http://example.com/2025/10/25/CMU15721%20P11S202410-Multi-WayJoinAlgorithms%E2%A7%B8Worst-CaseOptimalJoinsCMUAdvancedD/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:06,000Carnegie Mellon University’s Advanced Database Systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio audience. 300:00:09,000 –&gt; 00:00:11,0">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-25T05:03:39.746Z">
<meta property="article:modified_time" content="2025-10-25T05:03:39.747Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>CMU15721 P11S202410 Multi WayJoinAlgorithms⧸Worst CaseOptimalJoinsCMUAdvancedD - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CMU15721 P11S202410 Multi WayJoinAlgorithms⧸Worst CaseOptimalJoinsCMUAdvancedD"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-25 13:03" pubdate>
          2025年10月25日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          54 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CMU15721 P11S202410 Multi WayJoinAlgorithms⧸Worst CaseOptimalJoinsCMUAdvancedD</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:06,000<br>Carnegie Mellon University’s Advanced Database Systems courses</p>
<p>2<br>00:00:06,000 –&gt; 00:00:09,000<br>filming front of the live studio audience.</p>
<p>3<br>00:00:09,000 –&gt; 00:00:11,000<br>I don’t want to know what kind of club it is.</p>
<p>4<br>00:00:11,000 –&gt; 00:00:13,000<br>I don’t want to know what kind of club it is.</p>
<p>5<br>00:00:13,000 –&gt; 00:00:15,000<br>The game is about welcoming a lot of public excellence.</p>
<p>6<br>00:00:15,000 –&gt; 00:00:19,000<br>And this would be a lot different than kind of joined you see in the intro class</p>
<p>7<br>00:00:19,000 –&gt; 00:00:23,000<br>and even in the last lecture we just had about parallel hashelons.</p>
<p>8<br>00:00:23,000 –&gt; 00:00:27,000<br>And we’ll sort of see, sort of motivate why we want to do this.</p>
<p>9<br>00:00:27,000 –&gt; 00:00:30,000<br>And then we’ll just discuss the sort of, one of the first invitations of it</p>
<p>10<br>00:00:30,000 –&gt; 00:00:33,000<br>and then we’ll see how the Germans are going to prove on it.</p>
<p>11<br>00:00:33,000 –&gt; 00:00:36,000<br>And then I’ll finish up with something from DuckDB that basically says</p>
<p>12<br>00:00:36,000 –&gt; 00:00:42,000<br>you may not actually need any of this if you build other things correctly.</p>
<p>13<br>00:00:42,000 –&gt; 00:00:46,000<br>All right, so last class we spent the entire lecture on how to do hashelons</p>
<p>14<br>00:00:46,000 –&gt; 00:00:47,000<br>as fast as possible.</p>
<p>15<br>00:00:47,000 –&gt; 00:00:50,000<br>Right, and the big focus was on how to use run this in parallel.</p>
<p>16<br>00:00:50,000 –&gt; 00:00:54,000<br>Again, not across multiple nodes, but across multiple workers running on the same box.</p>
<p>17<br>00:00:55,000 –&gt; 00:01:00,000<br>And it was really about trying to minimize the number of cycles per instruction,</p>
<p>18<br>00:01:00,000 –&gt; 00:01:03,000<br>minimize the remote memory access to the different numer regions,</p>
<p>19<br>00:01:03,000 –&gt; 00:01:05,000<br>just trying to run fast as possible.</p>
<p>20<br>00:01:05,000 –&gt; 00:01:10,000<br>And then although there were some examples and some results that showed that the partition hashed</p>
<p>21<br>00:01:10,000 –&gt; 00:01:13,000<br>going was going to be superior to the other approaches,</p>
<p>22<br>00:01:13,000 –&gt; 00:01:18,000<br>getting the engineering right for different hardware, different workloads, different data sets</p>
<p>23<br>00:01:18,000 –&gt; 00:01:19,000<br>is really challenging.</p>
<p>24<br>00:01:19,000 –&gt; 00:01:23,000<br>So oftentimes, you should just do a non partition hashed one.</p>
<p>25<br>00:01:23,000 –&gt; 00:01:29,000<br>And that’s going to be good enough to get you, maybe 95%, 90% of the benefit</p>
<p>26<br>00:01:29,000 –&gt; 00:01:32,000<br>but again, getting into low-level details and more former things.</p>
<p>27<br>00:01:32,000 –&gt; 00:01:39,000<br>So again, for this, for the last lecture, this was doing what it’s called a binary join.</p>
<p>28<br>00:01:39,000 –&gt; 00:01:42,000<br>Right, or joining two tables.</p>
<p>29<br>00:01:42,000 –&gt; 00:01:49,000<br>Right, and as you can imagine, these things are super common in pretty much every database system,</p>
<p>30<br>00:01:50,000 –&gt; 00:01:55,000<br>and there’s been years and years and years, decades of research and trying to make hash joins go as fast as possible.</p>
<p>31<br>00:01:55,000 –&gt; 00:02:00,000<br>As I said, I had a PHA student spend a little time trying to make the hash join go faster,</p>
<p>32<br>00:02:00,000 –&gt; 00:02:04,000<br>and we were literally going and trying to count from going from 12 cycles per two-bole to 11 cycles per two-bole.</p>
<p>33<br>00:02:04,000 –&gt; 00:02:08,000<br>You’re really getting down to the bone, the bare metal performance,</p>
<p>34<br>00:02:08,000 –&gt; 00:02:10,000<br>so there’s not much else you can optimize.</p>
<p>35<br>00:02:10,000 –&gt; 00:02:16,000<br>So the binary joins are going to be the preferred approach, the better approach,</p>
<p>36<br>00:02:17,000 –&gt; 00:02:22,000<br>when we know that the output of the join operator is going to be smaller than its inputs.</p>
<p>37<br>00:02:23,000 –&gt; 00:02:28,000<br>Right, so in this case here, we’re joining RS and T, we’re taking, we’re joining S and T,</p>
<p>38<br>00:02:28,000 –&gt; 00:02:31,000<br>we do a join, and then we’re going to produce 10 tables.</p>
<p>39<br>00:02:31,000 –&gt; 00:02:35,000<br>Right, these are imaginary numbers. They’re small, but think of like orders and magnitude bigger.</p>
<p>40<br>00:02:35,000 –&gt; 00:02:37,000<br>Right, the output is going to be much smaller.</p>
<p>41<br>00:02:38,000 –&gt; 00:02:44,000<br>The proms are going to be, though, and what we’re going to try to adjust today is when the output of the join operator</p>
<p>42<br>00:02:45,000 –&gt; 00:02:47,000<br>is going to be larger than the inputs.</p>
<p>43<br>00:02:47,000 –&gt; 00:02:51,000<br>So, say for whatever reason, based on the data and what we’re trying to join on,</p>
<p>44<br>00:02:51,000 –&gt; 00:02:54,000<br>this thing, the operator is not going to produce 1,000 tables.</p>
<p>45<br>00:02:55,000 –&gt; 00:03:00,000<br>Right, and this is the problem we want, this is the worst case scenario for database,</p>
<p>46<br>00:03:00,000 –&gt; 00:03:02,000<br>because now we have to materialize that.</p>
<p>47<br>00:03:02,000 –&gt; 00:03:07,000<br>And even though it’s producing 1,000 tables here, when we do the join on this output and R,</p>
<p>48<br>00:03:07,000 –&gt; 00:03:08,000<br>now we’re going to produce 10 tables.</p>
<p>49<br>00:03:09,000 –&gt; 00:03:15,000<br>So, we had a bunch of data that we’ve materialized or synthesized from the join operator that we now have to deal with,</p>
<p>50<br>00:03:15,000 –&gt; 00:03:19,000<br>even though we’re still ending up throwing a ton of it away.</p>
<p>51<br>00:03:21,000 –&gt; 00:03:25,000<br>So, another way to think about it, or look at it, is like this, we actually start using real tables.</p>
<p>52<br>00:03:25,000 –&gt; 00:03:30,000<br>Again, same query, trying to do a cycle join between R, R, S and T.</p>
<p>53<br>00:03:31,000 –&gt; 00:03:35,000<br>Right, so, the proms are going to be that no matter what order that I choose to join my tables,</p>
<p>54<br>00:03:36,000 –&gt; 00:03:40,000<br>or if I choose to join R and S first, then join T.</p>
<p>55<br>00:03:40,000 –&gt; 00:03:43,000<br>This intermediate result is going to get ballooned up and get bigger.</p>
<p>56<br>00:03:43,000 –&gt; 00:03:49,000<br>Same thing, if I try to join R and T, and then join S, ballooned up, same thing,</p>
<p>57<br>00:03:49,000 –&gt; 00:03:53,000<br>do S and T, balloons up in the M.</p>
<p>58<br>00:03:53,000 –&gt; 00:03:56,000<br>So, again, the reason why this is going to be a problem for us is,</p>
<p>59<br>00:03:56,000 –&gt; 00:03:59,000<br>I’ve already said, it’s going to be wasted storage, because now again,</p>
<p>60<br>00:03:59,000 –&gt; 00:04:04,000<br>we have to materialize these results somewhere in memory, and then if it gets too big,</p>
<p>61<br>00:04:04,000 –&gt; 00:04:09,000<br>we have to end up having to spill a disk, and that will be typically the local disk on the worker node.</p>
<p>62<br>00:04:09,000 –&gt; 00:04:15,000<br>Worst case scenario, we spill to S3 of the object store, a team of the slaughter.</p>
<p>63<br>00:04:15,000 –&gt; 00:04:18,000<br>Then, of course, obviously, it’s going to be a bunch of wasted computation,</p>
<p>64<br>00:04:18,000 –&gt; 00:04:23,000<br>because, you know, we’re materializing tuples, we’re passing them along,</p>
<p>65<br>00:04:23,000 –&gt; 00:04:28,000<br>and then we’re going to do the next join on the last table,</p>
<p>66<br>00:04:28,000 –&gt; 00:04:31,000<br>it’s not going to match, we’re going to throw it away.</p>
<p>67<br>00:04:32,000 –&gt; 00:04:38,000<br>So, ideally, we want to be able to identify, if we can, which of these tuples we’d actually don’t need,</p>
<p>68<br>00:04:38,000 –&gt; 00:04:41,000<br>when we’re going to join with the third table, or any other additional tables,</p>
<p>69<br>00:04:41,000 –&gt; 00:04:46,000<br>to avoid having to, you know, again, materialize it.</p>
<p>70<br>00:04:46,000 –&gt; 00:04:49,000<br>So, that’s the high level approach that we’re going to promentern to solve today,</p>
<p>71<br>00:04:49,000 –&gt; 00:04:54,000<br>is how to avoid this blow up at the intermediate results.</p>
<p>72<br>00:04:54,000 –&gt; 00:04:59,000<br>And what we’ll see in the multi-way join, the way it’s going to work is that,</p>
<p>73<br>00:04:59,000 –&gt; 00:05:03,000<br>rather than sort of thinking the join operator in terms of like,</p>
<p>74<br>00:05:03,000 –&gt; 00:05:06,000<br>I got this table and this table, let me join it together,</p>
<p>75<br>00:05:06,000 –&gt; 00:05:08,000<br>you’re going to think of terms of attributes.</p>
<p>76<br>00:05:08,000 –&gt; 00:05:11,000<br>And now you don’t care where the attributes are coming from,</p>
<p>77<br>00:05:11,000 –&gt; 00:05:14,000<br>whether it’s table one, table two, table three, or so forth,</p>
<p>78<br>00:05:14,000 –&gt; 00:05:17,000<br>and now you want to do comparison on these attributes,</p>
<p>79<br>00:05:17,000 –&gt; 00:05:21,000<br>and then have that be, which you synthesize, as part of the output.</p>
<p>80<br>00:05:21,000 –&gt; 00:05:26,000<br>So, that’s the big picture of what the multi-way join is going to try to do for us.</p>
<p>81<br>00:05:26,000 –&gt; 00:05:29,000<br>First sort of background, what worst case optimal joins are.</p>
<p>82<br>00:05:29,000 –&gt; 00:05:32,000<br>Again, the lecture I’m calling multi-way joins, because that’s the idea,</p>
<p>83<br>00:05:32,000 –&gt; 00:05:35,000<br>like we’re joining more than just two tables.</p>
<p>84<br>00:05:35,000 –&gt; 00:05:39,000<br>Right? So, the class of outcomes are going to be multi-way joins,</p>
<p>85<br>00:05:39,000 –&gt; 00:05:44,000<br>and then these category of the implementations that we’ll see will be called worst case optimal joins.</p>
<p>86<br>00:05:44,000 –&gt; 00:05:47,000<br>But typically, the terms are used interchangeably.</p>
<p>87<br>00:05:47,000 –&gt; 00:05:51,000<br>But the multi-way joins, the idea of multi-way joins existed in the literature,</p>
<p>88<br>00:05:51,000 –&gt; 00:05:54,000<br>I think, back of the 80s, but the worst case optimal implementations</p>
<p>89<br>00:05:54,000 –&gt; 00:05:57,000<br>that came along in the late 2000s.</p>
<p>90<br>00:05:57,000 –&gt; 00:06:00,000<br>All right, so first first, again, in the highlight of the idea, what worst case optimal joins are,</p>
<p>91<br>00:06:00,000 –&gt; 00:06:03,000<br>then we’ll look at the one of the earliest implementations of leapfrog join,</p>
<p>92<br>00:06:03,000 –&gt; 00:06:06,000<br>leapfrog tri-join, and then we’ll see the Germans hash tri-join,</p>
<p>93<br>00:06:06,000 –&gt; 00:06:10,000<br>which is sort of an optimization of the data structures they’re going to use</p>
<p>94<br>00:06:10,000 –&gt; 00:06:14,000<br>over the leapfrog join, but at high level, the method’s still going to be the same.</p>
<p>95<br>00:06:14,000 –&gt; 00:06:19,000<br>Again, we’ll finish up some quick optimizations from DuckDB,</p>
<p>96<br>00:06:19,000 –&gt; 00:06:23,000<br>and then I want to briefly talk about how to do system profiling in a data system,</p>
<p>97<br>00:06:23,000 –&gt; 00:06:28,000<br>and then talk a little bit about the harbor counter stuff that he had a question about a few weeks ago.</p>
<p>98<br>00:06:28,000 –&gt; 00:06:38,000<br>All right, so again, the idea of a worst case optimal join is that we want to join more,</p>
<p>99<br>00:06:38,000 –&gt; 00:06:41,000<br>or three or more tables at the same time.</p>
<p>100<br>00:06:41,000 –&gt; 00:06:43,000<br>And again, the way this is going to work is that,</p>
<p>101<br>00:06:43,000 –&gt; 00:06:47,000<br>rather than taking the entire tuple from one table and the entire tuple from another table,</p>
<p>102<br>00:06:47,000 –&gt; 00:06:50,000<br>and then comparing all the attributes in our join key,</p>
<p>103<br>00:06:50,000 –&gt; 00:06:54,000<br>we’re instead going to grab a single attribute for our join key,</p>
<p>104<br>00:06:54,000 –&gt; 00:06:56,000<br>it could be multiple columns.</p>
<p>105<br>00:06:56,000 –&gt; 00:06:58,000<br>From all the tables we want to join together,</p>
<p>106<br>00:06:58,000 –&gt; 00:07:01,000<br>mash them up, figure out whether we have any matches,</p>
<p>107<br>00:07:01,000 –&gt; 00:07:06,000<br>and only proceed with doing additional comparisons for a given attribute,</p>
<p>108<br>00:07:06,000 –&gt; 00:07:11,000<br>for given tuple, if we know that the subset of the values on our join key</p>
<p>109<br>00:07:11,000 –&gt; 00:07:12,000<br>are actually matching already.</p>
<p>110<br>00:07:12,000 –&gt; 00:07:17,000<br>Again, we want to avoid waste of work of doing a bunch of comparisons for things that are going to get thrown away.</p>
<p>111<br>00:07:18,000 –&gt; 00:07:21,000<br>So as soon as we can identify that there isn’t going to be a match on a given tuple,</p>
<p>112<br>00:07:21,000 –&gt; 00:07:26,000<br>as we’re doing our join, we can throw that way as soon as possible.</p>
<p>113<br>00:07:26,000 –&gt; 00:07:29,000<br>So as I said, the idea of a multi-way join has existed for a while,</p>
<p>114<br>00:07:29,000 –&gt; 00:07:33,000<br>but in terms of proving that you can have a worst case optimal join,</p>
<p>115<br>00:07:33,000 –&gt; 00:07:35,000<br>and on the final that is in a second,</p>
<p>116<br>00:07:35,000 –&gt; 00:07:38,000<br>came from these other Germans in 2008,</p>
<p>117<br>00:07:38,000 –&gt; 00:07:43,000<br>which I think was, for this paper, I think actually was Thomas Nomean’s PC advisor,</p>
<p>118<br>00:07:43,000 –&gt; 00:07:44,000<br>but I might be wrong.</p>
<p>119<br>00:07:45,000 –&gt; 00:07:49,000<br>And then the first two implementations of this will be empty-headed at a Stanford,</p>
<p>120<br>00:07:49,000 –&gt; 00:07:52,000<br>and then a commercial system called Logic Blocks,</p>
<p>121<br>00:07:52,000 –&gt; 00:07:58,000<br>which is like, it’s a answering database system that you use data log instead of SQL.</p>
<p>122<br>00:07:58,000 –&gt; 00:08:01,000<br>Data log is another declared query language,</p>
<p>123<br>00:08:01,000 –&gt; 00:08:05,000<br>but very few people actually use it other than Logic Blocks.</p>
<p>124<br>00:08:05,000 –&gt; 00:08:11,000<br>So again, the interesting about these worst case optimal joins are,</p>
<p>125<br>00:08:12,000 –&gt; 00:08:20,000<br>rather than thinking about the computational complexity in terms of the size of my input tuples,</p>
<p>126<br>00:08:20,000 –&gt; 00:08:29,000<br>the performance will be bounded by the output and the number of attributes that are actually compared against.</p>
<p>127<br>00:08:29,000 –&gt; 00:08:35,000<br>And this is hard to actually have an exact estimation without selectivity information about the attributes,</p>
<p>128<br>00:08:35,000 –&gt; 00:08:38,000<br>to say, here’s how much longer things are going to take,</p>
<p>129<br>00:08:39,000 –&gt; 00:08:43,000<br>whereas like a hash join, for example, you know you’ve got to build a hash table,</p>
<p>130<br>00:08:43,000 –&gt; 00:08:47,000<br>there’s a cost of that, you’ve got to probe a hash table, there’s another cost of that,</p>
<p>131<br>00:08:47,000 –&gt; 00:08:52,000<br>and you can more or less ignore the selectivity of the hash join itself,</p>
<p>132<br>00:08:52,000 –&gt; 00:08:54,000<br>because you’re always going to do that work,</p>
<p>133<br>00:08:54,000 –&gt; 00:08:56,000<br>whereas in the worst case optimal join,</p>
<p>134<br>00:08:56,000 –&gt; 00:08:58,000<br>because we can short-circuit comparisons,</p>
<p>135<br>00:08:58,000 –&gt; 00:09:01,000<br>once we know an attribute within a join key is not going to match,</p>
<p>136<br>00:09:01,000 –&gt; 00:09:04,000<br>then it actually is, you know, it’ll vary.</p>
<p>137<br>00:09:05,000 –&gt; 00:09:11,000<br>So what’s also interesting about too is that the more tables we’re going to throw at our worst case optimal join algorithm,</p>
<p>138<br>00:09:11,000 –&gt; 00:09:14,000<br>the better its performance is actually going to be relative to the input,</p>
<p>139<br>00:09:14,000 –&gt; 00:09:18,000<br>because the idea is that we’re going to try to compare as much as we can all at once,</p>
<p>140<br>00:09:18,000 –&gt; 00:09:25,000<br>again, rather than having these stages in the, you know, in a binary join, yes.</p>
<p>141<br>00:09:25,000 –&gt; 00:09:29,000<br>So all the things you’re talking about would you also throw it at the join key which is my attribute?</p>
<p>142<br>00:09:29,000 –&gt; 00:09:34,000<br>The statement is a question is would all the things I’m talking about here still hold if it was join key which is one attribute?</p>
<p>143<br>00:09:34,000 –&gt; 00:09:42,000<br>In terms of would you, well, you wouldn’t get the benefit of short-circuiting additional comparisons for additional attributes.</p>
<p>144<br>00:09:42,000 –&gt; 00:09:52,000<br>Is it an easier problem if it’s one attribute to do a multi-way join?</p>
<p>145<br>00:09:52,000 –&gt; 00:09:59,000<br>No, I mean, you wouldn’t, how does this?</p>
<p>146<br>00:09:59,000 –&gt; 00:10:07,000<br>You wouldn’t get any benefit of some of the data structures that they’re going to build,</p>
<p>147<br>00:10:07,000 –&gt; 00:10:11,000<br>like the tries or in case of empty-headeds, like nested hash tables.</p>
<p>148<br>00:10:11,000 –&gt; 00:10:20,000<br>Yeah, I actually don’t know the complexity of this thing.</p>
<p>149<br>00:10:20,000 –&gt; 00:10:27,000<br>If it’s one attribute, if it’s one attribute, I still think it’s, this is going to be better if the intermediaries also are going to balloon up,</p>
<p>150<br>00:10:27,000 –&gt; 00:10:33,000<br>because again, you’re not materializing it, but all those optimizations that, like, we’ll see from the paper you guys read,</p>
<p>151<br>00:10:33,000 –&gt; 00:10:38,000<br>are like, how to do singletons and fast-pass down to the leaf nodes of the try.</p>
<p>152<br>00:10:39,000 –&gt; 00:10:44,000<br>Those obviously don’t make any sense if it’s only one level.</p>
<p>153<br>00:10:44,000 –&gt; 00:10:50,000<br>So we’ll see this a little bit, and the hyper-paper you guys read, or the umbra-paper you guys read talks about this as well.</p>
<p>154<br>00:10:50,000 –&gt; 00:10:57,000<br>In the same way that we have to get the join order right for binary joins, like make sure that if A joined B joined C, we have to get that ordering right.</p>
<p>155<br>00:10:57,000 –&gt; 00:11:05,000<br>We have to get the ordering correct in a worst case-up node join, but the thing we have to worry about is not so much the ordering of the tables themselves,</p>
<p>156<br>00:11:05,000 –&gt; 00:11:12,000<br>it’s actually the ordering of the attributes. So we want to do comparisons on attribute attributes that we know very many of us are selective, as soon as possible.</p>
<p>157<br>00:11:12,000 –&gt; 00:11:17,000<br>So again, we start throwing away data and not doing useless computations.</p>
<p>158<br>00:11:17,000 –&gt; 00:11:29,000<br>So the definition that’s sort of floating around the internet actually comes from this professor up in Waterloo for, he’s building an embedded graph database called Kuzu.</p>
<p>159<br>00:11:30,000 –&gt; 00:11:36,000<br>You think of like, you know, ducty B or SQLite, but for graph databases.</p>
<p>160<br>00:11:36,000 –&gt; 00:11:47,000<br>Right? So his definition of a worst-cut orbital join is one where the worst case runtime of the algorithm meets a known lower bound for the worst case runtime of any join algorithm.</p>
<p>161<br>00:11:47,000 –&gt; 00:11:50,000<br>So I read this and like, what the hell are you talking about?</p>
<p>162<br>00:11:50,000 –&gt; 00:11:57,000<br>Because you’re kind of using the definition of the thing, using the word time defined in the definition itself.</p>
<p>163<br>00:11:58,000 –&gt; 00:12:08,000<br>So an alternative would be something like this, where the worst case-up node join is one where the runtime of the join algorithm is better than all other join algorithms with a query and the data represent the worst possible scenario.</p>
<p>164<br>00:12:08,000 –&gt; 00:12:23,000<br>So if you have the situation where the intermediate size is going to balloon up massively, if I think of a Cartesian product as the worst case scenario, then we want to choose an algorithm where it’s not going to be magically log in,</p>
<p>165<br>00:12:23,000 –&gt; 00:12:33,000<br>but it’s still going to be better than just doing all other approaches with a binary join, no matter what ordering you have for your tables in a binary join.</p>
<p>166<br>00:12:33,000 –&gt; 00:12:41,000<br>So again, if you just, that’s why I called this lecture the multi-way join because that one I think is easy to wrap around.</p>
<p>167<br>00:12:41,000 –&gt; 00:12:44,000<br>This one is a bit screwy, and don’t take my word for it also.</p>
<p>168<br>00:12:44,000 –&gt; 00:12:55,000<br>For this guy’s blogger, he has this anecdote where he talks about where he met Don Canuth, and he told Don Canuth he was working on worst case-up node join algorithms, and Canuth was like, what the hell are you talking about either?</p>
<p>169<br>00:12:55,000 –&gt; 00:13:01,000<br>So as he says, are they so good that they’re optimal in the worst case performance?</p>
<p>170<br>00:13:01,000 –&gt; 00:13:03,000<br>Yes.</p>
<p>171<br>00:13:03,000 –&gt; 00:13:12,000<br>So anyway, so again, if you understand that, this is going to be the best approach for the worst case scenario when we have this in ballooning up in-mere results.</p>
<p>172<br>00:13:12,000 –&gt; 00:13:14,000<br>That’s the thing we want to solve.</p>
<p>173<br>00:13:14,000 –&gt; 00:13:20,000<br>So as I said, there’s not very many systems that are actually going to implement this.</p>
<p>174<br>00:13:20,000 –&gt; 00:13:24,000<br>So the logic blocks was the one I mentioned before.</p>
<p>175<br>00:13:24,000 –&gt; 00:13:29,000<br>That’s going to be, we’ll see this when they do comparison in the umbra paper.</p>
<p>176<br>00:13:29,000 –&gt; 00:13:40,000<br>Again, this was an early reasoning system that was trying to do graph traversals, and they had, they supported, they had an early invitation of, or they had a leaf frog hash line.</p>
<p>177<br>00:13:40,000 –&gt; 00:13:43,000<br>Umbra, what you guys read about relational AI is the follow up to logic blocks.</p>
<p>178<br>00:13:43,000 –&gt; 00:13:45,000<br>So logic blocks got bought.</p>
<p>179<br>00:13:45,000 –&gt; 00:13:49,000<br>All the key people left the company ever got acquired and then built relational AI.</p>
<p>180<br>00:13:49,000 –&gt; 00:14:03,000<br>Um, it’s written in Julia, it’s a relational database system that’s doing um, uh, what’s doing a graph representation on a relational database system and they’re using their variant of a new version of the leaf frog joint.</p>
<p>181<br>00:14:03,000 –&gt; 00:14:07,000<br>Um, and the cause is this is not a waterload that I mentioned before.</p>
<p>182<br>00:14:07,000 –&gt; 00:14:14,000<br>So the reason why this is going to be important and we’re not going to go too deep into the latest equal extension, uh, SQL PGQ.</p>
<p>183<br>00:14:14,000 –&gt; 00:14:22,000<br>Um, but last year in March of February, the new specification for the SQL standard came out and in it, they have this thing called SQL PGQ.</p>
<p>184<br>00:14:22,000 –&gt; 00:14:36,000<br>So it’s an extension, a new, uh, new capabilities in the SQL standard that lie to define property graphs over relational tables and then do, uh, pattern searching your graph traversals directly in SQL.</p>
<p>185<br>00:14:36,000 –&gt; 00:14:45,000<br>So the, the, the extensions are inspired by a new for J cipher, I think tiger graph has their graph query language.</p>
<p>186<br>00:14:45,000 –&gt; 00:14:50,000<br>Like there’s bits and pieces of existing graph databases, but now all this exists in the SQL standard.</p>
<p>187<br>00:14:50,000 –&gt; 00:14:56,000<br>Um, the only system that I know that actually supports this is, uh, is, it’s Oracle.</p>
<p>188<br>00:14:56,000 –&gt; 00:14:59,000<br>Oracle was on the standards, standards committee.</p>
<p>189<br>00:14:59,000 –&gt; 00:15:09,000<br>Um, there’s a, there’s a, there’s a experimental development branch of, of, of ducty B that has some portions of this, but they’re all, the language is all sort of slightly different.</p>
<p>190<br>00:15:09,000 –&gt; 00:15:17,000<br>Um, so we’re going to need, we’re going to need the worst case out no joints in order to implement this efficiently, right for these kind of queries.</p>
<p>191<br>00:15:17,000 –&gt; 00:15:22,000<br>Do you graph traversals on, on, uh, on, on relational basis?</p>
<p>192<br>00:15:22,000 –&gt; 00:15:30,000<br>So that’s why this matters. So even though in Oracle only supports it now, I think in the next five years, every major olactated system will have, will have support for this.</p>
<p>193<br>00:15:30,000 –&gt; 00:15:35,000<br>And you’re going to need to do a worst case optimal join to make that run efficiently.</p>
<p>194<br>00:15:35,000 –&gt; 00:15:41,000<br>Alright, so let’s go to the first implementation or first one of first limitations leaf log, leaf log try join.</p>
<p>195<br>00:15:41,000 –&gt; 00:15:46,000<br>And then, uh, and then we’ll see how the Germans extended this to make it, make it run faster.</p>
<p>196<br>00:15:46,000 –&gt; 00:16:03,000<br>Um, so the idea is that to do a multiway join, the, the leaf log try joins, going to assume that either the data is already pre sorted, or that you’re going to build a, an index data structure on the join keys, uh, right before before the join itself.</p>
<p>197<br>00:16:03,000 –&gt; 00:16:12,000<br>So as we talked about in, in our world, we’re, we’re accessing much of park a files, we’re sending us three. Those things are unlikely to be sorted.</p>
<p>198<br>00:16:12,000 –&gt; 00:16:24,000<br>And in the park a or file specifications, you can’t store additional data structures. So either we have to pre compute these things and store it as this, put your separate files that we load back in, or as we’re scanning data or building these tribes on the fly.</p>
<p>199<br>00:16:25,000 –&gt; 00:16:35,000<br>And the, the umber paper you guys read, they’re going to be doing the same thing, they’re going to be building the tribes on the fly too, but they’re going to do a bunch of tricks to try to lazy evaluation or lazy materialization in the data structure.</p>
<p>200<br>00:16:35,000 –&gt; 00:16:46,000<br>Right, so another way to get this is when I call create index in postgres or whatever, what is that what’s going to happen? Well, the data says does a sequential scan reads every single row and then populates the index.</p>
<p>201<br>00:16:46,000 –&gt; 00:16:53,000<br>And so the umber guys are going to try to avoid having to do that. These guys are going to, are going to build everything.</p>
<p>202<br>00:16:53,000 –&gt; 00:17:07,000<br>So in this try, we’ll see in a second, they’re going to have a separate data structure per table per relation, we’re trying to join and then each level in this try is going to correspond to one attribute that that’s in our joint key.</p>
<p>203<br>00:17:07,000 –&gt; 00:17:16,000<br>Right, for that, for that table, each level correspond to an attribute that it has that’s involved in the joint operator.</p>
<p>204<br>00:17:16,000 –&gt; 00:17:30,000<br>So as I said, logical blocks and men in this in 2010 or 2013, I think 14 paper group out, they have their new company relation AI, they have an, especially a better version of the leapfrog hash join called a dovetail join.</p>
<p>205<br>00:17:30,000 –&gt; 00:17:39,000<br>I can’t actually figure out what they’re doing because there’s a five minute, you know, there’s this blog article here and a five minute YouTube video that doesn’t listen to anything deep, right?</p>
<p>206<br>00:17:39,000 –&gt; 00:17:45,000<br>But they claim it’s better than than what these guys have.</p>
<p>207<br>00:17:45,000 –&gt; 00:18:02,000<br>All right, so the way to think about this is that we are again, we’re going to sort our data or build it next for it and then we need a way to to iterate through the, all the tables are trying to join at the same time and then do comparison across the attributes to see whether we have a match.</p>
<p>208<br>00:18:02,000 –&gt; 00:18:15,000<br>And because the things are sorted, we don’t have to backtrack on our join keys. Right, so let’s say we have three tables x, y, z, first step, we’re just going to sort it, so that’s fine.</p>
<p>209<br>00:18:15,000 –&gt; 00:18:25,000<br>And then for now, for this demonstration, I’m going to switch to horizontal view and I’m going to put spaces into where there’s actually new values, you know, corresponding to the sequence, like, you know, zero to 10.</p>
<p>210<br>00:18:25,000 –&gt; 00:18:32,000<br>So at the very beginning, we’re going to have an iterator for each of three tables, right? So in this case here, we’re trying to join in one attribute, ID.</p>
<p>211<br>00:18:32,000 –&gt; 00:18:41,000<br>And so the, for x, the first value is zero, so the x iterator is 20 is zero, y is pointing at zero, and then z is pointing at two.</p>
<p>212<br>00:18:42,000 –&gt; 00:18:57,000<br>So we’re going to start with the, at the top, and we’re going to sort of, we’re going to do comparisons with the, what the iterator is pointing at, across the different tables, because we know what they’re pointing at too.</p>
<p>213<br>00:18:57,000 –&gt; 00:19:05,000<br>And then we find that the value that our iterator is pointing at is less than what the other iterators are pointing at.</p>
<p>214<br>00:19:06,000 –&gt; 00:19:21,000<br>Then we know that there isn’t a match for us here, and therefore we’re going to leave for all of our jump to some other point in our, in our value list, that’s going to be equal to or greater than the maximum what everyone else is pointing to.</p>
<p>215<br>00:19:22,000 –&gt; 00:19:35,000<br>Right, so in this case here, zero is less than two, so we need to jump over and find the next, the, the next value for x, that is greater than or equal to two.</p>
<p>216<br>00:19:35,000 –&gt; 00:19:40,000<br>In this case here, it’s three, so the iterator is going to jump over there, and we update that that.</p>
<p>217<br>00:19:40,000 –&gt; 00:19:46,000<br>Now because this guy now did a jump, we then need to come down to the next one and do the same comparison here.</p>
<p>218<br>00:19:46,000 –&gt; 00:20:00,000<br>So the x-rayer is pointing at zero, so it needs to find a, since zero is less than two and three, we need to now jump to another position where the, but the next value is greater than equal to three.</p>
<p>219<br>00:20:01,000 –&gt; 00:20:12,000<br>So even though it has a two, so we know this guy is pointing at three, so we know that there isn’t going to be a match, because otherwise this thing would be pointing at two as well, so we skip this, so he’s now going to leave for all of our jump over to six.</p>
<p>220<br>00:20:12,000 –&gt; 00:20:22,000<br>Same thing, come down here, he’s at two, two is less than six, two is less than three, so we need to find something that’s going to be greater than or equal to six, which is eight here.</p>
<p>221<br>00:20:22,000 –&gt; 00:20:31,000<br>Then we look back around and do the same thing, now the x-rayer can jump to eight, the y-rayer can jump to eight, and then lo and behold, we have a match.</p>
<p>222<br>00:20:31,000 –&gt; 00:20:39,000<br>So at a high level, this is a conceptually what we’re trying to do, but obviously the devil’s in the details, because how am I doing this jump?</p>
<p>223<br>00:20:39,000 –&gt; 00:20:48,000<br>Because you switch your scan would be stupid and slow, and I’m also only showing how to do this for a single attribute.</p>
<p>224<br>00:20:48,000 –&gt; 00:20:56,000<br>So the way they’re going to represent these values in sort of a manner is through a try.</p>
<p>225<br>00:20:56,000 –&gt; 00:21:00,000<br>So we have everyone here knows how to try it, because that’s the project zero.</p>
<p>226<br>00:21:00,000 –&gt; 00:21:02,000<br>Okay, so I’ll skip into the try.</p>
<p>227<br>00:21:02,000 –&gt; 00:21:13,000<br>Actually, the guy that coined the name Edward Franken, he was his faculty, I think he just died last year, so the try guy died.</p>
<p>228<br>00:21:13,000 –&gt; 00:21:23,000<br>Okay, so we now need to build a try for every single table, and where we’re going to have each level in the try is going to represent a single attribute.</p>
<p>229<br>00:21:23,000 –&gt; 00:21:38,000<br>So we slightly different than the try representation we think of in databases to replace a B plus tree, because in a try you would take a string value, and you break it up to different digits or red X’s, and store those as a single level.</p>
<p>230<br>00:21:38,000 –&gt; 00:21:46,000<br>So we’re going to store the entire value in a node at a level for each corresponding to a two-pole at a table.</p>
<p>231<br>00:21:46,000 –&gt; 00:21:48,000<br>But we’re not going to have any duplicate values.</p>
<p>232<br>00:21:48,000 –&gt; 00:21:59,000<br>So if we see the same value for a given attribute over and over again, we’ll have one instance of it, but we have multiple pointers coming out of it for the different sub-values for the next attribute.</p>
<p>233<br>00:21:59,000 –&gt; 00:22:03,000<br>So again, I’m going to just flip it on its side to make it easier to visualize.</p>
<p>234<br>00:22:03,000 –&gt; 00:22:12,000<br>So we have two attributes, A and B. So in the first step here, we want to add an entry in our try for these three zeros.</p>
<p>235<br>00:22:12,000 –&gt; 00:22:18,000<br>So we always start with the root, to first down, and generate the zero node.</p>
<p>236<br>00:22:18,000 –&gt; 00:22:31,000<br>And then we come down to the B, and then for all the B values that correspond to the zero values, we’re going to have edges coming out of them and have those three values.</p>
<p>237<br>00:22:31,000 –&gt; 00:22:38,000<br>And then you just scan down the line to do the same thing for one and zero, and then for two and zero.</p>
<p>238<br>00:22:39,000 –&gt; 00:22:48,000<br>So again, anything at this first level here, ignoring the root, this corresponds to attribute A. Everything below that, the second level was actually B.</p>
<p>239<br>00:22:48,000 –&gt; 00:22:54,000<br>And then depending on how many attributes I have my joint key, this keeps going down and down.</p>
<p>240<br>00:22:54,000 –&gt; 00:23:04,000<br>And then in this leaf node here, obviously, when they have the same parent, they’re going to be in sort of order.</p>
<p>241<br>00:23:04,000 –&gt; 00:23:13,000<br>So now let’s put this together in a complete example to do a joint between R and S and T here.</p>
<p>242<br>00:23:13,000 –&gt; 00:23:18,000<br>So I’ve already built the tries for the three tables.</p>
<p>243<br>00:23:18,000 –&gt; 00:23:28,000<br>And again, here in our join, we’re trying to join R at S and T, we’re trying to join R at R dot A equals T at dot A, R dot B equals S dot B and S dot C equals T dot C.</p>
<p>244<br>00:23:28,000 –&gt; 00:23:35,000<br>So in this case here, one relation does not have all of the attributes that we need to compute the join.</p>
<p>245<br>00:23:35,000 –&gt; 00:23:44,000<br>And so assuming that the optimizer has figured out that the optimal joint, sort of optimal evaluation ordering for attributes is going to be A, B, and C.</p>
<p>246<br>00:23:44,000 –&gt; 00:23:55,000<br>So for this, say we start with table R, and we started the root, traverse down, the first entry is going to be, the first level is going to be A, the first value you can see for A is zero.</p>
<p>247<br>00:23:55,000 –&gt; 00:24:03,000<br>So then we can use this value to now do a look up in the table T. So again, since our join is R dot A dot equals T dot A.</p>
<p>248<br>00:24:03,000 –&gt; 00:24:15,000<br>So then now as an entry point going into the root of this try, we come down to the first level, we have A equals zero. We have a matching value there.</p>
<p>249<br>00:24:15,000 –&gt; 00:24:31,000<br>So now what we need to do is traverse down, at this point here, since we know we have a match for R dot A equals zero and T dot A equals zero, then we need to now go to the level below them and actually start comparing the two pulls of the values for the different attributes at the next level.</p>
<p>250<br>00:24:31,000 –&gt; 00:24:40,000<br>So in this case here, the next level for table R is going to be B. So when we go down to, you go down the left side, the first value we’re going to hit is zero.</p>
<p>251<br>00:24:40,000 –&gt; 00:24:54,000<br>So we can use that now as the probe into the try for table S because we’re trying to do R dot B equals S dot B, right, in the, in our, in our where it calls up there.</p>
<p>252<br>00:24:54,000 –&gt; 00:25:10,000<br>So same thing we enter R, sorry, we enter the try for S to first down, now we match for B. Great. So now we know that we have for a match of at least one attribute for R dot A to T dot A and R dot B into S dot B.</p>
<p>253<br>00:25:10,000 –&gt; 00:25:29,000<br>So the last step now is to do the comparison for where S dot C equals T dot C. So to do this, we’re just going to have iterators in the, in the region that the link list or the list that’s below the first attribute in the try for T and S.</p>
<p>254<br>00:25:29,000 –&gt; 00:25:40,000<br>And we’re just going to scan along and accumulate all the values for, for C across these two different, you know, for these two different tables, right.</p>
<p>255<br>00:25:40,000 –&gt; 00:25:48,000<br>And then now we have a, we now we have a set, we just do the intersection and we tell us whether we have matches.</p>
<p>256<br>00:25:48,000 –&gt; 00:26:09,000<br>And we know how to fill in the values for a and B because we know how we got into our try in the first place. So we prove property here got A equals zero. We had a match there. Then we had B equals zero, how to match over there. So when we fill this out, we know what the values of a and B are. So we’re just doing the intersection over C. Yes.</p>
<p>257<br>00:26:09,000 –&gt; 00:26:14,000<br>So what is the order in the region has come?</p>
<p>258<br>00:26:14,000 –&gt; 00:26:19,000<br>Question is what if what if the ordering of the.</p>
<p>259<br>00:26:19,000 –&gt; 00:26:24,000<br>The C goes on top of the.</p>
<p>260<br>00:26:24,000 –&gt; 00:26:29,000<br>I don’t know if it’s C goes the top of B. What do you mean? Yeah.</p>
<p>261<br>00:26:29,000 –&gt; 00:26:38,000<br>So if I put this above this, you can’t do that.</p>
<p>262<br>00:26:38,000 –&gt; 00:26:51,000<br>Because I know what I know the global order, I know the global evaluation ordering. A B C. So in my try, even though I don’t have all the attributes in for a given table, I still have to follow that ordering.</p>
<p>263<br>00:26:51,000 –&gt; 00:27:01,000<br>So B’s got to come before C. The order is determined by the query optimizer before you start running this.</p>
<p>264<br>00:27:01,000 –&gt; 00:27:08,000<br>It’s the same as joint order when you’re doing a binary joint.</p>
<p>265<br>00:27:08,000 –&gt; 00:27:16,000<br>Yes. Is there a table or we need one for every possible order and success of this question?</p>
<p>266<br>00:27:16,000 –&gt; 00:27:21,000<br>Is it okay to have one try per table or do you need to have one try for every possible joint ordering?</p>
<p>267<br>00:27:21,000 –&gt; 00:27:27,000<br>So this brings a good point. I think the empty head of paper.</p>
<p>268<br>00:27:27,000 –&gt; 00:27:32,000<br>And I think this paper says you’d want to pre-compute these ahead of time.</p>
<p>269<br>00:27:32,000 –&gt; 00:27:35,000<br>So all possible joint orderings, you would have to pre-compute them.</p>
<p>270<br>00:27:35,000 –&gt; 00:27:39,000<br>The umber guy is claiming the correct it, like that’s super wasteful.</p>
<p>271<br>00:27:39,000 –&gt; 00:27:49,000<br>And you would have built them on the fly. And that’s better than trying to pre-populate everything.</p>
<p>272<br>00:27:49,000 –&gt; 00:27:54,000<br>Okay. So we did a match where a equals zero, b equals zero, and we got all the C’s for that.</p>
<p>273<br>00:27:54,000 –&gt; 00:28:01,000<br>So now all we need to do is start back over here with our b iterator in table R. Just go to the next one.</p>
<p>274<br>00:28:01,000 –&gt; 00:28:08,000<br>Do the same thing. Probe into table S. Follow along the path to get the b.</p>
<p>275<br>00:28:08,000 –&gt; 00:28:21,000<br>Now we have an iterator for the C value over here. For this one here, because we’re still at the same A value that we don’t need to switch over to another leaf node,</p>
<p>276<br>00:28:21,000 –&gt; 00:28:25,000<br>we just restart and go back at the beginning of our linked list here.</p>
<p>277<br>00:28:25,000 –&gt; 00:28:33,000<br>So now we would only end up with one entry for S dot C. And then three entries for T dot C.</p>
<p>278<br>00:28:33,000 –&gt; 00:28:36,000<br>You obviously could catch this because you know it’s going to be the same thing every time.</p>
<p>279<br>00:28:36,000 –&gt; 00:28:42,000<br>Compute the intersection and then we end up with one table.</p>
<p>280<br>00:28:42,000 –&gt; 00:28:45,000<br>Then do the same thing. Move over to the next one.</p>
<p>281<br>00:28:45,000 –&gt; 00:28:52,000<br>To verse down into to do the S. Get our you know get our sets of C values intersect.</p>
<p>282<br>00:28:52,000 –&gt; 00:29:00,000<br>And pre-s the table. So again now at this point here, since we’ve exhausted all the b’s and so we’re dumb in this A,</p>
<p>283<br>00:29:00,000 –&gt; 00:29:07,000<br>we go back up the route and come down to the next side. Now we get a equals one probe into the tri for T.</p>
<p>284<br>00:29:07,000 –&gt; 00:29:13,000<br>A equals one. We got a match. Do the same thing. Scan along and then do the intersection.</p>
<p>285<br>00:29:13,000 –&gt; 00:29:23,000<br>Same thing. Come to two and so forth like that. Not so bad.</p>
<p>286<br>00:29:23,000 –&gt; 00:29:33,000<br>So related to his point, either pre-computing or building a tri on the fly for every time we want to do this joint is going to be expensive.</p>
<p>287<br>00:29:33,000 –&gt; 00:29:43,000<br>Again always think it’s strange. If you have billions or two bulls having to build this tri and you know across every single table every single time it’s going to be slow.</p>
<p>288<br>00:29:43,000 –&gt; 00:29:50,000<br>And even though in our world we’re assuming our data set is read only where’s the hyperfavorite you they were talking about.</p>
<p>289<br>00:29:50,000 –&gt; 00:29:58,000<br>Again trying to figure out all possible joins ahead of time and then materialize them and then fetch them from disk every time you join is going to be in practice.</p>
<p>290<br>00:29:58,000 –&gt; 00:30:05,000<br>Yes. What do you mean by building for every joint? Do you use how it wants to order the attributes you need to be able to try to get that?</p>
<p>291<br>00:30:05,000 –&gt; 00:30:10,000<br>His question is what do you mean what I mean by building over every possible joint reading? Wouldn’t you have one ordering the attributes? No. Right.</p>
<p>292<br>00:30:10,000 –&gt; 00:30:22,000<br>So in my example, ABC was the optimal ordering for giving the data. But what if I add a bunch of wear clauses or conditional predicates that start filtering from a filtering B and C or RST before I join.</p>
<p>293<br>00:30:22,000 –&gt; 00:30:30,000<br>So now the ordering can be completely different one query the next. Yeah.</p>
<p>294<br>00:30:30,000 –&gt; 00:30:37,000<br>So trying to figure that out for every single possible combination is is is wasteful.</p>
<p>295<br>00:30:37,000 –&gt; 00:30:46,000<br>So the empty had approach from Stanford with their going to claim that’s going to be better than the this try is just using national hash tables.</p>
<p>296<br>00:30:46,000 –&gt; 00:30:52,000<br>But again this is this is going to be expensive to do as well even if even building on the fly.</p>
<p>297<br>00:30:52,000 –&gt; 00:30:59,000<br>And this is part because the hash table despite the how great it was for doing a binary join we saw less class.</p>
<p>298<br>00:30:59,000 –&gt; 00:31:07,000<br>In this world is going to be really expensive because you’re just doing so many different hash lookups over again.</p>
<p>299<br>00:31:07,000 –&gt; 00:31:19,000<br>And a lot of it and it can be wasteful. Right. So the onberg eyes would argue that if you use hash tables for this you’re going to need to do one key comparison to see whether you have a collision in your hash table and you look up.</p>
<p>300<br>00:31:19,000 –&gt; 00:31:30,000<br>And then but you still need to store the actual keys the pointer to the two pulls the deal collisions. And now you’re just trashing your CPU cache because you’re jumping on to random locations over and over again for all these national hash table data structures.</p>
<p>301<br>00:31:30,000 –&gt; 00:31:39,000<br>Right. In case of the binary hash join it’s one hash table now can you dig enough where it can complete my CPU cache but there will be still some locality in that because I’m not.</p>
<p>302<br>00:31:39,000 –&gt; 00:31:44,000<br>You know traversing different paths reading a bunch of different random things all the time.</p>
<p>303<br>00:31:44,000 –&gt; 00:31:59,000<br>The argument that they’re going to claim is that you if you have very long keys or strings then you still need to use dictionary encoding to make sure that you you can keep things all nicely aligned in your data structure.</p>
<p>304<br>00:31:59,000 –&gt; 00:32:08,000<br>And that means potentially it’s still having to do lookups in the dictionary to go figure out what the actual value is when you want to do maybe deeper comparisons.</p>
<p>305<br>00:32:09,000 –&gt; 00:32:18,000<br>So these are all the flaws of the early worst case hopman joint approaches that the younger guys are trying to fix with their implementation.</p>
<p>306<br>00:32:18,000 –&gt; 00:32:26,000<br>And the key idea what they’re going to do is that it’s basically going to be the leapfrog hash join me to solve the leapfrog try hash join.</p>
<p>307<br>00:32:27,000 –&gt; 00:32:38,000<br>I’m sorry, leapfrog try join but instead of now storing the actual values of the attributes in the tribe of cells they’re going to store the hashes for the values.</p>
<p>308<br>00:32:38,000 –&gt; 00:32:49,000<br>Just 64 bit values and the idea is there that’s going to be good enough to do a quick comparison to see whether two possible values can even match at all.</p>
<p>309<br>00:32:50,000 –&gt; 00:33:01,000<br>So that we end up throwing away as much as we can without having to go maybe do deeper, deeper investigations to go read the actual data themselves to see whether there’s going to be a match or not.</p>
<p>310<br>00:33:01,000 –&gt; 00:33:17,000<br>So again, another thing about this is like you’re trying to make the sort of first peak to see whether this these two attributes are going to be the same or not be that cheap as possible because you know you’re going to throw most things away.</p>
<p>311<br>00:33:17,000 –&gt; 00:33:36,000<br>So within the try itself that each note is just going to be another hash table and they do some tricks of storing things that are raised to do quick lookups inside that and that’s going to be it’s going to have a map is going to be or the hash will map a hash value for given attribute to a pointer to the other parts of the tried out of structure.</p>
<p>312<br>00:33:36,000 –&gt; 00:33:44,000<br>And that pointer actually point to be either a child node or a pointer to the actual tuple represent that represented by that value.</p>
<p>313<br>00:33:44,000 –&gt; 00:33:52,000<br>And now because everything’s going to be in doing hash hash is which would be 64 bit integers.</p>
<p>314<br>00:33:52,000 –&gt; 00:34:00,000<br>We don’t need any additional logic in our lookups and in the certions when we build this this try to deal with the different data that we could have.</p>
<p>315<br>00:34:00,000 –&gt; 00:34:11,000<br>So it’s going back to this code specialization idea, but rather than code gending stuff at the very beginning or you know generating code and then compiling it, they just make sure that the date itself is always going to be one data type.</p>
<p>316<br>00:34:11,000 –&gt; 00:34:20,000<br>So that you can have the in a simple one one implementation that has no in direction or no lookups or no branching the deal with different possible data types.</p>
<p>317<br>00:34:20,000 –&gt; 00:34:34,000<br>And obviously if it’s if it’s hashing we could have false positives they argue with something like murmur hash maybe mention aquahash or XX hash from Facebook that’s going to be good enough where in most of the times they’re not going to have collisions.</p>
<p>318<br>00:34:35,000 –&gt; 00:34:45,000<br>And so if you do have so collisions you have at the very end just to check to see whether the actual the tuples themselves actually matching even the hash is don’t.</p>
<p>319<br>00:34:45,000 –&gt; 00:34:56,000<br>So this is the diagram from the paper this is the data structure the proposing and I’m going to go through a bunch of different operations that they have in here, but again it’s the try itself is not fancy.</p>
<p>320<br>00:34:56,000 –&gt; 00:35:06,000<br>Like they have another data structure called art the art index the adaptor index try that was in hyper that thing is having different allocations for different notes, different sizes.</p>
<p>321<br>00:35:06,000 –&gt; 00:35:14,000<br>I don’t think they’re doing any of that here that the real magic is in how they’re going to store the pointers and try to do lazy materialization.</p>
<p>322<br>00:35:15,000 –&gt; 00:35:34,000<br>So you’re always going to have to build the root of the of the try and these are going to be 16 bite buckets right there use eight bite 64 bits for the hash and 64 bits for the pointers to the actual tuple themselves or the pointer to the next level in the tree.</p>
<p>323<br>00:35:35,000 –&gt; 00:35:44,000<br>But as I said before the Germans like sticking things in pointers where they have unused bits and that’s that’s the key thing that they’re going to do here so I want to go through couple of positions.</p>
<p>324<br>00:35:45,000 –&gt; 00:35:53,000<br>How can you use these tag pointers and then how to do the late materialization because to me that’s the really clever part of what they’re doing because the hash join itself.</p>
<p>325<br>00:35:54,000 –&gt; 00:36:00,000<br>Like the leaf of try join that’s that’s been already proposed they’re making it work actually efficiently.</p>
<p>326<br>00:36:01,000 –&gt; 00:36:17,000<br>So they said Germans love sticking things in pointers we said before x86 64 only use 48 bits for memory addresses the harbor ignores anything else for the other 16 bits so because you got to allocate 64 bits that’s they want to put something in there.</p>
<p>327<br>00:36:18,000 –&gt; 00:36:24,000<br>So within the pointer itself they’re going to use 16 bits to record three additional things.</p>
<p>328<br>00:36:25,000 –&gt; 00:36:43,000<br>So the first is they’re going to have a single bit flag that corresponds to whether something is a single to not meaning there isn’t going to be a path through the through the single to meaning like there isn’t anything in between the root node and the bottom node it’s a direct path to the leaf nodes.</p>
<p>329<br>00:36:44,000 –&gt; 00:37:10,000<br>And then they’re going to use a another bit to for expansion flag just mean that has the has the the nodes below it have they’ve been allocated and expanded because they’re trying to lazy materialization so even though the data structure will have a pointer to something to lower levels in the try they’re not actually going to materialize it until you actually try to go look it up.</p>
<p>330<br>00:37:10,000 –&gt; 00:37:20,000<br>So if this flag just says hey by the way you brought to jumps on location that hasn’t been expanded or allocated yet so go do that first then flip this bit and then traverse down.</p>
<p>331<br>00:37:22,000 –&gt; 00:37:35,000<br>And to know how to expand they’re going to maintain the 14 bits for the chain length so that you know when you’re traversing along the leaf node what’s the number elements you expect to see because everything’s fixed length.</p>
<p>332<br>00:37:35,000 –&gt; 00:37:45,000<br>It’s always going to be 16 bits or 16 bytes you know that the size of the chain length can be can be computed from this from this counter here.</p>
<p>333<br>00:37:47,000 –&gt; 00:37:51,000<br>And the rest is just going to be the 48 bits that the harbor is going to use for memory addresses.</p>
<p>334<br>00:37:52,000 –&gt; 00:38:02,000<br>We saw this example with the hash table right they would store a bloom filter in the 16 bits there was another example to I’m blanking on to as well.</p>
<p>335<br>00:38:05,000 –&gt; 00:38:09,000<br>Yeah there was another another example of the Germans they were doing this as well I forgot what it was.</p>
<p>336<br>00:38:10,000 –&gt; 00:38:13,000<br>But okay so let’s go through the single to install and how the expansion stuff works.</p>
<p>337<br>00:38:14,000 –&gt; 00:38:34,000<br>So again the size of the hash it was in the try is going to get smaller smaller as you go down because there’s end up being oftentimes the single two or sorry single pair of values for an attribute.</p>
<p>338<br>00:38:35,000 –&gt; 00:38:46,000<br>So it isn’t going to be a lot of too much duplication as you go down so you end up with these paths through your try where each node is only have one entry right.</p>
<p>339<br>00:38:47,000 –&gt; 00:38:53,000<br>So the idea is that instead of storing the you know it’s all separate hash table.</p>
<p>340<br>00:38:53,000 –&gt; 00:39:06,000<br>Or node within the try for for it for a node that only has one entry at a level then you just bypass that and skip down to the bottom right.</p>
<p>341<br>00:39:07,000 –&gt; 00:39:15,000<br>So in this case here for when the hash value say is some value zero when we jump down here we only have one entry inside this.</p>
<p>342<br>00:39:15,000 –&gt; 00:39:29,000<br>So then now rather than storing this digital node just go again follow follow the pointer go down look at it only find one thing and the choice down here instead what they do is just have a fast path pointer that takes you directly down down here.</p>
<p>343<br>00:39:31,000 –&gt; 00:39:44,000<br>So then you would use that that this expansion bit or sorry the single to fit set at the one to know that if you’re at the root there isn’t going to be anything else below you just jump right down to the node at the bottom.</p>
<p>344<br>00:39:45,000 –&gt; 00:39:55,000<br>Now you obviously still need to store the the information that was that was in this guy so that you can actually you know do the comparison whether you actually have a match or not.</p>
<p>345<br>00:39:56,000 –&gt; 00:39:58,000<br>But again that’s just done down the leaf node yes.</p>
<p>346<br>00:39:58,000 –&gt; 00:40:02,000<br>So the single to the bit you can use anywhere down the tree so the moment you know you’re having more children.</p>
<p>347<br>00:40:02,000 –&gt; 00:40:11,000<br>Yes his statement is is the single to the bit use at any point the tree so that at any moment you look at it and you know that the next thing the pointer going to follow is to take you to the bottom yes.</p>
<p>348<br>00:40:16,000 –&gt; 00:40:33,000<br>So the next optimization to do the lady child expansion again the idea here is that unlike in the logic blocks you know multi way join the worst case of no join where they’re popular in the entire try before you start joining idea here is that you.</p>
<p>349<br>00:40:33,000 –&gt; 00:40:41,000<br>You would populate the first the root node you still have the obviously have the tubals at the bottom but in the ideas that.</p>
<p>350<br>00:40:41,000 –&gt; 00:40:56,000<br>If nothing when you do the join itself if there isn’t any comparisons along a path in the try then why instantiate the memory for it and why try to allocate it right only when you actually go to need it then then you populate it.</p>
<p>351<br>00:40:56,000 –&gt; 00:41:01,000<br>So this limits the overhead of trying to build the trying beginning because you’re just building the first level.</p>
<p>352<br>00:41:01,000 –&gt; 00:41:04,000<br>And the bottom level right.</p>
<p>353<br>00:41:05,000 –&gt; 00:41:09,000<br>So the way works is like say in the very beginning my try would look like this.</p>
<p>354<br>00:41:11,000 –&gt; 00:41:14,000<br>This is kind of confusing here but you would have.</p>
<p>355<br>00:41:14,000 –&gt; 00:41:19,000<br>You know sort of think that the bottom is a linked list that tells you the ordering of of things.</p>
<p>356<br>00:41:20,000 –&gt; 00:41:29,000<br>So if now I someone comes along and tries to do a look up down this path and say this is trying to do join on two attributes so I’m missing that second level.</p>
<p>357<br>00:41:30,000 –&gt; 00:41:37,000<br>So I look inside this I see that the expansion bit is set to zero so I know that I’m.</p>
<p>358<br>00:41:37,000 –&gt; 00:41:48,000<br>I don’t have anything below me at this point so then I could go do now comparison or sorry fast back down to the bottom I need to do a comparison and I scan along the leafens to find what I want.</p>
<p>359<br>00:41:49,000 –&gt; 00:42:01,000<br>But then now I go ahead and populate what the values actually were and I know how many things I should be looking at because my chain length would tell me when the expansion bit is set to zero.</p>
<p>360<br>00:42:01,000 –&gt; 00:42:12,000<br>This is going to tell me how many things I need to look at the bottom so I can then allocate that node put that here and then I update the new node pointers to point to different parts of the list of the bottom.</p>
<p>361<br>00:42:12,000 –&gt; 00:42:29,000<br>Then I go ahead and flip the bit to be one so now that anybody else comes along follow down the same path though know that they’re actually looking at expanded those below me and not the not directly to the bottom.</p>
<p>362<br>00:42:29,000 –&gt; 00:42:30,000<br>Yes.</p>
<p>363<br>00:42:30,000 –&gt; 00:42:31,000<br>So there’s a lot of my things here.</p>
<p>364<br>00:42:31,000 –&gt; 00:42:38,000<br>Surely like there’s only one I do as much more built side or that’s not rather that’s for more.</p>
<p>365<br>00:42:38,000 –&gt; 00:42:45,000<br>So question is why is this an optimization don’t you want to do as much work as you can on the build side to make the products go fast as possible.</p>
<p>366<br>00:42:45,000 –&gt; 00:42:49,000<br>But yes but like you’re trying to join.</p>
<p>367<br>00:42:49,000 –&gt; 00:42:56,000<br>Three or more tables all at once so there’s going to be so much memory pressure for that data structure.</p>
<p>368<br>00:42:56,000 –&gt; 00:43:03,000<br>Think of like trying to build like build complete hash tables for all three tables at the same time that would be super expensive.</p>
<p>369<br>00:43:03,000 –&gt; 00:43:09,000<br>Again think it extremes like you know each table is ten petabytes or ten terabytes.</p>
<p>370<br>00:43:09,000 –&gt; 00:43:19,000<br>So this is just trying to minimize the amount of work that minimize the explosion of memory and storage for your data structure for parts you never actually going to need.</p>
<p>371<br>00:43:19,000 –&gt; 00:43:25,000<br>Did you mind explaining the algorithm to the creatures you know that the end of the world was the most important?</p>
<p>372<br>00:43:25,000 –&gt; 00:43:26,000<br>Yeah this is sort of not clear.</p>
<p>373<br>00:43:26,000 –&gt; 00:43:31,000<br>So this is all in sort of order and I think this is going down here.</p>
<p>374<br>00:43:31,000 –&gt; 00:43:38,000<br>This is going over here and this is just saying that the thing of this is again the link list had to follow along for the rest of the tables.</p>
<p>375<br>00:43:38,000 –&gt; 00:43:39,000<br>Yeah.</p>
<p>376<br>00:43:39,000 –&gt; 00:43:43,000<br>Actually I think this is actually not in sort of order right.</p>
<p>377<br>00:43:43,000 –&gt; 00:43:50,000<br>You have one three one two two three so this is this is how the original two was appeared and now you’re just keeping it in that order.</p>
<p>378<br>00:43:50,000 –&gt; 00:43:52,000<br>But then you’re storing link list.</p>
<p>379<br>00:43:52,000 –&gt; 00:43:53,000<br>Yeah.</p>
<p>380<br>00:43:53,000 –&gt; 00:43:55,000<br>When do you do that in this point?</p>
<p>381<br>00:43:55,000 –&gt; 00:43:56,000<br>When do you create a list?</p>
<p>382<br>00:43:56,000 –&gt; 00:43:58,000<br>I so I think you have to do one pass.</p>
<p>383<br>00:43:58,000 –&gt; 00:44:04,000<br>You have to do one pass with the data anyway beginning because you have to hash it and figure out what the root is.</p>
<p>384<br>00:44:04,000 –&gt; 00:44:09,000<br>Right and I think they that’s when they construct this link list.</p>
<p>385<br>00:44:09,000 –&gt; 00:44:15,000<br>So I have to double check that.</p>
<p>386<br>00:44:15,000 –&gt; 00:44:18,000<br>So I’m going to show one graph from their paper.</p>
<p>387<br>00:44:18,000 –&gt; 00:44:26,000<br>So this one they’re comparing against empty headed which is the thing from Stanford early prototype logic blocks and then the original version of umbra.</p>
<p>388<br>00:44:26,000 –&gt; 00:44:33,000<br>Umbra with the leap frog try join from the logic blocks guys and then the umbra with their hash try.</p>
<p>389<br>00:44:33,000 –&gt; 00:44:47,000<br>Right and for this one they’re trying to compute a three clique query sorry three clique graph or sub graph from a graph data set from Google plus or kit and Twitter.</p>
<p>390<br>00:44:47,000 –&gt; 00:44:54,000<br>Google plus was like early Google’s attempt doing Facebook.</p>
<p>391<br>00:44:54,000 –&gt; 00:45:00,000<br>Or cut was um the Brazilian Facebook.</p>
<p>392<br>00:45:00,000 –&gt; 00:45:06,000<br>Google and Google about these right and then Twitter is sorry.</p>
<p>393<br>00:45:06,000 –&gt; 00:45:21,000<br>So again the main takeaway is that like the for these larger graph data sets the you know the in the case of the Twitter one I think the graph is highly connected.</p>
<p>394<br>00:45:21,000 –&gt; 00:45:25,000<br>So building those data structures in the beginning.</p>
<p>395<br>00:45:25,000 –&gt; 00:45:28,000<br>You know it’s just super expensive and it’s just timing out.</p>
<p>396<br>00:45:28,000 –&gt; 00:45:34,000<br>Whereas the late materialization shows the real benefit here because you’re you know.</p>
<p>397<br>00:45:34,000 –&gt; 00:45:41,000<br>Yes I mean it’s not going to run as fast as if you built everything ahead of time but you have.</p>
<p>398<br>00:45:41,000 –&gt; 00:45:52,000<br>You know you don’t have too much memory pressure of trying to maintain again the data structure to do this uh to do the to do the join right.</p>
<p>399<br>00:45:52,000 –&gt; 00:46:02,000<br>So again it’s just showing you that the umbra has try is preferable over than the leap frog try so they the real comparison is like this one versus this one right because.</p>
<p>400<br>00:46:02,000 –&gt; 00:46:05,000<br>Empty headed is a prototype was acting prototype.</p>
<p>401<br>00:46:05,000 –&gt; 00:46:09,000<br>So it’s like the blocks is getting the only commercial system at the time they compare against.</p>
<p>402<br>00:46:09,000 –&gt; 00:46:15,000<br>Right this is what the care about like if you Germans building your your hash try in Germans building your leap frog try.</p>
<p>403<br>00:46:15,000 –&gt; 00:46:21,000<br>Then you know the hash tries better.</p>
<p>404<br>00:46:21,000 –&gt; 00:46:24,000<br>So the.</p>
<p>405<br>00:46:24,000 –&gt; 00:46:29,000<br>The challenges though in the paper brings us up which is a good point is that.</p>
<p>406<br>00:46:29,000 –&gt; 00:46:32,000<br>You need you still need binary joints.</p>
<p>407<br>00:46:32,000 –&gt; 00:46:36,000<br>And so I think there was one it had a bunch of experience with this show that the.</p>
<p>408<br>00:46:36,000 –&gt; 00:46:41,000<br>For for for workloads like TPCH and the joint out of benchmark if you’re just doing binary joins.</p>
<p>409<br>00:46:41,000 –&gt; 00:46:47,000<br>Uh even when it’s not unfiltered uh the multi way joint is actually not going to be as good.</p>
<p>410<br>00:46:47,000 –&gt; 00:46:57,000<br>Right it’s not going to be as performant and as as the binary join it’s only the cases when the immediate result size is going to blow up is when you want to use the worst case out.</p>
<p>411<br>00:46:57,000 –&gt; 00:47:00,000<br>No join again as we define in the very beginning.</p>
<p>412<br>00:47:00,000 –&gt; 00:47:04,000<br>So what you really want is a system that can support both.</p>
<p>413<br>00:47:04,000 –&gt; 00:47:12,000<br>And then at when a query shows up the determine which joins within your query plan should be using one algorithm versus another.</p>
<p>414<br>00:47:12,000 –&gt; 00:47:17,000<br>It’s no different than trying to figure out whether I when use the sort of merge join or hash join or.</p>
<p>415<br>00:47:17,000 –&gt; 00:47:21,000<br>A nest loop join which you typically don’t want to use that but.</p>
<p>416<br>00:47:21,000 –&gt; 00:47:23,000<br>You want your optimize better figure this out.</p>
<p>417<br>00:47:23,000 –&gt; 00:47:27,000<br>And so in the paper they talk about how on bro I was able to.</p>
<p>418<br>00:47:27,000 –&gt; 00:47:35,000<br>Extender optimizer using heuristics to basically figure out on the fly based on the system they’ve collected whether to use one versus another.</p>
<p>419<br>00:47:35,000 –&gt; 00:47:37,000<br>And no system can do this.</p>
<p>420<br>00:47:37,000 –&gt; 00:47:42,000<br>I’m not trying to advertise for for for umbra but like larger blocks only the multi way join.</p>
<p>421<br>00:47:42,000 –&gt; 00:47:45,000<br>I think kuzu only does multi way joint yes.</p>
<p>422<br>00:47:45,000 –&gt; 00:47:53,000<br>Yes yes yes yes yes yes.</p>
<p>423<br>00:47:53,000 –&gt; 00:47:57,000<br>Nobody does that.</p>
<p>424<br>00:47:57,000 –&gt; 00:48:07,000<br>So you just are like hard to know that if you’re like.</p>
<p>425<br>00:48:07,000 –&gt; 00:48:14,000<br>If you do an echo join in a join or echo join with on primary keys to know exactly low up.</p>
<p>426<br>00:48:14,000 –&gt; 00:48:17,000<br>Yeah but it’s like it’s like he’s saying so much he restricts the figure things out right.</p>
<p>427<br>00:48:17,000 –&gt; 00:48:20,000<br>I mean one of the use case to say I know I want to use a binary join.</p>
<p>428<br>00:48:20,000 –&gt; 00:48:24,000<br>It’s like this really this has problems when again you’re doing.</p>
<p>429<br>00:48:24,000 –&gt; 00:48:26,000<br>Graph traversals is a lot of self joins.</p>
<p>430<br>00:48:26,000 –&gt; 00:48:30,000<br>Like you’re like looking up the edge you’re doing joins on the edge table over again.</p>
<p>431<br>00:48:30,000 –&gt; 00:48:37,000<br>Or if you’re joining on like non foreign key primary key attributes then things can blow up.</p>
<p>432<br>00:48:37,000 –&gt; 00:48:44,000<br>Again it’s not that they’re not they’re not as common as foreign key primary key joints that’s probably the most common use case.</p>
<p>433<br>00:48:44,000 –&gt; 00:48:49,000<br>But they still they still exist enough where like this all falls apart.</p>
<p>434<br>00:48:49,000 –&gt; 00:48:56,000<br>Okay so I’m going to quickly finish up and talk about one addition optimization from.</p>
<p>435<br>00:48:56,000 –&gt; 00:49:00,000<br>From the duct B guys so it’s the guy who wrote the fast lanes paper.</p>
<p>436<br>00:49:00,000 –&gt; 00:49:08,000<br>The people at CWRI they they had a can experiment or branch of duct B where they add a support for the PG SQL PGQ extensions.</p>
<p>437<br>00:49:08,000 –&gt; 00:49:15,000<br>Owned relational database system and in this great paper which I get a person I can post on piata.</p>
<p>438<br>00:49:15,000 –&gt; 00:49:22,000<br>They basically lay out here’s all the things you’d want to have in a relational database system to make a.</p>
<p>439<br>00:49:22,000 –&gt; 00:49:34,000<br>Do officially support SQL PGQ queries right and that they basically opine that all these specialized graph databases that are out there the Neo4j’s and so forth are.</p>
<p>440<br>00:49:34,000 –&gt; 00:49:43,000<br>Just fundamentally flawed because they’re based on storing edges and vertices in these inefficient data structures that it don’t take advantage of all the less.</p>
<p>441<br>00:49:43,000 –&gt; 00:49:50,000<br>10 20 years of development developments and optimization so we’ve been talking about in this class to make relational queries run faster.</p>
<p>442<br>00:49:50,000 –&gt; 00:49:57,000<br>So independent other words case up in the joint there’s a bunch of stuff that we’ve already covered like vectorization better query optimization will cover in a second.</p>
<p>443<br>00:49:57,000 –&gt; 00:50:16,000<br>Or cover later this semester or compression all those things which is what you need to make a graph query run faster and that the isn’t graph databases basically ignored all those developments and went down the run path and they’re going to lose out to relational databases and I agree to that.</p>
<p>444<br>00:50:16,000 –&gt; 00:50:19,000<br>I agree to that that with that statement.</p>
<p>445<br>00:50:19,000 –&gt; 00:50:35,000<br>So I’m going to show one optimization that we haven’t really covered it doesn’t really fit into other parts of the talk to I mean kind of need to understand okay when you have the balloon up of these in the results in these graph or triangle queries like this is when you actually want to apply this technique for binary joins it doesn’t make sense.</p>
<p>446<br>00:50:35,000 –&gt; 00:50:52,000<br>So the technique is called factorization the idea is really simple basically rather than materializing duplicate tuples over and over again for a joint whatever operator you’re trying to generate you just figure out here’s all the actual unique values and maintain a column of a counter.</p>
<p>447<br>00:50:52,000 –&gt; 00:50:56,000<br>It says how many times have I seen this seen seen this to pull.</p>
<p>448<br>00:50:56,000 –&gt; 00:51:08,000<br>So now going back to my examples I have before when I was doing those joints and the enemy results blowing up is that again to have materialize all those results I could store it in a factorized form and have a counter.</p>
<p>449<br>00:51:08,000 –&gt; 00:51:25,000<br>But now the challenges in my invitation all the operators in my system need to be aware of that they’re operating on factorized tuples and and be able to account for that right if I’m running a count query right you know this can’t to be something internal that something that just gets synthesized and ignored treated like any other column.</p>
<p>450<br>00:51:25,000 –&gt; 00:51:33,000<br>The system needs to know this is a counter column and you know adjust the computations accordingly.</p>
<p>451<br>00:51:33,000 –&gt; 00:51:37,000<br>Simple trick nobody does this.</p>
<p>452<br>00:51:37,000 –&gt; 00:51:43,000<br>But again I think this is something of the relational guys will eventually have to eventually have to add.</p>
<p>453<br>00:51:43,000 –&gt; 00:51:59,000<br>So here’s a graph here’s some graphs from this again the paper that I mentioned from the dr. Meek eyes where the comparing is new Neo4j they’re comparing against the extended version of ducty with PGQ or SQL PGQ and I think they only implemented worst case optimal joint.</p>
<p>454<br>00:51:59,000 –&gt; 00:52:07,000<br>I don’t think and they already obviously already have vectorized execution and compression and all the stuff that we talked about so far that dr. Meek has.</p>
<p>455<br>00:52:07,000 –&gt; 00:52:17,000<br>And then they compare it against on bra with the try hash and the main takeaways that the Neo4j basically is crushed like these are all log scale right.</p>
<p>456<br>00:52:17,000 –&gt; 00:52:19,000<br>So they’re running the same.</p>
<p>457<br>00:52:19,000 –&gt; 00:52:22,000<br>Same queries for this.</p>
<p>458<br>00:52:22,000 –&gt; 00:52:32,000<br>The link data benchmark is something that the see see if it is created with the other graph databases so this is a bunch of workloads that are trying to do.</p>
<p>459<br>00:52:32,000 –&gt; 00:52:43,000<br>Pattern matching on on grass structures or the logical graph and again just going down the line for different scale factors Neo4j gets crushed.</p>
<p>460<br>00:52:43,000 –&gt; 00:52:51,000<br>And I’m not trying to like you know dunk on Neo4j but like that’s the oldest graph database they’ve raised the most money and they probably like 200 million right.</p>
<p>461<br>00:52:51,000 –&gt; 00:53:01,000<br>And this is when you think of graph database people think of Neo4j and you know for millions millions of dollars you know they’re getting crushed by you know Ragtag group of Germans although they’re the best</p>
<p>462<br>00:53:01,000 –&gt; 00:53:06,000<br>Germans and the and the dr. Meek.</p>
<p>463<br>00:53:06,000 –&gt; 00:53:16,000<br>Right and that’s because again the system even though wasn’t they were not originally designed for doing graph graph analytics by taking advantage of all the</p>
<p>464<br>00:53:16,000 –&gt; 00:53:21,000<br>oppositions we talked about so far plus the worst case optimal join you know they can crush Neo4j.</p>
<p>465<br>00:53:21,000 –&gt; 00:53:30,000<br>Neo4j as far as I know they store like the there’s a separate data structure for the vertices and then you have pointers to another data structure that keeps track of edges.</p>
<p>466<br>00:53:30,000 –&gt; 00:53:31,000<br>Right yes.</p>
<p>467<br>00:53:31,000 –&gt; 00:53:38,000<br>I agree to why is umbra scale back to 30 slower than scale back to 100.</p>
<p>468<br>00:53:38,000 –&gt; 00:53:47,000<br>Sorry it’s question is why why is umbra slower and scale back to 100 then so why is it faster here than here?</p>
<p>469<br>00:53:47,000 –&gt; 00:53:52,000<br>I don’t know I have a good look.</p>
<p>470<br>00:53:52,000 –&gt; 00:54:08,000<br>Okay so this is this is both a um I think you think both have an advertised for why you want worst case optimal join you want to support these kind of queries but also like why you don’t want to use a specialized graph database.</p>
<p>471<br>00:54:08,000 –&gt; 00:54:24,000<br>So this is active very active area of research and as I said only a small number of systems actually support worst case optimal joins but I think that’s going to change over time and there’s new papers coming out all the time there’s a new paper out of</p>
<p>472<br>00:54:24,000 –&gt; 00:54:36,000<br>University College of London for their sonic join which beats the hash drive join I can post a link to that but this people are actually working this trying to make this go better and I think that</p>
<p>473<br>00:54:36,000 –&gt; 00:54:52,000<br>industry typically is you know three or four or five years behind academia on this kind of stuff but I think now it’ll be with again with the the sequel extension for graph queries this will get to start rolling out in more systems.</p>
<p>474<br>00:54:52,000 –&gt; 00:54:58,000<br>And I guess that once you support SQL PGQ why would you want to use a graph database.</p>
<p>475<br>00:54:58,000 –&gt; 00:55:10,000<br>Alright so next class before we jump into the system profiling stuff again we’re going to have on Wednesday we’re going to have project presentations everyone’s going to get five minutes going to try to be more strict on the time so we can get through this.</p>
<p>476<br>00:55:10,000 –&gt; 00:55:26,000<br>We’re going to reverse order then we went last time I promised and then what we’re going to do is we’re going to record to resume the talks so that women I can then watch it again and then provide you guys notes and feedback because I didn’t do that last time we lost track of everything was so much so we’re going to record it on my laptop.</p>
<p>477<br>00:55:26,000 –&gt; 00:55:34,000<br>We won’t share it outside one person on YouTube and then we’ll and then we’ll give you feedback this weekend.</p>
<p>478<br>00:55:34,000 –&gt; 00:55:50,000<br>Alright so there’s a quick run through of how to basically data system profiling and this so these slides are a few years old but all the techniques are basically work and we referencing the system that the previous system we were building but the high level ideas are still the same.</p>
<p>479<br>00:55:50,000 –&gt; 00:55:57,000<br>And this is all being sequels plus I don’t know I’m assuming rust works the same way.</p>
<p>480<br>00:55:57,000 –&gt; 00:56:19,000<br>Alright so let’s say we have some some some programs today we said we have two functions food and bar and so we want to be able to speed it up with only debugger so the really simple way to do this is literally open up gdb run run the program and this click you know pause it stop it then do turn up the stack trace figure out what function you’re in and just run it.</p>
<p>481<br>00:56:19,000 –&gt; 00:56:23,000<br>And then we’re in and just record it in the spreadsheet.</p>
<p>482<br>00:56:23,000 –&gt; 00:56:26,000<br>It’s ghetto but it would it would work right.</p>
<p>483<br>00:56:26,000 –&gt; 00:56:36,000<br>So we do this and say that we we pause it ten times get the stack trace and then six out of the time times we were in the function food.</p>
<p>484<br>00:56:36,000 –&gt; 00:56:46,000<br>So we can basically say that roughly 60% of the time is of our program based on the data we collected in food.</p>
<p>485<br>00:56:46,000 –&gt; 00:56:53,000<br>It’s bad but like it’s like it would work right you just do it more and more and then you get better samples.</p>
<p>486<br>00:56:53,000 –&gt; 00:56:56,000<br>It’s a perfect.</p>
<p>487<br>00:56:56,000 –&gt; 00:57:06,000<br>Yeah basically yes it’s came in this is what perfect does yes but it has hardware support not you sitting with you know the keyboard like this.</p>
<p>488<br>00:57:06,000 –&gt; 00:57:13,000<br>Alright so if we say all right food is we’re spending all our time in food we don’t make that run faster.</p>
<p>489<br>00:57:13,000 –&gt; 00:57:18,000<br>What do we do? Well this is omdos law right.</p>
<p>490<br>00:57:18,000 –&gt; 00:57:25,000<br>So if we say we’re going to make food run two times faster we want to compete with the overall potential speed up it’s going to be right.</p>
<p>491<br>00:57:25,000 –&gt; 00:57:31,000<br>So we get 60% of our time food jobs on half the 4% of time for the function bar we leave alone.</p>
<p>492<br>00:57:31,000 –&gt; 00:57:36,000<br>And so omdos law basically tells us that you know it’s going to be whatever the formula here.</p>
<p>493<br>00:57:36,000 –&gt; 00:57:43,000<br>One over the 1 over the the percentage time in the thing we’re trying to optimize what we’re speeding up and then 1 minus the percentage time there.</p>
<p>494<br>00:57:43,000 –&gt; 00:57:50,000<br>So do the plug and chuck of the number means that our program run 1.4x faster.</p>
<p>495<br>00:57:50,000 –&gt; 00:57:58,000<br>Right back your mind on those law actually works and keep this in you know you want to keep this in mind when you try to figure out what you actually want to optimize for.</p>
<p>496<br>00:57:58,000 –&gt; 00:58:04,000<br>So now the question is how do we actually do something better than hitting with the keyboard right.</p>
<p>497<br>00:58:04,000 –&gt; 00:58:09,000<br>And a high level there’s two approaches. There’s we valgrine and perf.</p>
<p>498<br>00:58:09,000 –&gt; 00:58:24,000<br>So valgrine is a heavyweight instrumentation of the actual binary itself to basically introduce some timers if you will for different function calls.</p>
<p>499<br>00:58:24,000 –&gt; 00:58:28,000<br>And that it’s going to collect this what wildlife actual program runs in user space.</p>
<p>500<br>00:58:28,000 –&gt; 00:58:33,000<br>And then at the end it spits out of a report you can then visualize and figure out what’s going on.</p>
<p>501<br>00:58:33,000 –&gt; 00:58:34,000<br>Yes.</p>
<p>502<br>00:58:34,000 –&gt; 00:58:36,000<br>And what would you do for code coverage as well?</p>
<p>503<br>00:58:36,000 –&gt; 00:58:37,000<br>More or less yes.</p>
<p>504<br>00:58:37,000 –&gt; 00:58:40,000<br>But code coverage will tell you what lines are at being executed.</p>
<p>505<br>00:58:40,000 –&gt; 00:58:43,000<br>It’s not going to tell you what where you’re spending the time.</p>
<p>506<br>00:58:43,000 –&gt; 00:58:47,000<br>This is the idea is you want to know what the time is. That’s what this is.</p>
<p>507<br>00:58:47,000 –&gt; 00:58:56,000<br>And in perf is going to basically be a better version of this that’s going to use hardware counters which again the CPU is maintaining these encounters about like everything.</p>
<p>508<br>00:58:56,000 –&gt; 00:59:07,000<br>L1, L2, L3, cache misses. How many times you get how many branch predictions cycles per instruction number instructions way more things.</p>
<p>509<br>00:59:07,000 –&gt; 00:59:13,000<br>The hardware is collecting all this information so you can actually get it for your your program wants running.</p>
<p>510<br>00:59:13,000 –&gt; 00:59:24,000<br>And if you compile a symbols you can then have it in the perf report and actually see what the lines are of code and how many times you’re being you know running them and how much time you’re spending in them.</p>
<p>511<br>00:59:24,000 –&gt; 00:59:30,000<br>So valgrine would be a valgrine is what you use back in the day.</p>
<p>512<br>00:59:30,000 –&gt; 00:59:37,000<br>It’s good sometimes the visualization will look better. It depends on the tool and the purpose what you want to use in a modern you know modern systems.</p>
<p>513<br>00:59:37,000 –&gt; 00:59:40,000<br>But it’s good at least look at both of them.</p>
<p>514<br>00:59:40,000 –&gt; 00:59:46,000<br>So valgrine is actually a collection of tools that you can use to do dynamic analysis.</p>
<p>515<br>00:59:46,000 –&gt; 00:59:53,000<br>Memchack would be again looking for leaks. Call grinds which you want to use to figure out how much time you’re spending in different parts of the code.</p>
<p>516<br>00:59:53,000 –&gt; 01:00:03,000<br>And then if you wanted to keep track of like what parts of the code are allocating this memory over time you would use the tool called massive.</p>
<p>517<br>01:00:03,000 –&gt; 01:00:10,000<br>So to use call grind you basically would run your program with a valgrine command line.</p>
<p>518<br>01:00:10,000 –&gt; 01:00:21,000<br>Tell it I want to run call grind tool. There’s additional flags of how how verbose or how detailed you want the report to be when it runs runs your code.</p>
<p>519<br>01:00:21,000 –&gt; 01:00:31,000<br>And then this is going to spit out this call grind out file. And then you can use a visualization tool like K cash grind to see something like this and you get a nice.</p>
<p>520<br>01:00:31,000 –&gt; 01:00:37,000<br>As visualization for here’s all the functions the functions calling this this other function how many times has been in vote.</p>
<p>521<br>01:00:37,000 –&gt; 01:00:41,000<br>What percentage of the execution of the program was spent in that time right.</p>
<p>522<br>01:00:41,000 –&gt; 01:00:46,000<br>So here you see that again the the the the human distribution of all the time being spent in different parts of the code.</p>
<p>523<br>01:00:46,000 –&gt; 01:00:51,000<br>Again you’ll see you know when you call libraries that are pre compiled that you don’t have symbols for.</p>
<p>524<br>01:00:51,000 –&gt; 01:00:54,000<br>You might just see the library name and like a memory address.</p>
<p>525<br>01:00:54,000 –&gt; 01:00:59,000<br>Right so there’s there’s ways to try to get that if you can use libraries that you compile yourselves.</p>
<p>526<br>01:00:59,000 –&gt; 01:01:05,000<br>And then again here we see the call graph view and they can drill into each of these and see additional information.</p>
<p>527<br>01:01:05,000 –&gt; 01:01:09,000<br>But again so this is going to be done like it generates this information while your program is running.</p>
<p>528<br>01:01:09,000 –&gt; 01:01:15,000<br>It doesn’t have any special privileges and there’s no harbor to make make things run better so your program is actually going to run slower.</p>
<p>529<br>01:01:15,000 –&gt; 01:01:24,000<br>So the timing could actually quite off like the wall clock time versus what the real like when you when you run with call grind turned on versus like just running by yourself.</p>
<p>530<br>01:01:24,000 –&gt; 01:01:27,000<br>The timing can be off and so for.</p>
<p>531<br>01:01:27,000 –&gt; 01:01:36,000<br>This matters a lot for race conditions and other things you may not experience the problems you would see when you run without call grind because it’s just running so much slowly.</p>
<p>532<br>01:01:36,000 –&gt; 01:01:44,000<br>Well you may see issues in this in this run that you wouldn’t see in the production run.</p>
<p>533<br>01:01:44,000 –&gt; 01:01:47,000<br>So the the better approaches you perf.</p>
<p>534<br>01:01:47,000 –&gt; 01:01:54,000<br>Again for this one I think you need root privileges because you have to get you have to have permissions to get stuff get the counters from the hardware.</p>
<p>535<br>01:01:54,000 –&gt; 01:02:01,000<br>The basic idea is that you’re going to start your program with word perf you can specify how many cycles.</p>
<p>536<br>01:02:01,000 –&gt; 01:02:11,000<br>How often you want to go check for events and you know how much detail you want the traces to be right there’s a bunch of different flags for these things.</p>
<p>537<br>01:02:11,000 –&gt; 01:02:22,000<br>And then the is going to run your program I think it runs about the same speed but again it has to materialize these results somewhere right so it has to start running to disk for this dump file.</p>
<p>538<br>01:02:22,000 –&gt; 01:02:31,000<br>So like if you’re if your program sensitive to like disk IO then this can interfere a little bit but it’s not as heavy weight as as call run.</p>
<p>539<br>01:02:31,000 –&gt; 01:02:40,000<br>So then after you run your program in the directory where you ran perf there’ll be like a dot dump file or has some kind of dot perf name.</p>
<p>540<br>01:02:40,000 –&gt; 01:02:51,000<br>And then you just use this this perf report tool and then that’ll give you a sort of visualization like this where again you’ll see this is actually measuring the time being spent.</p>
<p>541<br>01:02:51,000 –&gt; 01:03:02,000<br>So you’ll see that the you know the rank list at the top the ones we’re spending most of the time and then you can drill into them and if you compile symbols you’d actually see the lines of code generated these things.</p>
<p>542<br>01:03:02,000 –&gt; 01:03:15,000<br>So cumulative events and then additional things you can click enter you’ll see how often you know what’s actually what were you spending your time standing call ground you can see lines of code again this is this is going to be way better.</p>
<p>543<br>01:03:15,000 –&gt; 01:03:26,000<br>So this is this is this is probably two or three now maybe four or five years old because before we named this is a noise page we named it after my dog so that’s why see the tear name in there.</p>
<p>544<br>01:03:26,000 –&gt; 01:03:33,000<br>But this is this is some benchmark we added to see how fast we can you know we can do reads across multiple threads.</p>
<p>545<br>01:03:33,000 –&gt; 01:03:51,000<br>And there’s other third party tools like hotspot and that’s a you know you’ll see nice things like this we ever see these flame grass these flame grass to be generated by by tools based on perf right and now you can see where you know we’re just spending most of your time in.</p>
<p>546<br>01:03:51,000 –&gt; 01:04:03,000<br>Right and then this is what this is just saying what would you say things you want to measure so this one measuring cycles last level cashmases see utilization all bunch of stuff you can tell purple you want to collect.</p>
<p>547<br>01:04:03,000 –&gt; 01:04:14,000<br>So much of these links in slides here you go for long and I’m assuming there’s there’s hooks to do this in rust what now.</p>
<p>548<br>01:04:14,000 –&gt; 01:04:17,000<br>If you use cargo flame brush you get a really nice.</p>
<p>549<br>01:04:17,000 –&gt; 01:04:26,000<br>He says if you use cargo flame you have to get nice thing we have and that’s assuming that’s running perf at yeah underneath covers but you need room privileges I think to run perf.</p>
<p>550<br>01:04:26,000 –&gt; 01:04:29,000<br>I think you actually just sell a good environment variable.</p>
<p>551<br>01:04:29,000 –&gt; 01:04:30,000<br>Okay.</p>
<p>552<br>01:04:30,000 –&gt; 01:04:41,000<br>It’s in a pile I think it’s different.</p>
<p>553<br>01:04:41,000 –&gt; 01:04:46,000<br>I think for low level hard work counters you need you need you need to measure the privileges.</p>
<p>554<br>01:04:46,000 –&gt; 01:04:56,000<br>Okay and any questions about performance counters yes yes.</p>
<p>555<br>01:04:56,000 –&gt; 01:05:03,000<br>What do you mean sorry.</p>
<p>556<br>01:05:03,000 –&gt; 01:05:12,000<br>So questions how would you use perfect optimize one single function right so you would get say say you just come in line get perfor port if you have this one function so one you can find the function in here.</p>
<p>557<br>01:05:12,000 –&gt; 01:05:22,000<br>But then you can drill that you this is not this is obviously a screenshot you can drill into that function and it’ll show you the lines of code and how much time you’re running and how much time you’re spending in it.</p>
<p>558<br>01:05:22,000 –&gt; 01:05:35,000<br>And they can use that to figure out where you’re you know where you’re wasting your time and it could be because like you’re calling malachala or something stupid in a way you think you’re calling and then you can then refactor and optimize that.</p>
<p>559<br>01:05:35,000 –&gt; 01:05:39,000<br>You can count by cycle civilization let the catch misses.</p>
<p>560<br>01:05:39,000 –&gt; 01:06:04,000<br>I think I don’t think you get memory allocations in this till bees would be another one you would care about right and those are all the the plan is trying to make is it gives perfect record things not that call grind can’t about why your program is slow call grind will tell you how much time you’re spending and how many times you invoked a function but it actually can’t tell you why that function is slow other than looking and looking the lines of code.</p>
<p>561<br>01:06:04,000 –&gt; 01:06:08,000<br>This will give you like the low lower things that we care about yes.</p>
<p>562<br>01:06:08,000 –&gt; 01:06:28,000<br>Yeah so this point is like yeah.</p>
<p>563<br>01:06:28,000 –&gt; 01:06:43,000<br>I know they think like this is basically this gets everything and you be too much and so his point you can basically put I don’t know if they’re like kernel programs or whatever like whatever their invocations tell per stop recording now and then when you leave the function turn it off.</p>
<p>564<br>01:06:43,000 –&gt; 01:06:57,000<br>But like just running this for everything first for like a small portion of your system will at least tell you what the high level things you want to target first and then you can then drill that into that and say why am I spending too much time which many cycles in this part.</p>
<p>565<br>01:06:57,000 –&gt; 01:07:02,000<br>Yeah.</p>
<p>566<br>01:07:02,000 –&gt; 01:07:09,000<br>Yeah.</p>
<p>567<br>01:07:09,000 –&gt; 01:07:16,000<br>Simples are separate then like compilation optimization right because again you need this.</p>
<p>568<br>01:07:16,000 –&gt; 01:07:44,000<br>So you like purple they’ll show you the lines of source code then you then get assembly view you actually then see the assembly so then you got like if you want to start a thing on what would it all three do to change my my beautiful seep a little</p>
<p>569<br>01:07:44,000 –&gt; 01:08:01,000<br>little less risk of something bizarre yeah look at the assembly there’s no other way to do it.</p>
<p>570<br>01:08:01,000 –&gt; 01:08:15,000<br>So you’re statement is there a way to prevent O3 from majorly writing your function so that you can can debug it.</p>
<p>571<br>01:08:15,000 –&gt; 01:08:24,000<br>Yeah.</p>
<p>572<br>01:08:24,000 –&gt; 01:08:31,000<br>And that case it could probably be doing the right thing.</p>
<p>573<br>01:08:31,000 –&gt; 01:08:32,000<br>Yeah.</p>
<p>574<br>01:08:32,000 –&gt; 01:08:34,000<br>We can take this online but like yeah.</p>
<p>575<br>01:08:34,000 –&gt; 01:08:38,000<br>Other questions.</p>
<p>576<br>01:08:38,000 –&gt; 01:08:39,000<br>Okay. Awesome.</p>
<p>577<br>01:08:39,000 –&gt; 01:08:40,000<br>Okay.</p>
<p>578<br>01:08:40,000 –&gt; 01:08:54,000<br>Next class presentations and then I mean I’m both of us now I’m happy to talk to you guys want and then make sure you send me the slides and your document before class starts.</p>
<p>579<br>01:08:54,000 –&gt; 01:08:55,000<br>Okay.</p>
<p>580<br>01:08:55,000 –&gt; 01:08:59,000<br>And I don’t think it should be 60 degree weather in February but enjoy it.</p>
<p>581<br>01:08:59,000 –&gt; 01:09:00,000<br>Yeah.</p>
<p>582<br>01:09:00,000 –&gt; 01:09:01,000<br>You know I’m ready.</p>
<p>583<br>01:09:01,000 –&gt; 01:09:02,000<br>Yeah.</p>
<p>584<br>01:09:02,000 –&gt; 01:09:03,000<br>Get a belt to get the 40 out of five.</p>
<p>585<br>01:09:03,000 –&gt; 01:09:06,000<br>Get a grip take a sip and you’ll be picking up bottles.</p>
<p>586<br>01:09:06,000 –&gt; 01:09:10,000<br>Ain’t ain’t no puzzle I’m just a person more man I’m telling the 40 I’m a 40 got four cans.</p>
<p>587<br>01:09:10,000 –&gt; 01:09:14,000<br>Stats and six packs on a table and I’m able to see saying I was on the label.</p>
<p>588<br>01:09:14,000 –&gt; 01:09:16,000<br>No short for the cross you know what got them.</p>
<p>589<br>01:09:16,000 –&gt; 01:09:19,000<br>I take off the cap my friends are tapped on the bottom.</p>
<p>590<br>01:09:19,000 –&gt; 01:09:21,000<br>Throw my three in the freezer so I can kill it.</p>
<p>591<br>01:09:21,000 –&gt; 01:09:22,000<br>Careful with the bottle baby.</p>
<p>592<br>01:09:22,000 –&gt; 01:09:23,000<br>Don’t spill it.</p>
<p>593<br>01:09:23,000 –&gt; 01:09:25,000<br>Go say no I can say the pain I’m wet.</p>
<p>594<br>01:09:25,000 –&gt; 01:09:27,000<br>You drink it down with the gauze little box head.</p>
<p>595<br>01:09:27,000 –&gt; 01:09:28,000<br>Take back the pack of drugs.</p>
<p>596<br>01:09:28,000 –&gt; 01:09:29,000<br>They go get you some safe now.</p>
<p>597<br>01:09:29,000 –&gt; 01:09:30,000<br>So drink it to the front.</p>
<p>598<br>01:09:30,000 –&gt; 01:09:33,000<br>Billy Dan just really takes the down with the weak guys.</p>
<p>599<br>01:09:33,000 –&gt; 01:09:34,000<br>Feel man to get a can of faith.</p>
<p>600<br>01:09:34,000 –&gt; 01:09:35,000<br>Hi.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CMU15721 P11S202410 Multi WayJoinAlgorithms⧸Worst CaseOptimalJoinsCMUAdvancedD</div>
      <div>http://example.com/2025/10/25/CMU15721 P11S202410-Multi-WayJoinAlgorithms⧸Worst-CaseOptimalJoinsCMUAdvancedD/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/25/CMU15721%20P13S202412-DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems/" title="CMU15721 P13S202412 DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CMU15721 P13S202412 DatabaseNetworkingProtocolsCMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/25/CMU15721%20P10S202409-ParallelHashJoinAlgorithmsCMUAdvancedDatabaseSystems/" title="CMU15721 P10S202409 ParallelHashJoinAlgorithmsCMUAdvancedDatabaseSystems">
                        <span class="hidden-mobile">CMU15721 P10S202409 ParallelHashJoinAlgorithmsCMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
