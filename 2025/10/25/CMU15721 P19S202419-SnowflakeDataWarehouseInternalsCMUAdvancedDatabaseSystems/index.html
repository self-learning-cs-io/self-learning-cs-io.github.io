

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:06,000Carnegie Mellon University’s Advanced Database Systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio audience. 300:00:15,000 –&gt; 00:00:18,0">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU15721 P19S202419 SnowflakeDataWarehouseInternalsCMUAdvancedDatabaseSystems">
<meta property="og:url" content="http://example.com/2025/10/25/CMU15721%20P19S202419-SnowflakeDataWarehouseInternalsCMUAdvancedDatabaseSystems/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:06,000Carnegie Mellon University’s Advanced Database Systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio audience. 300:00:15,000 –&gt; 00:00:18,0">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-25T05:03:39.751Z">
<meta property="article:modified_time" content="2025-10-25T05:03:39.751Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>CMU15721 P19S202419 SnowflakeDataWarehouseInternalsCMUAdvancedDatabaseSystems - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CMU15721 P19S202419 SnowflakeDataWarehouseInternalsCMUAdvancedDatabaseSystems"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-25 13:03" pubdate>
          2025年10月25日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          20k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          164 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CMU15721 P19S202419 SnowflakeDataWarehouseInternalsCMUAdvancedDatabaseSystems</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:06,000<br>Carnegie Mellon University’s Advanced Database Systems courses</p>
<p>2<br>00:00:06,000 –&gt; 00:00:09,000<br>filming front of the live studio audience.</p>
<p>3<br>00:00:15,000 –&gt; 00:00:18,000<br>So today, again, we’re continuing down the path of</p>
<p>4<br>00:00:18,000 –&gt; 00:00:21,000<br>discussing about real world systems that are implementing</p>
<p>5<br>00:00:21,000 –&gt; 00:00:24,000<br>the concept and ideas that we’ve talked about.</p>
<p>6<br>00:00:24,000 –&gt; 00:00:27,000<br>So before we jump into today’s lecture,</p>
<p>7<br>00:00:27,000 –&gt; 00:00:30,000<br>again, some administrators that I posted some of this on</p>
<p>8<br>00:00:30,000 –&gt; 00:00:33,000<br>Piazza, but I’m going to put it all in one place now.</p>
<p>9<br>00:00:33,000 –&gt; 00:00:36,000<br>So the final presentations for the project is going to be when we have</p>
<p>10<br>00:00:36,000 –&gt; 00:00:38,000<br>our scheduled final exam.</p>
<p>11<br>00:00:38,000 –&gt; 00:00:40,000<br>I think it’s in this room.</p>
<p>12<br>00:00:40,000 –&gt; 00:00:43,000<br>It’s scheduled to start on Thursday morning at 8.30am.</p>
<p>13<br>00:00:43,000 –&gt; 00:00:45,000<br>That’s f***ing we’re not doing that.</p>
<p>14<br>00:00:45,000 –&gt; 00:00:50,000<br>Let’s start at 9am and we’ll do donuts and bagels.</p>
<p>15<br>00:00:50,000 –&gt; 00:00:52,000<br>We can decide what we want to do.</p>
<p>16<br>00:00:52,000 –&gt; 00:00:55,000<br>And then the written final exam, that will be given out</p>
<p>17<br>00:00:55,000 –&gt; 00:00:58,000<br>on April 24th, which I think is next week, next Wednesday.</p>
<p>18<br>00:00:58,000 –&gt; 00:01:06,000<br>Again, that’ll be a prompt to asking you a question about the</p>
<p>19<br>00:01:06,000 –&gt; 00:01:09,000<br>treason encompass all the ideas that we’ve talked about</p>
<p>20<br>00:01:09,000 –&gt; 00:01:10,000<br>throughout the entire semester.</p>
<p>21<br>00:01:10,000 –&gt; 00:01:12,000<br>So it’s not like multiple choice questions like,</p>
<p>22<br>00:01:12,000 –&gt; 00:01:13,000<br>what does this paper say?</p>
<p>23<br>00:01:13,000 –&gt; 00:01:14,000<br>What does that paper say?</p>
<p>24<br>00:01:14,000 –&gt; 00:01:15,000<br>Because that’s f***ing you.</p>
<p>25<br>00:01:15,000 –&gt; 00:01:16,000<br>You can go figure that stuff out.</p>
<p>26<br>00:01:16,000 –&gt; 00:01:20,000<br>It’s more about synthesizing the ideas, again, that we’ve evolved</p>
<p>27<br>00:01:20,000 –&gt; 00:01:23,000<br>the various things we’ve talked about and applying it to a new</p>
<p>28<br>00:01:23,000 –&gt; 00:01:24,000<br>situation.</p>
<p>29<br>00:01:24,000 –&gt; 00:01:27,000<br>Which is again, the main thing you want to get away, get out of this</p>
<p>30<br>00:01:27,000 –&gt; 00:01:30,000<br>course, in addition to all development stuff you guys doing for the</p>
<p>31<br>00:01:30,000 –&gt; 00:01:33,000<br>project, you can how to take all these ideas and see how they fit</p>
<p>32<br>00:01:33,000 –&gt; 00:01:37,000<br>into the bigger picture of some data processing or data</p>
<p>33<br>00:01:37,000 –&gt; 00:01:38,000<br>system.</p>
<p>34<br>00:01:38,000 –&gt; 00:01:40,000<br>Okay?</p>
<p>35<br>00:01:40,000 –&gt; 00:01:43,000<br>And again, that’ll be due when we, the same day we have the final</p>
<p>36<br>00:01:43,000 –&gt; 00:01:45,000<br>exam, you just show up and hand it to me.</p>
<p>37<br>00:01:45,000 –&gt; 00:01:48,000<br>And then we’ll do what we did a lot last year.</p>
<p>38<br>00:01:48,000 –&gt; 00:01:51,000<br>You can use that TPP to help you answer the question.</p>
<p>39<br>00:01:51,000 –&gt; 00:01:54,000<br>But obviously, if you’re stupid and copy the prompt, you know,</p>
<p>40<br>00:01:54,000 –&gt; 00:01:58,000<br>copy the output and put it right into your response without</p>
<p>41<br>00:01:58,000 –&gt; 00:02:00,000<br>checking it, you’re going to cause problems.</p>
<p>42<br>00:02:00,000 –&gt; 00:02:01,000<br>This will be problems.</p>
<p>43<br>00:02:01,000 –&gt; 00:02:03,000<br>At least last year when we put the question in, it said,</p>
<p>44<br>00:02:03,000 –&gt; 00:02:05,000<br>I invented stuff which is not true.</p>
<p>45<br>00:02:05,000 –&gt; 00:02:07,000<br>I’m sure you’re not true.</p>
<p>46<br>00:02:07,000 –&gt; 00:02:09,000<br>So be mindful of that.</p>
<p>47<br>00:02:09,000 –&gt; 00:02:10,000<br>Okay?</p>
<p>48<br>00:02:10,000 –&gt; 00:02:14,000<br>And then we’ll also do what we did last year is you can, again,</p>
<p>49<br>00:02:14,000 –&gt; 00:02:17,000<br>you won’t, you’re not penalized for this, you should have to</p>
<p>50<br>00:02:17,000 –&gt; 00:02:18,000<br>do that.</p>
<p>51<br>00:02:18,000 –&gt; 00:02:19,000<br>Because why wouldn’t you?</p>
<p>52<br>00:02:19,000 –&gt; 00:02:22,000<br>And it’s the way things are going.</p>
<p>53<br>00:02:22,000 –&gt; 00:02:27,000<br>But we’ll do a, William will set up a, a, a, a Google</p>
<p>54<br>00:02:27,000 –&gt; 00:02:30,000<br>form that I can’t see and you just tell us whether you use</p>
<p>55<br>00:02:30,000 –&gt; 00:02:32,000<br>chat GPD or not and then I’ll try to predict whether you did</p>
<p>56<br>00:02:32,000 –&gt; 00:02:33,000<br>it or not.</p>
<p>57<br>00:02:33,000 –&gt; 00:02:34,000<br>Okay?</p>
<p>58<br>00:02:34,000 –&gt; 00:02:35,000<br>Wow, that’s fun.</p>
<p>59<br>00:02:35,000 –&gt; 00:02:36,000<br>Okay?</p>
<p>60<br>00:02:36,000 –&gt; 00:02:37,000<br>Any questions?</p>
<p>61<br>00:02:37,000 –&gt; 00:02:40,000<br>Okay.</p>
<p>62<br>00:02:40,000 –&gt; 00:02:45,000<br>So, do you know what’s s*** is?</p>
<p>63<br>00:02:46,000 –&gt; 00:02:48,000<br>You ever heard a s*** struggling language?</p>
<p>64<br>00:02:48,000 –&gt; 00:02:49,000<br>Okay.</p>
<p>65<br>00:02:49,000 –&gt; 00:02:50,000<br>All right.</p>
<p>66<br>00:02:50,000 –&gt; 00:02:52,000<br>Let’s check in.</p>
<p>67<br>00:02:52,000 –&gt; 00:02:53,000<br>All right.</p>
<p>68<br>00:02:53,000 –&gt; 00:02:55,000<br>I’ll explain afterwards.</p>
<p>69<br>00:02:55,000 –&gt; 00:02:56,000<br>All right.</p>
<p>70<br>00:02:56,000 –&gt; 00:02:58,000<br>So again, last class we were talking about Databricks for</p>
<p>71<br>00:02:58,000 –&gt; 00:02:59,000<br>Oton.</p>
<p>72<br>00:02:59,000 –&gt; 00:03:00,000<br>Again, that wasn’t a full-fledged system.</p>
<p>73<br>00:03:00,000 –&gt; 00:03:03,000<br>That was an extension library that you would add that they,</p>
<p>74<br>00:03:03,000 –&gt; 00:03:06,000<br>that the Databricks people added into Spark that the,</p>
<p>75<br>00:03:06,000 –&gt; 00:03:09,000<br>the Java code running Spark SQL would then invoke through</p>
<p>76<br>00:03:09,000 –&gt; 00:03:14,000<br>J&amp;I and that was a C++ extra, C++ vectorized engine.</p>
<p>77<br>00:03:14,000 –&gt; 00:03:17,000<br>That would try to offload the competition expensive tasks in</p>
<p>78<br>00:03:17,000 –&gt; 00:03:20,000<br>when you’re running a query in Spark SQL and push that it down to</p>
<p>79<br>00:03:20,000 –&gt; 00:03:23,000<br>C++ and they showed pretty significant performance gains.</p>
<p>80<br>00:03:23,000 –&gt; 00:03:26,000<br>So today again, when we talk about snowflake and, um,</p>
<p>81<br>00:03:26,000 –&gt; 00:03:29,000<br>and we’ll see this also in redshift, you know, these are going to be,</p>
<p>82<br>00:03:29,000 –&gt; 00:03:32,000<br>you know, full-fledged systems that are going to look and smell</p>
<p>83<br>00:03:32,000 –&gt; 00:03:34,000<br>a lot like a Dremel and other systems we’ve talked about throughout</p>
<p>84<br>00:03:34,000 –&gt; 00:03:38,000<br>the entire semester and yellow brick as well.</p>
<p>85<br>00:03:38,000 –&gt; 00:03:39,000<br>All right.</p>
<p>86<br>00:03:39,000 –&gt; 00:03:42,000<br>So, just like before, before we jump into snowflake,</p>
<p>87<br>00:03:42,000 –&gt; 00:03:45,000<br>uh, it’s important to sort of, again, to take a step back and</p>
<p>88<br>00:03:45,000 –&gt; 00:03:48,000<br>understand what the, what the, sort of, the landscape and the database</p>
<p>89<br>00:03:48,000 –&gt; 00:03:52,000<br>will look like at the time that snowflake came on the scene.</p>
<p>90<br>00:03:52,000 –&gt; 00:03:55,000<br>Um, and a lot of this, she gives repeating the things that we talked</p>
<p>91<br>00:03:55,000 –&gt; 00:03:57,000<br>about throughout the entire semester.</p>
<p>92<br>00:03:57,000 –&gt; 00:04:00,000<br>Um, so again, the, in the 2000s, that’s when we saw the,</p>
<p>93<br>00:04:00,000 –&gt; 00:04:04,000<br>the, these, these special purpose of specialized O-Lap systems</p>
<p>94<br>00:04:04,000 –&gt; 00:04:07,000<br>that were built just around O-Lap, kind of O-Lap queries,</p>
<p>95<br>00:04:07,000 –&gt; 00:04:09,000<br>we talked about in the entire semester, that they sort of came on the</p>
<p>96<br>00:04:09,000 –&gt; 00:04:12,000<br>scene, uh, and for the most part, a lot of them were pushing this idea</p>
<p>97<br>00:04:12,000 –&gt; 00:04:14,000<br>of, of a column store.</p>
<p>98<br>00:04:14,000 –&gt; 00:04:18,000<br>Uh, it’s a little before, I mean, vector wise came along in the</p>
<p>99<br>00:04:18,000 –&gt; 00:04:21,000<br>later 2010s, but, you know, everyone sort of, operating column</p>
<p>100<br>00:04:21,000 –&gt; 00:04:24,000<br>stores compressed data and then vectorized showed how to do vectorized</p>
<p>101<br>00:04:24,000 –&gt; 00:04:26,000<br>processing on these things.</p>
<p>102<br>00:04:26,000 –&gt; 00:04:29,000<br>So, of all these Vertica and Green Plum are probably the two biggest</p>
<p>103<br>00:04:29,000 –&gt; 00:04:30,000<br>ones.</p>
<p>104<br>00:04:30,000 –&gt; 00:04:33,000<br>Um, Moneti, we’ve talked about, and we’ll talk about the scan amount of</p>
<p>105<br>00:04:33,000 –&gt; 00:04:34,000<br>ducty-b.</p>
<p>106<br>00:04:34,000 –&gt; 00:04:38,000<br>Right, ducty-b, the, the early version of ducty-b was Moneti-b light,</p>
<p>107<br>00:04:38,000 –&gt; 00:04:41,000<br>which is a fork of this system, and we talked a little bit about that.</p>
<p>108<br>00:04:41,000 –&gt; 00:04:43,000<br>Vector wise recovered in early semester.</p>
<p>109<br>00:04:43,000 –&gt; 00:04:46,000<br>Park cell, we’ll see again when we talk about redshift,</p>
<p>110<br>00:04:46,000 –&gt; 00:04:48,000<br>because redshift wasn’t written for that scratch on Amazon.</p>
<p>111<br>00:04:48,000 –&gt; 00:04:51,000<br>They bought a license to the park, the park cell source code.</p>
<p>112<br>00:04:51,000 –&gt; 00:04:54,000<br>Uh, and we’ll see the transition that going from a shared nothing system</p>
<p>113<br>00:04:54,000 –&gt; 00:04:58,000<br>that park cell was into, uh, into what redshift is today.</p>
<p>114<br>00:04:58,000 –&gt; 00:05:02,000<br>So, of all of these except for vector wise Moneti-b, these are all forks</p>
<p>115<br>00:05:02,000 –&gt; 00:05:04,000<br>of postgres.</p>
<p>116<br>00:05:04,000 –&gt; 00:05:07,000<br>Uh, and they’ve ripped out the, you know, the storage layer and rewrote a lot</p>
<p>117<br>00:05:07,000 –&gt; 00:05:11,000<br>of stuff to make it, you know, operate it on, uh, analytical workloads.</p>
<p>118<br>00:05:11,000 –&gt; 00:05:13,000<br>And at the same time, this is all going on.</p>
<p>119<br>00:05:13,000 –&gt; 00:05:17,000<br>Hadoop became popular, everybody was trying to shove a lot of data on</p>
<p>120<br>00:05:17,000 –&gt; 00:05:22,000<br>HDFS, and it’s data lakes before data lakes, uh, before, uh, that term came to</p>
<p>121<br>00:05:22,000 –&gt; 00:05:23,000<br>prominence.</p>
<p>122<br>00:05:23,000 –&gt; 00:05:25,000<br>Right, Hive, we talked about Presto and Paul and Stinger.</p>
<p>123<br>00:05:25,000 –&gt; 00:05:29,000<br>So actually Stinger, written, it’s basically Sting is in Paula, or actually,</p>
<p>124<br>00:05:29,000 –&gt; 00:05:31,000<br>Sting is Hive.</p>
<p>125<br>00:05:31,000 –&gt; 00:05:34,000<br>It’s Seek on top of, uh, MapReduce and Hadoop.</p>
<p>126<br>00:05:34,000 –&gt; 00:05:38,000<br>So all these systems at the time, right, in the various form, there’s</p>
<p>127<br>00:05:38,000 –&gt; 00:05:44,000<br>supporting analytical systems, but their primary, uh, uh, distribution model, like, the company,</p>
<p>128<br>00:05:44,000 –&gt; 00:05:48,000<br>the vendor selling the data system, the primary way that you got access to these</p>
<p>129<br>00:05:48,000 –&gt; 00:05:52,000<br>various data systems was by downloading it and running it on prem.</p>
<p>130<br>00:05:52,000 –&gt; 00:05:55,000<br>So meaning you would buy a license to the source code, or sorry, buy a license to, to,</p>
<p>131<br>00:05:55,000 –&gt; 00:05:59,000<br>the data system, but then you would provision the hardware and you would</p>
<p>132<br>00:05:59,000 –&gt; 00:06:03,000<br>just want to run it on your local machines, right?</p>
<p>133<br>00:06:03,000 –&gt; 00:06:07,000<br>And this, you know, pretty much how many of your RAM data systems were, for decades,</p>
<p>134<br>00:06:07,000 –&gt; 00:06:09,000<br>prior to this.</p>
<p>135<br>00:06:09,000 –&gt; 00:06:14,000<br>So as we talked about last, last week, the Dremel paper comes out in 2011, uh, and shows</p>
<p>136<br>00:06:14,000 –&gt; 00:06:19,000<br>that, okay, you know, you can build something in a cloud sort of a native environment to run on</p>
<p>137<br>00:06:19,000 –&gt; 00:06:22,000<br>a bunch of files that are sitting on these object stores, right?</p>
<p>138<br>00:06:22,000 –&gt; 00:06:26,000<br>It’s no longer native, uh, natively, the storage is no longer natively managed by the</p>
<p>139<br>00:06:26,000 –&gt; 00:06:27,000<br>database system.</p>
<p>140<br>00:06:27,000 –&gt; 00:06:30,000<br>Facebook also starts building Presto in 2012.</p>
<p>141<br>00:06:30,000 –&gt; 00:06:34,000<br>Uh, again, Park Sales, we said this will discuss this next week, we talk about Redshift,</p>
<p>142<br>00:06:34,000 –&gt; 00:06:41,000<br>but AWS buys a license to Park Sales in 2011 and then releases it in 2013 as Redshift.</p>
<p>143<br>00:06:41,000 –&gt; 00:06:47,000<br>They actually beat Snowflake to the market, uh, by a couple of months, uh, where it’s, but Snowflake,</p>
<p>144<br>00:06:47,000 –&gt; 00:06:52,000<br>so I think it was written to scratch, uh, and Redshift was, again, was, was based on Park Sales.</p>
<p>145<br>00:06:52,000 –&gt; 00:06:56,000<br>Park, I mean, I’ll cover this next week. Park Sales basically going bankrupt, and they were</p>
<p>146<br>00:06:56,000 –&gt; 00:07:00,000<br>hoping that Amazon was going to acquire them. Amazon does acquired the source of the license,</p>
<p>147<br>00:07:00,000 –&gt; 00:07:05,000<br>and I forget who, I think, actually, and bought, uh, in a blind park sale.</p>
<p>148<br>00:07:05,000 –&gt; 00:07:08,000<br>So it’s still around, but like it’s basically a zombie database.</p>
<p>149<br>00:07:08,000 –&gt; 00:07:14,000<br>So around this same time, uh, there’s a VC firm out of, uh, out of Silicon Valley,</p>
<p>150<br>00:07:14,000 –&gt; 00:07:19,000<br>it’s called Sutter Hill, um, when they, they decided to, hey, we’re going to build a new cloud</p>
<p>151<br>00:07:19,000 –&gt; 00:07:27,000<br>native database startup. Um, so they got these two guys that were, uh, you know, very prominent engineers</p>
<p>152<br>00:07:27,000 –&gt; 00:07:33,000<br>at Oracle, and then the vector wise developer, uh, from the paper you guys read, Marzen Sikowski,</p>
<p>153<br>00:07:33,000 –&gt; 00:07:37,000<br>from, you know, vector wise going under at the time. So they got him, they just got binding</p>
<p>154<br>00:07:37,000 –&gt; 00:07:42,000<br>three together, gave him a ton of money and said, go build, you know, go build a cloud-dated cloud</p>
<p>155<br>00:07:42,000 –&gt; 00:07:46,000<br>native warehouse, you know, we’ll call it Snowflake. Sutter Hill is different than most of the</p>
<p>156<br>00:07:46,000 –&gt; 00:07:50,000<br>VC firms you’ve probably been familiar with, like the, and Jason Horowitz, the Kleiner Perkins,</p>
<p>157<br>00:07:50,000 –&gt; 00:07:56,000<br>Greylock and so forth. Right? That, their models is, or like, I have an idea, and you go to them,</p>
<p>158<br>00:07:56,000 –&gt; 00:08:00,000<br>and you pitch them, and say, hey, give me money to go build a startup. Sutter Hill is basically</p>
<p>159<br>00:08:00,000 –&gt; 00:08:04,000<br>like putting together a boy band at a record label. You say, let’s get some good-looking people</p>
<p>160<br>00:08:04,000 –&gt; 00:08:07,000<br>together, get them in a room, or give them money, and then they put out the almonds, right?</p>
<p>161<br>00:08:07,000 –&gt; 00:08:11,000<br>So they’re dictating what we should build. So that, that’s how Snowflake sort of came about.</p>
<p>162<br>00:08:11,000 –&gt; 00:08:15,000<br>Um, and so again, obviously Snowflake was super successful, because here we are talking</p>
<p>163<br>00:08:15,000 –&gt; 00:08:21,000<br>about it, you know, 12 years later. So again, all these guys are super nice.</p>
<p>164<br>00:08:21,000 –&gt; 00:08:27,000<br>So, uh, Marcin is, um, it’s much younger than these two French guys here, but this is just</p>
<p>165<br>00:08:27,000 –&gt; 00:08:30,000<br>really how hardcore they are about databases. Probably just, just hardcore as I am.</p>
<p>166<br>00:08:30,000 –&gt; 00:08:36,000<br>So this is actually Marcin’s leg. Uh, he has a Snowflake tattoo after they went IPO, right?</p>
<p>167<br>00:08:36,000 –&gt; 00:08:40,000<br>That’s, that’s dedication to databases. I, I don’t even know how that form.</p>
<p>168<br>00:08:41,000 –&gt; 00:08:46,000<br>Alright, so what is Snowflake? Snowflake is going to be a managed OLAP database system written</p>
<p>169<br>00:08:46,000 –&gt; 00:08:52,000<br>into a plus that is only going to run on in the cloud. And again, like this seems obvious today,</p>
<p>170<br>00:08:52,000 –&gt; 00:08:59,000<br>but back then, 10 years ago, 12 years ago, this was, this was sort of unheard of for, for, for database systems, right?</p>
<p>171<br>00:08:59,000 –&gt; 00:09:02,000<br>And certainly, you know, the, the Snowflake guys have told me they got a lot of pressure in the early days.</p>
<p>172<br>00:09:02,000 –&gt; 00:09:07,000<br>Like, hey, we, great system, you know, can we download and run it on prem? We don’t want to run in the cloud,</p>
<p>173<br>00:09:07,000 –&gt; 00:09:12,000<br>and they, they said no. And then eventually everyone just, you know, moved to the cloud. And that’s where, you know,</p>
<p>174<br>00:09:12,000 –&gt; 00:09:18,000<br>if you’re a new database startup today and you don’t have a cloud, you know, a cloud offering with some exceptions,</p>
<p>175<br>00:09:18,000 –&gt; 00:09:23,000<br>like DuckDB, then, although we’ll see Mother Duck next class as well, like, it doesn’t, you know,</p>
<p>176<br>00:09:23,000 –&gt; 00:09:30,000<br>it’s very hard to gain traction, right? So everything’s, everything’s been written from scratch.</p>
<p>177<br>00:09:30,000 –&gt; 00:09:35,000<br>Uh, and the paper guys talk about like they were, you know, they considered like, oh, should we go tapings from like</p>
<p>178<br>00:09:35,000 –&gt; 00:09:40,000<br>a do proco, do you think they think things from postgres, like other systems that have done? And they decided that</p>
<p>179<br>00:09:40,000 –&gt; 00:09:45,000<br>in order to have complete control of everything, they wanted to write everything from scratch.</p>
<p>180<br>00:09:45,000 –&gt; 00:09:52,000<br>They’re going to be doing a shared disarchitecture as we talked about before. And then one thing that’s going to be different than we saw in Dremel,</p>
<p>181<br>00:09:52,000 –&gt; 00:09:56,000<br>and I think the photon paper doesn’t really talk about this, but Spark SQL doesn’t really do this,</p>
<p>182<br>00:09:56,000 –&gt; 00:10:01,000<br>um, is that they’re going to do aggressive compute side caching on the worker nodes themselves.</p>
<p>183<br>00:10:01,000 –&gt; 00:10:07,000<br>Right? So, since, again, they’re not the cloud vendor, it costs them real money to go get things from S3,</p>
<p>184<br>00:10:07,000 –&gt; 00:10:12,000<br>which is obviously also very slow as well. They want to do as much caching as they can on their side,</p>
<p>185<br>00:10:12,000 –&gt; 00:10:18,000<br>and it notes that they’re already paying for to avoid those, those look up suit to S3. Right?</p>
<p>186<br>00:10:18,000 –&gt; 00:10:25,000<br>Uh, the, the other interesting thing is that, rather than doing what most people do today, like taking the,</p>
<p>187<br>00:10:25,000 –&gt; 00:10:31,000<br>the postgres SQL dialect, the grammar file, and using that as the basis to start your, you know,</p>
<p>188<br>00:10:31,000 –&gt; 00:10:35,000<br>what kind of SQL you’re going to support, they wrote everything from scratch.</p>
<p>189<br>00:10:35,000 –&gt; 00:10:39,000<br>And it kind of looks, if you ever look at the documentation of Synophilic, it kind of looks a little orically orically,</p>
<p>190<br>00:10:39,000 –&gt; 00:10:45,000<br>a little enterprisey, right? And I think that’s, that’s sort of the lineage of coming from,</p>
<p>191<br>00:10:45,000 –&gt; 00:10:48,000<br>um, you know, the two wrench guys coming from Oracle.</p>
<p>192<br>00:10:48,000 –&gt; 00:10:52,000<br>So, I just, I always had to say this, obviously there’s not any impropriety,</p>
<p>193<br>00:10:52,000 –&gt; 00:10:56,000<br>but, Snowflake actually sponsored this class in 721 before they went IPO.</p>
<p>194<br>00:10:56,000 –&gt; 00:10:59,000<br>A lot of my best students went there and still worked there.</p>
<p>195<br>00:10:59,000 –&gt; 00:11:05,000<br>Um, so like a she stood literally here and presented, uh, presented the Snowflake architecture back in the day.</p>
<p>196<br>00:11:05,000 –&gt; 00:11:08,000<br>Um, so if you want, you can watch the guest lecture from, from back then.</p>
<p>197<br>00:11:08,000 –&gt; 00:11:12,000<br>Um, and last year when I was putting this, this, uh, this lecture together,</p>
<p>198<br>00:11:12,000 –&gt; 00:11:15,000<br>I had a bunch of questions like, could it, you know, it’s a close-source system,</p>
<p>199<br>00:11:15,000 –&gt; 00:11:18,000<br>you can’t always infer exactly what they’re doing based on the, the blogs and the documentation.</p>
<p>200<br>00:11:19,000 –&gt; 00:11:21,000<br>Uh, so I actually had a phone call with the C-ish.</p>
<p>201<br>00:11:21,000 –&gt; 00:11:25,000<br>This is Sunday night, but the day before the lecture, while he was like cooking in his kitchen,</p>
<p>202<br>00:11:25,000 –&gt; 00:11:27,000<br>he’s answering all my snowflake questions.</p>
<p>203<br>00:11:27,000 –&gt; 00:11:30,000<br>So, the combination of what we’re talking about today is from documentation,</p>
<p>204<br>00:11:30,000 –&gt; 00:11:33,000<br>the paper you guys read, there’s another paper as well,</p>
<p>205<br>00:11:33,000 –&gt; 00:11:37,000<br>some blog articles and then well, they’re asking a sheesh while he’s cooking spaghetti,</p>
<p>206<br>00:11:37,000 –&gt; 00:11:41,000<br>uh, what does Snowflake do? Um, these are good dude.</p>
<p>207<br>00:11:41,000 –&gt; 00:11:45,000<br>Okay, so again, here’s that high level, uh, bowl of points of all,</p>
<p>208<br>00:11:45,000 –&gt; 00:11:48,000<br>everything that we care about in Snowflake that, you know, related to other systems,</p>
<p>209<br>00:11:48,000 –&gt; 00:11:50,000<br>right? Again, not surprising.</p>
<p>210<br>00:11:50,000 –&gt; 00:11:52,000<br>Share this, just add good storage.</p>
<p>211<br>00:11:52,000 –&gt; 00:11:58,000<br>Again, they were the one of the first systems, uh, to, to, to commercialize this and pursue this.</p>
<p>212<br>00:11:58,000 –&gt; 00:12:02,000<br>But again, that’s, that’s burning off a dream all done, burning off a wood, um,</p>
<p>213<br>00:12:02,000 –&gt; 00:12:06,000<br>uh, you know, what HGFs and the dude were doing at the time.</p>
<p>214<br>00:12:06,000 –&gt; 00:12:09,000<br>They’re new push-based vectorized query processing, uh,</p>
<p>215<br>00:12:09,000 –&gt; 00:12:13,000<br>they’re relying on, uh, pre-compile primitives, similar to vector-wise X100.</p>
<p>216<br>00:12:13,000 –&gt; 00:12:15,000<br>Again, not surprising.</p>
<p>217<br>00:12:15,000 –&gt; 00:12:18,000<br>Marcin was the guy who built vector-wise.</p>
<p>218<br>00:12:18,000 –&gt; 00:12:22,000<br>Uh, they’re not going to do any cogen, except for, uh, for,</p>
<p>219<br>00:12:22,000 –&gt; 00:12:26,000<br>serializing, deserializing the moon of data from workers or the another.</p>
<p>220<br>00:12:26,000 –&gt; 00:12:29,000<br>They’re using LAM for this, it’s very limited thing like,</p>
<p>221<br>00:12:29,000 –&gt; 00:12:32,000<br>I had some, some data I need to, to serialize, to a binary format,</p>
<p>222<br>00:12:32,000 –&gt; 00:12:35,000<br>ship that over the wire, send it to another node.</p>
<p>223<br>00:12:35,000 –&gt; 00:12:37,000<br>Again, this is like 2013, 2014.</p>
<p>224<br>00:12:37,000 –&gt; 00:12:39,000<br>This is a four Apache arrow.</p>
<p>225<br>00:12:39,000 –&gt; 00:12:43,000<br>So, to make this work fast, they would, they would have this little cogen piece that could,</p>
<p>226<br>00:12:43,000 –&gt; 00:12:46,000<br>that you could compile it to send data over.</p>
<p>227<br>00:12:46,000 –&gt; 00:12:50,000<br>It’s somewhat, somewhat similar to like, what Protoboff would,</p>
<p>228<br>00:12:50,000 –&gt; 00:12:52,000<br>would actually do for you as well.</p>
<p>229<br>00:12:52,000 –&gt; 00:12:55,000<br>Uh, they’re gonna make, they’re gonna separate the table data from the met,</p>
<p>230<br>00:12:55,000 –&gt; 00:12:57,000<br>the metadata, and we’ll talk a little bit about this,</p>
<p>231<br>00:12:57,000 –&gt; 00:13:00,000<br>because that opens up some opportunities for other organizations,</p>
<p>232<br>00:13:00,000 –&gt; 00:13:04,000<br>um, and certainly different than, oh, I mean, now it’s sort of commonplace,</p>
<p>233<br>00:13:04,000 –&gt; 00:13:06,000<br>can you run something like hive catalog or whatever,</p>
<p>234<br>00:13:06,000 –&gt; 00:13:08,000<br>or Databricks says they’re a unique catalog.</p>
<p>235<br>00:13:08,000 –&gt; 00:13:11,000<br>Uh, but this is certainly different from a single node system.</p>
<p>236<br>00:13:11,000 –&gt; 00:13:14,000<br>There’s not gonna be an explicit buffer pool in every single node.</p>
<p>237<br>00:13:14,000 –&gt; 00:13:16,000<br>Uh, they’re basically have ALRU cache aside,</p>
<p>238<br>00:13:16,000 –&gt; 00:13:18,000<br>when things, move things in and out.</p>
<p>239<br>00:13:18,000 –&gt; 00:13:21,000<br>But nothing really, uh, nothing fancy.</p>
<p>240<br>00:13:21,000 –&gt; 00:13:24,000<br>Like everyone else, they can use packs, uh, clumb in our storage.</p>
<p>241<br>00:13:24,000 –&gt; 00:13:26,000<br>Because again, they started before, like,</p>
<p>242<br>00:13:26,000 –&gt; 00:13:29,000<br>Parkane or, or like, a, like a big thing,</p>
<p>243<br>00:13:29,000 –&gt; 00:13:33,000<br>that, that they are now, they’re gonna have the RIMPA Pireterage Storage format,</p>
<p>244<br>00:13:33,000 –&gt; 00:13:35,000<br>that they’ll have for, for managed data,</p>
<p>245<br>00:13:35,000 –&gt; 00:13:38,000<br>but now, since the last five years or so,</p>
<p>246<br>00:13:38,000 –&gt; 00:13:42,000<br>they’re supporting all the, the open source file formats that we’d expect.</p>
<p>247<br>00:13:42,000 –&gt; 00:13:44,000<br>I think they can use SortMars, John, but primarily,</p>
<p>248<br>00:13:44,000 –&gt; 00:13:46,000<br>most of the time they’re gonna pick cache join,</p>
<p>249<br>00:13:46,000 –&gt; 00:13:48,000<br>as we talked about, it was always me better,</p>
<p>250<br>00:13:48,000 –&gt; 00:13:50,000<br>and then they have a Cascade style query optimizer</p>
<p>251<br>00:13:50,000 –&gt; 00:13:53,000<br>that, again, tries to leverage the depth of the optimizations that we talked about before.</p>
<p>252<br>00:13:53,000 –&gt; 00:13:56,000<br>So, we’re gonna mostly focus on these things,</p>
<p>253<br>00:13:56,000 –&gt; 00:14:00,000<br>but I’ll sprinkle in discussions as we go along for, for the other topics.</p>
<p>254<br>00:14:01,000 –&gt; 00:14:04,000<br>So, the first thing is, what does the architecture look like?</p>
<p>255<br>00:14:04,000 –&gt; 00:14:07,000<br>So, they are, obviously, again, they’re gonna run on,</p>
<p>256<br>00:14:07,000 –&gt; 00:14:09,000<br>uh, to say I got into storage,</p>
<p>257<br>00:14:09,000 –&gt; 00:14:12,000<br>so this is just using an object store, uh, to leverage that.</p>
<p>258<br>00:14:12,000 –&gt; 00:14:14,000<br>And again, the paper talks about how they,</p>
<p>259<br>00:14:14,000 –&gt; 00:14:17,000<br>they made this decision early on when, when designing Snowflake,</p>
<p>260<br>00:14:17,000 –&gt; 00:14:20,000<br>should they actually spend time building the storage layer,</p>
<p>261<br>00:14:20,000 –&gt; 00:14:23,000<br>or should they just, uh, give up control and let, you know,</p>
<p>262<br>00:14:23,000 –&gt; 00:14:27,000<br>just use S3 and let Amazon, uh, handle that for them.</p>
<p>263<br>00:14:27,000 –&gt; 00:14:29,000<br>And part of that decision was, you know,</p>
<p>264<br>00:14:29,000 –&gt; 00:14:30,000<br>it’s from an engineering effort,</p>
<p>265<br>00:14:30,000 –&gt; 00:14:33,000<br>you can only do so many things when you first start building a new system.</p>
<p>266<br>00:14:33,000 –&gt; 00:14:36,000<br>They decided they would rather focus on, uh,</p>
<p>267<br>00:14:36,000 –&gt; 00:14:38,000<br>the, you know, the execution engine,</p>
<p>268<br>00:14:38,000 –&gt; 00:14:42,000<br>and leverage client-side caching, or sorry, worker-side caching,</p>
<p>269<br>00:14:42,000 –&gt; 00:14:45,000<br>or compute-side caching, to speed things up,</p>
<p>270<br>00:14:45,000 –&gt; 00:14:49,000<br>and just, you know, just let Amazon handle all the, you know,</p>
<p>271<br>00:14:49,000 –&gt; 00:14:52,000<br>the replication and storage, uh,</p>
<p>272<br>00:14:52,000 –&gt; 00:14:54,000<br>durability guarantees you would need.</p>
<p>273<br>00:14:54,000 –&gt; 00:14:56,000<br>Um, because I think that turned out to be a smart choice.</p>
<p>274<br>00:14:56,000 –&gt; 00:14:58,000<br>I think originally version, the original version,</p>
<p>275<br>00:14:58,000 –&gt; 00:15:01,000<br>the only one is S3, and now this is what all the other major cloud</p>
<p>276<br>00:15:01,000 –&gt; 00:15:03,000<br>vendors for their storage.</p>
<p>277<br>00:15:03,000 –&gt; 00:15:07,000<br>So they’re going to have this notion of, uh, yes.</p>
<p>278<br>00:15:07,000 –&gt; 00:15:10,000<br>Um, some of the, you know, they’re using Amazon</p>
<p>279<br>00:15:10,000 –&gt; 00:15:12,000<br>and all these other companies that have their own databases,</p>
<p>280<br>00:15:12,000 –&gt; 00:15:14,000<br>and would there be sort of a conflict of interest</p>
<p>281<br>00:15:14,000 –&gt; 00:15:17,000<br>like they can do something to Snowflake, right?</p>
<p>282<br>00:15:17,000 –&gt; 00:15:19,000<br>His question, the statement is, uh,</p>
<p>283<br>00:15:19,000 –&gt; 00:15:22,000<br>if you’re running on Amazon, Amazon has a competing product.</p>
<p>284<br>00:15:22,000 –&gt; 00:15:23,000<br>Yeah.</p>
<p>285<br>00:15:23,000 –&gt; 00:15:26,000<br>Like, are you, should you be afraid of Amazon,</p>
<p>286<br>00:15:26,000 –&gt; 00:15:28,000<br>like trying to like do something to screw you over?</p>
<p>287<br>00:15:28,000 –&gt; 00:15:31,000<br>It’s a big company that’s something.</p>
<p>288<br>00:15:31,000 –&gt; 00:15:33,000<br>But I mean Snowflake’s a big company too, right?</p>
<p>289<br>00:15:33,000 –&gt; 00:15:35,000<br>I think they love business from Snowflake.</p>
<p>290<br>00:15:35,000 –&gt; 00:15:41,000<br>Yeah, they make up, so, um, how to say this?</p>
<p>291<br>00:15:41,000 –&gt; 00:15:43,000<br>Think about from a publicity standpoint,</p>
<p>292<br>00:15:43,000 –&gt; 00:15:45,000<br>how terrible that would be for Amazon, be like,</p>
<p>293<br>00:15:45,000 –&gt; 00:15:48,000<br>hey, we just like screwed over our biggest competitor,</p>
<p>294<br>00:15:48,000 –&gt; 00:15:50,000<br>one of our biggest competitors, um,</p>
<p>295<br>00:15:50,000 –&gt; 00:15:52,000<br>then like that would immediately panic all the other companies</p>
<p>296<br>00:15:52,000 –&gt; 00:15:54,000<br>that are, you know, relying having an Amazon</p>
<p>297<br>00:15:54,000 –&gt; 00:15:56,000<br>and make them go elsewhere.</p>
<p>298<br>00:15:56,000 –&gt; 00:15:59,000<br>From a business standpoint, like a short-term gain,</p>
<p>299<br>00:15:59,000 –&gt; 00:16:03,000<br>short-term benefit for long-term, you know, problems,</p>
<p>300<br>00:16:03,000 –&gt; 00:16:05,000<br>it’s just not worth it.</p>
<p>301<br>00:16:05,000 –&gt; 00:16:07,000<br>Now, there are some companies we’ve talked to,</p>
<p>302<br>00:16:07,000 –&gt; 00:16:09,000<br>at least in the start-up, where like, they should have told us,</p>
<p>303<br>00:16:09,000 –&gt; 00:16:11,000<br>we don’t run on Amazon because, you know,</p>
<p>304<br>00:16:11,000 –&gt; 00:16:13,000<br>we can see, consider them a competitor,</p>
<p>305<br>00:16:13,000 –&gt; 00:16:16,000<br>and so they have to run on GCP or something else.</p>
<p>306<br>00:16:16,000 –&gt; 00:16:18,000<br>But again, Amazon’s not stupid.</p>
<p>307<br>00:16:18,000 –&gt; 00:16:21,000<br>They’re not going to let, you know, I don’t think they would,</p>
<p>308<br>00:16:21,000 –&gt; 00:16:24,000<br>I like to think they would not make decisions like that.</p>
<p>309<br>00:16:24,000 –&gt; 00:16:27,000<br>Now, so, I will say though, the way Amazon’s going to get around this,</p>
<p>310<br>00:16:27,000 –&gt; 00:16:31,000<br>so even though they may not make, um,</p>
<p>311<br>00:16:31,000 –&gt; 00:16:34,000<br>you know, they may not make S3 slower,</p>
<p>312<br>00:16:34,000 –&gt; 00:16:37,000<br>because they recognize it’s a snowflake query or something.</p>
<p>313<br>00:16:37,000 –&gt; 00:16:38,000<br>That would be terrible, right?</p>
<p>314<br>00:16:38,000 –&gt; 00:16:39,000<br>It’s not scalable.</p>
<p>315<br>00:16:39,000 –&gt; 00:16:41,000<br>Though they can do other things like,</p>
<p>316<br>00:16:41,000 –&gt; 00:16:44,000<br>not so much for, well, actually for RetroFullSeeders,</p>
<p>317<br>00:16:44,000 –&gt; 00:16:46,000<br>they can add hardware accelerators</p>
<p>318<br>00:16:46,000 –&gt; 00:16:49,000<br>and other things above S3, right?</p>
<p>319<br>00:16:49,000 –&gt; 00:16:51,000<br>That’s running on the same data center that, you know,</p>
<p>320<br>00:16:51,000 –&gt; 00:16:54,000<br>maybe snowflake can’t easily do to accelerate certain things.</p>
<p>321<br>00:16:54,000 –&gt; 00:16:56,000<br>And they do this for Aurora as well, right?</p>
<p>322<br>00:16:56,000 –&gt; 00:16:59,000<br>They push down, they have a layer above EDS</p>
<p>323<br>00:16:59,000 –&gt; 00:17:02,000<br>that does transactional, uh, transaction uppropagations</p>
<p>324<br>00:17:02,000 –&gt; 00:17:05,000<br>to replicas for, you know, post-gust in my SQL</p>
<p>325<br>00:17:05,000 –&gt; 00:17:06,000<br>and you just can’t get if you run it,</p>
<p>326<br>00:17:06,000 –&gt; 00:17:08,000<br>if you’re an external to Amazon.</p>
<p>327<br>00:17:08,000 –&gt; 00:17:12,000<br>So there’s other organizations you can do.</p>
<p>328<br>00:17:12,000 –&gt; 00:17:15,000<br>Uh, with regard to adding support for AzureStore</p>
<p>329<br>00:17:15,000 –&gt; 00:17:17,000<br>and the cost for it later, is that right?</p>
<p>330<br>00:17:17,000 –&gt; 00:17:18,000<br>Yes.</p>
<p>331<br>00:17:18,000 –&gt; 00:17:21,000<br>That something, then you’re referring to like internally</p>
<p>332<br>00:17:21,000 –&gt; 00:17:25,000<br>that we’re using S3 to store all this troll image storage</p>
<p>333<br>00:17:25,000 –&gt; 00:17:27,000<br>and then they switched over to a mix of the three</p>
<p>334<br>00:17:27,000 –&gt; 00:17:31,000<br>or you’re saying something more like they add a support</p>
<p>335<br>00:17:31,000 –&gt; 00:17:34,000<br>to actually add a support to 19 views and give views.</p>
<p>336<br>00:17:34,000 –&gt; 00:17:36,000<br>This question is like, when I say they add a support</p>
<p>337<br>00:17:36,000 –&gt; 00:17:38,000<br>for like, say Google Cloud Storage, or Azure,</p>
<p>338<br>00:17:38,000 –&gt; 00:17:42,000<br>does that mean that like, like if you’re a new customer</p>
<p>339<br>00:17:42,000 –&gt; 00:17:44,000<br>you show up and you start storing data into snowflake,</p>
<p>340<br>00:17:44,000 –&gt; 00:17:47,000<br>that little spread of the cross-different data centers?</p>
<p>341<br>00:17:47,000 –&gt; 00:17:49,000<br>No, I think you tell them when you sign up,</p>
<p>342<br>00:17:49,000 –&gt; 00:17:51,000<br>like I want to run an AWS, I want to run on this.</p>
<p>343<br>00:17:51,000 –&gt; 00:17:54,000<br>But it’s still managed to do that.</p>
<p>344<br>00:17:54,000 –&gt; 00:17:56,000<br>Who’s them?</p>
<p>345<br>00:17:56,000 –&gt; 00:17:58,000<br>So it still makes managed storage.</p>
<p>346<br>00:17:58,000 –&gt; 00:17:59,000<br>Yes.</p>
<p>347<br>00:17:59,000 –&gt; 00:18:01,000<br>So you’re just saying like, do this other one?</p>
<p>348<br>00:18:01,000 –&gt; 00:18:04,000<br>But the library here, which is to use one of the other?</p>
<p>349<br>00:18:04,000 –&gt; 00:18:06,000<br>Uh, like why would you use the other cloud vendors?</p>
<p>350<br>00:18:06,000 –&gt; 00:18:08,000<br>Yeah, there’s companies that, like,</p>
<p>351<br>00:18:08,000 –&gt; 00:18:12,000<br>we’ve talked to like a, they were a Canadian grocery store</p>
<p>352<br>00:18:12,000 –&gt; 00:18:14,000<br>but like, we see Amazon as competitive.</p>
<p>353<br>00:18:14,000 –&gt; 00:18:17,000<br>We don’t run on Amazon, we run on Google, right?</p>
<p>354<br>00:18:17,000 –&gt; 00:18:19,000<br>People have various reasons.</p>
<p>355<br>00:18:19,000 –&gt; 00:18:23,000<br>But you can’t like integrate it with existing data on an object store</p>
<p>356<br>00:18:23,000 –&gt; 00:18:25,000<br>because it’s going to manage.</p>
<p>357<br>00:18:25,000 –&gt; 00:18:26,000<br>No, we’ll get to that in a second.</p>
<p>358<br>00:18:26,000 –&gt; 00:18:28,000<br>They, in the, like, we’re leading up to it.</p>
<p>359<br>00:18:28,000 –&gt; 00:18:30,000<br>Like the original version of snowflake was like,</p>
<p>360<br>00:18:30,000 –&gt; 00:18:33,000<br>okay, we’re going to store things on S3,</p>
<p>361<br>00:18:33,000 –&gt; 00:18:36,000<br>but the data we’re storing, actually inside the buckets in S3,</p>
<p>362<br>00:18:36,000 –&gt; 00:18:38,000<br>it’s our proprietary data format.</p>
<p>363<br>00:18:38,000 –&gt; 00:18:41,000<br>Because at the time, that’s how everyone built these data warehouses.</p>
<p>364<br>00:18:41,000 –&gt; 00:18:44,000<br>Now Dremel was doing its own thing, right?</p>
<p>365<br>00:18:44,000 –&gt; 00:18:47,000<br>Uh, but, you know, it wasn’t,</p>
<p>366<br>00:18:47,000 –&gt; 00:18:50,000<br>it wasn’t until like, Parkay and other things came along.</p>
<p>367<br>00:18:50,000 –&gt; 00:18:52,000<br>People, people, people, people, people, people, oh yeah.</p>
<p>368<br>00:18:52,000 –&gt; 00:18:54,000<br>Like, I can have my disparate system generate a bunch of these files</p>
<p>369<br>00:18:54,000 –&gt; 00:18:56,000<br>and I want to be able to scan it with my database system.</p>
<p>370<br>00:18:56,000 –&gt; 00:18:59,000<br>That precipitated them having to support external tables</p>
<p>371<br>00:18:59,000 –&gt; 00:19:02,000<br>or other things to, to be able to read data from,</p>
<p>372<br>00:19:02,000 –&gt; 00:19:04,000<br>from S3 that are, you know, that, that wasn’t ingested</p>
<p>373<br>00:19:04,000 –&gt; 00:19:06,000<br>through the front of the data system.</p>
<p>374<br>00:19:06,000 –&gt; 00:19:09,000<br>Right, so it’s going to go through the same transformation as well.</p>
<p>375<br>00:19:15,000 –&gt; 00:19:17,000<br>So the question is, at this point,</p>
<p>376<br>00:19:17,000 –&gt; 00:19:20,000<br>why does snowflake not build their S3?</p>
<p>377<br>00:19:20,000 –&gt; 00:19:23,000<br>Above my pay grade, I don’t know.</p>
<p>378<br>00:19:23,000 –&gt; 00:19:24,000<br>Like,</p>
<p>379<br>00:19:24,000 –&gt; 00:19:27,000<br>Yeah, the data center is.</p>
<p>380<br>00:19:27,000 –&gt; 00:19:29,000<br>Yeah, you have to have done data centers.</p>
<p>381<br>00:19:29,000 –&gt; 00:19:31,000<br>I’ll be excessive.</p>
<p>382<br>00:19:31,000 –&gt; 00:19:32,000<br>What that?</p>
<p>383<br>00:19:32,000 –&gt; 00:19:33,000<br>And like,</p>
<p>384<br>00:19:33,000 –&gt; 00:19:34,000<br>I mean, they’re not stupid.</p>
<p>385<br>00:19:34,000 –&gt; 00:19:36,000<br>I guarantee they did the back of the envelope calculations.</p>
<p>386<br>00:19:36,000 –&gt; 00:19:39,000<br>Like, does this actually make sense or not, right?</p>
<p>387<br>00:19:39,000 –&gt; 00:19:41,000<br>I think next Netflix did something similar.</p>
<p>388<br>00:19:41,000 –&gt; 00:19:43,000<br>They realized that like,</p>
<p>389<br>00:19:43,000 –&gt; 00:19:45,000<br>I think they were running on-prem and then they went,</p>
<p>390<br>00:19:45,000 –&gt; 00:19:46,000<br>they switched to the data centers.</p>
<p>391<br>00:19:46,000 –&gt; 00:19:48,000<br>Like, the big company is always trying to figure out,</p>
<p>392<br>00:19:48,000 –&gt; 00:19:49,000<br>is it cheaper to do this?</p>
<p>393<br>00:19:49,000 –&gt; 00:19:51,000<br>But think of it, if you’re like snowflakes,</p>
<p>394<br>00:19:51,000 –&gt; 00:19:52,000<br>snowflakes is a huge company, right?</p>
<p>395<br>00:19:52,000 –&gt; 00:19:53,000<br>But it’s not as big as Amazon.</p>
<p>396<br>00:19:53,000 –&gt; 00:19:56,000<br>And how many data centers is snowflake building?</p>
<p>397<br>00:19:56,000 –&gt; 00:19:58,000<br>One a year maybe, I don’t know.</p>
<p>398<br>00:19:58,000 –&gt; 00:20:02,000<br>Amazon’s probably spinning up a new one, like every, every few months.</p>
<p>399<br>00:20:02,000 –&gt; 00:20:07,000<br>Right? So, at economies of scale, they can just do way more efficiently than anyone else.</p>
<p>400<br>00:20:07,000 –&gt; 00:20:10,000<br>So, the interesting data between the two virtual warehouses,</p>
<p>401<br>00:20:10,000 –&gt; 00:20:12,000<br>is that being sent to,</p>
<p>402<br>00:20:12,000 –&gt; 00:20:14,000<br>I know there’s no in-memory in-memory shopper.</p>
<p>403<br>00:20:14,000 –&gt; 00:20:17,000<br>Is the reason for that, that they don’t have control over,</p>
<p>404<br>00:20:17,000 –&gt; 00:20:19,000<br>they can’t have the app, the hardware accelerator,</p>
<p>405<br>00:20:19,000 –&gt; 00:20:20,000<br>and so they’ll say,</p>
<p>406<br>00:20:20,000 –&gt; 00:20:22,000<br>hey, they’re all needs to do instances.</p>
<p>407<br>00:20:22,000 –&gt; 00:20:25,000<br>Might work even memory in the shared data.</p>
<p>408<br>00:20:25,000 –&gt; 00:20:26,000<br>The question is,</p>
<p>409<br>00:20:26,000 –&gt; 00:20:27,000<br>I mean, we haven’t got there yet.</p>
<p>410<br>00:20:27,000 –&gt; 00:20:28,000<br>The question is,</p>
<p>411<br>00:20:28,000 –&gt; 00:20:30,000<br>why are they going to allow worker nodes to talk to each other,</p>
<p>412<br>00:20:30,000 –&gt; 00:20:31,000<br>rather than going through their shopper phase?</p>
<p>413<br>00:20:31,000 –&gt; 00:20:32,000<br>Yeah.</p>
<p>414<br>00:20:32,000 –&gt; 00:20:39,000<br>I think it’s just from a,</p>
<p>415<br>00:20:39,000 –&gt; 00:20:41,000<br>it’s just a philosophical decision that, like,</p>
<p>416<br>00:20:41,000 –&gt; 00:20:43,000<br>that’s how they want to build it.</p>
<p>417<br>00:20:43,000 –&gt; 00:20:44,000<br>Right?</p>
<p>418<br>00:20:44,000 –&gt; 00:20:47,000<br>It’s, there’s pros and cons of both of them.</p>
<p>419<br>00:20:47,000 –&gt; 00:20:48,000<br>Right?</p>
<p>420<br>00:20:48,000 –&gt; 00:20:49,000<br>And actually, this is a good discussion.</p>
<p>421<br>00:20:49,000 –&gt; 00:20:50,000<br>We can have this now.</p>
<p>422<br>00:20:50,000 –&gt; 00:20:51,000<br>Like, you know, the shopper phase, it’s nice,</p>
<p>423<br>00:20:51,000 –&gt; 00:20:54,000<br>because here’s this abstraction layer that I can just write things too.</p>
<p>424<br>00:20:54,000 –&gt; 00:20:58,000<br>You know, it has some fault tolerant guarantees that they’re not going to be able to do.</p>
<p>425<br>00:20:58,000 –&gt; 00:20:59,000<br>Right.</p>
<p>426<br>00:20:59,000 –&gt; 00:21:02,000<br>So, that’s why I think it’s not going to be able to do that.</p>
<p>427<br>00:21:02,000 –&gt; 00:21:05,000<br>But now there’s a whole other service I got to run with additional nodes,</p>
<p>428<br>00:21:05,000 –&gt; 00:21:08,000<br>and essentially now making another copy of data.</p>
<p>429<br>00:21:08,000 –&gt; 00:21:09,000<br>Right?</p>
<p>430<br>00:21:09,000 –&gt; 00:21:10,000<br>So there’s pros and cons,</p>
<p>431<br>00:21:10,000 –&gt; 00:21:11,000<br>there’s no free lunch.</p>
<p>432<br>00:21:11,000 –&gt; 00:21:12,000<br>That’s why I know, like,</p>
<p>433<br>00:21:12,000 –&gt; 00:21:14,000<br>obviously it’s no place only around the top.</p>
<p>434<br>00:21:14,000 –&gt; 00:21:16,000<br>But there’s companies up there that actually also want,</p>
<p>435<br>00:21:16,000 –&gt; 00:21:18,000<br>maybe have some database on-prem,</p>
<p>436<br>00:21:18,000 –&gt; 00:21:21,000<br>or maybe move workloads between the cloud and on-prem.</p>
<p>437<br>00:21:21,000 –&gt; 00:21:23,000<br>Is there a big market to prevent,</p>
<p>438<br>00:21:23,000 –&gt; 00:21:25,000<br>or is it just every cloud to change?</p>
<p>439<br>00:21:25,000 –&gt; 00:21:27,000<br>I mean, this is not exactly the same as like,</p>
<p>440<br>00:21:27,000 –&gt; 00:21:30,000<br>this is a big market where people are running on-prem databases.</p>
<p>441<br>00:21:30,000 –&gt; 00:21:31,000<br>Yes.</p>
<p>442<br>00:21:33,000 –&gt; 00:21:34,000<br>But like,</p>
<p>443<br>00:21:35,000 –&gt; 00:21:37,000<br>the sales cycle is for those things,</p>
<p>444<br>00:21:37,000 –&gt; 00:21:38,000<br>which is way different.</p>
<p>445<br>00:21:38,000 –&gt; 00:21:41,000<br>Because you’ve got to, like, you know, go out and have, like,</p>
<p>446<br>00:21:41,000 –&gt; 00:21:43,000<br>go fly out there and talk to the customer,</p>
<p>447<br>00:21:43,000 –&gt; 00:21:45,000<br>like, you know, take them out to dinner,</p>
<p>448<br>00:21:45,000 –&gt; 00:21:47,000<br>and that kind of crap, go golfing, you know,</p>
<p>449<br>00:21:47,000 –&gt; 00:21:49,000<br>like, f***ing things in the 80s.</p>
<p>450<br>00:21:49,000 –&gt; 00:21:50,000<br>Whereas, like, snowflake,</p>
<p>451<br>00:21:50,000 –&gt; 00:21:51,000<br>and the data service model, like,</p>
<p>452<br>00:21:51,000 –&gt; 00:21:52,000<br>hey, here’s our website,</p>
<p>453<br>00:21:52,000 –&gt; 00:21:55,000<br>gives you credit card and you’re up and running.</p>
<p>454<br>00:21:55,000 –&gt; 00:21:56,000<br>Right?</p>
<p>455<br>00:21:56,000 –&gt; 00:21:58,000<br>So again, like, for small startups,</p>
<p>456<br>00:21:58,000 –&gt; 00:21:59,000<br>sure, you can do that.</p>
<p>457<br>00:21:59,000 –&gt; 00:22:00,000<br>But like, yeah, obviously, no banks can be like,</p>
<p>458<br>00:22:00,000 –&gt; 00:22:02,000<br>oh, here’s the credit card, just do it.</p>
<p>459<br>00:22:02,000 –&gt; 00:22:05,000<br>Yeah, no, there is a huge market.</p>
<p>460<br>00:22:05,000 –&gt; 00:22:06,000<br>I think that,</p>
<p>461<br>00:22:09,000 –&gt; 00:22:11,000<br>I mean, just, there’s everybody,</p>
<p>462<br>00:22:12,000 –&gt; 00:22:15,000<br>I think the market of people going to the cloud</p>
<p>463<br>00:22:15,000 –&gt; 00:22:17,000<br>is that percentage,</p>
<p>464<br>00:22:17,000 –&gt; 00:22:19,000<br>that pie is growing at a martial-ledger rate</p>
<p>465<br>00:22:19,000 –&gt; 00:22:21,000<br>than people spinning up stuff on-prem.</p>
<p>466<br>00:22:23,000 –&gt; 00:22:25,000<br>Again, it’s not just from terms of, like,</p>
<p>467<br>00:22:25,000 –&gt; 00:22:27,000<br>don’t think of this, like, the cost of, like,</p>
<p>468<br>00:22:27,000 –&gt; 00:22:29,000<br>oh, if I ran it on-prem,</p>
<p>469<br>00:22:29,000 –&gt; 00:22:31,000<br>I certainly can run it cheaper than what Amazon</p>
<p>470<br>00:22:31,000 –&gt; 00:22:33,000<br>would charge me for machines, right?</p>
<p>471<br>00:22:33,000 –&gt; 00:22:35,000<br>But then, like, then you’ve got to pay for humans</p>
<p>472<br>00:22:35,000 –&gt; 00:22:37,000<br>to go actually and manage those things.</p>
<p>473<br>00:22:37,000 –&gt; 00:22:39,000<br>So there’s, like, pros and cons of all these.</p>
<p>474<br>00:22:39,000 –&gt; 00:22:40,000<br>All right.</p>
<p>475<br>00:22:42,000 –&gt; 00:22:43,000<br>Okay, so,</p>
<p>476<br>00:22:44,000 –&gt; 00:22:46,000<br>right, so the abstraction, they’re going to have data storage,</p>
<p>477<br>00:22:46,000 –&gt; 00:22:49,000<br>they’re going to have this notion of a virtual warehouse.</p>
<p>478<br>00:22:49,000 –&gt; 00:22:52,000<br>Again, this is how they first designed it,</p>
<p>479<br>00:22:52,000 –&gt; 00:22:55,000<br>where you basically say, I want to,</p>
<p>480<br>00:22:55,000 –&gt; 00:22:57,000<br>you don’t say exactly on our node,</p>
<p>481<br>00:22:57,000 –&gt; 00:22:59,000<br>say I want to do this compute capacity,</p>
<p>482<br>00:22:59,000 –&gt; 00:23:01,000<br>you say, here’s some virtual data warehouse</p>
<p>483<br>00:23:01,000 –&gt; 00:23:03,000<br>that I can have, give me an endpoint</p>
<p>484<br>00:23:03,000 –&gt; 00:23:05,000<br>where I can start sending data into and run queries on.</p>
<p>485<br>00:23:05,000 –&gt; 00:23:06,000<br>Right?</p>
<p>486<br>00:23:06,000 –&gt; 00:23:09,000<br>They then, and so when you turn on a virtual data warehouse,</p>
<p>487<br>00:23:09,000 –&gt; 00:23:11,000<br>whether or not you’re running queries,</p>
<p>488<br>00:23:11,000 –&gt; 00:23:13,000<br>you’re always paying for it. Right?</p>
<p>489<br>00:23:13,000 –&gt; 00:23:15,000<br>And we’ll see how, to know if they could leverage that</p>
<p>490<br>00:23:15,000 –&gt; 00:23:16,000<br>when they do the flexible compute,</p>
<p>491<br>00:23:16,000 –&gt; 00:23:19,000<br>because they can steal all your cycles from these warehouses.</p>
<p>492<br>00:23:20,000 –&gt; 00:23:22,000<br>In 2022, they added support for serverless deployments.</p>
<p>493<br>00:23:22,000 –&gt; 00:23:25,000<br>So now basically the virtual data warehouse spins itself down</p>
<p>494<br>00:23:25,000 –&gt; 00:23:27,000<br>if you’re not running any queries,</p>
<p>495<br>00:23:27,000 –&gt; 00:23:29,000<br>but obviously they charge a premium for that.</p>
<p>496<br>00:23:29,000 –&gt; 00:23:31,000<br>Because now you’re using more shared infrastructure</p>
<p>497<br>00:23:31,000 –&gt; 00:23:35,000<br>at the cloud service’s layer instead of spinning that up yourself.</p>
<p>498<br>00:23:35,000 –&gt; 00:23:38,000<br>And then the cloud service’s layer is just the catch-all phrase</p>
<p>499<br>00:23:38,000 –&gt; 00:23:42,000<br>for the front end of the system that encompasses all the things</p>
<p>500<br>00:23:42,000 –&gt; 00:23:44,000<br>that we’ve been talking about in the entire semester.</p>
<p>501<br>00:23:44,000 –&gt; 00:23:46,000<br>Some coordinator, scheduler, the catalog, the query optimizer,</p>
<p>502<br>00:23:47,000 –&gt; 00:23:49,000<br>all that is the entry point for queries.</p>
<p>503<br>00:23:49,000 –&gt; 00:23:52,000<br>And let’s see at the end of the semester, or sorry, in the class,</p>
<p>504<br>00:23:52,000 –&gt; 00:23:55,000<br>the catalog is interesting because they’re going to be built</p>
<p>505<br>00:23:55,000 –&gt; 00:23:57,000<br>on another data system called FoundationDB</p>
<p>506<br>00:23:57,000 –&gt; 00:24:01,000<br>that provides them transaction semantics for doing updates.</p>
<p>507<br>00:24:04,000 –&gt; 00:24:07,000<br>All right, so now within a, at the compute layer,</p>
<p>508<br>00:24:07,000 –&gt; 00:24:10,000<br>they have a notion of team, a worker node, and a worker process.</p>
<p>509<br>00:24:10,000 –&gt; 00:24:13,000<br>And again, this is from 2012, 2013,</p>
<p>510<br>00:24:14,000 –&gt; 00:24:17,000<br>so a worker node, at least in the original version,</p>
<p>511<br>00:24:17,000 –&gt; 00:24:19,000<br>is just an EC2 instance.</p>
<p>512<br>00:24:19,000 –&gt; 00:24:20,000<br>Right?</p>
<p>513<br>00:24:20,000 –&gt; 00:24:22,000<br>This is for Docker, this is for Kubernetes.</p>
<p>514<br>00:24:22,000 –&gt; 00:24:25,000<br>Docker is 2012, Kubernetes is 2014,</p>
<p>515<br>00:24:25,000 –&gt; 00:24:30,000<br>but in 2012, you know, you had all EC2 instances.</p>
<p>516<br>00:24:30,000 –&gt; 00:24:33,000<br>And so on that instance, this is where they’re going to maintain</p>
<p>517<br>00:24:33,000 –&gt; 00:24:38,000<br>the local cache on the attached storage device of that instance.</p>
<p>518<br>00:24:38,000 –&gt; 00:24:40,000<br>So not reading and writing to EBS,</p>
<p>519<br>00:24:41,000 –&gt; 00:24:44,000<br>it’s always running on a local, or now the local SSD.</p>
<p>520<br>00:24:44,000 –&gt; 00:24:45,000<br>Right?</p>
<p>521<br>00:24:46,000 –&gt; 00:24:49,000<br>And this cache is going to be a combination of</p>
<p>522<br>00:24:49,000 –&gt; 00:24:53,000<br>intermediate results that you’re generating for a query-wise running,</p>
<p>523<br>00:24:53,000 –&gt; 00:24:56,000<br>as well as some of the persistent files that you may be retrieving from S3.</p>
<p>524<br>00:24:57,000 –&gt; 00:24:59,000<br>So the idea is that if another query shows up,</p>
<p>525<br>00:24:59,000 –&gt; 00:25:01,000<br>it reads the same data that you just read from S3,</p>
<p>526<br>00:25:01,000 –&gt; 00:25:03,000<br>I can read it from my local cache,</p>
<p>527<br>00:25:03,000 –&gt; 00:25:06,000<br>which would be faster and cheaper than having to go</p>
<p>528<br>00:25:07,000 –&gt; 00:25:11,000<br>to a round trip lookup on over S3 or whatever the object store is.</p>
<p>529<br>00:25:11,000 –&gt; 00:25:12,000<br>Right?</p>
<p>530<br>00:25:12,000 –&gt; 00:25:14,000<br>Again, we’ll see this in a second.</p>
<p>531<br>00:25:14,000 –&gt; 00:25:15,000<br>The way they’re going to manage this,</p>
<p>532<br>00:25:15,000 –&gt; 00:25:16,000<br>keep this everything consistent,</p>
<p>533<br>00:25:16,000 –&gt; 00:25:19,000<br>or keep spread data out evenly,</p>
<p>534<br>00:25:19,000 –&gt; 00:25:21,000<br>and be able to scale up and scale down</p>
<p>535<br>00:25:21,000 –&gt; 00:25:25,000<br>without having to reshuffle everything as you would in a shared nothing architecture,</p>
<p>536<br>00:25:25,000 –&gt; 00:25:27,000<br>is that they’re going to rely on consistent hash,</p>
<p>537<br>00:25:27,000 –&gt; 00:25:30,000<br>and to keep track of what worker node is responsible for,</p>
<p>538<br>00:25:30,000 –&gt; 00:25:34,000<br>what persistent data on in their own cache.</p>
<p>539<br>00:25:36,000 –&gt; 00:25:39,000<br>And then within the worker node, when a query shows up,</p>
<p>540<br>00:25:39,000 –&gt; 00:25:42,000<br>the fire off a whole new worker process,</p>
<p>541<br>00:25:42,000 –&gt; 00:25:46,000<br>literally like a spawn of a new process in the OS,</p>
<p>542<br>00:25:46,000 –&gt; 00:25:50,000<br>and that’s going to be executing whatever the task are for this query,</p>
<p>543<br>00:25:50,000 –&gt; 00:25:54,000<br>and it can read write data to inmate results and other workers</p>
<p>544<br>00:25:54,000 –&gt; 00:25:56,000<br>or out the S3,</p>
<p>545<br>00:25:56,000 –&gt; 00:26:00,000<br>and then when the query is done, the process ends and goes away.</p>
<p>546<br>00:26:01,000 –&gt; 00:26:02,000<br>Yes?</p>
<p>547<br>00:26:02,000 –&gt; 00:26:04,000<br>It’s like a tangential question,</p>
<p>548<br>00:26:04,000 –&gt; 00:26:07,000<br>but you can have the EBS volume as the root device.</p>
<p>549<br>00:26:07,000 –&gt; 00:26:09,000<br>So is that not like a low-oh,</p>
<p>550<br>00:26:09,000 –&gt; 00:26:11,000<br>you mean the low-oh-reconnected?</p>
<p>551<br>00:26:11,000 –&gt; 00:26:13,000<br>This question is, on ECT,</p>
<p>552<br>00:26:13,000 –&gt; 00:26:15,000<br>you can have an EBS volume mounted as the root device.</p>
<p>553<br>00:26:15,000 –&gt; 00:26:16,000<br>Yes, you have to, anyway,</p>
<p>554<br>00:26:16,000 –&gt; 00:26:18,000<br>because if the AMI image has to spin up,</p>
<p>555<br>00:26:18,000 –&gt; 00:26:21,000<br>but you still kind of locally attached SSD,</p>
<p>556<br>00:26:21,000 –&gt; 00:26:23,000<br>that you can then use NVMe or whatever,</p>
<p>557<br>00:26:23,000 –&gt; 00:26:25,000<br>2012 before that,</p>
<p>558<br>00:26:25,000 –&gt; 00:26:26,000<br>that you can then read right locally.</p>
<p>559<br>00:26:26,000 –&gt; 00:26:29,000<br>That’s just another mountain of file system.</p>
<p>560<br>00:26:29,000 –&gt; 00:26:31,000<br>And that’s going to be way faster than EBS.</p>
<p>561<br>00:26:34,000 –&gt; 00:26:35,000<br>Okay.</p>
<p>562<br>00:26:36,000 –&gt; 00:26:40,000<br>Actually, so I don’t know whether they’ve switched over to Kubernetes now.</p>
<p>563<br>00:26:40,000 –&gt; 00:26:43,000<br>We’ll see it in, we’ll tell you what, yellow brick, the paper,</p>
<p>564<br>00:26:43,000 –&gt; 00:26:44,000<br>they’re all in on Kubernetes,</p>
<p>565<br>00:26:44,000 –&gt; 00:26:47,000<br>and they make a big deal about how they’re designed to run in the,</p>
<p>566<br>00:26:47,000 –&gt; 00:26:52,000<br>in the sort of the Kubernetes infrastructure.</p>
<p>567<br>00:26:52,000 –&gt; 00:26:54,000<br>I assume, now, they’re not dumb,</p>
<p>568<br>00:26:54,000 –&gt; 00:26:56,000<br>they’re doing something very similar these days.</p>
<p>569<br>00:26:56,000 –&gt; 00:26:58,000<br>Whether it’s exactly Kubernetes or something else.</p>
<p>570<br>00:26:59,000 –&gt; 00:27:01,000<br>It doesn’t matter.</p>
<p>571<br>00:27:02,000 –&gt; 00:27:03,000<br>All right.</p>
<p>572<br>00:27:03,000 –&gt; 00:27:05,000<br>So when it actually starts running,</p>
<p>573<br>00:27:05,000 –&gt; 00:27:07,000<br>they’re going to be doing a push-based vectorized execution,</p>
<p>574<br>00:27:07,000 –&gt; 00:27:09,000<br>again, using the pre-compiled primitives,</p>
<p>575<br>00:27:09,000 –&gt; 00:27:11,000<br>with template and C++,</p>
<p>576<br>00:27:11,000 –&gt; 00:27:13,000<br>based on the different data types that we’ve talked about.</p>
<p>577<br>00:27:13,000 –&gt; 00:27:15,000<br>We’ve already mentioned that they’re only doing code gen</p>
<p>578<br>00:27:15,000 –&gt; 00:27:17,000<br>for when they serialized, and de-serialized data,</p>
<p>579<br>00:27:17,000 –&gt; 00:27:19,000<br>going from one worker node to another.</p>
<p>580<br>00:27:19,000 –&gt; 00:27:21,000<br>And as he mentioned,</p>
<p>581<br>00:27:21,000 –&gt; 00:27:24,000<br>they’re not going to do explicit shuffle between stages,</p>
<p>582<br>00:27:24,000 –&gt; 00:27:26,000<br>and instead, the worker processes are going to be allowed</p>
<p>583<br>00:27:26,000 –&gt; 00:27:28,000<br>to send data directly to,</p>
<p>584<br>00:27:28,000 –&gt; 00:27:30,000<br>push the data directly to the next node,</p>
<p>585<br>00:27:30,000 –&gt; 00:27:32,000<br>who’s going to process it,</p>
<p>586<br>00:27:32,000 –&gt; 00:27:34,000<br>or they keep it locally and keep processing it,</p>
<p>587<br>00:27:34,000 –&gt; 00:27:36,000<br>if they’re going up the pipeline as further,</p>
<p>588<br>00:27:36,000 –&gt; 00:27:38,000<br>as needed.</p>
<p>589<br>00:27:38,000 –&gt; 00:27:40,000<br>Right?</p>
<p>590<br>00:27:40,000 –&gt; 00:27:42,000<br>So that means now,</p>
<p>591<br>00:27:42,000 –&gt; 00:27:47,000<br>when if the worker node has all the intimate results,</p>
<p>592<br>00:27:47,000 –&gt; 00:27:49,000<br>if it crashes, or there’s a failure,</p>
<p>593<br>00:27:49,000 –&gt; 00:27:51,000<br>there now isn’t a,</p>
<p>594<br>00:27:51,000 –&gt; 00:27:53,000<br>there isn’t, it’s not replicated,</p>
<p>595<br>00:27:53,000 –&gt; 00:27:56,000<br>it’s not being stored as an external service</p>
<p>596<br>00:27:56,000 –&gt; 00:27:58,000<br>from the worker node.</p>
<p>597<br>00:27:58,000 –&gt; 00:28:01,000<br>So that means the computation is lost.</p>
<p>598<br>00:28:01,000 –&gt; 00:28:04,000<br>And unlike in Dremel and Spark,</p>
<p>599<br>00:28:04,000 –&gt; 00:28:06,000<br>where if one worker goes down,</p>
<p>600<br>00:28:06,000 –&gt; 00:28:09,000<br>then the coordinator then just invokes a new owner,</p>
<p>601<br>00:28:09,000 –&gt; 00:28:11,000<br>hands off that task to another worker,</p>
<p>602<br>00:28:11,000 –&gt; 00:28:13,000<br>which snowflake will do,</p>
<p>603<br>00:28:13,000 –&gt; 00:28:15,000<br>which is kill the entire query,</p>
<p>604<br>00:28:15,000 –&gt; 00:28:18,000<br>and then to restart it from the beginning.</p>
<p>605<br>00:28:18,000 –&gt; 00:28:20,000<br>And that’s actually how the people build</p>
<p>606<br>00:28:20,000 –&gt; 00:28:22,000<br>their systems back in the day.</p>
<p>607<br>00:28:22,000 –&gt; 00:28:23,000<br>I mentioned this before,</p>
<p>608<br>00:28:23,000 –&gt; 00:28:24,000<br>with MapReduce,</p>
<p>609<br>00:28:24,000 –&gt; 00:28:28,000<br>they were storing things on disk as they went along,</p>
<p>610<br>00:28:28,000 –&gt; 00:28:31,000<br>but they had the ability to kill tasks,</p>
<p>611<br>00:28:31,000 –&gt; 00:28:33,000<br>and re-exude things,</p>
<p>612<br>00:28:33,000 –&gt; 00:28:36,000<br>and do basically partial retry.</p>
<p>613<br>00:28:36,000 –&gt; 00:28:38,000<br>And in the snowflake world,</p>
<p>614<br>00:28:38,000 –&gt; 00:28:41,000<br>they’re not going to add any of that infrastructure,</p>
<p>615<br>00:28:41,000 –&gt; 00:28:43,000<br>because that’s additional engineering complexity.</p>
<p>616<br>00:28:43,000 –&gt; 00:28:45,000<br>They’re just going to make the decision,</p>
<p>617<br>00:28:45,000 –&gt; 00:28:47,000<br>okay, well one worker failed,</p>
<p>618<br>00:28:47,000 –&gt; 00:28:49,000<br>okay, just kill the whole thing and restart.</p>
<p>619<br>00:28:49,000 –&gt; 00:28:51,000<br>Cosmer.</p>
<p>620<br>00:28:51,000 –&gt; 00:28:52,000<br>Right?</p>
<p>621<br>00:28:52,000 –&gt; 00:28:53,000<br>So obviously, you know,</p>
<p>622<br>00:28:53,000 –&gt; 00:28:56,000<br>they’re not killing nodes randomly, right?</p>
<p>623<br>00:28:56,000 –&gt; 00:28:58,000<br>They have a blog article when they discussed like,</p>
<p>624<br>00:28:58,000 –&gt; 00:29:00,000<br>okay, like, if a worker dies,</p>
<p>625<br>00:29:00,000 –&gt; 00:29:01,000<br>they have to identify,</p>
<p>626<br>00:29:01,000 –&gt; 00:29:02,000<br>is this something that we did,</p>
<p>627<br>00:29:02,000 –&gt; 00:29:04,000<br>or is this a transit network failure?</p>
<p>628<br>00:29:04,000 –&gt; 00:29:05,000<br>Right?</p>
<p>629<br>00:29:05,000 –&gt; 00:29:08,000<br>In some cases, they can actually automatically roll you back</p>
<p>630<br>00:29:08,000 –&gt; 00:29:10,000<br>to a previous version of snowflake,</p>
<p>631<br>00:29:10,000 –&gt; 00:29:12,000<br>and rerun that query,</p>
<p>632<br>00:29:12,000 –&gt; 00:29:15,000<br>rerun the query, see whether that solves the problem.</p>
<p>633<br>00:29:15,000 –&gt; 00:29:16,000<br>The tricky thing also too is,</p>
<p>634<br>00:29:16,000 –&gt; 00:29:18,000<br>like, if now you’re ingesting new data,</p>
<p>635<br>00:29:18,000 –&gt; 00:29:20,000<br>you want to make sure that the query winner reruns,</p>
<p>636<br>00:29:20,000 –&gt; 00:29:23,000<br>like, is it seeing the same data that I had before?</p>
<p>637<br>00:29:23,000 –&gt; 00:29:24,000<br>Question or?</p>
<p>638<br>00:29:24,000 –&gt; 00:29:27,000<br>How often you query these queries fails?</p>
<p>639<br>00:29:27,000 –&gt; 00:29:28,000<br>Is this the only way you say it?</p>
<p>640<br>00:29:28,000 –&gt; 00:29:29,000<br>This question is how often queries fail?</p>
<p>641<br>00:29:29,000 –&gt; 00:29:31,000<br>I mean, not that often.</p>
<p>642<br>00:29:31,000 –&gt; 00:29:32,000<br>Right?</p>
<p>643<br>00:29:32,000 –&gt; 00:29:35,000<br>Actually, they have a blog article I should link.</p>
<p>644<br>00:29:35,000 –&gt; 00:29:37,000<br>I don’t know if you have that number,</p>
<p>645<br>00:29:37,000 –&gt; 00:29:39,000<br>but it’s not like, you know, one out of ten.</p>
<p>646<br>00:29:39,000 –&gt; 00:29:43,000<br>It’s some way smaller fraction.</p>
<p>647<br>00:29:43,000 –&gt; 00:29:44,000<br>Again, cos it’s like,</p>
<p>648<br>00:29:44,000 –&gt; 00:29:46,000<br>you’re not running,</p>
<p>649<br>00:29:46,000 –&gt; 00:29:47,000<br>again, just going back to the map-reduce world,</p>
<p>650<br>00:29:47,000 –&gt; 00:29:49,000<br>like, her dude was talking about,</p>
<p>651<br>00:29:49,000 –&gt; 00:29:51,000<br>okay, we’re going to run this query,</p>
<p>652<br>00:29:51,000 –&gt; 00:29:53,000<br>or this map-reduce job,</p>
<p>653<br>00:29:53,000 –&gt; 00:29:55,000<br>1,000 of, like, cheap pizza box machines,</p>
<p>654<br>00:29:55,000 –&gt; 00:29:57,000<br>like, the one-unit rack machines.</p>
<p>655<br>00:29:57,000 –&gt; 00:29:59,000<br>And in that environment, yeah,</p>
<p>656<br>00:29:59,000 –&gt; 00:30:01,000<br>one of them is going to go down.</p>
<p>657<br>00:30:01,000 –&gt; 00:30:03,000<br>If a query is going to run for an hour,</p>
<p>658<br>00:30:03,000 –&gt; 00:30:05,000<br>certainly one is going to go down.</p>
<p>659<br>00:30:05,000 –&gt; 00:30:07,000<br>But, like, now, only these queries running so fast,</p>
<p>660<br>00:30:07,000 –&gt; 00:30:10,000<br>you know, they’re running on a small number of machines anyway.</p>
<p>661<br>00:30:10,000 –&gt; 00:30:14,000<br>So, the likelihood of a failure is quite low.</p>
<p>662<br>00:30:14,000 –&gt; 00:30:15,000<br>Yes?</p>
<p>663<br>00:30:15,000 –&gt; 00:30:17,000<br>Does that come with scale?</p>
<p>664<br>00:30:17,000 –&gt; 00:30:19,000<br>It doesn’t come with scale, I mean, terms of what?</p>
<p>665<br>00:30:19,000 –&gt; 00:30:21,000<br>I don’t know what you can,</p>
<p>666<br>00:30:21,000 –&gt; 00:30:22,000<br>I can’t even know it.</p>
<p>667<br>00:30:22,000 –&gt; 00:30:24,000<br>Yeah, so the question is, like,</p>
<p>668<br>00:30:24,000 –&gt; 00:30:26,000<br>statement is like,</p>
<p>669<br>00:30:26,000 –&gt; 00:30:28,000<br>statement is like, okay,</p>
<p>670<br>00:30:28,000 –&gt; 00:30:30,000<br>if I’m saying, like, the more machines you have,</p>
<p>671<br>00:30:30,000 –&gt; 00:30:32,000<br>the more likely one’s going to fail,</p>
<p>672<br>00:30:32,000 –&gt; 00:30:34,000<br>does that have some upper bound how many machines you would need?</p>
<p>673<br>00:30:34,000 –&gt; 00:30:37,000<br>Again, it’s so fast that I don’t think you need</p>
<p>674<br>00:30:37,000 –&gt; 00:30:40,000<br>thousands of machines to process petabytes of data.</p>
<p>675<br>00:30:40,000 –&gt; 00:30:41,000<br>The problem is,</p>
<p>676<br>00:30:41,000 –&gt; 00:30:42,000<br>because it wasn’t slow.</p>
<p>677<br>00:30:42,000 –&gt; 00:30:45,000<br>It was so slow that, like, because, right?</p>
<p>678<br>00:30:45,000 –&gt; 00:30:47,000<br>Because it wasn’t an query optimizer,</p>
<p>679<br>00:30:47,000 –&gt; 00:30:49,000<br>and it was just doing this dumb-mat-produced shuffle,</p>
<p>680<br>00:30:49,000 –&gt; 00:30:51,000<br>a map shuffle thing over and over again,</p>
<p>681<br>00:30:51,000 –&gt; 00:30:53,000<br>no matter what the query actually was doing,</p>
<p>682<br>00:30:53,000 –&gt; 00:30:55,000<br>it had no notion of, like, pipelines,</p>
<p>683<br>00:30:55,000 –&gt; 00:30:57,000<br>unless someone wrote everything inside of, you know,</p>
<p>684<br>00:30:57,000 –&gt; 00:30:59,000<br>this single map job.</p>
<p>685<br>00:30:59,000 –&gt; 00:31:00,000<br>Again, I think it’s,</p>
<p>686<br>00:31:00,000 –&gt; 00:31:01,000<br>whereas, like, at the time,</p>
<p>687<br>00:31:01,000 –&gt; 00:31:03,000<br>other parallel data systems, like,</p>
<p>688<br>00:31:03,000 –&gt; 00:31:05,000<br>the verticals of the world,</p>
<p>689<br>00:31:05,000 –&gt; 00:31:07,000<br>you know, they were running on,</p>
<p>690<br>00:31:07,000 –&gt; 00:31:09,000<br>they need fewer nodes to compute the same amount of,</p>
<p>691<br>00:31:09,000 –&gt; 00:31:10,000<br>you know, the same results,</p>
<p>692<br>00:31:10,000 –&gt; 00:31:11,000<br>and less time.</p>
<p>693<br>00:31:11,000 –&gt; 00:31:18,000<br>So one thing sort of like does do,</p>
<p>694<br>00:31:18,000 –&gt; 00:31:21,000<br>even though on the shuffle phase,</p>
<p>695<br>00:31:21,000 –&gt; 00:31:23,000<br>they can do work-stealing,</p>
<p>696<br>00:31:23,000 –&gt; 00:31:25,000<br>and it’s similar to the morsel stuff that we saw before,</p>
<p>697<br>00:31:25,000 –&gt; 00:31:27,000<br>where, instead of a coordinator,</p>
<p>698<br>00:31:27,000 –&gt; 00:31:29,000<br>like, in Dremel, recognizing that this guy’s running slow,</p>
<p>699<br>00:31:29,000 –&gt; 00:31:30,000<br>this task is running slow,</p>
<p>700<br>00:31:30,000 –&gt; 00:31:33,000<br>let me kill him and let it fire up the task ourselves,</p>
<p>701<br>00:31:33,000 –&gt; 00:31:36,000<br>the workers themselves, the worker processes, excuse me,</p>
<p>702<br>00:31:36,000 –&gt; 00:31:39,000<br>they’re looking for work to do,</p>
<p>703<br>00:31:39,000 –&gt; 00:31:41,000<br>and so they recognize that for all the input files,</p>
<p>704<br>00:31:41,000 –&gt; 00:31:42,000<br>they were told at the beginning of,</p>
<p>705<br>00:31:42,000 –&gt; 00:31:45,000<br>here you need a process for this stage of the query plan.</p>
<p>706<br>00:31:45,000 –&gt; 00:31:47,000<br>If it runs out of stuff to do,</p>
<p>707<br>00:31:47,000 –&gt; 00:31:52,000<br>then they can go do quick lookups on other workers,</p>
<p>708<br>00:31:52,000 –&gt; 00:31:53,000<br>running the same, you know,</p>
<p>709<br>00:31:53,000 –&gt; 00:31:55,000<br>the same stages they are,</p>
<p>710<br>00:31:55,000 –&gt; 00:31:56,000<br>and see whether they’re falling behind</p>
<p>711<br>00:31:56,000 –&gt; 00:31:58,000<br>and go steal files from them.</p>
<p>712<br>00:31:58,000 –&gt; 00:32:03,000<br>But, and avoid, to avoid burdening the other worker nodes</p>
<p>713<br>00:32:03,000 –&gt; 00:32:05,000<br>with sending the data from, you know,</p>
<p>714<br>00:32:05,000 –&gt; 00:32:07,000<br>from their local locash data</p>
<p>715<br>00:32:08,000 –&gt; 00:32:11,000<br>to the guy that’s gonna do the steal the task from them,</p>
<p>716<br>00:32:11,000 –&gt; 00:32:13,000<br>they always go out to S3,</p>
<p>717<br>00:32:13,000 –&gt; 00:32:15,000<br>because the idea is that,</p>
<p>718<br>00:32:15,000 –&gt; 00:32:17,000<br>if the node is already running behind,</p>
<p>719<br>00:32:17,000 –&gt; 00:32:19,000<br>because it’s slow for some reason,</p>
<p>720<br>00:32:19,000 –&gt; 00:32:20,000<br>if now another node says,</p>
<p>721<br>00:32:20,000 –&gt; 00:32:21,000<br>okay, yeah, you’re running too slow,</p>
<p>722<br>00:32:21,000 –&gt; 00:32:22,000<br>give me the data that you have,</p>
<p>723<br>00:32:22,000 –&gt; 00:32:24,000<br>that’s just gonna make it even slower,</p>
<p>724<br>00:32:24,000 –&gt; 00:32:25,000<br>make things worse.</p>
<p>725<br>00:32:25,000 –&gt; 00:32:28,000<br>So they make the conscientious decision that the node’s gonna go out to S3,</p>
<p>726<br>00:32:28,000 –&gt; 00:32:29,000<br>even though they pay for it,</p>
<p>727<br>00:32:29,000 –&gt; 00:32:31,000<br>even though they have a local cache version,</p>
<p>728<br>00:32:31,000 –&gt; 00:32:32,000<br>they’ll go out to S3,</p>
<p>729<br>00:32:32,000 –&gt; 00:32:36,000<br>because that avoids slowing things down even further.</p>
<p>730<br>00:32:37,000 –&gt; 00:32:41,000<br>And then when this, this, the stealing worker goes against the data from S3,</p>
<p>731<br>00:32:41,000 –&gt; 00:32:44,000<br>it can put any results in its local storage,</p>
<p>732<br>00:32:44,000 –&gt; 00:32:45,000<br>just like before,</p>
<p>733<br>00:32:45,000 –&gt; 00:32:46,000<br>but it’s not gonna maintain the,</p>
<p>734<br>00:32:46,000 –&gt; 00:32:48,000<br>the persistent files in its cache,</p>
<p>735<br>00:32:50,000 –&gt; 00:32:52,000<br>beyond the, you know, the worker to stole,</p>
<p>736<br>00:32:52,000 –&gt; 00:32:55,000<br>because, again, there’s some high level organization through this consistent hashing</p>
<p>737<br>00:32:55,000 –&gt; 00:32:57,000<br>that’s deciding what worker node is responsible for,</p>
<p>738<br>00:32:57,000 –&gt; 00:33:00,000<br>what file on, on S3.</p>
<p>739<br>00:33:00,000 –&gt; 00:33:02,000<br>So, you know, the next time the query runs,</p>
<p>740<br>00:33:02,000 –&gt; 00:33:03,000<br>it meets the same data,</p>
<p>741<br>00:33:03,000 –&gt; 00:33:04,000<br>it wouldn’t go to this,</p>
<p>742<br>00:33:04,000 –&gt; 00:33:05,000<br>that node anyway,</p>
<p>743<br>00:33:05,000 –&gt; 00:33:07,000<br>it would go back to the original one.</p>
<p>744<br>00:33:07,000 –&gt; 00:33:08,000<br>Yes.</p>
<p>745<br>00:33:08,000 –&gt; 00:33:11,000<br>So you said that the intermediate results are stored in local displays,</p>
<p>746<br>00:33:11,000 –&gt; 00:33:12,000<br>how can you get from S3,</p>
<p>747<br>00:33:12,000 –&gt; 00:33:15,000<br>unless you send it to it?</p>
<p>748<br>00:33:15,000 –&gt; 00:33:16,000<br>So, it’s at the end, what?</p>
<p>749<br>00:33:16,000 –&gt; 00:33:19,000<br>So, when your work’s seen from other nodes,</p>
<p>750<br>00:33:19,000 –&gt; 00:33:21,000<br>I’m, that node’s working on,</p>
<p>751<br>00:33:21,000 –&gt; 00:33:23,000<br>so, the intermediate results,</p>
<p>752<br>00:33:23,000 –&gt; 00:33:25,000<br>that were already on that local list,</p>
<p>753<br>00:33:25,000 –&gt; 00:33:27,000<br>so, how can you get from S3?</p>
<p>754<br>00:33:27,000 –&gt; 00:33:29,000<br>I say it is, like, if you’re,</p>
<p>755<br>00:33:29,000 –&gt; 00:33:32,000<br>if it’s processing data from,</p>
<p>756<br>00:33:32,000 –&gt; 00:33:34,000<br>it’s not processing, like, the visual persistent files,</p>
<p>757<br>00:33:34,000 –&gt; 00:33:37,000<br>instead, it’s, it’s reading from,</p>
<p>758<br>00:33:37,000 –&gt; 00:33:40,000<br>it’s reading from the intermediate results,</p>
<p>759<br>00:33:40,000 –&gt; 00:33:42,000<br>how can you go to S3 and get it?</p>
<p>760<br>00:33:42,000 –&gt; 00:33:43,000<br>Because you, you couldn’t go to the other,</p>
<p>761<br>00:33:43,000 –&gt; 00:33:45,000<br>the worker node that it got from, right?</p>
<p>762<br>00:33:45,000 –&gt; 00:33:47,000<br>I remember, I treated the data.</p>
<p>763<br>00:33:47,000 –&gt; 00:33:50,000<br>So then, you do set the start from the data,</p>
<p>764<br>00:33:50,000 –&gt; 00:33:51,000<br>do you want to do that?</p>
<p>765<br>00:33:51,000 –&gt; 00:33:53,000<br>No, no, no, no, so, like, so, like, though,</p>
<p>766<br>00:33:53,000 –&gt; 00:33:55,000<br>if the worker node got, you know,</p>
<p>767<br>00:33:55,000 –&gt; 00:33:57,000<br>worker node, and I’m slides here, or diagrams,</p>
<p>768<br>00:33:57,000 –&gt; 00:33:59,000<br>if worker node X is running behind,</p>
<p>769<br>00:33:59,000 –&gt; 00:34:02,000<br>but it got its data from worker node Y.</p>
<p>770<br>00:34:02,000 –&gt; 00:34:04,000<br>Now, worker node Z is going to steal that data,</p>
<p>771<br>00:34:04,000 –&gt; 00:34:06,000<br>it can go to worker node Y,</p>
<p>772<br>00:34:06,000 –&gt; 00:34:08,000<br>and get those intermediate results.</p>
<p>773<br>00:34:08,000 –&gt; 00:34:10,000<br>Or, if it’s, again, if it’s reading from persistent files,</p>
<p>774<br>00:34:10,000 –&gt; 00:34:11,000<br>it would go to S3.</p>
<p>775<br>00:34:11,000 –&gt; 00:34:14,000<br>I think the worker node can also spill to S3, as well.</p>
<p>776<br>00:34:14,000 –&gt; 00:34:16,000<br>Like, if you just run it, it’s facing entirely,</p>
<p>777<br>00:34:16,000 –&gt; 00:34:18,000<br>then, the last case, let, you know,</p>
<p>778<br>00:34:18,000 –&gt; 00:34:21,000<br>the fallback is to store things in S3, as well.</p>
<p>779<br>00:34:21,000 –&gt; 00:34:25,000<br>All the workers know the problem,</p>
<p>780<br>00:34:25,000 –&gt; 00:34:28,000<br>and they both cost the cost for the</p>
<p>781<br>00:34:28,000 –&gt; 00:34:31,000<br>user and the user to use it,</p>
<p>782<br>00:34:31,000 –&gt; 00:34:32,000<br>as a student.</p>
<p>783<br>00:34:32,000 –&gt; 00:34:34,000<br>His question is, how can a worker know</p>
<p>784<br>00:34:34,000 –&gt; 00:34:35,000<br>the progress of another worker,</p>
<p>785<br>00:34:35,000 –&gt; 00:34:37,000<br>and identify that they’re running behind?</p>
<p>786<br>00:34:37,000 –&gt; 00:34:39,000<br>I don’t know whether they talked to the coordinator,</p>
<p>787<br>00:34:39,000 –&gt; 00:34:42,000<br>or they talked to the other worker, right?</p>
<p>788<br>00:34:42,000 –&gt; 00:34:44,000<br>But, like, I don’t, it’s not broadcast,</p>
<p>789<br>00:34:44,000 –&gt; 00:34:47,000<br>because, like, there’ll be, there’ll be, like, a heartbeat</p>
<p>790<br>00:34:47,000 –&gt; 00:34:49,000<br>that, that, that, that, that, that, that, that,</p>
<p>791<br>00:34:49,000 –&gt; 00:34:51,000<br>that broadcast, every so often, is, hey, look, I’m still alive,</p>
<p>792<br>00:34:51,000 –&gt; 00:34:53,000<br>but he wouldn’t say, like, I’m, here’s my progress,</p>
<p>793<br>00:34:53,000 –&gt; 00:34:54,000<br>I’m going along.</p>
<p>794<br>00:34:54,000 –&gt; 00:34:57,000<br>So, it’s either the coordinator, or the worker, you say,</p>
<p>795<br>00:34:57,000 –&gt; 00:35:00,000<br>you know, give me something to do.</p>
<p>796<br>00:35:03,000 –&gt; 00:35:05,000<br>Okay, so, okay, so, so, it’s, so, it’s,</p>
<p>797<br>00:35:05,000 –&gt; 00:35:07,000<br>it’s going to work-stealing, and, again,</p>
<p>798<br>00:35:07,000 –&gt; 00:35:09,000<br>what I like about this paper is, like, they, they describe,</p>
<p>799<br>00:35:09,000 –&gt; 00:35:11,000<br>like, here’s why we did it this way,</p>
<p>800<br>00:35:11,000 –&gt; 00:35:14,000<br>and they go a bit more details than, than, Dremel,</p>
<p>801<br>00:35:14,000 –&gt; 00:35:17,000<br>and, uh, data for it’s too.</p>
<p>802<br>00:35:18,000 –&gt; 00:35:20,000<br>The other interesting thing they can support as well,</p>
<p>803<br>00:35:20,000 –&gt; 00:35:22,000<br>is they, what they call, flexible compute.</p>
<p>804<br>00:35:22,000 –&gt; 00:35:26,000<br>And, the idea here is that, because the, you know,</p>
<p>805<br>00:35:26,000 –&gt; 00:35:28,000<br>the original model of Snow-Thick, was like,</p>
<p>806<br>00:35:28,000 –&gt; 00:35:30,000<br>you, you define this virtual, what, data warehouse,</p>
<p>807<br>00:35:30,000 –&gt; 00:35:32,000<br>that sort of sets up the number of compute nodes</p>
<p>808<br>00:35:32,000 –&gt; 00:35:35,000<br>you’re going to have, um, at the beginning,</p>
<p>809<br>00:35:35,000 –&gt; 00:35:38,000<br>and that, those, unless you’re using serverless,</p>
<p>810<br>00:35:38,000 –&gt; 00:35:41,000<br>those, those machines are always running.</p>
<p>811<br>00:35:41,000 –&gt; 00:35:44,000<br>So, maybe the case that, for any, some query shows up,</p>
<p>812<br>00:35:44,000 –&gt; 00:35:45,000<br>you’re actually under-provisioned,</p>
<p>813<br>00:35:45,000 –&gt; 00:35:47,000<br>you don’t have as much, uh, compute capacity,</p>
<p>814<br>00:35:47,000 –&gt; 00:35:50,000<br>you actually need to run the query in a, in a timely manner.</p>
<p>815<br>00:35:50,000 –&gt; 00:35:52,000<br>So, what they’ll do is, they’ll recognize,</p>
<p>816<br>00:35:52,000 –&gt; 00:35:55,000<br>prior to running, they’ll look at the query plan and identify,</p>
<p>817<br>00:35:55,000 –&gt; 00:35:58,000<br>is there any part where, I think, the query plan,</p>
<p>818<br>00:35:58,000 –&gt; 00:36:00,000<br>this, this portion of the query plan,</p>
<p>819<br>00:36:00,000 –&gt; 00:36:03,000<br>is going to take a longer time than, than I, I would want.</p>
<p>820<br>00:36:03,000 –&gt; 00:36:07,000<br>And, can I then, uh, hand off those, the tasks,</p>
<p>821<br>00:36:07,000 –&gt; 00:36:09,000<br>for that part of the query plan, to other nodes,</p>
<p>822<br>00:36:09,000 –&gt; 00:36:12,000<br>that I actually, the customer is actually not paying for,</p>
<p>823<br>00:36:12,000 –&gt; 00:36:14,000<br>basically, think of, like, other, other idle customers,</p>
<p>824<br>00:36:14,000 –&gt; 00:36:16,000<br>that, that have compute nodes that aren’t using.</p>
<p>825<br>00:36:16,000 –&gt; 00:36:18,000<br>And, if I can farm out part of the query plan,</p>
<p>826<br>00:36:18,000 –&gt; 00:36:21,000<br>to those of those nodes, it’s a win-win situation for everyone,</p>
<p>827<br>00:36:21,000 –&gt; 00:36:23,000<br>because the query runs faster,</p>
<p>828<br>00:36:23,000 –&gt; 00:36:25,000<br>snowflake is not spending any more money,</p>
<p>829<br>00:36:25,000 –&gt; 00:36:27,000<br>because the customer is already paying for the,</p>
<p>830<br>00:36:27,000 –&gt; 00:36:30,000<br>the, the, the, the, the, the, the, the, the customer,</p>
<p>831<br>00:36:30,000 –&gt; 00:36:31,000<br>that you’re borrowing machines from,</p>
<p>832<br>00:36:31,000 –&gt; 00:36:35,000<br>they don’t even know that, their machines are being used in this way,</p>
<p>833<br>00:36:35,000 –&gt; 00:36:38,000<br>and that, when they run queries, they can leverage the same,</p>
<p>834<br>00:36:38,000 –&gt; 00:36:41,000<br>uh, uh, spare capacity as well.</p>
<p>835<br>00:36:41,000 –&gt; 00:36:43,000<br>So, let’s say, again, so, say we have them,</p>
<p>836<br>00:36:43,000 –&gt; 00:36:46,000<br>this side of the query plan here, uh, on the probe side of this join,</p>
<p>837<br>00:36:46,000 –&gt; 00:36:48,000<br>it’s wants to do with some large scan.</p>
<p>838<br>00:36:48,000 –&gt; 00:36:52,000<br>So, snowflake can then split this up into two,</p>
<p>839<br>00:36:52,000 –&gt; 00:36:56,000<br>uh, sort of, subplans that are going to be combined together</p>
<p>840<br>00:36:56,000 –&gt; 00:36:57,000<br>with the union all.</p>
<p>841<br>00:36:57,000 –&gt; 00:37:00,000<br>And so, here we have the, the, the, the portion of the query,</p>
<p>842<br>00:37:00,000 –&gt; 00:37:03,000<br>uh, that’s going to run on, on the, the customers,</p>
<p>843<br>00:37:03,000 –&gt; 00:37:06,000<br>the customer initiate the query on their,</p>
<p>844<br>00:37:06,000 –&gt; 00:37:08,000<br>data warehouse, their, their, their compute nodes.</p>
<p>845<br>00:37:08,000 –&gt; 00:37:09,000<br>But this, this piece over here,</p>
<p>846<br>00:37:09,000 –&gt; 00:37:12,000<br>this is going to run on, on the spare hardware.</p>
<p>847<br>00:37:12,000 –&gt; 00:37:15,000<br>Again, item machines running in, you know,</p>
<p>848<br>00:37:15,000 –&gt; 00:37:19,000<br>running in, running in the snowflake, uh, you know, ecosystem.</p>
<p>849<br>00:37:19,000 –&gt; 00:37:22,000<br>So, but because these machines are controlled by the,</p>
<p>850<br>00:37:22,000 –&gt; 00:37:24,000<br>the customer that’s invoking the query,</p>
<p>851<br>00:37:24,000 –&gt; 00:37:27,000<br>you can’t write any, any, any results to the local disk,</p>
<p>852<br>00:37:27,000 –&gt; 00:37:29,000<br>because at any moment, the customer could,</p>
<p>853<br>00:37:29,000 –&gt; 00:37:32,000<br>the customer who owns these machines could start running the query,</p>
<p>854<br>00:37:32,000 –&gt; 00:37:34,000<br>and you got to, Victor, all this right away.</p>
<p>855<br>00:37:34,000 –&gt; 00:37:36,000<br>Right? It doesn’t look good if like, hey, you know,</p>
<p>856<br>00:37:36,000 –&gt; 00:37:38,000<br>you’re a similar query. Uh, give me, give me 20 seconds,</p>
<p>857<br>00:37:38,000 –&gt; 00:37:40,000<br>I got to finish up, you know, Joe’s, Joe’s query.</p>
<p>858<br>00:37:40,000 –&gt; 00:37:42,000<br>Like, could, could people get pissed, right?</p>
<p>859<br>00:37:42,000 –&gt; 00:37:46,000<br>So, what they’ll do is, instead of writing the data to the local storage,</p>
<p>860<br>00:37:46,000 –&gt; 00:37:51,000<br>they’ll instead insert it as if it was a table back into S3.</p>
<p>861<br>00:37:51,000 –&gt; 00:37:55,000<br>And then now, when I, when I, when I’m going to retrieve it again,</p>
<p>862<br>00:37:55,000 –&gt; 00:37:58,000<br>uh, you know, the, the, the, the query operator above it,</p>
<p>863<br>00:37:58,000 –&gt; 00:38:02,000<br>is just reading from S3 like it, like it was a regular table.</p>
<p>864<br>00:38:02,000 –&gt; 00:38:04,000<br>Right?</p>
<p>865<br>00:38:04,000 –&gt; 00:38:06,000<br>Actually going back here, this is actually,</p>
<p>866<br>00:38:06,000 –&gt; 00:38:08,000<br>this is actually from, it’s not like,</p>
<p>867<br>00:38:08,000 –&gt; 00:38:11,000<br>so this is another example of the S3 information passion stuff we talked before.</p>
<p>868<br>00:38:11,000 –&gt; 00:38:13,000<br>So they have this, you build the hash join, uh,</p>
<p>869<br>00:38:13,000 –&gt; 00:38:15,000<br>sorry, you build the hash equal to the join,</p>
<p>870<br>00:38:15,000 –&gt; 00:38:17,000<br>and they have this operator kind of a join filter.</p>
<p>871<br>00:38:17,000 –&gt; 00:38:21,000<br>That’s passing over the Bloom filter from, from the build side to the probe side.</p>
<p>872<br>00:38:21,000 –&gt; 00:38:25,000<br>Right? It is, it’s, they explicitly call it out as a separate operator called join filter.</p>
<p>873<br>00:38:25,000 –&gt; 00:38:30,000<br>Right? Again, so, so this is just,</p>
<p>874<br>00:38:30,000 –&gt; 00:38:32,000<br>because it’s a manager’s service,</p>
<p>875<br>00:38:32,000 –&gt; 00:38:34,000<br>you’re not running on prem, right?</p>
<p>876<br>00:38:34,000 –&gt; 00:38:37,000<br>There’s elasticity to the, the resources that are available,</p>
<p>877<br>00:38:37,000 –&gt; 00:38:39,000<br>and again, they smartly recognize,</p>
<p>878<br>00:38:39,000 –&gt; 00:38:43,000<br>okay, these machines are idle, uh, right now,</p>
<p>879<br>00:38:43,000 –&gt; 00:38:46,000<br>we’ll need to use them to make queries run faster.</p>
<p>880<br>00:38:46,000 –&gt; 00:38:51,000<br>And this is all, again, all transparent to, to the customer.</p>
<p>881<br>00:38:51,000 –&gt; 00:38:55,000<br>You can also use this for the, for basically, basically query result caching.</p>
<p>882<br>00:38:55,000 –&gt; 00:38:57,000<br>Almost like, not exactly like a materialized view,</p>
<p>883<br>00:38:57,000 –&gt; 00:38:59,000<br>because it’s not going to automatically refresh,</p>
<p>884<br>00:38:59,000 –&gt; 00:39:03,000<br>but you’re, you’re writing out the output of this query plan fragment</p>
<p>885<br>00:39:03,000 –&gt; 00:39:06,000<br>into s3, you can then update the catalog and say,</p>
<p>886<br>00:39:06,000 –&gt; 00:39:10,000<br>okay, we receive this query plan fragment again on, on these, these files.</p>
<p>887<br>00:39:10,000 –&gt; 00:39:14,000<br>Here’s some materialized result for it that you can then reuse.</p>
<p>888<br>00:39:14,000 –&gt; 00:39:15,000<br>Yes?</p>
<p>889<br>00:39:16,000 –&gt; 00:39:18,000<br>So, you have to be concerning the customers,</p>
<p>890<br>00:39:18,000 –&gt; 00:39:21,000<br>but if the customers don’t want to do that anywhere,</p>
<p>891<br>00:39:21,000 –&gt; 00:39:24,000<br>then you have to do another customer, right?</p>
<p>892<br>00:39:24,000 –&gt; 00:39:27,000<br>Let’s go ahead and write the query,</p>
<p>893<br>00:39:27,000 –&gt; 00:39:29,000<br>and you can just use it.</p>
<p>894<br>00:39:29,000 –&gt; 00:39:30,000<br>Stay with us.</p>
<p>895<br>00:39:30,000 –&gt; 00:39:31,000<br>Isn’t this, um,</p>
<p>896<br>00:39:31,000 –&gt; 00:39:34,000<br>wouldn’t this be concerning for customers?</p>
<p>897<br>00:39:34,000 –&gt; 00:39:37,000<br>Because they don’t want, they’re dated in the mix with any of data.</p>
<p>898<br>00:39:37,000 –&gt; 00:39:38,000<br>Well, one is they have,</p>
<p>899<br>00:39:38,000 –&gt; 00:39:40,000<br>they have sort of compute isolation,</p>
<p>900<br>00:39:40,000 –&gt; 00:39:41,000<br>because, as I said before,</p>
<p>901<br>00:39:41,000 –&gt; 00:39:43,000<br>the worker process gets killed after the query.</p>
<p>902<br>00:39:43,000 –&gt; 00:39:46,000<br>You know, you’re whatever task you run for this query,</p>
<p>903<br>00:39:46,000 –&gt; 00:39:49,000<br>wakes up and can now start seeing the next customer’s data, right?</p>
<p>904<br>00:39:49,000 –&gt; 00:39:51,000<br>It’s a managed service,</p>
<p>905<br>00:39:51,000 –&gt; 00:39:53,000<br>so it’s not running arbitrary code,</p>
<p>906<br>00:39:53,000 –&gt; 00:39:54,000<br>it’s all snowflake code.</p>
<p>907<br>00:39:54,000 –&gt; 00:39:56,000<br>So, if you’re trusting snowflake with your data anyway,</p>
<p>908<br>00:39:56,000 –&gt; 00:39:59,000<br>you could trust them to write the compute side of things.</p>
<p>909<br>00:39:59,000 –&gt; 00:40:00,000<br>Um,</p>
<p>910<br>00:40:02,000 –&gt; 00:40:03,000<br>okay?</p>
<p>911<br>00:40:03,000 –&gt; 00:40:04,000<br>Ah.</p>
<p>912<br>00:40:07,000 –&gt; 00:40:09,000<br>Yeah, it’s not, it’s not that big of a secret.</p>
<p>913<br>00:40:09,000 –&gt; 00:40:10,000<br>And again,</p>
<p>914<br>00:40:10,000 –&gt; 00:40:11,000<br>to your original point,</p>
<p>915<br>00:40:11,000 –&gt; 00:40:12,000<br>I don’t think it’s not,</p>
<p>916<br>00:40:12,000 –&gt; 00:40:14,000<br>I don’t think it’s a video concern, right?</p>
<p>917<br>00:40:14,000 –&gt; 00:40:16,000<br>And if you really, I think you can opt out of this and say,</p>
<p>918<br>00:40:16,000 –&gt; 00:40:17,000<br>like, I want to run in a,</p>
<p>919<br>00:40:17,000 –&gt; 00:40:18,000<br>you know,</p>
<p>920<br>00:40:18,000 –&gt; 00:40:20,000<br>I don’t think it’s anything that’s in the mix.</p>
<p>921<br>00:40:20,000 –&gt; 00:40:23,000<br>No, no, no, no, no, no.</p>
<p>922<br>00:40:23,000 –&gt; 00:40:25,000<br>Right? This is not, this is not,</p>
<p>923<br>00:40:25,000 –&gt; 00:40:26,000<br>this is not controversial.</p>
<p>924<br>00:40:26,000 –&gt; 00:40:27,000<br>It’s not in snowflake code,</p>
<p>925<br>00:40:27,000 –&gt; 00:40:28,000<br>it should be.</p>
<p>926<br>00:40:28,000 –&gt; 00:40:29,000<br>Yeah, it’s running snowflake code,</p>
<p>927<br>00:40:29,000 –&gt; 00:40:30,000<br>and you should be,</p>
<p>928<br>00:40:30,000 –&gt; 00:40:31,000<br>no one,</p>
<p>929<br>00:40:31,000 –&gt; 00:40:32,000<br>yeah, there’s other,</p>
<p>930<br>00:40:32,000 –&gt; 00:40:34,000<br>there’s other things to be word out.</p>
<p>931<br>00:40:34,000 –&gt; 00:40:35,000<br>And again, it’s like,</p>
<p>932<br>00:40:35,000 –&gt; 00:40:36,000<br>it’s like,</p>
<p>933<br>00:40:36,000 –&gt; 00:40:37,000<br>it’s like the, the,</p>
<p>934<br>00:40:37,000 –&gt; 00:40:38,000<br>the give of pen,</p>
<p>935<br>00:40:38,000 –&gt; 00:40:39,000<br>right?</p>
<p>936<br>00:40:39,000 –&gt; 00:40:40,000<br>So like, right now,</p>
<p>937<br>00:40:40,000 –&gt; 00:40:41,000<br>my, my data warehouses,</p>
<p>938<br>00:40:41,000 –&gt; 00:40:42,000<br>I’d also, yeah,</p>
<p>939<br>00:40:42,000 –&gt; 00:40:44,000<br>if you could someone else take advantage of it, sure.</p>
<p>940<br>00:40:44,000 –&gt; 00:40:45,000<br>But then went, you know,</p>
<p>941<br>00:40:45,000 –&gt; 00:40:46,000<br>and when I need it,</p>
<p>942<br>00:40:46,000 –&gt; 00:40:50,000<br>then I can leverage somebody else’s.</p>
<p>943<br>00:40:50,000 –&gt; 00:40:52,000<br>And it all works out.</p>
<p>944<br>00:40:52,000 –&gt; 00:40:53,000<br>Yes.</p>
<p>945<br>00:40:53,000 –&gt; 00:40:54,000<br>This is not unique to snowflake,</p>
<p>946<br>00:40:54,000 –&gt; 00:40:55,000<br>right?</p>
<p>947<br>00:40:55,000 –&gt; 00:40:56,000<br>Is it other than,</p>
<p>948<br>00:40:56,000 –&gt; 00:40:57,000<br>other than some of these?</p>
<p>949<br>00:40:57,000 –&gt; 00:40:58,000<br>It’s question, this is not,</p>
<p>950<br>00:40:58,000 –&gt; 00:40:59,000<br>you need to,</p>
<p>951<br>00:40:59,000 –&gt; 00:41:00,000<br>I mean,</p>
<p>952<br>00:41:00,000 –&gt; 00:41:01,000<br>it’s like,</p>
<p>953<br>00:41:01,000 –&gt; 00:41:02,000<br>you need to,</p>
<p>954<br>00:41:02,000 –&gt; 00:41:03,000<br>I don’t know.</p>
<p>955<br>00:41:03,000 –&gt; 00:41:04,000<br>It’s like,</p>
<p>956<br>00:41:04,000 –&gt; 00:41:05,000<br>I think of examples,</p>
<p>957<br>00:41:05,000 –&gt; 00:41:06,000<br>I feel like,</p>
<p>958<br>00:41:06,000 –&gt; 00:41:07,000<br>I mean,</p>
<p>959<br>00:41:07,000 –&gt; 00:41:08,000<br>there was a,</p>
<p>960<br>00:41:08,000 –&gt; 00:41:10,000<br>there was a system out of the 80s that actually I worked on,</p>
<p>961<br>00:41:10,000 –&gt; 00:41:11,000<br>it’s called my pre-doc,</p>
<p>962<br>00:41:11,000 –&gt; 00:41:12,000<br>this thing called Condor.</p>
<p>963<br>00:41:12,000 –&gt; 00:41:14,000<br>And it was, it was called a cycle scavenger.</p>
<p>964<br>00:41:14,000 –&gt; 00:41:15,000<br>It’s basically,</p>
<p>965<br>00:41:15,000 –&gt; 00:41:17,000<br>if you had a bunch of machines in your computer science department,</p>
<p>966<br>00:41:17,000 –&gt; 00:41:18,000<br>at night,</p>
<p>967<br>00:41:18,000 –&gt; 00:41:20,000<br>it would recognize that no one would touch the keyboard or the mouse.</p>
<p>968<br>00:41:20,000 –&gt; 00:41:22,000<br>And then it would start running, you know,</p>
<p>969<br>00:41:22,000 –&gt; 00:41:24,000<br>compute heavy jobs on the machines.</p>
<p>970<br>00:41:24,000 –&gt; 00:41:25,000<br>And then when you,</p>
<p>971<br>00:41:25,000 –&gt; 00:41:26,000<br>you came back the next morning,</p>
<p>972<br>00:41:26,000 –&gt; 00:41:27,000<br>when you started using the mouse,</p>
<p>973<br>00:41:27,000 –&gt; 00:41:29,000<br>there was a little small pause,</p>
<p>974<br>00:41:29,000 –&gt; 00:41:30,000<br>like,</p>
<p>975<br>00:41:30,000 –&gt; 00:41:31,000<br>it addicted to the jobs,</p>
<p>976<br>00:41:31,000 –&gt; 00:41:32,000<br>but then like, you know,</p>
<p>977<br>00:41:32,000 –&gt; 00:41:33,000<br>you got additional resources.</p>
<p>978<br>00:41:33,000 –&gt; 00:41:34,000<br>So that,</p>
<p>979<br>00:41:34,000 –&gt; 00:41:35,000<br>the idea of like,</p>
<p>980<br>00:41:35,000 –&gt; 00:41:37,000<br>a cycle scavenging is not new.</p>
<p>981<br>00:41:37,000 –&gt; 00:41:39,000<br>Specific for databases,</p>
<p>982<br>00:41:39,000 –&gt; 00:41:43,000<br>again, I think what’s different about this is because it’s in the cloud,</p>
<p>983<br>00:41:43,000 –&gt; 00:41:48,000<br>it’s a single giant pool of all this compute capacity, right?</p>
<p>984<br>00:41:48,000 –&gt; 00:41:54,000<br>That, that Snowflake has, has under its control that you can do this.</p>
<p>985<br>00:41:54,000 –&gt; 00:41:56,000<br>Amazon does it differently, right?</p>
<p>986<br>00:41:56,000 –&gt; 00:41:57,000<br>Amazon has spare EC2 resources,</p>
<p>987<br>00:41:57,000 –&gt; 00:41:58,000<br>they try to sell them off as,</p>
<p>988<br>00:41:58,000 –&gt; 00:41:59,000<br>as, as,</p>
<p>989<br>00:41:59,000 –&gt; 00:42:00,000<br>as spot instances,</p>
<p>990<br>00:42:00,000 –&gt; 00:42:01,000<br>at a low price.</p>
<p>991<br>00:42:01,000 –&gt; 00:42:02,000<br>But of course,</p>
<p>992<br>00:42:02,000 –&gt; 00:42:04,000<br>any time you could get evicted,</p>
<p>993<br>00:42:04,000 –&gt; 00:42:06,000<br>because someone else wants to pay higher price.</p>
<p>994<br>00:42:06,000 –&gt; 00:42:08,000<br>Um,</p>
<p>995<br>00:42:08,000 –&gt; 00:42:10,000<br>in terms of databases that,</p>
<p>996<br>00:42:10,000 –&gt; 00:42:12,000<br>doing something similar, um,</p>
<p>997<br>00:42:12,000 –&gt; 00:42:16,000<br>uh,</p>
<p>998<br>00:42:16,000 –&gt; 00:42:18,000<br>I’ll have to cut this, right?</p>
<p>999<br>00:42:18,000 –&gt; 00:42:20,000<br>Not exactly the same, but like,</p>
<p>1000<br>00:42:20,000 –&gt; 00:42:23,000<br>yeah, taking advantage of idle resources is a different thing.</p>
<p>1001<br>00:42:23,000 –&gt; 00:42:24,000<br>Oh, Carl, also too, like,</p>
<p>1002<br>00:42:24,000 –&gt; 00:42:25,000<br>thinking of the data system,</p>
<p>1003<br>00:42:25,000 –&gt; 00:42:27,000<br>like, you know, maybe not so much for the,</p>
<p>1004<br>00:42:27,000 –&gt; 00:42:28,000<br>oh, that’s, I can’t,</p>
<p>1005<br>00:42:28,000 –&gt; 00:42:29,000<br>we’ll see some micro partitions.</p>
<p>1006<br>00:42:29,000 –&gt; 00:42:31,000<br>Like, there’s all background jobs,</p>
<p>1007<br>00:42:31,000 –&gt; 00:42:32,000<br>you want to run anyway,</p>
<p>1008<br>00:42:32,000 –&gt; 00:42:33,000<br>and you do this when you have downtime.</p>
<p>1009<br>00:42:33,000 –&gt; 00:42:34,000<br>Right?</p>
<p>1010<br>00:42:34,000 –&gt; 00:42:36,000<br>So it’s, the idea is not far fetched.</p>
<p>1011<br>00:42:36,000 –&gt; 00:42:37,000<br>Because again,</p>
<p>1012<br>00:42:37,000 –&gt; 00:42:38,000<br>because they’re in a cloud,</p>
<p>1013<br>00:42:38,000 –&gt; 00:42:39,000<br>this opens up opportunity to,</p>
<p>1014<br>00:42:39,000 –&gt; 00:42:42,000<br>you would not be able to get, uh,</p>
<p>1015<br>00:42:42,000 –&gt; 00:42:45,000<br>uh, easily otherwise.</p>
<p>1016<br>00:42:48,000 –&gt; 00:42:49,000<br>Okay.</p>
<p>1017<br>00:42:49,000 –&gt; 00:42:50,000<br>So as I said before,</p>
<p>1018<br>00:42:50,000 –&gt; 00:42:51,000<br>the,</p>
<p>1019<br>00:42:51,000 –&gt; 00:42:53,000<br>they’re going to rely on some object store,</p>
<p>1020<br>00:42:53,000 –&gt; 00:42:55,000<br>typically, originally S3.</p>
<p>1021<br>00:42:55,000 –&gt; 00:42:56,000<br>Um, but of course,</p>
<p>1022<br>00:42:56,000 –&gt; 00:42:57,000<br>you know, there’s downsides of this,</p>
<p>1023<br>00:42:57,000 –&gt; 00:42:58,000<br>because this can be slower.</p>
<p>1024<br>00:42:58,000 –&gt; 00:43:00,000<br>You have to go make requests over,</p>
<p>1025<br>00:43:00,000 –&gt; 00:43:01,000<br>you know,</p>
<p>1026<br>00:43:02,000 –&gt; 00:43:03,000<br>you can’t do kernel bypass,</p>
<p>1027<br>00:43:03,000 –&gt; 00:43:04,000<br>you got to go over the network,</p>
<p>1028<br>00:43:04,000 –&gt; 00:43:05,000<br>make a HGPS recall,</p>
<p>1029<br>00:43:05,000 –&gt; 00:43:07,000<br>call to their API.</p>
<p>1030<br>00:43:07,000 –&gt; 00:43:08,000<br>That’s got to get encrypted,</p>
<p>1031<br>00:43:08,000 –&gt; 00:43:10,000<br>and decrypt it when it comes back.</p>
<p>1032<br>00:43:10,000 –&gt; 00:43:11,000<br>Right?</p>
<p>1033<br>00:43:11,000 –&gt; 00:43:12,000<br>That’s expensive.</p>
<p>1034<br>00:43:12,000 –&gt; 00:43:13,000<br>We’ll see next week,</p>
<p>1035<br>00:43:13,000 –&gt; 00:43:14,000<br>we talked about a yellow brick</p>
<p>1036<br>00:43:14,000 –&gt; 00:43:15,000<br>that they’re super hardcore about this,</p>
<p>1037<br>00:43:15,000 –&gt; 00:43:17,000<br>and they wrote their own S3 drivers</p>
<p>1038<br>00:43:17,000 –&gt; 00:43:18,000<br>that use kernel bypass</p>
<p>1039<br>00:43:18,000 –&gt; 00:43:19,000<br>to go as fast as possible,</p>
<p>1040<br>00:43:19,000 –&gt; 00:43:20,000<br>talking to S3.</p>
<p>1041<br>00:43:20,000 –&gt; 00:43:22,000<br>I don’t know whether S3 does it,</p>
<p>1042<br>00:43:22,000 –&gt; 00:43:23,000<br>does something similar,</p>
<p>1043<br>00:43:23,000 –&gt; 00:43:25,000<br>but you can imagine they have a lot of money that they could.</p>
<p>1044<br>00:43:25,000 –&gt; 00:43:27,000<br>So instead of what they’re going to do,</p>
<p>1045<br>00:43:27,000 –&gt; 00:43:29,000<br>uh, in Snowflake is that,</p>
<p>1046<br>00:43:30,000 –&gt; 00:43:32,000<br>instead of having to build their own,</p>
<p>1047<br>00:43:32,000 –&gt; 00:43:33,000<br>uh, again, in their,</p>
<p>1048<br>00:43:33,000 –&gt; 00:43:34,000<br>in their novice store,</p>
<p>1049<br>00:43:34,000 –&gt; 00:43:35,000<br>or their own storage layer,</p>
<p>1050<br>00:43:35,000 –&gt; 00:43:37,000<br>they’re just going to build their own cache layer,</p>
<p>1051<br>00:43:37,000 –&gt; 00:43:38,000<br>caching layer on the worker nodes,</p>
<p>1052<br>00:43:38,000 –&gt; 00:43:39,000<br>uh,</p>
<p>1053<br>00:43:39,000 –&gt; 00:43:41,000<br>and make that as fast as possible,</p>
<p>1054<br>00:43:41,000 –&gt; 00:43:42,000<br>because now the benefit is,</p>
<p>1055<br>00:43:42,000 –&gt; 00:43:44,000<br>if they do a really good job caching,</p>
<p>1056<br>00:43:44,000 –&gt; 00:43:47,000<br>they end up paying less money to Amazon</p>
<p>1057<br>00:43:47,000 –&gt; 00:43:49,000<br>because they’re making fewer requests to S3,</p>
<p>1058<br>00:43:49,000 –&gt; 00:43:51,000<br>but it also makes the queries run faster</p>
<p>1059<br>00:43:51,000 –&gt; 00:43:52,000<br>because now you’re,</p>
<p>1060<br>00:43:52,000 –&gt; 00:43:53,000<br>you’re not going to S3.</p>
<p>1061<br>00:43:53,000 –&gt; 00:43:55,000<br>So it’s like a winning-bearing situation for everyone,</p>
<p>1062<br>00:43:55,000 –&gt; 00:43:57,000<br>uh, except maybe Amazon,</p>
<p>1063<br>00:43:57,000 –&gt; 00:43:58,000<br>but like,</p>
<p>1064<br>00:43:58,000 –&gt; 00:43:59,000<br>they have enough money.</p>
<p>1065<br>00:43:59,000 –&gt; 00:44:00,000<br>Like, you know,</p>
<p>1066<br>00:44:00,000 –&gt; 00:44:02,000<br>so I think this was a smart engineering,</p>
<p>1067<br>00:44:02,000 –&gt; 00:44:03,000<br>uh, decision for them to do.</p>
<p>1068<br>00:44:03,000 –&gt; 00:44:07,000<br>So it’s a separate layer of nodes that are just like the cache?</p>
<p>1069<br>00:44:07,000 –&gt; 00:44:08,000<br>No, the, the, the,</p>
<p>1070<br>00:44:08,000 –&gt; 00:44:09,000<br>the question is,</p>
<p>1071<br>00:44:09,000 –&gt; 00:44:10,000<br>is it a separate layer of nodes that are extra cached?</p>
<p>1072<br>00:44:10,000 –&gt; 00:44:11,000<br>No, the worker nodes themselves,</p>
<p>1073<br>00:44:11,000 –&gt; 00:44:12,000<br>have,</p>
<p>1074<br>00:44:12,000 –&gt; 00:44:13,000<br>each have a,</p>
<p>1075<br>00:44:13,000 –&gt; 00:44:14,000<br>have a local cache,</p>
<p>1076<br>00:44:14,000 –&gt; 00:44:15,000<br>right?</p>
<p>1077<br>00:44:15,000 –&gt; 00:44:16,000<br>And then if that cache fills,</p>
<p>1078<br>00:44:16,000 –&gt; 00:44:18,000<br>they can then spill to S3,</p>
<p>1079<br>00:44:18,000 –&gt; 00:44:20,000<br>if it’s like an e-mere result,</p>
<p>1080<br>00:44:20,000 –&gt; 00:44:21,000<br>right?</p>
<p>1081<br>00:44:21,000 –&gt; 00:44:23,000<br>And then they’re going to prioritize,</p>
<p>1082<br>00:44:23,000 –&gt; 00:44:24,000<br>this paper talks about it,</p>
<p>1083<br>00:44:24,000 –&gt; 00:44:25,000<br>I don’t think the paper you guys read</p>
<p>1084<br>00:44:25,000 –&gt; 00:44:26,000<br>talks about it,</p>
<p>1085<br>00:44:26,000 –&gt; 00:44:28,000<br>they prioritize the persistent files,</p>
<p>1086<br>00:44:28,000 –&gt; 00:44:31,000<br>sorry, they’re going to prioritize the enemy results,</p>
<p>1087<br>00:44:31,000 –&gt; 00:44:33,000<br>uh, keeping that local</p>
<p>1088<br>00:44:33,000 –&gt; 00:44:35,000<br>versus going out to,</p>
<p>1089<br>00:44:35,000 –&gt; 00:44:37,000<br>uh, versus maintaining,</p>
<p>1090<br>00:44:37,000 –&gt; 00:44:39,000<br>uh, maintaining their persistent files.</p>
<p>1091<br>00:44:39,000 –&gt; 00:44:40,000<br>Because the enemy results are a femoral,</p>
<p>1092<br>00:44:40,000 –&gt; 00:44:42,000<br>you want to be able to get the map really quickly,</p>
<p>1093<br>00:44:42,000 –&gt; 00:44:43,000<br>make the,</p>
<p>1094<br>00:44:43,000 –&gt; 00:44:44,000<br>make the equation faster,</p>
<p>1095<br>00:44:44,000 –&gt; 00:44:45,000<br>uh,</p>
<p>1096<br>00:44:45,000 –&gt; 00:44:47,000<br>and so you want to use as much as your local storage,</p>
<p>1097<br>00:44:47,000 –&gt; 00:44:49,000<br>and, and your local cache,</p>
<p>1098<br>00:44:49,000 –&gt; 00:44:50,000<br>for those enemy results.</p>
<p>1099<br>00:44:50,000 –&gt; 00:44:52,000<br>And they’re not doing anything fancy,</p>
<p>1100<br>00:44:52,000 –&gt; 00:44:54,000<br>they just talk about how they’re using this LRU</p>
<p>1101<br>00:44:54,000 –&gt; 00:44:55,000<br>to do cache from the present policy,</p>
<p>1102<br>00:44:55,000 –&gt; 00:44:57,000<br>and that’s good enough for,</p>
<p>1103<br>00:44:57,000 –&gt; 00:44:59,000<br>for the work, their environment.</p>
<p>1104<br>00:44:59,000 –&gt; 00:45:00,000<br>Yes.</p>
<p>1105<br>00:45:00,000 –&gt; 00:45:02,000<br>So it’s not like, let’s say traditional local manager,</p>
<p>1106<br>00:45:02,000 –&gt; 00:45:03,000<br>but like it’s still like,</p>
<p>1107<br>00:45:03,000 –&gt; 00:45:04,000<br>sort of a local manager,</p>
<p>1108<br>00:45:04,000 –&gt; 00:45:06,000<br>but instead of like local engineers testing.</p>
<p>1109<br>00:45:06,000 –&gt; 00:45:08,000<br>It’s question, same it is,</p>
<p>1110<br>00:45:08,000 –&gt; 00:45:10,000<br>like it’s,</p>
<p>1111<br>00:45:10,000 –&gt; 00:45:11,000<br>it’s not like a pure,</p>
<p>1112<br>00:45:11,000 –&gt; 00:45:12,000<br>not a traditional local manager,</p>
<p>1113<br>00:45:12,000 –&gt; 00:45:13,000<br>where it’s two layers,</p>
<p>1114<br>00:45:13,000 –&gt; 00:45:15,000<br>either in memory or on disk.</p>
<p>1115<br>00:45:15,000 –&gt; 00:45:16,000<br>It’s multi-leared, yes.</p>
<p>1116<br>00:45:16,000 –&gt; 00:45:17,000<br>It’s either in memory,</p>
<p>1117<br>00:45:17,000 –&gt; 00:45:18,000<br>on disk,</p>
<p>1118<br>00:45:18,000 –&gt; 00:45:20,000<br>or S3.</p>
<p>1119<br>00:45:20,000 –&gt; 00:45:21,000<br>And I think they talk about,</p>
<p>1120<br>00:45:21,000 –&gt; 00:45:23,000<br>at least in this paper,</p>
<p>1121<br>00:45:24,000 –&gt; 00:45:26,000<br>on 2020, this is before,</p>
<p>1122<br>00:45:26,000 –&gt; 00:45:29,000<br>there was this sort of persistent memory work,</p>
<p>1123<br>00:45:29,000 –&gt; 00:45:31,000<br>or devices that Intel was putting out,</p>
<p>1124<br>00:45:31,000 –&gt; 00:45:32,000<br>and that was sort of seen as,</p>
<p>1125<br>00:45:32,000 –&gt; 00:45:34,000<br>as another layer, like you had,</p>
<p>1126<br>00:45:34,000 –&gt; 00:45:35,000<br>you had, you had,</p>
<p>1127<br>00:45:35,000 –&gt; 00:45:36,000<br>DRAM memory,</p>
<p>1128<br>00:45:36,000 –&gt; 00:45:38,000<br>then you would have persistent memory,</p>
<p>1129<br>00:45:38,000 –&gt; 00:45:39,000<br>like Optane,</p>
<p>1130<br>00:45:39,000 –&gt; 00:45:40,000<br>then you had SSD,</p>
<p>1131<br>00:45:40,000 –&gt; 00:45:41,000<br>you know, you would have,</p>
<p>1132<br>00:45:41,000 –&gt; 00:45:43,000<br>and then the S3.</p>
<p>1133<br>00:45:43,000 –&gt; 00:45:44,000<br>Intel kept off the Optane,</p>
<p>1134<br>00:45:44,000 –&gt; 00:45:45,000<br>so that’s not a thing anymore,</p>
<p>1135<br>00:45:45,000 –&gt; 00:45:47,000<br>but they talk about how like, you know,</p>
<p>1136<br>00:45:47,000 –&gt; 00:45:50,000<br>having sort of a holistic view</p>
<p>1137<br>00:45:50,000 –&gt; 00:45:52,000<br>of a multi-level cache,</p>
<p>1138<br>00:45:52,000 –&gt; 00:45:54,000<br>is something that they’re thinking about doing.</p>
<p>1139<br>00:45:59,000 –&gt; 00:46:00,000<br>Okay, so again,</p>
<p>1140<br>00:46:00,000 –&gt; 00:46:01,000<br>the original version of,</p>
<p>1141<br>00:46:01,000 –&gt; 00:46:02,000<br>of snowflake,</p>
<p>1142<br>00:46:02,000 –&gt; 00:46:03,000<br>or I guess by default,</p>
<p>1143<br>00:46:03,000 –&gt; 00:46:05,000<br>when you put, when you put data in snowflake,</p>
<p>1144<br>00:46:05,000 –&gt; 00:46:06,000<br>they’re going to be using their own</p>
<p>1145<br>00:46:06,000 –&gt; 00:46:08,000<br>proprietary storage format.</p>
<p>1146<br>00:46:08,000 –&gt; 00:46:10,000<br>And again, this is before,</p>
<p>1147<br>00:46:10,000 –&gt; 00:46:11,000<br>before, before, orc,</p>
<p>1148<br>00:46:11,000 –&gt; 00:46:12,000<br>but at a high load,</p>
<p>1149<br>00:46:12,000 –&gt; 00:46:13,000<br>it’s going to look,</p>
<p>1150<br>00:46:13,000 –&gt; 00:46:15,000<br>I’ve had students tell me that</p>
<p>1151<br>00:46:15,000 –&gt; 00:46:17,000<br>it looks basically equivalent to Parquet and Orc.</p>
<p>1152<br>00:46:17,000 –&gt; 00:46:18,000<br>Right?</p>
<p>1153<br>00:46:18,000 –&gt; 00:46:19,000<br>It’s using packs,</p>
<p>1154<br>00:46:19,000 –&gt; 00:46:20,000<br>it’s columnar storage,</p>
<p>1155<br>00:46:20,000 –&gt; 00:46:21,000<br>you know,</p>
<p>1156<br>00:46:21,000 –&gt; 00:46:22,000<br>it’s doing dictionary encoding,</p>
<p>1157<br>00:46:22,000 –&gt; 00:46:23,000<br>I think they’re doing,</p>
<p>1158<br>00:46:23,000 –&gt; 00:46:24,000<br>run length encoding.</p>
<p>1159<br>00:46:24,000 –&gt; 00:46:25,000<br>Right? So that,</p>
<p>1160<br>00:46:25,000 –&gt; 00:46:26,000<br>there’s nothing dramatically different,</p>
<p>1161<br>00:46:26,000 –&gt; 00:46:28,000<br>or special about what they’re doing there,</p>
<p>1162<br>00:46:28,000 –&gt; 00:46:29,000<br>other than it’s proprietary to them.</p>
<p>1163<br>00:46:29,000 –&gt; 00:46:30,000<br>Like, you couldn’t,</p>
<p>1164<br>00:46:30,000 –&gt; 00:46:31,000<br>you, they’re not going to give you,</p>
<p>1165<br>00:46:31,000 –&gt; 00:46:32,000<br>like, a binary file in the format,</p>
<p>1166<br>00:46:32,000 –&gt; 00:46:33,000<br>because they wouldn’t have,</p>
<p>1167<br>00:46:33,000 –&gt; 00:46:35,000<br>there’s no readers externally for these things.</p>
<p>1168<br>00:46:35,000 –&gt; 00:46:37,000<br>But then one thing they’re going to do</p>
<p>1169<br>00:46:37,000 –&gt; 00:46:38,000<br>is, for any data that shows up,</p>
<p>1170<br>00:46:38,000 –&gt; 00:46:39,000<br>they’re going to break it up</p>
<p>1171<br>00:46:39,000 –&gt; 00:46:40,000<br>into what they call micropartitions,</p>
<p>1172<br>00:46:40,000 –&gt; 00:46:43,000<br>and I think this is roughly like a,</p>
<p>1173<br>00:46:43,000 –&gt; 00:46:46,000<br>I’m just equivalent to like a row group</p>
<p>1174<br>00:46:46,000 –&gt; 00:46:48,000<br>that we talked about in,</p>
<p>1175<br>00:46:48,000 –&gt; 00:46:49,000<br>in Parquet.</p>
<p>1176<br>00:46:50,000 –&gt; 00:46:52,000<br>And so the original data for micropartition</p>
<p>1177<br>00:46:52,000 –&gt; 00:46:54,000<br>range up to 50 to 500 megs,</p>
<p>1178<br>00:46:54,000 –&gt; 00:46:56,000<br>but after doing all of the compression stuff,</p>
<p>1179<br>00:46:56,000 –&gt; 00:46:59,000<br>including, I think they run like a block-based compression,</p>
<p>1180<br>00:46:59,000 –&gt; 00:47:00,000<br>like snappy or,</p>
<p>1181<br>00:47:00,000 –&gt; 00:47:01,000<br>as the standard,</p>
<p>1182<br>00:47:01,000 –&gt; 00:47:02,000<br>they’ll get each,</p>
<p>1183<br>00:47:02,000 –&gt; 00:47:05,000<br>each micropartition down to 16 megabytes.</p>
<p>1184<br>00:47:05,000 –&gt; 00:47:07,000<br>Then in the background,</p>
<p>1185<br>00:47:07,000 –&gt; 00:47:10,000<br>they’re going to,</p>
<p>1186<br>00:47:10,000 –&gt; 00:47:13,000<br>they’re going to periodically check to see whether the,</p>
<p>1187<br>00:47:13,000 –&gt; 00:47:16,000<br>the clustering of these micropartitions</p>
<p>1188<br>00:47:16,000 –&gt; 00:47:17,000<br>is actually ideal,</p>
<p>1189<br>00:47:17,000 –&gt; 00:47:19,000<br>and they can reorganize and,</p>
<p>1190<br>00:47:19,000 –&gt; 00:47:21,000<br>and resort them based on how,</p>
<p>1191<br>00:47:21,000 –&gt; 00:47:22,000<br>what, what,</p>
<p>1192<br>00:47:22,000 –&gt; 00:47:23,000<br>what, what, what,</p>
<p>1193<br>00:47:23,000 –&gt; 00:47:24,000<br>access key people,</p>
<p>1194<br>00:47:24,000 –&gt; 00:47:26,000<br>people are using for queries.</p>
<p>1195<br>00:47:26,000 –&gt; 00:47:27,000<br>So there’s, there’s,</p>
<p>1196<br>00:47:27,000 –&gt; 00:47:28,000<br>there’s, there’s,</p>
<p>1197<br>00:47:28,000 –&gt; 00:47:30,000<br>extra work that they’re doing in the background</p>
<p>1198<br>00:47:30,000 –&gt; 00:47:31,000<br>to, to optimize the,</p>
<p>1199<br>00:47:31,000 –&gt; 00:47:32,000<br>the, the, the,</p>
<p>1200<br>00:47:32,000 –&gt; 00:47:33,000<br>the storage,</p>
<p>1201<br>00:47:33,000 –&gt; 00:47:35,000<br>when it’s in the proprietary format.</p>
<p>1202<br>00:47:35,000 –&gt; 00:47:37,000<br>And that’s different than we talked about in Databricks</p>
<p>1203<br>00:47:37,000 –&gt; 00:47:38,000<br>and Spark,</p>
<p>1204<br>00:47:38,000 –&gt; 00:47:39,000<br>Spark SQL and,</p>
<p>1205<br>00:47:39,000 –&gt; 00:47:40,000<br>and Dremel,</p>
<p>1206<br>00:47:40,000 –&gt; 00:47:42,000<br>where they just assume that people</p>
<p>1207<br>00:47:42,000 –&gt; 00:47:45,000<br>are putting random files on S3,</p>
<p>1208<br>00:47:45,000 –&gt; 00:47:48,000<br>and they don’t have the ability to go and rewrite them</p>
<p>1209<br>00:47:48,000 –&gt; 00:47:50,000<br>and modify them and reorganize them.</p>
<p>1210<br>00:47:50,000 –&gt; 00:47:51,000<br>And they just had to, you know,</p>
<p>1211<br>00:47:51,000 –&gt; 00:47:54,000<br>run the query on directly as the files as they existed,</p>
<p>1212<br>00:47:54,000 –&gt; 00:47:55,000<br>whereas in, in Snowflake,</p>
<p>1213<br>00:47:55,000 –&gt; 00:47:57,000<br>again, using their internal format,</p>
<p>1214<br>00:47:57,000 –&gt; 00:47:59,000<br>they can use the extra cycles to,</p>
<p>1215<br>00:47:59,000 –&gt; 00:48:02,000<br>to this, this be things up.</p>
<p>1216<br>00:48:02,000 –&gt; 00:48:03,000<br>But we’ll see how they can,</p>
<p>1217<br>00:48:03,000 –&gt; 00:48:05,000<br>you know,</p>
<p>1218<br>00:48:05,000 –&gt; 00:48:06,000<br>they had to support external tables</p>
<p>1219<br>00:48:06,000 –&gt; 00:48:08,000<br>and things where they can’t do this.</p>
<p>1220<br>00:48:08,000 –&gt; 00:48:09,000<br>I’ll talk a little bit about how they,</p>
<p>1221<br>00:48:09,000 –&gt; 00:48:12,000<br>how they handle that.</p>
<p>1222<br>00:48:12,000 –&gt; 00:48:14,000<br>So now, one thing that is interesting</p>
<p>1223<br>00:48:14,000 –&gt; 00:48:17,000<br>about Snowflake’s proprietary format</p>
<p>1224<br>00:48:17,000 –&gt; 00:48:20,000<br>is how they want to handle semi-structured data.</p>
<p>1225<br>00:48:20,000 –&gt; 00:48:24,000<br>And so they have three types that are specific</p>
<p>1226<br>00:48:24,000 –&gt; 00:48:26,000<br>or unique to Snowflake,</p>
<p>1227<br>00:48:26,000 –&gt; 00:48:28,000<br>variant array and object.</p>
<p>1228<br>00:48:28,000 –&gt; 00:48:30,000<br>Variant basically means anything,</p>
<p>1229<br>00:48:30,000 –&gt; 00:48:32,000<br>like any kind of JSON hierarchy or something</p>
<p>1230<br>00:48:32,000 –&gt; 00:48:33,000<br>that wrecks the smell,</p>
<p>1231<br>00:48:33,000 –&gt; 00:48:35,000<br>think of like that.</p>
<p>1232<br>00:48:35,000 –&gt; 00:48:36,000<br>Arrays as the sounds,</p>
<p>1233<br>00:48:36,000 –&gt; 00:48:40,000<br>it’s just an array of values of a arbitrary length.</p>
<p>1234<br>00:48:40,000 –&gt; 00:48:41,000<br>And an object,</p>
<p>1235<br>00:48:41,000 –&gt; 00:48:42,000<br>I think, is,</p>
<p>1236<br>00:48:42,000 –&gt; 00:48:46,000<br>equivalent to the gender of a case of variant</p>
<p>1237<br>00:48:46,000 –&gt; 00:48:49,000<br>where like it’s a single level hierarchy,</p>
<p>1238<br>00:48:49,000 –&gt; 00:48:54,000<br>whereas variant can go any arbitrary length or depth, right?</p>
<p>1239<br>00:48:54,000 –&gt; 00:48:57,000<br>So in the case of the Dremel paper,</p>
<p>1240<br>00:48:57,000 –&gt; 00:48:59,000<br>they talked about how they were trying to process</p>
<p>1241<br>00:48:59,000 –&gt; 00:49:02,000<br>all these protobuff files that were internal to Google.</p>
<p>1242<br>00:49:02,000 –&gt; 00:49:03,000<br>Well, if it’s a protobuff file,</p>
<p>1243<br>00:49:03,000 –&gt; 00:49:04,000<br>you have the schema.</p>
<p>1244<br>00:49:04,000 –&gt; 00:49:07,000<br>You know the data types of the data,</p>
<p>1245<br>00:49:07,000 –&gt; 00:49:09,000<br>the fields that are inside of them,</p>
<p>1246<br>00:49:09,000 –&gt; 00:49:11,000<br>so they know how to convert them</p>
<p>1247<br>00:49:11,000 –&gt; 00:49:13,000<br>into the proper binary format.</p>
<p>1248<br>00:49:13,000 –&gt; 00:49:15,000<br>And doing this shredding or breaking out the separate columns</p>
<p>1249<br>00:49:15,000 –&gt; 00:49:16,000<br>as we talked about.</p>
<p>1250<br>00:49:16,000 –&gt; 00:49:18,000<br>In the case of Databricks and Photon,</p>
<p>1251<br>00:49:18,000 –&gt; 00:49:21,000<br>they didn’t have the schema for these files.</p>
<p>1252<br>00:49:21,000 –&gt; 00:49:23,000<br>So the way they would handle that is</p>
<p>1253<br>00:49:23,000 –&gt; 00:49:25,000<br>while the query was running,</p>
<p>1254<br>00:49:25,000 –&gt; 00:49:27,000<br>that they would do this runtime at activity</p>
<p>1255<br>00:49:27,000 –&gt; 00:49:30,000<br>where they would switch what version of a,</p>
<p>1256<br>00:49:30,000 –&gt; 00:49:33,000<br>of a primitive they would use to say,</p>
<p>1257<br>00:49:33,000 –&gt; 00:49:35,000<br>oh, I know processing, you know,</p>
<p>1258<br>00:49:35,000 –&gt; 00:49:37,000<br>unicode data or ASCII data or date data</p>
<p>1259<br>00:49:37,000 –&gt; 00:49:38,000<br>versus, you know,</p>
<p>1260<br>00:49:38,000 –&gt; 00:49:40,000<br>there’s random numbers, right?</p>
<p>1261<br>00:49:40,000 –&gt; 00:49:43,000<br>And so they were trying to learn why they were running the query,</p>
<p>1262<br>00:49:43,000 –&gt; 00:49:46,000<br>what the data type actually was for these different fields.</p>
<p>1263<br>00:49:46,000 –&gt; 00:49:48,000<br>What Snowflick is going to do,</p>
<p>1264<br>00:49:48,000 –&gt; 00:49:50,000<br>it’s different, is that they’re going to try to figure things out</p>
<p>1265<br>00:49:50,000 –&gt; 00:49:51,000<br>upon ingestion.</p>
<p>1266<br>00:49:51,000 –&gt; 00:49:55,000<br>And again, this is when you use their proprietary format,</p>
<p>1267<br>00:49:55,000 –&gt; 00:49:59,000<br>you’re calling insert into the database</p>
<p>1268<br>00:49:59,000 –&gt; 00:50:01,000<br>or you’re bulk loading some file.</p>
<p>1269<br>00:50:01,000 –&gt; 00:50:03,000<br>So as they’re processing it and putting it into</p>
<p>1270<br>00:50:03,000 –&gt; 00:50:05,000<br>their internal format,</p>
<p>1271<br>00:50:05,000 –&gt; 00:50:07,000<br>they’re going to figure out what is the data type</p>
<p>1272<br>00:50:07,000 –&gt; 00:50:09,000<br>for the different fields.</p>
<p>1273<br>00:50:09,000 –&gt; 00:50:12,000<br>And so they’ll do things like,</p>
<p>1274<br>00:50:12,000 –&gt; 00:50:14,000<br>you know, if you identify your string,</p>
<p>1275<br>00:50:14,000 –&gt; 00:50:17,000<br>like, you know, a year, a month, and the day,</p>
<p>1276<br>00:50:17,000 –&gt; 00:50:19,000<br>well, they would parse that and recognize,</p>
<p>1277<br>00:50:19,000 –&gt; 00:50:21,000<br>oh, this is actually in the proper date format,</p>
<p>1278<br>00:50:21,000 –&gt; 00:50:23,000<br>so then they’ll convert it automatically into,</p>
<p>1279<br>00:50:23,000 –&gt; 00:50:26,000<br>you know, whatever the binary date format or time stamp format is.</p>
<p>1280<br>00:50:26,000 –&gt; 00:50:28,000<br>But they’re always going to maintain</p>
<p>1281<br>00:50:28,000 –&gt; 00:50:30,000<br>the original unparsed version of all the strings</p>
<p>1282<br>00:50:30,000 –&gt; 00:50:32,000<br>in your JSON file or whatever it is,</p>
<p>1283<br>00:50:32,000 –&gt; 00:50:34,000<br>in case they get it wrong,</p>
<p>1284<br>00:50:34,000 –&gt; 00:50:36,000<br>like if someone puts a poop emoji in there</p>
<p>1285<br>00:50:36,000 –&gt; 00:50:38,000<br>and you’re processing it and you’ve got to fall back</p>
<p>1286<br>00:50:38,000 –&gt; 00:50:41,000<br>and say, okay, this is actually not what I thought it was.</p>
<p>1287<br>00:50:41,000 –&gt; 00:50:42,000<br>Right?</p>
<p>1288<br>00:50:42,000 –&gt; 00:50:44,000<br>So again, this is interesting.</p>
<p>1289<br>00:50:44,000 –&gt; 00:50:47,000<br>This is, now you start to see the difference</p>
<p>1290<br>00:50:47,000 –&gt; 00:50:49,000<br>between the different systems.</p>
<p>1291<br>00:50:49,000 –&gt; 00:50:52,000<br>You know, Dremel is doing it in one way,</p>
<p>1292<br>00:50:52,000 –&gt; 00:50:54,000<br>photon does another way, snowflakes are going to do it</p>
<p>1293<br>00:50:54,000 –&gt; 00:50:55,000<br>upon ingestion.</p>
<p>1294<br>00:50:55,000 –&gt; 00:50:57,000<br>And, you know, in a high level,</p>
<p>1295<br>00:50:57,000 –&gt; 00:50:59,000<br>they’re all doing vectorized query execution upon,</p>
<p>1296<br>00:50:59,000 –&gt; 00:51:01,000<br>you know, on an object store,</p>
<p>1297<br>00:51:01,000 –&gt; 00:51:03,000<br>but the low-level details and the nuances of them</p>
<p>1298<br>00:51:03,000 –&gt; 00:51:05,000<br>are going to be slightly different.</p>
<p>1299<br>00:51:05,000 –&gt; 00:51:07,000<br>So I’m not saying that this is a good idea or a bad idea.</p>
<p>1300<br>00:51:07,000 –&gt; 00:51:10,000<br>I think it’s for, if it’s proprietary storage</p>
<p>1301<br>00:51:10,000 –&gt; 00:51:12,000<br>and you can get the data as it comes in,</p>
<p>1302<br>00:51:12,000 –&gt; 00:51:14,000<br>yeah, she should definitely do this because now you don’t need,</p>
<p>1303<br>00:51:14,000 –&gt; 00:51:16,000<br>like, you don’t need to redo this over and over again</p>
<p>1304<br>00:51:16,000 –&gt; 00:51:19,000<br>to figure out what the data type is while you’re running the query.</p>
<p>1305<br>00:51:19,000 –&gt; 00:51:21,000<br>And so you just do this parsing once</p>
<p>1306<br>00:51:21,000 –&gt; 00:51:23,000<br>and you get all the advantages of compression and coding</p>
<p>1307<br>00:51:23,000 –&gt; 00:51:25,000<br>that we talked about before.</p>
<p>1308<br>00:51:25,000 –&gt; 00:51:26,000<br>Yes?</p>
<p>1309<br>00:51:26,000 –&gt; 00:51:28,000<br>So, this is a Dremel question,</p>
<p>1310<br>00:51:28,000 –&gt; 00:51:30,000<br>which now is in Dremel lecture,</p>
<p>1311<br>00:51:30,000 –&gt; 00:51:32,000<br>which is that they were doing it to do it with expensive,</p>
<p>1312<br>00:51:32,000 –&gt; 00:51:34,000<br>because that’s what you do.</p>
<p>1313<br>00:51:34,000 –&gt; 00:51:36,000<br>Is performance games maybe because this,</p>
<p>1314<br>00:51:36,000 –&gt; 00:51:39,000<br>that they have this conversion done for the semi-future,</p>
<p>1315<br>00:51:39,000 –&gt; 00:51:40,000<br>so I’m already…</p>
<p>1316<br>00:51:40,000 –&gt; 00:51:43,000<br>So, your question, the Dremel one was what, that, sorry?</p>
<p>1317<br>00:51:43,000 –&gt; 00:51:45,000<br>Was that in Dremel,</p>
<p>1318<br>00:51:45,000 –&gt; 00:51:47,000<br>that they could take up,</p>
<p>1319<br>00:51:47,000 –&gt; 00:51:50,000<br>that storage place could be anywhere,</p>
<p>1320<br>00:51:50,000 –&gt; 00:51:53,000<br>that it didn’t have to be in a specific format.</p>
<p>1321<br>00:51:53,000 –&gt; 00:51:56,000<br>It could be from S3,</p>
<p>1322<br>00:51:56,000 –&gt; 00:51:57,000<br>and I was like,</p>
<p>1323<br>00:51:57,000 –&gt; 00:51:59,000<br>that there’s extra cost and slope,</p>
<p>1324<br>00:51:59,000 –&gt; 00:52:00,000<br>like, where’s the result over here?</p>
<p>1325<br>00:52:00,000 –&gt; 00:52:01,000<br>And this is the benefit?</p>
<p>1326<br>00:52:01,000 –&gt; 00:52:03,000<br>Yeah, so his question is,</p>
<p>1327<br>00:52:03,000 –&gt; 00:52:04,000<br>when we talk about Dremel,</p>
<p>1328<br>00:52:04,000 –&gt; 00:52:06,000<br>Dremel talked about how,</p>
<p>1329<br>00:52:06,000 –&gt; 00:52:11,000<br>rather than have people put data into a proper scheme of form,</p>
<p>1330<br>00:52:11,000 –&gt; 00:52:13,000<br>where you know these data types,</p>
<p>1331<br>00:52:13,000 –&gt; 00:52:17,000<br>and set all that up ahead of time when you load the data,</p>
<p>1332<br>00:52:17,000 –&gt; 00:52:19,000<br>and then that way the query runs faster,</p>
<p>1333<br>00:52:19,000 –&gt; 00:52:21,000<br>from an engineering and time perspective,</p>
<p>1334<br>00:52:21,000 –&gt; 00:52:22,000<br>from a human side,</p>
<p>1335<br>00:52:22,000 –&gt; 00:52:24,000<br>they were better to just people to store whatever follows they want,</p>
<p>1336<br>00:52:24,000 –&gt; 00:52:26,000<br>and at runtime, the query engine will figure out</p>
<p>1337<br>00:52:26,000 –&gt; 00:52:27,000<br>what the data type is.</p>
<p>1338<br>00:52:27,000 –&gt; 00:52:28,000<br>Yes.</p>
<p>1339<br>00:52:28,000 –&gt; 00:52:29,000<br>So, this is the opposite.</p>
<p>1340<br>00:52:29,000 –&gt; 00:52:30,000<br>This is like,</p>
<p>1341<br>00:52:30,000 –&gt; 00:52:31,000<br>you’ve got to give the data,</p>
<p>1342<br>00:52:31,000 –&gt; 00:52:32,000<br>actually, it’s not exactly the same,</p>
<p>1343<br>00:52:32,000 –&gt; 00:52:33,000<br>because it’s JSON,</p>
<p>1344<br>00:52:33,000 –&gt; 00:52:35,000<br>you could throw any JSON you want in,</p>
<p>1345<br>00:52:35,000 –&gt; 00:52:37,000<br>but then they’re going to figure out</p>
<p>1346<br>00:52:37,000 –&gt; 00:52:38,000<br>when you load it,</p>
<p>1347<br>00:52:38,000 –&gt; 00:52:39,000<br>what the data type is.</p>
<p>1348<br>00:52:39,000 –&gt; 00:52:40,000<br>So, at a high load,</p>
<p>1349<br>00:52:40,000 –&gt; 00:52:41,000<br>they’re achieving the same thing.</p>
<p>1350<br>00:52:41,000 –&gt; 00:52:42,000<br>They’re going to be saying,</p>
<p>1351<br>00:52:42,000 –&gt; 00:52:43,000<br>like, okay, throw a word of data out,</p>
<p>1352<br>00:52:43,000 –&gt; 00:52:44,000<br>we’ll figure it out.</p>
<p>1353<br>00:52:44,000 –&gt; 00:52:45,000<br>Snowflake’s going to figure it out,</p>
<p>1354<br>00:52:45,000 –&gt; 00:52:47,000<br>when it’s inserted,</p>
<p>1355<br>00:52:47,000 –&gt; 00:52:50,000<br>Dremel figures it out while it’s running.</p>
<p>1356<br>00:52:50,000 –&gt; 00:52:51,000<br>But again,</p>
<p>1357<br>00:52:51,000 –&gt; 00:52:54,000<br>if it’s parquet files or whatever,</p>
<p>1358<br>00:52:54,000 –&gt; 00:52:56,000<br>random JSON files in S3,</p>
<p>1359<br>00:52:56,000 –&gt; 00:52:57,000<br>and it’s not in your proprietary format,</p>
<p>1360<br>00:52:57,000 –&gt; 00:52:59,000<br>then you’ve got to do what Dremel does,</p>
<p>1361<br>00:52:59,000 –&gt; 00:53:00,000<br>or photon is.</p>
<p>1362<br>00:53:00,000 –&gt; 00:53:02,000<br>You kind of need,</p>
<p>1363<br>00:53:02,000 –&gt; 00:53:03,000<br>ideally, both.</p>
<p>1364<br>00:53:03,000 –&gt; 00:53:04,000<br>But if you know,</p>
<p>1365<br>00:53:04,000 –&gt; 00:53:05,000<br>most of your data is not going to be</p>
<p>1366<br>00:53:05,000 –&gt; 00:53:07,000<br>inserted directly into your file format,</p>
<p>1367<br>00:53:07,000 –&gt; 00:53:09,000<br>you need to do what Dremel does.</p>
<p>1368<br>00:53:13,000 –&gt; 00:53:14,000<br>All right, so the cases</p>
<p>1369<br>00:53:14,000 –&gt; 00:53:15,000<br>that I mentioned before,</p>
<p>1370<br>00:53:15,000 –&gt; 00:53:17,000<br>again, this is how they’re going to use to,</p>
<p>1371<br>00:53:17,000 –&gt; 00:53:19,000<br>this is how they’re going to organize</p>
<p>1372<br>00:53:19,000 –&gt; 00:53:21,000<br>this system to figure out what worker nodes are,</p>
<p>1373<br>00:53:21,000 –&gt; 00:53:22,000<br>you know, quote unquote,</p>
<p>1374<br>00:53:22,000 –&gt; 00:53:23,000<br>responsible,</p>
<p>1375<br>00:53:23,000 –&gt; 00:53:28,000<br>or the owners of a micropartition file for a table.</p>
<p>1376<br>00:53:29,000 –&gt; 00:53:31,000<br>I recovered consistent hashing in the,</p>
<p>1377<br>00:53:31,000 –&gt; 00:53:32,000<br>in the intro class.</p>
<p>1378<br>00:53:32,000 –&gt; 00:53:36,000<br>The basic idea is that it’s a ring of a bunch of nodes,</p>
<p>1379<br>00:53:36,000 –&gt; 00:53:39,000<br>and you can insert a new entry into the ring,</p>
<p>1380<br>00:53:39,000 –&gt; 00:53:42,000<br>and only move the files from its predecessor,</p>
<p>1381<br>00:53:42,000 –&gt; 00:53:45,000<br>and not reshuffle everything as if you were just doing,</p>
<p>1382<br>00:53:45,000 –&gt; 00:53:47,000<br>sort of naive hashing.</p>
<p>1383<br>00:53:47,000 –&gt; 00:53:49,000<br>So that means that when it query shows up,</p>
<p>1384<br>00:53:49,000 –&gt; 00:53:51,000<br>the catalog is going to look at this,</p>
<p>1385<br>00:53:51,000 –&gt; 00:53:52,000<br>this hash table,</p>
<p>1386<br>00:53:52,000 –&gt; 00:53:54,000<br>figure out what file,</p>
<p>1387<br>00:53:54,000 –&gt; 00:53:55,000<br>what workers or sounds for,</p>
<p>1388<br>00:53:55,000 –&gt; 00:53:56,000<br>what files,</p>
<p>1389<br>00:53:56,000 –&gt; 00:53:58,000<br>and then when it hands up the task,</p>
<p>1390<br>00:53:58,000 –&gt; 00:53:59,000<br>it tells them,</p>
<p>1391<br>00:53:59,000 –&gt; 00:54:00,000<br>okay, here’s the files you need to process,</p>
<p>1392<br>00:54:00,000 –&gt; 00:54:01,000<br>and it knows which ones,</p>
<p>1393<br>00:54:01,000 –&gt; 00:54:03,000<br>you know, which ones, you know,</p>
<p>1394<br>00:54:03,000 –&gt; 00:54:04,000<br>can compute that data,</p>
<p>1395<br>00:54:04,000 –&gt; 00:54:06,000<br>and it knows that the likelihood that they’ll have</p>
<p>1396<br>00:54:06,000 –&gt; 00:54:07,000<br>locally cache data,</p>
<p>1397<br>00:54:07,000 –&gt; 00:54:09,000<br>because the worker node,</p>
<p>1398<br>00:54:09,000 –&gt; 00:54:11,000<br>that’s responsible for some persistent file,</p>
<p>1399<br>00:54:11,000 –&gt; 00:54:13,000<br>is the only one that can maintain</p>
<p>1400<br>00:54:13,000 –&gt; 00:54:16,000<br>a long-term cache of that data.</p>
<p>1401<br>00:54:18,000 –&gt; 00:54:19,000<br>And then you compute nodes,</p>
<p>1402<br>00:54:19,000 –&gt; 00:54:21,000<br>which they say their customers do all the time,</p>
<p>1403<br>00:54:21,000 –&gt; 00:54:23,000<br>then you don’t have to,</p>
<p>1404<br>00:54:23,000 –&gt; 00:54:24,000<br>you know,</p>
<p>1405<br>00:54:24,000 –&gt; 00:54:26,000<br>you don’t have to get everything,</p>
<p>1406<br>00:54:26,000 –&gt; 00:54:28,000<br>get everything all over again from S3,</p>
<p>1407<br>00:54:28,000 –&gt; 00:54:30,000<br>or pass every work on all their files around,</p>
<p>1408<br>00:54:30,000 –&gt; 00:54:32,000<br>you can just go retrieve things,</p>
<p>1409<br>00:54:32,000 –&gt; 00:54:35,000<br>and a more fine grain manner.</p>
<p>1410<br>00:54:35,000 –&gt; 00:54:37,000<br>So this part is unique to Snowflake.</p>
<p>1411<br>00:54:37,000 –&gt; 00:54:38,000<br>I think this part is clever,</p>
<p>1412<br>00:54:38,000 –&gt; 00:54:39,000<br>and this is the right way to do this,</p>
<p>1413<br>00:54:39,000 –&gt; 00:54:40,000<br>if you’re going to build a,</p>
<p>1414<br>00:54:40,000 –&gt; 00:54:41,000<br>you know, sort of,</p>
<p>1415<br>00:54:41,000 –&gt; 00:54:43,000<br>a no-level system like this.</p>
<p>1416<br>00:54:45,000 –&gt; 00:54:46,000<br>All right, so the query optimizer,</p>
<p>1417<br>00:54:46,000 –&gt; 00:54:48,000<br>it’s going to be a unified cascade style,</p>
<p>1418<br>00:54:48,000 –&gt; 00:54:50,000<br>doing top-down optimization.</p>
<p>1419<br>00:54:51,000 –&gt; 00:54:52,000<br>If you go read,</p>
<p>1420<br>00:54:52,000 –&gt; 00:54:53,000<br>I think in the paper you guys read,</p>
<p>1421<br>00:54:53,000 –&gt; 00:54:55,000<br>and if you go read the documentation,</p>
<p>1422<br>00:54:55,000 –&gt; 00:54:57,000<br>they’re going to refer to the query optimizer</p>
<p>1423<br>00:54:57,000 –&gt; 00:54:58,000<br>as the compiler.</p>
<p>1424<br>00:54:58,000 –&gt; 00:54:59,000<br>And as I said before,</p>
<p>1425<br>00:54:59,000 –&gt; 00:55:01,000<br>that’s a remnant of, like,</p>
<p>1426<br>00:55:01,000 –&gt; 00:55:03,000<br>the vernacular from the 1970s,</p>
<p>1427<br>00:55:03,000 –&gt; 00:55:05,000<br>because when people sort of built a first-seq compiler,</p>
<p>1428<br>00:55:05,000 –&gt; 00:55:07,000<br>it was taking a high-level language like C</p>
<p>1429<br>00:55:07,000 –&gt; 00:55:08,000<br>and converting it to assembly.</p>
<p>1430<br>00:55:08,000 –&gt; 00:55:09,000<br>Same idea.</p>
<p>1431<br>00:55:09,000 –&gt; 00:55:10,000<br>And in SQL,</p>
<p>1432<br>00:55:10,000 –&gt; 00:55:11,000<br>you’re taking a high-level language like SQL,</p>
<p>1433<br>00:55:11,000 –&gt; 00:55:13,000<br>and converting it to the machine code</p>
<p>1434<br>00:55:13,000 –&gt; 00:55:16,000<br>or the executable code of a database system.</p>
<p>1435<br>00:55:16,000 –&gt; 00:55:18,000<br>So for, you know,</p>
<p>1436<br>00:55:18,000 –&gt; 00:55:19,000<br>for historical reasons,</p>
<p>1437<br>00:55:20,000 –&gt; 00:55:21,000<br>oracle, sorry,</p>
<p>1438<br>00:55:21,000 –&gt; 00:55:23,000<br>still looks and call their thing a compiler.</p>
<p>1439<br>00:55:23,000 –&gt; 00:55:26,000<br>So, they’re not going to rely on,</p>
<p>1440<br>00:55:26,000 –&gt; 00:55:30,000<br>just like Dremel and Databricks and Photon,</p>
<p>1441<br>00:55:30,000 –&gt; 00:55:31,000<br>like, they’re not,</p>
<p>1442<br>00:55:31,000 –&gt; 00:55:33,000<br>they’re soon they’re not going to have GoSys 6.</p>
<p>1443<br>00:55:33,000 –&gt; 00:55:35,000<br>Either because, I mean,</p>
<p>1444<br>00:55:35,000 –&gt; 00:55:36,000<br>in the paper you guys read,</p>
<p>1445<br>00:55:36,000 –&gt; 00:55:37,000<br>is before they had external tables,</p>
<p>1446<br>00:55:37,000 –&gt; 00:55:38,000<br>but like,</p>
<p>1447<br>00:55:38,000 –&gt; 00:55:40,000<br>if it’s external tables,</p>
<p>1448<br>00:55:40,000 –&gt; 00:55:42,000<br>you know nothing about potentially about the files.</p>
<p>1449<br>00:55:42,000 –&gt; 00:55:43,000<br>But even if you,</p>
<p>1450<br>00:55:43,000 –&gt; 00:55:44,000<br>if it’s data been sorted</p>
<p>1451<br>00:55:44,000 –&gt; 00:55:45,000<br>and you’re in proprietary storage,</p>
<p>1452<br>00:55:45,000 –&gt; 00:55:47,000<br>they assume that all the stats are going to be garbage,</p>
<p>1453<br>00:55:48,000 –&gt; 00:55:50,000<br>and it can be changing and become stale over time,</p>
<p>1454<br>00:55:50,000 –&gt; 00:55:52,000<br>that they’re going to have their optimizer</p>
<p>1455<br>00:55:52,000 –&gt; 00:55:54,000<br>try to operate as much as possible,</p>
<p>1456<br>00:55:54,000 –&gt; 00:55:55,000<br>make decisions as much as possible,</p>
<p>1457<br>00:55:56,000 –&gt; 00:55:59,000<br>without relying on high-quality statistics.</p>
<p>1458<br>00:55:59,000 –&gt; 00:56:01,000<br>So they use some of the heuristic-based techniques</p>
<p>1459<br>00:56:01,000 –&gt; 00:56:02,000<br>we talked about before,</p>
<p>1460<br>00:56:02,000 –&gt; 00:56:03,000<br>like,</p>
<p>1461<br>00:56:03,000 –&gt; 00:56:04,000<br>if it’s a star schema,</p>
<p>1462<br>00:56:04,000 –&gt; 00:56:05,000<br>do certain things,</p>
<p>1463<br>00:56:05,000 –&gt; 00:56:07,000<br>versus other organizations,</p>
<p>1464<br>00:56:07,000 –&gt; 00:56:08,000<br>of the schema.</p>
<p>1465<br>00:56:09,000 –&gt; 00:56:10,000<br>But the optimizer’s big,</p>
<p>1466<br>00:56:10,000 –&gt; 00:56:13,000<br>the big goal that it’s trying to achieve in the beginning,</p>
<p>1467<br>00:56:13,000 –&gt; 00:56:15,000<br>is trying to decide which micro-partitions are files</p>
<p>1468<br>00:56:16,000 –&gt; 00:56:17,000<br>that it can throw away,</p>
<p>1469<br>00:56:17,000 –&gt; 00:56:18,000<br>as soon as possible,</p>
<p>1470<br>00:56:18,000 –&gt; 00:56:20,000<br>before it even starts running.</p>
<p>1471<br>00:56:20,000 –&gt; 00:56:22,000<br>And again, if you have some basic stats,</p>
<p>1472<br>00:56:22,000 –&gt; 00:56:23,000<br>like some zone maps,</p>
<p>1473<br>00:56:23,000 –&gt; 00:56:24,000<br>that’ll scroll up in the catalog,</p>
<p>1474<br>00:56:24,000 –&gt; 00:56:25,000<br>you can say,</p>
<p>1475<br>00:56:25,000 –&gt; 00:56:26,000<br>well, I can look at my query plan,</p>
<p>1476<br>00:56:26,000 –&gt; 00:56:27,000<br>I can look at my predicates and decide,</p>
<p>1477<br>00:56:27,000 –&gt; 00:56:28,000<br>these are the files that I know</p>
<p>1478<br>00:56:28,000 –&gt; 00:56:30,000<br>could never have the data that I’m actually needing,</p>
<p>1479<br>00:56:30,000 –&gt; 00:56:31,000<br>I could ever need,</p>
<p>1480<br>00:56:31,000 –&gt; 00:56:34,000<br>and therefore go ahead and skip it.</p>
<p>1481<br>00:56:34,000 –&gt; 00:56:36,000<br>And like the other systems we talked about,</p>
<p>1482<br>00:56:36,000 –&gt; 00:56:37,000<br>they’re not staying rely on,</p>
<p>1483<br>00:56:37,000 –&gt; 00:56:39,000<br>runtime activity to adjust their query plans,</p>
<p>1484<br>00:56:39,000 –&gt; 00:56:40,000<br>as needed.</p>
<p>1485<br>00:56:40,000 –&gt; 00:56:42,000<br>And we’ll look at one example,</p>
<p>1486<br>00:56:42,000 –&gt; 00:56:43,000<br>what they’re doing.</p>
<p>1487<br>00:56:45,000 –&gt; 00:56:48,000<br>So if you go through and insert data to snowflake</p>
<p>1488<br>00:56:48,000 –&gt; 00:56:49,000<br>using the, again,</p>
<p>1489<br>00:56:49,000 –&gt; 00:56:50,000<br>that ends up in the proprietary format,</p>
<p>1490<br>00:56:50,000 –&gt; 00:56:52,000<br>they are going to have some basic stats,</p>
<p>1491<br>00:56:52,000 –&gt; 00:56:55,000<br>but it’s going to be simple things like zone maps,</p>
<p>1492<br>00:56:55,000 –&gt; 00:56:56,000<br>minmax,</p>
<p>1493<br>00:56:56,000 –&gt; 00:56:58,000<br>and ranges within the,</p>
<p>1494<br>00:56:58,000 –&gt; 00:57:00,000<br>within each column.</p>
<p>1495<br>00:57:00,000 –&gt; 00:57:02,000<br>They’re not going to maintain any histograms,</p>
<p>1496<br>00:57:02,000 –&gt; 00:57:05,000<br>and they’re not going to maintain any sketches.</p>
<p>1497<br>00:57:05,000 –&gt; 00:57:06,000<br>Right?</p>
<p>1498<br>00:57:06,000 –&gt; 00:57:08,000<br>And the, the data is,</p>
<p>1499<br>00:57:08,000 –&gt; 00:57:10,000<br>you only get this when you’re using there,</p>
<p>1500<br>00:57:10,000 –&gt; 00:57:12,000<br>and they’re in proprietary format.</p>
<p>1501<br>00:57:12,000 –&gt; 00:57:13,000<br>So they have some,</p>
<p>1502<br>00:57:13,000 –&gt; 00:57:15,000<br>some really basic information,</p>
<p>1503<br>00:57:15,000 –&gt; 00:57:17,000<br>and instead at runtime,</p>
<p>1504<br>00:57:17,000 –&gt; 00:57:18,000<br>they’re going to have triggers that decide,</p>
<p>1505<br>00:57:18,000 –&gt; 00:57:20,000<br>should they adjust things,</p>
<p>1506<br>00:57:20,000 –&gt; 00:57:23,000<br>as needed.</p>
<p>1507<br>00:57:23,000 –&gt; 00:57:25,000<br>But one of the challenges that they’re going to face is that,</p>
<p>1508<br>00:57:25,000 –&gt; 00:57:27,000<br>and this, this is,</p>
<p>1509<br>00:57:27,000 –&gt; 00:57:28,000<br>a bit of a nuanced topic,</p>
<p>1510<br>00:57:28,000 –&gt; 00:57:31,000<br>that only comes out if you’re actually building a query optimizer,</p>
<p>1511<br>00:57:31,000 –&gt; 00:57:33,000<br>is that,</p>
<p>1512<br>00:57:33,000 –&gt; 00:57:36,000<br>if you need to figure out what micro-partitions you need to,</p>
<p>1513<br>00:57:36,000 –&gt; 00:57:38,000<br>skip,</p>
<p>1514<br>00:57:38,000 –&gt; 00:57:40,000<br>based on the statistics that you do have,</p>
<p>1515<br>00:57:40,000 –&gt; 00:57:42,000<br>then now you’ve got to start reasing about</p>
<p>1516<br>00:57:42,000 –&gt; 00:57:44,000<br>what your expressions look like to decide,</p>
<p>1517<br>00:57:44,000 –&gt; 00:57:46,000<br>whether they satisfy or not,</p>
<p>1518<br>00:57:46,000 –&gt; 00:57:48,000<br>the, you know,</p>
<p>1519<br>00:57:48,000 –&gt; 00:57:50,000<br>whether micro-partition could,</p>
<p>1520<br>00:57:50,000 –&gt; 00:57:52,000<br>potentially satisfy any data</p>
<p>1521<br>00:57:52,000 –&gt; 00:57:54,000<br>that may be used by this query.</p>
<p>1522<br>00:57:54,000 –&gt; 00:57:55,000<br>Right?</p>
<p>1523<br>00:57:55,000 –&gt; 00:57:56,000<br>So simple things like, you know,</p>
<p>1524<br>00:57:56,000 –&gt; 00:57:57,000<br>where column,</p>
<p>1525<br>00:57:57,000 –&gt; 00:57:58,000<br>greater than 1, 2, 3, 4,</p>
<p>1526<br>00:57:58,000 –&gt; 00:57:59,000<br>so single column by itself,</p>
<p>1527<br>00:57:59,000 –&gt; 00:58:02,000<br>yeah, you could use the minmax ranges within your zone maps,</p>
<p>1528<br>00:58:02,000 –&gt; 00:58:04,000<br>and each, each micro-partition to figure that out.</p>
<p>1529<br>00:58:04,000 –&gt; 00:58:07,000<br>But when you start doing more complex expressions,</p>
<p>1530<br>00:58:07,000 –&gt; 00:58:10,000<br>the column 1 plus column 2 is greater than 1, 2, 3, 4.</p>
<p>1531<br>00:58:10,000 –&gt; 00:58:14,000<br>Now you’ve got kind of to evaluate this thing and figure out what it actually is.</p>
<p>1532<br>00:58:14,000 –&gt; 00:58:16,000<br>Right?</p>
<p>1533<br>00:58:16,000 –&gt; 00:58:18,000<br>Or if you have, like, a function like this,</p>
<p>1534<br>00:58:18,000 –&gt; 00:58:20,000<br>truncate the date, extract the year,</p>
<p>1535<br>00:58:20,000 –&gt; 00:58:22,000<br>and see whether it equals 2024,</p>
<p>1536<br>00:58:22,000 –&gt; 00:58:25,000<br>if you’re just looking blindly at, you know,</p>
<p>1537<br>00:58:25,000 –&gt; 00:58:28,000<br>without understanding the semantics of what this is actually doing,</p>
<p>1538<br>00:58:28,000 –&gt; 00:58:31,000<br>like, how could you actually ever reason about this?</p>
<p>1539<br>00:58:31,000 –&gt; 00:58:34,000<br>We’ve got to go execute this function.</p>
<p>1540<br>00:58:34,000 –&gt; 00:58:35,000<br>Right? So that you,</p>
<p>1541<br>00:58:35,000 –&gt; 00:58:37,000<br>would you really want to do with,</p>
<p>1542<br>00:58:37,000 –&gt; 00:58:38,000<br>would you really want to do with,</p>
<p>1543<br>00:58:38,000 –&gt; 00:58:41,000<br>would you write it into something like this?</p>
<p>1544<br>00:58:41,000 –&gt; 00:58:46,000<br>So they talk about how they have,</p>
<p>1545<br>00:58:46,000 –&gt; 00:58:47,000<br>rather than having sort of,</p>
<p>1546<br>00:58:47,000 –&gt; 00:58:48,000<br>sort of, two separate code bases,</p>
<p>1547<br>00:58:48,000 –&gt; 00:58:52,000<br>one for, like, expression evaluation that’s abused at runtime for,</p>
<p>1548<br>00:58:52,000 –&gt; 00:58:53,000<br>you know, from your own queries,</p>
<p>1549<br>00:58:53,000 –&gt; 00:58:55,000<br>an expression evaluation within the,</p>
<p>1550<br>00:58:55,000 –&gt; 00:58:56,000<br>the optimizer itself,</p>
<p>1551<br>00:58:56,000 –&gt; 00:58:59,000<br>they try to leverage that same code base</p>
<p>1552<br>00:58:59,000 –&gt; 00:59:02,000<br>to be able to reuse them,</p>
<p>1553<br>00:59:02,000 –&gt; 00:59:04,000<br>so that you always have,</p>
<p>1554<br>00:59:04,000 –&gt; 00:59:05,000<br>guaranteed to have the same semantics.</p>
<p>1555<br>00:59:05,000 –&gt; 00:59:09,000<br>Except that you need to be mindful that you’re not actually processing real data,</p>
<p>1556<br>00:59:09,000 –&gt; 00:59:10,000<br>or even sampled data,</p>
<p>1557<br>00:59:10,000 –&gt; 00:59:13,000<br>you’re trying to reason about what’s actually inside of,</p>
<p>1558<br>00:59:13,000 –&gt; 00:59:16,000<br>you know, what the expression actually could possibly do.</p>
<p>1559<br>00:59:16,000 –&gt; 00:59:18,000<br>And again, this seems like,</p>
<p>1560<br>00:59:18,000 –&gt; 00:59:20,000<br>it seems like a true one matter,</p>
<p>1561<br>00:59:20,000 –&gt; 00:59:21,000<br>but from engineering perspective,</p>
<p>1562<br>00:59:21,000 –&gt; 00:59:22,000<br>it’s actually quite difficult,</p>
<p>1563<br>00:59:22,000 –&gt; 00:59:23,000<br>because you have to deal with, like,</p>
<p>1564<br>00:59:23,000 –&gt; 00:59:27,000<br>you know, the null semantics of what data actually could be.</p>
<p>1565<br>00:59:27,000 –&gt; 00:59:28,000<br>Right?</p>
<p>1566<br>00:59:28,000 –&gt; 00:59:30,000<br>Like, in the case of,</p>
<p>1567<br>00:59:30,000 –&gt; 00:59:34,000<br>I know, once it’s like my sequel,</p>
<p>1568<br>00:59:34,000 –&gt; 00:59:37,000<br>what they do is when they see, like, a nested query,</p>
<p>1569<br>00:59:37,000 –&gt; 00:59:41,000<br>in some cases, if it’s a nested query that should produce a scalar,</p>
<p>1570<br>00:59:41,000 –&gt; 00:59:43,000<br>though inside of the query optimizer,</p>
<p>1571<br>00:59:43,000 –&gt; 00:59:45,000<br>the little stop query optimization,</p>
<p>1572<br>00:59:45,000 –&gt; 00:59:48,000<br>go run that query, right?</p>
<p>1573<br>00:59:48,000 –&gt; 00:59:49,000<br>Like, one plus one equals two.</p>
<p>1574<br>00:59:49,000 –&gt; 00:59:51,000<br>Run that query in the execution engine,</p>
<p>1575<br>00:59:51,000 –&gt; 00:59:52,000<br>get back the result,</p>
<p>1576<br>00:59:52,000 –&gt; 00:59:55,000<br>and then inject that back in the query plan.</p>
<p>1577<br>00:59:55,000 –&gt; 00:59:58,000<br>And then you don’t, then you have the constant value.</p>
<p>1578<br>00:59:58,000 –&gt; 00:59:59,000<br>That’s an extreme case,</p>
<p>1579<br>00:59:59,000 –&gt; 01:00:00,000<br>but again, that’s,</p>
<p>1580<br>01:00:00,000 –&gt; 01:00:01,000<br>because they don’t have a way to,</p>
<p>1581<br>01:00:01,000 –&gt; 01:00:03,000<br>to evaluate expressions directly within the query,</p>
<p>1582<br>01:00:03,000 –&gt; 01:00:06,000<br>at least, these are a few years ago,</p>
<p>1583<br>01:00:06,000 –&gt; 01:00:08,000<br>directly in the query optimizer,</p>
<p>1584<br>01:00:08,000 –&gt; 01:00:11,000<br>you can only use the execution engine within, you know,</p>
<p>1585<br>01:00:11,000 –&gt; 01:00:12,000<br>within my sequel itself.</p>
<p>1586<br>01:00:12,000 –&gt; 01:00:13,000<br>So, again,</p>
<p>1587<br>01:00:13,000 –&gt; 01:00:15,000<br>to avoid having to go run some queries,</p>
<p>1588<br>01:00:15,000 –&gt; 01:00:17,000<br>go figure out how to plan this query,</p>
<p>1589<br>01:00:17,000 –&gt; 01:00:18,000<br>they have a way to,</p>
<p>1590<br>01:00:18,000 –&gt; 01:00:22,000<br>to, to repackage the expression evaluation engine,</p>
<p>1591<br>01:00:22,000 –&gt; 01:00:25,000<br>to something that can be leveraged on top of, uh,</p>
<p>1592<br>01:00:25,000 –&gt; 01:00:26,000<br>statistics.</p>
<p>1593<br>01:00:31,000 –&gt; 01:00:32,000<br>Again, I don’t, again,</p>
<p>1594<br>01:00:32,000 –&gt; 01:00:34,000<br>I’m being, but the hand wave here, like,</p>
<p>1595<br>01:00:34,000 –&gt; 01:00:35,000<br>this is hard.</p>
<p>1596<br>01:00:35,000 –&gt; 01:00:36,000<br>Trust me.</p>
<p>1597<br>01:00:36,000 –&gt; 01:00:37,000<br>Um,</p>
<p>1598<br>01:00:37,000 –&gt; 01:00:40,000<br>and the cosmodel team should surely tell you this.</p>
<p>1599<br>01:00:40,000 –&gt; 01:00:42,000<br>Okay, so the one-up,</p>
<p>1600<br>01:00:42,000 –&gt; 01:00:44,000<br>adaption optimization that they’re going to do,</p>
<p>1601<br>01:00:44,000 –&gt; 01:00:46,000<br>uh, that I don’t think is unique to snowflake,</p>
<p>1602<br>01:00:46,000 –&gt; 01:00:47,000<br>but they, they make a big deal about it.</p>
<p>1603<br>01:00:47,000 –&gt; 01:00:48,000<br>Um, that’s kind of cool.</p>
<p>1604<br>01:00:48,000 –&gt; 01:00:51,000<br>It’s able to do, uh, aggregation push down.</p>
<p>1605<br>01:00:51,000 –&gt; 01:00:54,000<br>So, after they figure out the join order,</p>
<p>1606<br>01:00:54,000 –&gt; 01:00:56,000<br>uh, using some basic heuristics,</p>
<p>1607<br>01:00:56,000 –&gt; 01:00:59,000<br>uh, basic cosmodel estimates in,</p>
<p>1608<br>01:00:59,000 –&gt; 01:01:01,000<br>in, uh, in the query optimizer,</p>
<p>1609<br>01:01:01,000 –&gt; 01:01:04,000<br>they then want to decide when is it appropriate</p>
<p>1610<br>01:01:04,000 –&gt; 01:01:07,000<br>to push down aggregations below the joints.</p>
<p>1611<br>01:01:07,000 –&gt; 01:01:10,000<br>And you want to do this when you recognize things that,</p>
<p>1612<br>01:01:10,000 –&gt; 01:01:12,000<br>the, the amount of data that I,</p>
<p>1613<br>01:01:12,000 –&gt; 01:01:14,000<br>I may be processing for the join, uh,</p>
<p>1614<br>01:01:14,000 –&gt; 01:01:16,000<br>could be reduced significantly,</p>
<p>1615<br>01:01:16,000 –&gt; 01:01:18,000<br>if I do look a partial aggregation right below,</p>
<p>1616<br>01:01:18,000 –&gt; 01:01:20,000<br>the, uh, uh,</p>
<p>1617<br>01:01:20,000 –&gt; 01:01:21,000<br>uh, right below the join,</p>
<p>1618<br>01:01:21,000 –&gt; 01:01:23,000<br>and then some things up again, down below.</p>
<p>1619<br>01:01:23,000 –&gt; 01:01:25,000<br>So in this case here,</p>
<p>1620<br>01:01:25,000 –&gt; 01:01:27,000<br>they could recognize that this aggregation could actually be,</p>
<p>1621<br>01:01:27,000 –&gt; 01:01:29,000<br>partially computed on the,</p>
<p>1622<br>01:01:29,000 –&gt; 01:01:30,000<br>on this side here,</p>
<p>1623<br>01:01:30,000 –&gt; 01:01:31,000<br>on the probe side of this join.</p>
<p>1624<br>01:01:31,000 –&gt; 01:01:33,000<br>And then now when I do the join,</p>
<p>1625<br>01:01:33,000 –&gt; 01:01:35,000<br>I’m just joining on the aggregation key,</p>
<p>1626<br>01:01:35,000 –&gt; 01:01:37,000<br>rather than all possible keys that,</p>
<p>1627<br>01:01:37,000 –&gt; 01:01:39,000<br>that, that, that are coming out of this table scan.</p>
<p>1628<br>01:01:39,000 –&gt; 01:01:40,000<br>So in this case here,</p>
<p>1629<br>01:01:40,000 –&gt; 01:01:42,000<br>I pushed down the table scan,</p>
<p>1630<br>01:01:42,000 –&gt; 01:01:43,000<br>aggregation child,</p>
<p>1631<br>01:01:43,000 –&gt; 01:01:46,000<br>and then update the top one to aggregation parent.</p>
<p>1632<br>01:01:46,000 –&gt; 01:01:48,000<br>And you do this for some things very easily,</p>
<p>1633<br>01:01:48,000 –&gt; 01:01:49,000<br>like if the mid and max,</p>
<p>1634<br>01:01:49,000 –&gt; 01:01:50,000<br>you know, in that case,</p>
<p>1635<br>01:01:50,000 –&gt; 01:01:51,000<br>like there’s not,</p>
<p>1636<br>01:01:51,000 –&gt; 01:01:52,000<br>you know, word about duplicates,</p>
<p>1637<br>01:01:52,000 –&gt; 01:01:53,000<br>but for some,</p>
<p>1638<br>01:01:53,000 –&gt; 01:01:54,000<br>and counts and averages,</p>
<p>1639<br>01:01:54,000 –&gt; 01:01:55,000<br>you need, you need to count for that.</p>
<p>1640<br>01:01:55,000 –&gt; 01:01:56,000<br>And so the aggregation is,</p>
<p>1641<br>01:01:56,000 –&gt; 01:01:57,000<br>at the top,</p>
<p>1642<br>01:01:57,000 –&gt; 01:01:58,000<br>the parent one,</p>
<p>1643<br>01:01:58,000 –&gt; 01:02:00,000<br>is, is, is a, is a bit more tricky to do.</p>
<p>1644<br>01:02:00,000 –&gt; 01:02:02,000<br>And so the, what are they going to do?</p>
<p>1645<br>01:02:02,000 –&gt; 01:02:03,000<br>This is that they’re always,</p>
<p>1646<br>01:02:03,000 –&gt; 01:02:04,000<br>under the right conditions,</p>
<p>1647<br>01:02:04,000 –&gt; 01:02:05,000<br>the query optimizer is going to,</p>
<p>1648<br>01:02:05,000 –&gt; 01:02:07,000<br>you inject these,</p>
<p>1649<br>01:02:07,000 –&gt; 01:02:08,000<br>uh,</p>
<p>1650<br>01:02:08,000 –&gt; 01:02:10,000<br>these special push down aggregation operators</p>
<p>1651<br>01:02:10,000 –&gt; 01:02:11,000<br>into the query plan,</p>
<p>1652<br>01:02:11,000 –&gt; 01:02:13,000<br>but they’re going to be disabled by default.</p>
<p>1653<br>01:02:13,000 –&gt; 01:02:15,000<br>And then just like before,</p>
<p>1654<br>01:02:15,000 –&gt; 01:02:16,000<br>when we talked about adaptive query optimization,</p>
<p>1655<br>01:02:16,000 –&gt; 01:02:18,000<br>they’re going to have trigger mechanisms to say,</p>
<p>1656<br>01:02:18,000 –&gt; 01:02:20,000<br>if the amount of data coming up through me</p>
<p>1657<br>01:02:20,000 –&gt; 01:02:22,000<br>is larger than I anticipated,</p>
<p>1658<br>01:02:22,000 –&gt; 01:02:23,000<br>or, or, then it should be,</p>
<p>1659<br>01:02:23,000 –&gt; 01:02:24,000<br>based on some cost model that,</p>
<p>1660<br>01:02:24,000 –&gt; 01:02:25,000<br>that they’ve generated.</p>
<p>1661<br>01:02:25,000 –&gt; 01:02:27,000<br>Then it’ll go ahead and just,</p>
<p>1662<br>01:02:27,000 –&gt; 01:02:28,000<br>enable that aggregation,</p>
<p>1663<br>01:02:28,000 –&gt; 01:02:29,000<br>uh,</p>
<p>1664<br>01:02:29,000 –&gt; 01:02:30,000<br>plan node,</p>
<p>1665<br>01:02:30,000 –&gt; 01:02:32,000<br>instead of just being a pass-through.</p>
<p>1666<br>01:02:32,000 –&gt; 01:02:33,000<br>Yes?</p>
<p>1667<br>01:02:33,000 –&gt; 01:02:34,000<br>Two questions.</p>
<p>1668<br>01:02:34,000 –&gt; 01:02:35,000<br>Yes.</p>
<p>1669<br>01:02:35,000 –&gt; 01:02:37,000<br>Why do we not always want to do this?</p>
<p>1670<br>01:02:37,000 –&gt; 01:02:38,000<br>So, why didn’t,</p>
<p>1671<br>01:02:38,000 –&gt; 01:02:39,000<br>why do you not always want to do this?</p>
<p>1672<br>01:02:39,000 –&gt; 01:02:40,000<br>Because the aggregation may be,</p>
<p>1673<br>01:02:40,000 –&gt; 01:02:41,000<br>computing may be expensive, right?</p>
<p>1674<br>01:02:41,000 –&gt; 01:02:42,000<br>It depends on the number of join key,</p>
<p>1675<br>01:02:42,000 –&gt; 01:02:43,000<br>or, or, or,</p>
<p>1676<br>01:02:43,000 –&gt; 01:02:44,000<br>the group by keys.</p>
<p>1677<br>01:02:44,000 –&gt; 01:02:46,000<br>Okay.</p>
<p>1678<br>01:02:46,000 –&gt; 01:02:47,000<br>Right, group by key,</p>
<p>1679<br>01:02:47,000 –&gt; 01:02:48,000<br>group by key,</p>
<p>1680<br>01:02:48,000 –&gt; 01:02:49,000<br>food, or,</p>
<p>1681<br>01:02:49,000 –&gt; 01:02:50,000<br>in a table,</p>
<p>1682<br>01:02:50,000 –&gt; 01:02:51,000<br>or column one,</p>
<p>1683<br>01:02:51,000 –&gt; 01:02:52,000<br>and, uh,</p>
<p>1684<br>01:02:52,000 –&gt; 01:02:53,000<br>the number of sync values,</p>
<p>1685<br>01:02:53,000 –&gt; 01:02:54,000<br>column one is,</p>
<p>1686<br>01:02:54,000 –&gt; 01:02:55,000<br>you know, is,</p>
<p>1687<br>01:02:55,000 –&gt; 01:02:56,000<br>is,</p>
<p>1688<br>01:02:56,000 –&gt; 01:02:57,000<br>is whatever,</p>
<p>1689<br>01:02:57,000 –&gt; 01:02:58,000<br>equal to the number of,</p>
<p>1690<br>01:02:58,000 –&gt; 01:02:59,000<br>of two pulls.</p>
<p>1691<br>01:02:59,000 –&gt; 01:03:02,000<br>And your second question was,</p>
<p>1692<br>01:03:02,000 –&gt; 01:03:04,000<br>you also did the same thing.</p>
<p>1693<br>01:03:04,000 –&gt; 01:03:05,000<br>Okay.</p>
<p>1694<br>01:03:05,000 –&gt; 01:03:07,000<br>Um, what other database is used to this?</p>
<p>1695<br>01:03:07,000 –&gt; 01:03:08,000<br>So, question one of those data is,</p>
<p>1696<br>01:03:08,000 –&gt; 01:03:09,000<br>I think, uh,</p>
<p>1697<br>01:03:09,000 –&gt; 01:03:11,000<br>Dremel might do this.</p>
<p>1698<br>01:03:11,000 –&gt; 01:03:12,000<br>Um,</p>
<p>1699<br>01:03:12,000 –&gt; 01:03:14,000<br>the, the blog article mentions this,</p>
<p>1700<br>01:03:14,000 –&gt; 01:03:15,000<br>so, so, when it’s like,</p>
<p>1701<br>01:03:15,000 –&gt; 01:03:16,000<br>yes.</p>
<p>1702<br>01:03:16,000 –&gt; 01:03:17,000<br>How does a D determine the point order,</p>
<p>1703<br>01:03:17,000 –&gt; 01:03:19,000<br>and you say you don’t have a strategy?</p>
<p>1704<br>01:03:19,000 –&gt; 01:03:21,000<br>It’s good.</p>
<p>1705<br>01:03:21,000 –&gt; 01:03:23,000<br>So, question, how did a Dermen join,</p>
<p>1706<br>01:03:23,000 –&gt; 01:03:24,000<br>or they don’t have sketches,</p>
<p>1707<br>01:03:24,000 –&gt; 01:03:25,000<br>or, or details,</p>
<p>1708<br>01:03:25,000 –&gt; 01:03:26,000<br>or decisions?</p>
<p>1709<br>01:03:26,000 –&gt; 01:03:27,000<br>Um,</p>
<p>1710<br>01:03:27,000 –&gt; 01:03:29,000<br>again, I think it’s,</p>
<p>1711<br>01:03:29,000 –&gt; 01:03:31,000<br>you, you have a rough estimate of the,</p>
<p>1712<br>01:03:31,000 –&gt; 01:03:33,000<br>you have a rough estimate of the,</p>
<p>1713<br>01:03:33,000 –&gt; 01:03:36,000<br>the, the data might be coming out of the,</p>
<p>1714<br>01:03:36,000 –&gt; 01:03:38,000<br>the,</p>
<p>1715<br>01:03:38,000 –&gt; 01:03:39,000<br>the table scans,</p>
<p>1716<br>01:03:39,000 –&gt; 01:03:41,000<br>based on the number of micro partitions you can prune,</p>
<p>1717<br>01:03:41,000 –&gt; 01:03:42,000<br>and statistics.</p>
<p>1718<br>01:03:42,000 –&gt; 01:03:43,000<br>Now, how they do,</p>
<p>1719<br>01:03:43,000 –&gt; 01:03:44,000<br>calls,</p>
<p>1720<br>01:03:44,000 –&gt; 01:03:45,000<br>estimations,</p>
<p>1721<br>01:03:45,000 –&gt; 01:03:46,000<br>you’re on the output of the join,</p>
<p>1722<br>01:03:46,000 –&gt; 01:03:47,000<br>that I don’t know.</p>
<p>1723<br>01:03:47,000 –&gt; 01:03:48,000<br>Like I said, they might,</p>
<p>1724<br>01:03:48,000 –&gt; 01:03:49,000<br>they probably do what Dremel does,</p>
<p>1725<br>01:03:49,000 –&gt; 01:03:50,000<br>is like,</p>
<p>1726<br>01:03:50,000 –&gt; 01:03:51,000<br>oh, I recognize I have a star schema.</p>
<p>1727<br>01:03:51,000 –&gt; 01:03:52,000<br>Let me have the,</p>
<p>1728<br>01:03:52,000 –&gt; 01:03:53,000<br>all the, the,</p>
<p>1729<br>01:03:53,000 –&gt; 01:03:54,000<br>the dimension tables be like,</p>
<p>1730<br>01:03:54,000 –&gt; 01:03:56,000<br>the, the build side of a hash join,</p>
<p>1731<br>01:03:56,000 –&gt; 01:03:57,000<br>and write up the fact table as,</p>
<p>1732<br>01:03:57,000 –&gt; 01:03:58,000<br>as the last pipeline.</p>
<p>1733<br>01:03:58,000 –&gt; 01:04:01,000<br>Like a simple, like, trick like that would be,</p>
<p>1734<br>01:04:01,000 –&gt; 01:04:03,000<br>you provide these benefits.</p>
<p>1735<br>01:04:03,000 –&gt; 01:04:06,000<br>But I don’t think they’re reordering the joins at runtime.</p>
<p>1736<br>01:04:06,000 –&gt; 01:04:08,000<br>I don’t think anybody does that.</p>
<p>1737<br>01:04:08,000 –&gt; 01:04:11,000<br>I thought they were doing distinct value estimations.</p>
<p>1738<br>01:04:11,000 –&gt; 01:04:13,000<br>I think that’s what it says with people.</p>
<p>1739<br>01:04:13,000 –&gt; 01:04:14,000<br>It says,</p>
<p>1740<br>01:04:14,000 –&gt; 01:04:15,000<br>I think they’re doing distinct value estimations.</p>
<p>1741<br>01:04:15,000 –&gt; 01:04:16,000<br>But like,</p>
<p>1742<br>01:04:16,000 –&gt; 01:04:17,000<br>after the join,</p>
<p>1743<br>01:04:17,000 –&gt; 01:04:18,000<br>like,</p>
<p>1744<br>01:04:18,000 –&gt; 01:04:19,000<br>like,</p>
<p>1745<br>01:04:19,000 –&gt; 01:04:20,000<br>the stats are all garbage.</p>
<p>1746<br>01:04:20,000 –&gt; 01:04:22,000<br>So,</p>
<p>1747<br>01:04:22,000 –&gt; 01:04:25,000<br>it’s no like,</p>
<p>1748<br>01:04:25,000 –&gt; 01:04:27,000<br>loves talking about this optimization that they do.</p>
<p>1749<br>01:04:27,000 –&gt; 01:04:30,000<br>And there’s a blog article about it,</p>
<p>1750<br>01:04:30,000 –&gt; 01:04:32,000<br>from, from last year,</p>
<p>1751<br>01:04:32,000 –&gt; 01:04:33,000<br>and actually written by Boway,</p>
<p>1752<br>01:04:33,000 –&gt; 01:04:34,000<br>who was my student,</p>
<p>1753<br>01:04:34,000 –&gt; 01:04:35,000<br>who took 721,</p>
<p>1754<br>01:04:35,000 –&gt; 01:04:38,000<br>by 2016, 2017,</p>
<p>1755<br>01:04:38,000 –&gt; 01:04:40,000<br>and went off and built this piece in,</p>
<p>1756<br>01:04:40,000 –&gt; 01:04:41,000<br>in,</p>
<p>1757<br>01:04:41,000 –&gt; 01:04:42,000<br>in,</p>
<p>1758<br>01:04:42,000 –&gt; 01:04:43,000<br>in,</p>
<p>1759<br>01:04:43,000 –&gt; 01:04:44,000<br>in,</p>
<p>1760<br>01:04:44,000 –&gt; 01:04:45,000<br>in,</p>
<p>1761<br>01:04:45,000 –&gt; 01:04:46,000<br>in,</p>
<p>1762<br>01:04:46,000 –&gt; 01:04:47,000<br>in,</p>
<p>1763<br>01:04:47,000 –&gt; 01:04:48,000<br>in,</p>
<p>1764<br>01:04:48,000 –&gt; 01:04:50,000<br>in,</p>
<p>1765<br>01:04:50,000 –&gt; 01:04:51,000<br>in,</p>
<p>1766<br>01:04:51,000 –&gt; 01:04:52,000<br>in,</p>
<p>1767<br>01:04:52,000 –&gt; 01:04:53,000<br>in,</p>
<p>1768<br>01:04:53,000 –&gt; 01:04:54,000<br>in,</p>
<p>1769<br>01:04:54,000 –&gt; 01:04:56,000<br>notwithstanding essentially,</p>
<p>1770<br>01:04:56,000 –&gt; 01:04:58,000<br>or solution systems that do this.</p>
<p>1771<br>01:04:58,000 –&gt; 01:04:59,000<br>I don’t,</p>
<p>1772<br>01:04:59,000 –&gt; 01:05:00,000<br>I don’t know what name names names.</p>
<p>1773<br>01:05:00,000 –&gt; 01:05:01,000<br>Okay,</p>
<p>1774<br>01:05:01,000 –&gt; 01:05:03,000<br>all right so,</p>
<p>1775<br>01:05:03,000 –&gt; 01:05:04,000<br>that’s the,</p>
<p>1776<br>01:05:04,000 –&gt; 01:05:06,000<br>that’s the highlight level.</p>
<p>1777<br>01:05:06,000 –&gt; 01:05:08,000<br>Overview of what slope Richard does.</p>
<p>1778<br>01:05:08,000 –&gt; 01:05:09,000<br>And again,</p>
<p>1779<br>01:05:09,000 –&gt; 01:05:11,000<br>the idea here is that you can compare and contrast.</p>
<p>1780<br>01:05:11,000 –&gt; 01:05:13,000<br>Some of the nuances they’re doing</p>
<p>1781<br>01:05:13,000 –&gt; 01:05:14,000<br>that are going to be different than,</p>
<p>1782<br>01:05:14,000 –&gt; 01:05:15,000<br>than Dremo,</p>
<p>1783<br>01:05:15,000 –&gt; 01:05:16,000<br>and,</p>
<p>1784<br>01:05:16,000 –&gt; 01:05:23,000<br>So I want to go back to this thing I mentioned at the end of last class about how</p>
<p>1785<br>01:05:23,000 –&gt; 01:05:27,000<br>you know, Databricks came out with photon and made a big announcement.</p>
<p>1786<br>01:05:27,000 –&gt; 01:05:30,000<br>It had the Sigma paper and then they also announced that they had,</p>
<p>1787<br>01:05:30,000 –&gt; 01:05:37,000<br>that they had, they had audited TBC DS numbers and they were the fastest implementation ever.</p>
<p>1788<br>01:05:37,000 –&gt; 01:05:42,000<br>So in addition with this, they put out a blog article announcing the paper,</p>
<p>1789<br>01:05:42,000 –&gt; 01:05:48,000<br>an announcing that they have the, the new world record in audited TBC DS.</p>
<p>1790<br>01:05:48,000 –&gt; 01:05:56,000<br>And in, in this, in this blog article, they include this graph here where they compare</p>
<p>1791<br>01:05:56,000 –&gt; 01:06:04,000<br>Databricks against snowflake and this is, this is being run by researchers at the Barcelona Super Computing Center</p>
<p>1792<br>01:06:04,000 –&gt; 01:06:09,000<br>and running on a, what was called the power set of, of TBC DS.</p>
<p>1793<br>01:06:09,000 –&gt; 01:06:15,000<br>So I think it like is a, so selected subset of the TBC, you know, the 100 TBC DS queries</p>
<p>1794<br>01:06:15,000 –&gt; 01:06:19,000<br>that it meant be, you know, representative like pushing a database to the really hard, right?</p>
<p>1795<br>01:06:19,000 –&gt; 01:06:24,000<br>So this blog article came out with November 2021 and then two or three weeks later,</p>
<p>1796<br>01:06:24,000 –&gt; 01:06:30,000<br>the snowflake skies came out and they started going on about how the database guys</p>
<p>1797<br>01:06:30,000 –&gt; 01:06:34,000<br>didn’t run snowflake correctly, that they’re, that results are a garbage and don’t,</p>
<p>1798<br>01:06:34,000 –&gt; 01:06:35,000<br>don’t trust what they’re saying.</p>
<p>1799<br>01:06:35,000 –&gt; 01:06:38,000<br>Snowflake is actually faster and not as expensive as what Databricks are saying.</p>
<p>1800<br>01:06:38,000 –&gt; 01:06:42,000<br>Like that, Databricks ran on the enterprise version of snowflake,</p>
<p>1801<br>01:06:42,000 –&gt; 01:06:44,000<br>but because they weren’t using any of the enterprise features,</p>
<p>1802<br>01:06:44,000 –&gt; 01:06:48,000<br>they could have run on the regular version of snowflake and cut down the cost quite significantly, right?</p>
<p>1803<br>01:06:48,000 –&gt; 01:06:52,000<br>And these are the two founders, the two French guys that I mentioned in the beginning, right?</p>
<p>1804<br>01:06:52,000 –&gt; 01:06:54,000<br>The two guys that came from Oracle.</p>
<p>1805<br>01:06:54,000 –&gt; 01:06:58,000<br>So they came out and take it, all the, all the Databricks numbers are garbage.</p>
<p>1806<br>01:06:58,000 –&gt; 01:07:02,000<br>Well, two days later, snowflake, oh sorry, the Databricks guys came out again</p>
<p>1807<br>01:07:02,000 –&gt; 01:07:08,000<br>and they go, now we stand by our numbers and that the snowflake guys are being disingenuous</p>
<p>1808<br>01:07:08,000 –&gt; 01:07:16,000<br>and that what’s really going on is that these are results that snowflake is publishing for their, for their data set.</p>
<p>1809<br>01:07:16,000 –&gt; 01:07:20,000<br>So like in the snowflake blog article, they gave you, like, here’s how to go, you know,</p>
<p>1810<br>01:07:20,000 –&gt; 01:07:24,000<br>sign up for a snowflake account and go access the TPCDS data set and run this experiment</p>
<p>1811<br>01:07:24,000 –&gt; 01:07:27,000<br>exactly yourself to see why the Databricks numbers are garbage.</p>
<p>1812<br>01:07:27,000 –&gt; 01:07:29,000<br>So that’s what this result is here.</p>
<p>1813<br>01:07:30,000 –&gt; 01:07:39,000<br>But what they’re, what the Databricks guys are saying though is the, the data set, the data that they’re actually running on</p>
<p>1814<br>01:07:39,000 –&gt; 01:07:44,000<br>and the snowflake results are when you use their internal proprietary storage format</p>
<p>1815<br>01:07:44,000 –&gt; 01:07:49,000<br>and when they’ve already run that micro partition rebalancing optimization that we talked about before.</p>
<p>1816<br>01:07:49,000 –&gt; 01:07:55,000<br>So the data has been, not cooked but prepared because it’s been ingested through the system</p>
<p>1817<br>01:07:55,000 –&gt; 01:08:00,000<br>and they’ve done the extra steps to getting to a form that is ideal for them.</p>
<p>1818<br>01:08:00,000 –&gt; 01:08:08,000<br>And that if you just take the raw data set that you’re given from the TPCDS data generator</p>
<p>1819<br>01:08:08,000 –&gt; 01:08:12,000<br>and then run that without any additional preparation on snowflake, this is the result that you’re getting</p>
<p>1820<br>01:08:12,000 –&gt; 01:08:15,000<br>and this is what they reported from the Barcelona data center.</p>
<p>1821<br>01:08:15,000 –&gt; 01:08:20,000<br>Whereas in Databricks if you don’t do any preparation, this is what you get.</p>
<p>1822<br>01:08:21,000 –&gt; 01:08:30,000<br>Right? So in the official TPCDS documentation, you actually have to include the preparation time of the data</p>
<p>1823<br>01:08:30,000 –&gt; 01:08:34,000<br>in your time measurements.</p>
<p>1824<br>01:08:34,000 –&gt; 01:08:40,000<br>So like if you think about this like, if my query is going to run for a minute but I spent 24 hours compressing the hell out of them</p>
<p>1825<br>01:08:40,000 –&gt; 01:08:44,000<br>and re-optimizing as much as possible, I have to report the 24 hours plus the one minute.</p>
<p>1826<br>01:08:44,000 –&gt; 01:08:50,000<br>And so that’s what the Databricks guys are arguing that like this time here doesn’t include whatever that preparation is</p>
<p>1827<br>01:08:50,000 –&gt; 01:08:54,000<br>and that if you throw all files at it, this is actually what you get.</p>
<p>1828<br>01:08:54,000 –&gt; 01:09:00,000<br>Right? So I like to be the Switzerland, what you call for me.</p>
<p>1829<br>01:09:00,000 –&gt; 01:09:05,000<br>I like to be the Switzerland update basis. I want to get along with everyone.</p>
<p>1830<br>01:09:05,000 –&gt; 01:09:13,000<br>So when this came out, this off the cut as well.</p>
<p>1831<br>01:09:14,000 –&gt; 01:09:20,000<br>You know, I would say for Databricks, they, for this was a big win for them because prior to this,</p>
<p>1832<br>01:09:20,000 –&gt; 01:09:27,000<br>certainly Spark SQL was not as sophisticated and as advanced, you know, compared to photon and other systems at the time.</p>
<p>1833<br>01:09:27,000 –&gt; 01:09:34,000<br>But this showed them, put them in a different light, you know, you can use Databricks as a high performance data warehouse</p>
<p>1834<br>01:09:34,000 –&gt; 01:09:42,000<br>and put some of the same equal footing in a sort of competitive market space against snowflake and other systems around at the time.</p>
<p>1835<br>01:09:42,000 –&gt; 01:09:45,000<br>So this was a win for Databricks, I think.</p>
<p>1836<br>01:09:45,000 –&gt; 01:09:51,000<br>21? This is 2021, yes. During the pandemic.</p>
<p>1837<br>01:09:51,000 –&gt; 01:09:52,000<br>Okay.</p>
<p>1838<br>01:09:52,000 –&gt; 01:09:55,000<br>Have you come out with any comparison since then?</p>
<p>1839<br>01:09:55,000 –&gt; 01:09:58,000<br>These questions have they come out with any comparison since then? No, I don’t think so.</p>
<p>1840<br>01:09:58,000 –&gt; 01:10:05,000<br>There’s always been some kind of like, for these guys fought, then like the time series data people fought over benchmarks, right?</p>
<p>1841<br>01:10:05,000 –&gt; 01:10:09,000<br>There’s always some battle between these various systems.</p>
<p>1842<br>01:10:09,000 –&gt; 01:10:16,000<br>Why is it hard to learn Databricks? Like why don’t we just learn the numbers in benchmark Databricks?</p>
<p>1843<br>01:10:16,000 –&gt; 01:10:20,000<br>So I should why, like, why is it hard to run the Databricks ones?</p>
<p>1844<br>01:10:20,000 –&gt; 01:10:27,000<br>I mean, like, just put the TPCDS data there and just run it.</p>
<p>1845<br>01:10:27,000 –&gt; 01:10:36,000<br>Yeah, so like if there’s role files on parquet and if you say zero preparation, that would be an app of the opposite comparison, right?</p>
<p>1846<br>01:10:36,000 –&gt; 01:10:48,000<br>But here’s where things get weird, like, not weird, but like, it’s a well-known fact that over the years, the various data’s vendors have various optimization tricks that are specific to the TPC benchmarks.</p>
<p>1847<br>01:10:48,000 –&gt; 01:10:53,000<br>So if you recognize, yes, well-known thing, recognize it. Oh, in TPC, this is a very common thing.</p>
<p>1848<br>01:10:53,000 –&gt; 01:10:58,000<br>Oh, you’re accessing the new orders table or the warehouse table? I know a benchmark you’re running.</p>
<p>1849<br>01:10:58,000 –&gt; 01:11:04,000<br>And they’ll do, like, they’ll give you certain query plans or new certain conversations that you would not normally get.</p>
<p>1850<br>01:11:04,000 –&gt; 01:11:06,000<br>Right?</p>
<p>1851<br>01:11:06,000 –&gt; 01:11:14,000<br>Oh, he’s like the Volkswagen one. It’s not that bad because like, that was polluting the environment. That’s worse.</p>
<p>1852<br>01:11:14,000 –&gt; 01:11:17,000<br>This is more like the speed test. Speed test your engine.</p>
<p>1853<br>01:11:17,000 –&gt; 01:11:21,000<br>Yeah, like, yes. Actually, no, they’re going to be the Volkswagen one.</p>
<p>1854<br>01:11:21,000 –&gt; 01:11:27,000<br>That’s, I’ve been like polluting. Like, yeah, like, Volkswagen, their cars would recognize, oh, I know I’m running the emissions test.</p>
<p>1855<br>01:11:27,000 –&gt; 01:11:33,000<br>So they ran at a more optimized manner. But then when it was out in the real world, they was polluting a lot more.</p>
<p>1856<br>01:11:33,000 –&gt; 01:11:37,000<br>Like, there’s tricks you can do in TPCC. I don’t know all the tricks or the analytical workloads.</p>
<p>1857<br>01:11:37,000 –&gt; 01:11:42,000<br>On TPCC, for example, like, the, you know, you call, create index on the warehouse table.</p>
<p>1858<br>01:11:42,000 –&gt; 01:11:46,000<br>But like, there’s only on a warehouse. So you don’t need a full, flash B plus tree.</p>
<p>1859<br>01:11:46,000 –&gt; 01:11:55,000<br>Just do a sort of sort of sort of array asking way faster than the, because the number of warehouses don’t increase when you run that benchmark.</p>
<p>1860<br>01:11:55,000 –&gt; 01:11:59,000<br>So you make a static array and do really fast lookups. Right?</p>
<p>1861<br>01:11:59,000 –&gt; 01:12:06,000<br>But like, if anybody else would not give that optimization, so there’s, there’s well-known tricks like this.</p>
<p>1862<br>01:12:06,000 –&gt; 01:12:13,000<br>Okay, so let’s finish up. This we talked about, I mentioned many times, again,</p>
<p>1863<br>01:12:13,000 –&gt; 01:12:20,000<br>it’s snowflake sort of off of being proprietary storage. The world of data lakes has evolved or has expanded.</p>
<p>1864<br>01:12:20,000 –&gt; 01:12:27,000<br>And so over the years, they’ve added support for accessing data that’s not directly in their proprietary format.</p>
<p>1865<br>01:12:27,000 –&gt; 01:12:32,000<br>It’s first of all, with this thing called Snowpipe, with basically, it was a Kafka endpoint that led you in just data,</p>
<p>1866<br>01:12:32,000 –&gt; 01:12:38,000<br>that in Apache, or in Aero format, they then actually did get written to their proprietary format.</p>
<p>1867<br>01:12:38,000 –&gt; 01:12:43,000<br>But in 2021, they added external tables. I actually don’t know what this actually looks like,</p>
<p>1868<br>01:12:43,000 –&gt; 01:12:46,000<br>because the definition say, oh, it’s this data format or whatever.</p>
<p>1869<br>01:12:46,000 –&gt; 01:12:50,000<br>So I don’t actually know what they’re doing other than I knew they could read from the high metadata catalog.</p>
<p>1870<br>01:12:50,000 –&gt; 01:12:54,000<br>But then to read parquet files, they’ve added support for iceberg in 2022,</p>
<p>1871<br>01:12:55,000 –&gt; 01:13:01,000<br>which we talked about last class. It’s basically parquet files with additional metadata to keep track of the scheme information,</p>
<p>1872<br>01:13:01,000 –&gt; 01:13:07,000<br>and you can do simple updates and insert updates to leads on those files.</p>
<p>1873<br>01:13:07,000 –&gt; 01:13:14,000<br>And then in 2022, they also announced support for, they call hybrid tables.</p>
<p>1874<br>01:13:14,000 –&gt; 01:13:20,000<br>And this is a service that I think is still called Unistore. And it’s basically a full-flash transaction database system.</p>
<p>1875<br>01:13:21,000 –&gt; 01:13:27,000<br>That’s a row store. It’s running inside the Snowpipe ecosystem that you can do queries,</p>
<p>1876<br>01:13:27,000 –&gt; 01:13:31,000<br>SQL queries on, and run TPC and other transactional workloads.</p>
<p>1877<br>01:13:31,000 –&gt; 01:13:36,000<br>And what will happen is the data will get inserted in a log structure format as a row,</p>
<p>1878<br>01:13:36,000 –&gt; 01:13:46,000<br>and then in the background, they’ll then run compaction and convert it to a columnar data stored in the Snowpipe proprietary format.</p>
<p>1879<br>01:13:47,000 –&gt; 01:13:51,000<br>And so when you now run an OLAP query, it’s basically the Fracture Mirrors approach,</p>
<p>1880<br>01:13:51,000 –&gt; 01:13:56,000<br>where query shows up, you have a table as being cleared as a hybrid table,</p>
<p>1881<br>01:13:56,000 –&gt; 01:14:01,000<br>and the executioner has to recognize, oh, some of the data I can get from the column store side,</p>
<p>1882<br>01:14:01,000 –&gt; 01:14:04,000<br>but I’ll seem to merge with some data that I have on the row store side.</p>
<p>1883<br>01:14:04,000 –&gt; 01:14:07,000<br>And it provides a single viewpoint for all of this.</p>
<p>1884<br>01:14:07,000 –&gt; 01:14:13,000<br>So again, this is in response to Delta Lake, actually I think these support Delta Lake now as well,</p>
<p>1885<br>01:14:13,000 –&gt; 01:14:20,000<br>but the idea of ingesting data from different sources is if it’s one additional thing a way to access,</p>
<p>1886<br>01:14:20,000 –&gt; 01:14:25,000<br>put data into Snowpipe, you’re not going to run your transactional application on top of this.</p>
<p>1887<br>01:14:25,000 –&gt; 01:14:30,000<br>So Snowpipe is a great OLAP system.</p>
<p>1888<br>01:14:30,000 –&gt; 01:14:37,000<br>How can they build a transactional system that’s just equally as hard, that’s fault-tolerant, reliable, and safe?</p>
<p>1889<br>01:14:37,000 –&gt; 01:14:41,000<br>How can they build a transactional database system at the same time?</p>
<p>1890<br>01:14:41,000 –&gt; 01:14:47,000<br>Well, let’s just say you have a transactional data system you’re already using for other things</p>
<p>1891<br>01:14:47,000 –&gt; 01:14:52,000<br>that you can then start using it for other parts of your system.</p>
<p>1892<br>01:14:52,000 –&gt; 01:14:56,000<br>So famously, Snowpipe runs their catalog on this thing called FoundationDB.</p>
<p>1893<br>01:14:56,000 –&gt; 01:14:59,000<br>Who here is sort of FoundationDB before, this class?</p>
<p>1894<br>01:14:59,000 –&gt; 01:15:01,000<br>Three, four, five, all right, small.</p>
<p>1895<br>01:15:01,000 –&gt; 01:15:10,000<br>Basically, in the NoSQL days, in the early 2010s, there’s all these NoSQL systems that were doing key value source that didn’t do any transactions,</p>
<p>1896<br>01:15:10,000 –&gt; 01:15:16,000<br>and FoundationDB said, well, we’re going to be a transactional key value store.</p>
<p>1897<br>01:15:16,000 –&gt; 01:15:23,000<br>And I think they were backed also by Sutter Hill, and so basically, they got the two boy bands to put out, you know, work together,</p>
<p>1898<br>01:15:23,000 –&gt; 01:15:27,000<br>and Snowpipe decided to use FoundationDB early on as their catalog.</p>
<p>1899<br>01:15:27,000 –&gt; 01:15:31,000<br>It’s one less thing they’d have to build because you need a transactional catalog.</p>
<p>1900<br>01:15:31,000 –&gt; 01:15:38,000<br>So, the challenge though is that FoundationDB got bought by Apple in 2015,</p>
<p>1901<br>01:15:38,000 –&gt; 01:15:46,000<br>and it was always closed source. So what happens is, Snowpipe had in their contract with FoundationDB that if they get acquired or go under,</p>
<p>1902<br>01:15:46,000 –&gt; 01:15:52,000<br>they get the source code in the SQL service, they get access to the source code, because again, by this point, 2015, Snowpipe was huge,</p>
<p>1903<br>01:15:52,000 –&gt; 01:15:56,000<br>not as big as it is now, but it was growing quite rapidly.</p>
<p>1904<br>01:15:56,000 –&gt; 01:16:01,000<br>So, you know, Apple buying the main thing that runs, you know, you’re trying to catalog service to be a huge problem.</p>
<p>1905<br>01:16:01,000 –&gt; 01:16:07,000<br>So they got access to the source code, and they kept maintaining that over the years.</p>
<p>1906<br>01:16:07,000 –&gt; 01:16:15,000<br>And then when Apple then opened source FoundationDB, they then had a spend time to get it merged back together and follow the open source version.</p>
<p>1907<br>01:16:15,000 –&gt; 01:16:21,000<br>And now right now, the number one contributor to FoundationDB, I think, is Apple. The number two is Snowpipe.</p>
<p>1908<br>01:16:21,000 –&gt; 01:16:31,000<br>But for legal reasons, the Snowpipe people can’t commit code directly into FoundationDB. Only Apple employees have to do that, but they literally should be like on Slack, they say, hey, commit this to the Apple people.</p>
<p>1909<br>01:16:31,000 –&gt; 01:16:36,000<br>And the people, they’ll do it for me. I don’t know whether that’s changed, but that’s what it was a few years ago.</p>
<p>1910<br>01:16:36,000 –&gt; 01:16:42,000<br>FoundationDB, we don’t have to cover this, it’s a very fascinating system. Their testing infrastructure was insane.</p>
<p>1911<br>01:16:42,000 –&gt; 01:16:53,000<br>They had this basically deterministic testing infrastructure where they could introduce faults, or like the disk, the network, and whatever, and show that thing, because fault was, could fail over it, and it was fault tolerant.</p>
<p>1912<br>01:16:53,000 –&gt; 01:17:04,000<br>The guys that built FoundationDB have a new startup called Antithesis, but now they’re trying to sell the infrastructure that they built for FoundationDB, new testing for distributed data disks.</p>
<p>1913<br>01:17:04,000 –&gt; 01:17:12,000<br>How do you make a key value source transactional?</p>
<p>1914<br>01:17:12,000 –&gt; 01:17:18,000<br>It doesn’t matter. Your view statement is how do I make a key value source transactional?</p>
<p>1915<br>01:17:18,000 –&gt; 01:17:33,000<br>I have to go look, I don’t remember, but like, the fact that it’s a key value source versus relational database doesn’t matter.</p>
<p>1916<br>01:17:33,000 –&gt; 01:17:46,000<br>It doesn’t matter. Begin, put, put, put, commit. It’s all the same. That’s basically what NODB is doing underneath the covers. NODB is a key value interface, and a B plus tree. My SQL does the higher level stuff, but it’s doing transactional of that.</p>
<p>1917<br>01:17:46,000 –&gt; 01:17:54,000<br>WireTiger, ROXDB, it’s all the same. It doesn’t matter what’s key value store now.</p>
<p>1918<br>01:17:54,000 –&gt; 01:18:06,000<br>This is a crash course on what Snowflake is. I think it’s a very fascinating system. Even though, again, it’s 12 years old now, I still consider it to be a very much state of the art.</p>
<p>1919<br>01:18:06,000 –&gt; 01:18:12,000<br>Yellow brick guys are going to go way overboard with some of the applications that they’re going to do. We’ll see that next week.</p>
<p>1920<br>01:18:12,000 –&gt; 01:18:26,000<br>But again, in terms of a disaggregated storage, the lake house system that does vectorized query execution, what Snowflake provides or did back then is common now, but it’s still state of the art.</p>
<p>1921<br>01:18:26,000 –&gt; 01:18:35,000<br>Although you can see, not cracks in it, but you can see how there’s aspects of it that are remnants of being designed 12 years ago.</p>
<p>1922<br>01:18:35,000 –&gt; 01:18:48,000<br>Whereas, again, whether or not they’re going to be using these two images, I don’t know, but adding support for external tables after you’ve already had this prior to your storage, that’s not how you would build a system today.</p>
<p>1923<br>01:18:48,000 –&gt; 01:18:56,000<br>If you want to do lake houses or data lakes. But again, it’s still a very fast and very good system.</p>
<p>1924<br>01:18:56,000 –&gt; 01:19:05,000<br>The other challenge that gets from Snowflake Effective, like you look at Velox, look at Data Fusion, the core engine itself has become commoditized.</p>
<p>1925<br>01:19:05,000 –&gt; 01:19:14,000<br>So it’s all the stuff above that Snowflake does, the Snowpark, the Snowpipe stuff, all that separates them from the competitors. That’s the user experience.</p>
<p>1926<br>01:19:14,000 –&gt; 01:19:21,000<br>And the adaptivity of runtime, it’s going to matter rather than just like how fast can you do your vectorized scan.</p>
<p>1927<br>01:19:21,000 –&gt; 01:19:31,000<br>So next class on Wednesday, when we read the ducty B paper, I think the paper I read you had to go to sign is like, it’s the demo paper, so it’s like two pages or four.</p>
<p>1928<br>01:19:31,000 –&gt; 01:19:38,000<br>Okay, yeah, so there isn’t a canonical ducty B paper out there. That’s the best we can do.</p>
<p>1929<br>01:19:38,000 –&gt; 01:19:45,000<br>Well, we’ll cover the mother duct paper that came out this year, but I don’t think that one discusses the core architecture.</p>
<p>1930<br>01:19:45,000 –&gt; 01:19:53,000<br>But I’ll go through like, hear what ducty B’s, like the internal ducts actually look like. And that’s based on public talks and other documentation that they’ve given.</p>
<p>1931<br>01:19:53,000 –&gt; 01:19:59,000<br>And this is going to be slightly different than everything we talked about before, because like we’re making a big deal about these OLAP systems that are running on Lake Houses.</p>
<p>1932<br>01:19:59,000 –&gt; 01:20:07,000<br>And now we’re talking about embedded in process database system. But again, we’ll see how they can read data from S3 and other things as well.</p>
<p>1933<br>01:20:07,000 –&gt; 01:20:11,000<br>Okay? All right guys, see ya.</p>
<p>1934<br>01:20:11,000 –&gt; 01:20:12,000<br>Hey, you know, you ready?</p>
<p>1935<br>01:20:12,000 –&gt; 01:20:17,000<br>I ain’t got a belt to get the 40M bar. Get a grip, take a sip, and you’ll be picking up bottles.</p>
<p>1936<br>01:20:17,000 –&gt; 01:20:22,000<br>Ain’t ain’t no puzzle, I’ll go through some more, man. I’m down in the 40M, I sure ain’t got four cans.</p>
<p>1937<br>01:20:22,000 –&gt; 01:20:26,000<br>Stack some sick packs on a table, and I’m able to see St. John’s on the label.</p>
<p>1938<br>01:20:26,000 –&gt; 01:20:31,000<br>No sure, put the fuck you know what got them. I take off the cap, my friends are tapped on the bottom.</p>
<p>1939<br>01:20:31,000 –&gt; 01:20:35,000<br>Throw my green and freezer, throw my utility. Careful with the bottle, baby, you can still spill it.</p>
<p>1940<br>01:20:35,000 –&gt; 01:20:40,000<br>Cause St. John’s been saved, the paint lots wet. You drink it down with the gauze, hit the bar head.</p>
<p>1941<br>01:20:40,000 –&gt; 01:20:44,000<br>Take back the pack of drugs. You gon’ get your soul saved now, so drink it till it’s flush.</p>
<p>1942<br>01:20:44,000 –&gt; 01:20:49,000<br>Billie Danes, the utility takes you down with the weak gauze. Be a man to get a can of St. John.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CMU15721 P19S202419 SnowflakeDataWarehouseInternalsCMUAdvancedDatabaseSystems</div>
      <div>http://example.com/2025/10/25/CMU15721 P19S202419-SnowflakeDataWarehouseInternalsCMUAdvancedDatabaseSystems/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/25/CMU15721%20P21S202421-YellowbrickDataWarehouseSystemCMUAdvancedDatabaseSystems/" title="CMU15721 P21S202421 YellowbrickDataWarehouseSystemCMUAdvancedDatabaseSystems">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CMU15721 P21S202421 YellowbrickDataWarehouseSystemCMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/25/CMU15721%20P16S202415-QueryOptimizerImplementation3CMUAdvancedDatabaseSystems/" title="CMU15721 P16S202415 QueryOptimizerImplementation3CMUAdvancedDatabaseSystems">
                        <span class="hidden-mobile">CMU15721 P16S202415 QueryOptimizerImplementation3CMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
