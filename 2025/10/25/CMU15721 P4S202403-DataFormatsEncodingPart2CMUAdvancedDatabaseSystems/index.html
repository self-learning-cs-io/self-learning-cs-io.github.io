

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:06,000Canneke Mellon University’s advanced database systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio board. 300:00:09,000 –&gt; 00:00:16,000Wh">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU15721 P4S202403 DataFormatsEncodingPart2CMUAdvancedDatabaseSystems">
<meta property="og:url" content="http://example.com/2025/10/25/CMU15721%20P4S202403-DataFormatsEncodingPart2CMUAdvancedDatabaseSystems/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:06,000Canneke Mellon University’s advanced database systems courses 200:00:06,000 –&gt; 00:00:09,000filming front of the live studio board. 300:00:09,000 –&gt; 00:00:16,000Wh">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-25T05:03:39.755Z">
<meta property="article:modified_time" content="2025-10-25T05:03:39.755Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>CMU15721 P4S202403 DataFormatsEncodingPart2CMUAdvancedDatabaseSystems - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CMU15721 P4S202403 DataFormatsEncodingPart2CMUAdvancedDatabaseSystems"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-25 13:03" pubdate>
          2025年10月25日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          9.3k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          78 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CMU15721 P4S202403 DataFormatsEncodingPart2CMUAdvancedDatabaseSystems</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:06,000<br>Canneke Mellon University’s advanced database systems courses</p>
<p>2<br>00:00:06,000 –&gt; 00:00:09,000<br>filming front of the live studio board.</p>
<p>3<br>00:00:09,000 –&gt; 00:00:16,000<br>What’s the starting?</p>
<p>4<br>00:00:16,000 –&gt; 00:00:23,000<br>Thought the desk was good yesterday and then we’ll finish up talking about the proposal presentations coming on this week on Wednesday.</p>
<p>5<br>00:00:23,000 –&gt; 00:00:27,000<br>So let’s hold off any questions until then.</p>
<p>6<br>00:00:27,000 –&gt; 00:00:35,000<br>All right, so today we’re going to pick off where we left last class talking about what data files actually look like, what actually data looks like.</p>
<p>7<br>00:00:35,000 –&gt; 00:00:43,000<br>And so recall from last class we talked about what these different storage models you’d have NSM or Rostore’s DSM column, like pure column store.</p>
<p>8<br>00:00:43,000 –&gt; 00:00:45,000<br>And then as I said, everything is pretty much packed these days.</p>
<p>9<br>00:00:45,000 –&gt; 00:00:51,000<br>You’re going to divide your table up into horizontal partitions to row groups.</p>
<p>10<br>00:00:51,000 –&gt; 00:00:59,000<br>And then within each row group you’re going to lay all the bits or bytes for each column continuously before jumping to the next column.</p>
<p>11<br>00:00:59,000 –&gt; 00:01:09,000<br>So you get the best both worlds. You get the column store, continues values, but also the spatial locality of a Rostore.</p>
<p>12<br>00:01:09,000 –&gt; 00:01:19,000<br>We then talk about all right for the different file formats, what’s actually inside of them, what additional things we’re going to record beyond just the data itself.</p>
<p>13<br>00:01:19,000 –&gt; 00:01:25,000<br>So we talk about the metadata keeping track of what’s in the footer where they jumped off says in the row groups.</p>
<p>14<br>00:01:25,000 –&gt; 00:01:33,000<br>The format layout specifying again, like is it Rostore comms store, what is the actual the nesting structure within that type system.</p>
<p>15<br>00:01:33,000 –&gt; 00:01:42,000<br>We sort of gloss over quickly to say there’s some primitive types, logical types coding schemes. We spend a lot of time on and we’ll talk about mostly today different ways to encode the data.</p>
<p>16<br>00:01:42,000 –&gt; 00:01:56,000<br>Now you block compression or general purpose compression is taking whatever you produce from the in your file from the lightweight encoding or the these schemes here and then throw snappy or Z standard or gzip at it.</p>
<p>17<br>00:01:56,000 –&gt; 00:01:59,000<br>I actually never use gzip snappy or Z standard.</p>
<p>18<br>00:01:59,000 –&gt; 00:02:13,000<br>So Matt Blume felt theirs and then we rushed through the shredding stuff. So I’m going to spend a little time beginning today going over that more detail because again I think this is a neat idea from the BigQuery Dremel stuff and we’ll see this again later in the semester.</p>
<p>19<br>00:02:13,000 –&gt; 00:02:17,000<br>And then we’ll kick off the conversation about today’s paper.</p>
<p>20<br>00:02:17,000 –&gt; 00:02:24,000<br>So again, real world data sets, there’s a lot of a lot of JSON up there and if you’re a Google, a lot of protocol buffers.</p>
<p>21<br>00:02:24,000 –&gt; 00:02:43,000<br>And if we just store the the JSON document as a varchar as a text or blob inside of a column, you know, yeah, we can run JSON functions on them to extract out the structure from it, but that’s not going to lose all the advantages of having a column store with packs layout and be a re-de vectorized execution.</p>
<p>22<br>00:02:43,000 –&gt; 00:02:54,000<br>So instead, what we want to do is split up or blow up the JSON document for every single two pull and store the paths within that document as separate columns.</p>
<p>23<br>00:02:54,000 –&gt; 00:03:01,000<br>So, you know, the no-segal guys talk about, oh, this is this is a schema list databases, you can define your schema later.</p>
<p>24<br>00:03:01,000 –&gt; 00:03:08,000<br>And that just means that you don’t have to call create table and specify here’s exactly the columns I have for different types. You just throw JSON on it.</p>
<p>25<br>00:03:08,000 –&gt; 00:03:17,000<br>But inherently, there’s always a schema, right, because it doesn’t make sense to have like random applications writing random documents into a table, because then nobody can make it make sense of it.</p>
<p>26<br>00:03:17,000 –&gt; 00:03:28,000<br>So the the documents may be putting in, maybe I have all the same fields, but at least there’ll be enough overlap in the structure that we can break things up and then store it as columns.</p>
<p>27<br>00:03:28,000 –&gt; 00:03:37,000<br>So again, I’m going to focus on the go through a walk through the record shredding from Dremel and then we can briefly talk about length and presence encoding.</p>
<p>28<br>00:03:37,000 –&gt; 00:03:55,000<br>All right, so the basic idea of shredding is that we’re going to store paths in our columns, or sorry, for each path, I’m going to store it as a separate column, and then we’ll record how many steps deep we are into a given document for that, for that hierarchy.</p>
<p>29<br>00:03:55,000 –&gt; 00:04:05,000<br>And unlike in length and presence, we’ll see in the next slide, if something doesn’t exist, doesn’t mean we need to always record that it’s actually there, where in length and presence you do.</p>
<p>30<br>00:04:05,000 –&gt; 00:04:14,000<br>So there’s going to be two additional columns we’re going to find. I think that these are just going to be integer columns that we can then do all the encoding and pressing stuff we talked about before.</p>
<p>31<br>00:04:14,000 –&gt; 00:04:26,000<br>So adding additional columns, yes, that’s more data restoring per attribute within our JSON document, but like again, we can compress these things pretty well and avoid a lot of the bloat of the storage space.</p>
<p>32<br>00:04:27,000 –&gt; 00:04:38,000<br>So the first one is going to include the definition level, and that’s going to determine how many, or it’s going to keep track of how many actual elements existed to get us to the current path we are in our hierarchy.</p>
<p>33<br>00:04:38,000 –&gt; 00:04:48,000<br>And the repetition level is going to say if it’s a repeated structure, like in our scheme up here, we have two repeated structures, we have the repeated group name and the repeated group language.</p>
<p>34<br>00:04:48,000 –&gt; 00:04:53,000<br>So how many times have we seen those repeated groups at that given level repeat?</p>
<p>35<br>00:04:53,000 –&gt; 00:05:03,000<br>So let’s walk through the example, there’s a simple document here again, this is roughly what protocol buffer looks like, or think of defining a schema on a JSON document for XML.</p>
<p>36<br>00:05:03,000 –&gt; 00:05:15,000<br>So we’re going to walk through this document here, and we’re going to scan through as if we were loading it into our database system and show how it’s going to generate the attributes across the different columns in our shredded model.</p>
<p>37<br>00:05:16,000 –&gt; 00:05:27,000<br>So the very beginning, it’s easy, we have a document ID, so we have a table that corresponds to the document ID path, that’s at the top of the document, so then we just insert a new record there.</p>
<p>38<br>00:05:27,000 –&gt; 00:05:40,000<br>But at this point here, there’s no repeats before us, so the repetition value is zero, and there’s no other things in the path before us, so the definition is zero.</p>
<p>39<br>00:05:40,000 –&gt; 00:06:06,000<br>And now as we scan down, we hit the first nested structure, we have name, and within SyVat, we have a repeated group called language, so now we see our first entry for the code here, so we’re going to create a new column for our shredded document, where we have the value that’s being stored, the repetition value is set to zero, because we’re the first language object or group that we’ve seen at this level in the hierarchy.</p>
<p>40<br>00:06:06,000 –&gt; 00:06:11,000<br>So we set the definition to two, because we’re two levels deep.</p>
<p>41<br>00:06:11,000 –&gt; 00:06:25,000<br>Then we go down to the country, and now we see that we can create a new column, the value is US, that’s easy, repetition is zero, because there’s nothing before us, and then now we’re sort of three elements into our path.</p>
<p>42<br>00:06:26,000 –&gt; 00:06:48,000<br>Then we go to the next group for language, and so again, we see a code, we insert that here, where the second, we’re getting starting at zero, but it’s the second repeated group within this hierarchy, so we set that to one, and then our path to get here is two, just like it was here, because we had to go from name to language to code.</p>
<p>43<br>00:06:48,000 –&gt; 00:07:08,000<br>Now we don’t have a country, so in this case here, because we at least have something at the group level within the language, we have to put an entry here, again, same as before, we’re one into the repetition, and then we have two elements to the path to get us here, but again, because there’s no value here, we set it to two.</p>
<p>44<br>00:07:09,000 –&gt; 00:07:28,000<br>Then we go down to the URL here, and again, repetition is zero, because with the first name in our group, just like we were in document, but then our depth is two, because it went from name and then to URL, just as we were over here.</p>
<p>45<br>00:07:29,000 –&gt; 00:07:56,000<br>Then we down to this group, this is just name, nothing else, so we put, sorry, it’s just a name with the URL, and no other attributes for the language, sorry, so we add our entry into here, repetition one, because we’re the second element in the repeated group, and the path is two to get us there, but now we’ve got to put placeholders here to say that there wasn’t anything within the repeated group for language.</p>
<p>46<br>00:07:56,000 –&gt; 00:08:19,000<br>So we’re repeated group one, because this is the second group within that level of the name, and then the definition is one to say the path is really one to get there, because the same as the path as, it’s one down from name, so if you want to know how deep you actually are, as you fall along from this, you could then get that, and see that your actually three levels deep.</p>
<p>47<br>00:08:20,000 –&gt; 00:08:21,000<br>Yes.</p>
<p>48<br>00:08:21,000 –&gt; 00:08:33,000<br>So, I don’t know if you have a definition level two, but I don’t understand why country would have a definition of three when it would seem like, or if it’s five, they would have a function.</p>
<p>49<br>00:08:33,000 –&gt; 00:08:57,000<br>Yeah, his question is, why is code going back here? Why is the error doesn’t, power point is being stupid? So in this case here, I add English US, the definition for the path is two, but then when I add the country, the definition is patch is three, as he said, the code is required, the country is optional.</p>
<p>50<br>00:08:58,000 –&gt; 00:09:00,000<br>Other question, sorry. Yes.</p>
<p>51<br>00:09:00,000 –&gt; 00:09:18,000<br>The question is, why is the definition two, it is taking place as the country?</p>
<p>52<br>00:09:18,000 –&gt; 00:09:32,000<br>Because it doesn’t exist, I think that’s why. Right? You’re not moving down even farther. Yes.</p>
<p>53<br>00:09:32,000 –&gt; 00:09:44,000<br>The question is, is it determined in the point of reversal? Yeah, the definition is, how many steps are you down within the path that gets to where you’re at?</p>
<p>54<br>00:09:44,000 –&gt; 00:09:50,000<br>And so if it’s not there, it doesn’t count. It’s my understanding of it. Yes.</p>
<p>55<br>00:09:50,000 –&gt; 00:10:06,000<br>Is there any benefit of doing this, like, doing this story with all this point? Is there any advantage of doing this, storing the structure as columns versus storing pointers?</p>
<p>56<br>00:10:06,000 –&gt; 00:10:24,000<br>No, no. So if we have this, like, the routine group of names, is this better than just storing some sort of a very small column that I’m going to, you know, missed a pointer to open next point?</p>
<p>57<br>00:10:24,000 –&gt; 00:10:27,000<br>What are these pointers, sorry.</p>
<p>58<br>00:10:27,000 –&gt; 00:10:37,000<br>I guess there’s a similar, but, like, it’s representing only as a…</p>
<p>59<br>00:10:37,000 –&gt; 00:10:49,000<br>The idea is that, think of it, you have to query. The reason why we’re storing this structure here is that we want to go through the column itself without having to go back to figure out how we actually got there when we do a select query.</p>
<p>60<br>00:10:49,000 –&gt; 00:10:59,000<br>So I don’t have a select query here, but think of like, select star from table where name.language.code equals eNUS.</p>
<p>61<br>00:10:59,000 –&gt; 00:11:11,000<br>So I can just rip through this column here. I don’t need to refer to any other ones. And when I find any matches, I can then use that to figure out where I need to go jump back in the offsets if I want to stitch things back together.</p>
<p>62<br>00:11:11,000 –&gt; 00:11:19,000<br>So is there any overhead in my type, where we can just drop the document from the most speculative?</p>
<p>63<br>00:11:19,000 –&gt; 00:11:27,000<br>It’s a steady answer. Is there what, sorry? Is there significant overhead in kind of drawing all the columns up to the original column?</p>
<p>64<br>00:11:27,000 –&gt; 00:11:47,000<br>The question is, is there a large overhead of, if I have to then reverse this shredding, taping it back together to go back to the original form? Absolutely, yes. But the advantage is that when we want to do lookups, it’s already broken out in a form that we can find things very quickly.</p>
<p>65<br>00:11:47,000 –&gt; 00:11:56,000<br>So you’re going to be looking at these specific things. Why don’t you just break up the column here first? Like, I can wait for the other stuff to go down here.</p>
<p>66<br>00:11:56,000 –&gt; 00:12:01,000<br>Yeah, this one they’re giving us. Some asshole developer says I’m going to give you JSON and we got to handle that.</p>
<p>67<br>00:12:01,000 –&gt; 00:12:05,000<br>Right? We haven’t even talked about how we’re going to handle the type either.</p>
<p>68<br>00:12:05,000 –&gt; 00:12:16,000<br>Right? And we’ll see this in snowflakes. Note that we’ll actually try to figure out, oh, I see these bunch of strings. I’ll keep your original JSON, but I’ll also make a synthesize a string column for you. A bar chart, better type is.</p>
<p>69<br>00:12:16,000 –&gt; 00:12:21,000<br>So does SQL know about this? Is there something about the execution?</p>
<p>70<br>00:12:21,000 –&gt; 00:12:37,000<br>It’s questions is this SQL know about JSON? I mean, the SQL standard has JSON. Yeah. Has JSON constructs of data types. But again, that’s the SQL is at the logical levels. The SQL is the programmer sees underneath the covers.</p>
<p>71<br>00:12:37,000 –&gt; 00:12:49,000<br>Right? We the databases is free to store data anyway that it’s once and Dremel made the decision to do it this way because they want to optimize for the common case of just doing lookups down paths.</p>
<p>72<br>00:12:49,000 –&gt; 00:13:05,000<br>Right? She examples everything is jace everything’s a blob. And then I have to parse it every single time run a query. This avoids all that you’re basically materializing as if you parse it ahead of time.</p>
<p>73<br>00:13:05,000 –&gt; 00:13:18,000<br>Okay. So in the sake of time, I don’t want to spend too much on this, but like you kind of get the better general idea that we’re breaking this up. We’re generating columns. And we can use that to figure out the path as you know, as we just can’t through.</p>
<p>74<br>00:13:18,000 –&gt; 00:13:45,000<br>The question is the the great Britain one. So we’re now here. Right? So we now have a new name. Right? There’s a we have it’s name is is is repeated group and we’ve really have the country. Now we have great Britain here. Our repetition is one. That might be wrong.</p>
<p>75<br>00:13:45,000 –&gt; 00:13:59,000<br>Yeah. This is from the Dremel paper. I had to fix some of these things. Yeah. I think the. Yeah. Yeah.</p>
<p>76<br>00:13:59,000 –&gt; 00:14:14,000<br>Yeah. Because it’s a tradition. I will define as the. Yeah. All right. We’ll fix that later. All right. So yeah.</p>
<p>77<br>00:14:14,000 –&gt; 00:14:28,000<br>The type of here is that it’s the number of times that the groups have repeated length at that level. Yeah. Again, low level details. Not the low level details.</p>
<p>78<br>00:14:28,000 –&gt; 00:14:42,000<br>Maybe not entirely matter. It’s the idea of like taking Jason taking something breaking up because we can do this at the physical level. And that’ll make queries run faster later on and the application program doesn’t know doesn’t care.</p>
<p>79<br>00:14:42,000 –&gt; 00:14:53,000<br>And in the second time, I’m going to skip past length of presence. Basically, the idea is that you’re just storing.</p>
<p>80<br>00:14:53,000 –&gt; 00:15:05,000<br>You know, walk down as if for each level, you’re just going to record whether something is exists or not. Right?</p>
<p>81<br>00:15:05,000 –&gt; 00:15:17,000<br>The Dremel paper already that are on there’s specific experience. They show that the shredding one is better. Okay. So let’s get back now talking about the will be left off last class.</p>
<p>82<br>00:15:17,000 –&gt; 00:15:28,000<br>Talk of the big picture of these these parking or showing how they have different levels of sophistication and complexity in the in their implementation. So how they encode things.</p>
<p>83<br>00:15:28,000 –&gt; 00:15:44,000<br>But the these file formats are really designed from a different harbor era, like 10 years ago, or you know, 12 years ago now, Parkes and or 2011 2012 back then the network was seen was always the slowest thing.</p>
<p>84<br>00:15:44,000 –&gt; 00:16:04,000<br>And then disk was slow and then memory and everything and the CPU stuff all that’s fast. So you want you they were making a trade off to to use heavyweight compression schemes like de standard like snappy because that would reduce the the size of the blocks they were fetching for data files.</p>
<p>85<br>00:16:04,000 –&gt; 00:16:14,000<br>But now the harbor is shifted such that like network is actually really really fast. You get on Amazon, I think 100 gigabyte connections for instances, and this is not that much.</p>
<p>86<br>00:16:14,000 –&gt; 00:16:28,000<br>So the trade offs and design decisions that parking or people made, you know, they’re not wrong in like as if they were doing something stupid. It’s just the harbor landscape is so much that we need to revisit what they were doing.</p>
<p>87<br>00:16:28,000 –&gt; 00:16:36,000<br>So there’s a couple other problems in these formats that are going to be problem for us when we want to start doing.</p>
<p>88<br>00:16:36,000 –&gt; 00:16:40,000<br>You know, start vectorizing the operations on our.</p>
<p>89<br>00:16:40,000 –&gt; 00:16:46,000<br>You know inside of our engine. So the first is that parking or going to generate variable size runs.</p>
<p>90<br>00:16:46,000 –&gt; 00:16:53,000<br>Right. Like they’re going to they’re making decisions of how to encode different things at different parts within a column chunk.</p>
<p>91<br>00:16:53,000 –&gt; 00:17:00,000<br>And that means as you’re scanning along trying to decode it to find data you’re looking for, you have to have these conditionals.</p>
<p>92<br>00:17:00,000 –&gt; 00:17:07,000<br>I think it is my data this way or that way. And then sometimes it might be a certain size versus another size.</p>
<p>93<br>00:17:07,000 –&gt; 00:17:12,000<br>Right. Well, that’s bad for Cindy. So we’re not. Cindy is I’m going to take in 14 16.</p>
<p>94<br>00:17:12,000 –&gt; 00:17:19,000<br>Because who here doesn’t know Cindy. Okay. In the paper. Okay.</p>
<p>95<br>00:17:19,000 –&gt; 00:17:25,000<br>Let me give you a quick crash course. For this, everything you know.</p>
<p>96<br>00:17:25,000 –&gt; 00:17:32,000<br>Single instruction multiple data says these class of it and see if you’re instructions that you can get a modern processor is that allow you to do multiple things.</p>
<p>97<br>00:17:32,000 –&gt; 00:17:40,000<br>Sorry. Do the same operation on multiple pieces of the data at the same time. Contrast this with with sissy in fling taxonomy single structure single piece of data.</p>
<p>98<br>00:17:40,000 –&gt; 00:17:47,000<br>Like you know x equals one. That’s a single instruction and take the value one put into a register of x. Right.</p>
<p>99<br>00:17:47,000 –&gt; 00:17:54,000<br>So the say when you start doing things like a major major tradition. Right. x plus y equals z.</p>
<p>100<br>00:17:54,000 –&gt; 00:18:01,000<br>So the way we’re typically write this using sissy instructions. You would have a little for loop. We just iterate over all the elements of I.</p>
<p>101<br>00:18:01,000 –&gt; 00:18:08,000<br>Sorry, elements of x assuming that x and y are the same same length. And then I’m just going to add them again and sort in Z.</p>
<p>102<br>00:18:08,000 –&gt; 00:18:17,000<br>Right. So with sissy again, you’re literally running through the for loop. And in each loop, you’re you’re adding one by one. Yeah, you can unroll it. That’ll speed things up. Whatever.</p>
<p>103<br>00:18:17,000 –&gt; 00:18:24,000<br>But it’s still at the age to it’s doing single instruction per each level within our vectors.</p>
<p>104<br>00:18:24,000 –&gt; 00:18:36,000<br>So that is a simdi is that I can break out the pieces of data that I’m trying to operate on into chunks lanes that I can store in these sissy registers.</p>
<p>105<br>00:18:36,000 –&gt; 00:18:45,000<br>So in this case here, really simple say I’m soaring 32 bit integers. And then I have a putting for for values in a single register. So I have 120 bit registers.</p>
<p>106<br>00:18:45,000 –&gt; 00:18:57,000<br>Right. The current. The large register you get now is 512. The fast lanes paper talks about a hypothetical 1024. Simdi register. That doesn’t exist. 512 is the state of the art and we’ll cover that more later on.</p>
<p>107<br>00:18:57,000 –&gt; 00:19:06,000<br>So now what I can do is that within the single instruction, I can just the the CPU will take this register in that register, add them up and then write it out to another register.</p>
<p>108<br>00:19:06,000 –&gt; 00:19:11,000<br>And now that’s one instruction to the same thing for the next the next block for the next portion of the data.</p>
<p>109<br>00:19:11,000 –&gt; 00:19:23,000<br>Again, another simdi simdi instruction to go out of that. So what what what what was before this simdi just counting the number addition instructions eight instructions to add the X and Y together.</p>
<p>110<br>00:19:23,000 –&gt; 00:19:35,000<br>I can now do this in two. I’m ignoring the cost of getting things into the register and out of the register and we’ll see problems of a VX 512 where there are actually the CPU will slow itself down when you start using a VX 512 in some cases.</p>
<p>111<br>00:19:35,000 –&gt; 00:19:42,000<br>Right. So it’s not magically magically free. There is some work to actually do this. But that’s the general idea of what simdi is.</p>
<p>112<br>00:19:42,000 –&gt; 00:19:48,000<br>And we’ll see more about this next week and then a few lectures after that as well.</p>
<p>113<br>00:19:48,000 –&gt; 00:20:03,000<br>Okay. So. But as I said, these these registers are always going to be like 128 bit 256 512 and then it’s going to have every element within within that I’m storing in the lane has to be the same size.</p>
<p>114<br>00:20:03,000 –&gt; 00:20:13,000<br>So I have very little length encoding. I got to put everything now to the same length. The same size before I can load into the register and that that’s expensive.</p>
<p>115<br>00:20:13,000 –&gt; 00:20:28,000<br>The other problem with these formats is that as I said before they they want to eagerly decompress everything so that they don’t expose to you the dictionary into the execution and under database system to allow you to start doing lookups on the dictionary itself.</p>
<p>116<br>00:20:28,000 –&gt; 00:20:56,000<br>When you iterate over a column chunk in parking or they give you back the decompress values. Likewise, if you’re using block compression like a naive scheme like Z standard or or snappy you can’t see anything of the data system can’t see anything inside of that compressed data because it’s opaque to the database system because Z standard snappy to have the wrong encoding scheme and we can actually interpret any any any values within the within the compressed data.</p>
<p>117<br>00:20:56,000 –&gt; 00:21:15,000<br>The other problems going to be in some encoding schemes like specifically delta encoding and run like encoding that there will be a dependencies between the Jason values in our column chunk and that means also we can’t use SIMD because there’s no way to pass data from one element to another element if they’re in the same register.</p>
<p>118<br>00:21:15,000 –&gt; 00:21:28,000<br>Delta coding is taking the difference between your neighbor the proceeding value in a column. So if you load that up in the SIMD register you can’t do that delta addition very easily.</p>
<p>119<br>00:21:28,000 –&gt; 00:21:57,000<br>The last one is going to be which not really that big of an issue for us at this point in the semester but the portability of the implementation because all there’s a lot more hardware out there a lot more vendors between arm and risk five and GPUs and Zians that if we even actually within just neon arm and Zians themselves there’s all these different versions of the ISA that have different features of SIMD.</p>
<p>120<br>00:21:58,000 –&gt; 00:22:11,000<br>SIMD, SIMD capabilities and there’s no guarantee that if you write low level and trends that code like the low level instructions to do SIMD that on one system is always going to work on another system.</p>
<p>121<br>00:22:11,000 –&gt; 00:22:22,000<br>So ideally when I rely on compiler to figure out how to vectorize the stuff for us but parking or because the certain design says they made they can’t do that.</p>
<p>122<br>00:22:22,000 –&gt; 00:22:36,000<br>Yes. Is there some kind of library that which is what we can use like these agnostic functions that are representing SIMD capabilities and the library within dispatches like this ISA this ISA.</p>
<p>123<br>00:22:36,000 –&gt; 00:22:51,000<br>His question is are there libraries like Libs in D. Yes. Are there libraries out there that can abstract away the low level details of certain operations and therefore if you write your code against that library then whatever I say you lane or whatever.</p>
<p>124<br>00:22:51,000 –&gt; 00:22:59,000<br>Hardly you lane on they can do it for you. Yes, but I’m not aware of anybody actually using those these in databases.</p>
<p>125<br>00:22:59,000 –&gt; 00:23:09,000<br>And we have friends on the inside I ask them whether they’re using a transics or some kind of abstraction layer everybody’s writing the transics.</p>
<p>126<br>00:23:09,000 –&gt; 00:23:20,000<br>I don’t know what ductyb does though. They are trying to be very portable so we could look at it see what they do. Yes.</p>
<p>127<br>00:23:20,000 –&gt; 00:23:26,000<br>So his question is why it depends on the json values bad because think of like if I have.</p>
<p>128<br>00:23:26,000 –&gt; 00:23:34,000<br>So it’s actually go back to my simb example here.</p>
<p>129<br>00:23:34,000 –&gt; 00:23:51,000<br>So go back here right say that these are the wrong coding on compress but say it was delta encoding right and so starting starting at the top right it’s eight and then the next one is 15 right or because it’s eight plus seven or something right.</p>
<p>130<br>00:23:51,000 –&gt; 00:24:00,000<br>So if I can’t load that in my register and have it do arithmetic right next to it the thing that’s next to it you can get the copying to another register and start.</p>
<p>131<br>00:24:00,000 –&gt; 00:24:10,000<br>Shifting things around. Yes we’re getting there yes.</p>
<p>132<br>00:24:10,000 –&gt; 00:24:17,000<br>You did the bad mood writer because like you basically give the end you know.</p>
<p>133<br>00:24:17,000 –&gt; 00:24:25,000<br>Right so you’re telling the ending of the story to the beginning. If I set the mood.</p>
<p>134<br>00:24:25,000 –&gt; 00:24:29,000<br>Yes the answer is fast lanes did solve this particular problem.</p>
<p>135<br>00:24:29,000 –&gt; 00:24:40,000<br>So I’m going to talk about three different schemes today and the better blocks and the fast lanes ones these are brand new these papers just come out in the last year.</p>
<p>136<br>00:24:40,000 –&gt; 00:24:45,000<br>Bit leaving as an old idea from Jignesh Patel the other data is faster here that came out.</p>
<p>137<br>00:24:45,000 –&gt; 00:24:53,000<br>I’m just 10 years ago but I still think these it’s worth looking at because it’s a completely different way thinking about how to store data so I want to cover that a bit.</p>
<p>138<br>00:24:53,000 –&gt; 00:25:10,000<br>But the way they went is better blocks is going to be like par k plus plus right still going to be in the sort of the same overall flavor of par k just with better light weight encoding seems and they’ll do nesting in a you know with a sort of recursive algorithm</p>
<p>139<br>00:25:10,000 –&gt; 00:25:20,000<br>tries to figure out the best nesting scheme automatically fast lanes of the paper I got had you guys read again it’s just a different way of thinking about actually how to store data in a way that people really haven’t considered that much.</p>
<p>140<br>00:25:20,000 –&gt; 00:25:27,000<br>The people have been sorting data all the time that’s a new trick but like to purposely go out of your way to store it in a sort of.</p>
<p>141<br>00:25:27,000 –&gt; 00:25:38,000<br>I’m just arbitrarily random order because that’s the best way to then decode it at runtime again that that’s a that’s a far it’s not a common way to think about how to build data systems.</p>
<p>142<br>00:25:38,000 –&gt; 00:25:58,000<br>And again the main takeaway from all this is going to be the sequel layer this is the application program doesn’t know what we’re doing the covers right to get all the benefit things will be faster and cheaper and more efficient but they don’t have to rewrite anything in their application code right because sequel is just going to run just fine the deities and all that for them.</p>
<p>143<br>00:25:58,000 –&gt; 00:26:01,000<br>So we’ll go through each of these one by one.</p>
<p>144<br>00:26:01,000 –&gt; 00:26:12,000<br>So better blocks is a pack space file format out of T. U. Minic. We’re going to be a lot of papers from from the guys at Munich they have a system called hyper and a new one called umbra.</p>
<p>145<br>00:26:12,000 –&gt; 00:26:19,000<br>They have very good data professors there the one place from the best people in the world. So this paper came out came out of their group last year.</p>
<p>146<br>00:26:19,000 –&gt; 00:26:31,000<br>And so the idea with better blocks is that it’s going to do more aggressive nested encoding schemes than with park a and work park a only did dictionary coding for for strings.</p>
<p>147<br>00:26:31,000 –&gt; 00:26:45,000<br>And it didn’t try to do any additional optimizations for like the the the codes that came out of them or try to be more sophisticated and have these for integer columns try to figure out you know should I compress it this way versus that way but it was basically static heuristics.</p>
<p>148<br>00:26:45,000 –&gt; 00:26:59,000<br>And so when better blocks what they’re going to do is they have a more or less a greedy algorithm that’s going to figure out for each column chunk what’s the best encoding scheme by looking at a sample of the data and what’s about how they do that generate that sample.</p>
<p>149<br>00:26:59,000 –&gt; 00:27:14,000<br>And then then they apply that encoding scheme which may produce more columns and it longs there of a fundamental type you then go back and run the same algorithm to figure out what’s the best encoding scheme for those derivative columns that came out of it.</p>
<p>150<br>00:27:14,000 –&gt; 00:27:30,000<br>And so you’re still going to be able to do the you basically get almost all the benefit of something like snappy and Z standard but you can you can still natively operate and decode the columns without having to decode decompress everything right.</p>
<p>151<br>00:27:30,000 –&gt; 00:27:40,000<br>And so that means a purpose that cannot use snappy is the standard for this same thing with fast lense or not they’re not going to touch that stuff because it’s too slow and hides everything with the data system.</p>
<p>152<br>00:27:40,000 –&gt; 00:27:54,000<br>Now interestingly better blocks makes the argument that they don’t want to store the metadata the schema and information about what’s in the file in the file itself and they said that’s better left to some management service.</p>
<p>153<br>00:27:54,000 –&gt; 00:28:03,000<br>But that breaks the portability capabilities we talked about before we just give someone a part of file and there’s everything you need to decipher what’s inside of it is in the file itself.</p>
<p>154<br>00:28:03,000 –&gt; 00:28:10,000<br>I would talk this up to more philosophical design decision argument rather than like oh my gosh they’re wrong or they’re right.</p>
<p>155<br>00:28:10,000 –&gt; 00:28:13,000<br>Some cases make sense in cases it doesn’t.</p>
<p>156<br>00:28:13,000 –&gt; 00:28:28,000<br>So statement is if the you’re saying if it’s embedded that you’re safer or not.</p>
<p>157<br>00:28:28,000 –&gt; 00:28:41,000<br>So the metadata gets corrupted.</p>
<p>158<br>00:28:41,000 –&gt; 00:28:48,000<br>So the file gets corrupted in some way and it trashes the metadata because it’s stored in the file you can’t do anything.</p>
<p>159<br>00:28:48,000 –&gt; 00:29:00,000<br>But the flips I would be if you’re storing out your metadata separate files and some other service or you’re more moving parts that could cause problems.</p>
<p>160<br>00:29:00,000 –&gt; 00:29:09,000<br>Furthermore again we say we’re storing an object store, Amazon’s replicating all that stuff like I think three or four times or six times.</p>
<p>161<br>00:29:09,000 –&gt; 00:29:19,000<br>So the likelihood in all honesty like the file is going to get truly corrupted and I have no and I can’t recover.</p>
<p>162<br>00:29:19,000 –&gt; 00:29:36,000<br>If it’s mission critical then I have all site backups I’m doing you know if it’s if my company fails my business fails because this like one file gets corrupted then like that’s my fault for not like making sure that like you know it’s written stone you know I mean so I think that would be the argument there.</p>
<p>163<br>00:29:36,000 –&gt; 00:29:46,000<br>Yes.</p>
<p>164<br>00:29:46,000 –&gt; 00:30:05,000<br>So she’s correct the thing we the beginning of the last class was in or they had a bunch of different coding schemes and as you ran your you know as you’re trying to decode things it’s trying to figure out like on the fly which decoding seems to be used isn’t that isn’t going to start with the same problem.</p>
<p>165<br>00:30:05,000 –&gt; 00:30:14,000<br>My understanding is though within the column chunk they’re picking one encoding scheme whereas or is trying to be clever on smaller runs.</p>
<p>166<br>00:30:14,000 –&gt; 00:30:28,000<br>And I will say they only compare against park a in this paper they don’t compare against work and then we we didn’t for our experiments and our paper we didn’t we didn’t compare against this but the that’s an open question.</p>
<p>167<br>00:30:28,000 –&gt; 00:30:41,000<br>Yes.</p>
<p>168<br>00:30:41,000 –&gt; 00:31:10,000<br>So there’s common is the argument that they’re making this paper about why they want to store the metadata is a separate file is that it allows them to retrieve the file which is going to be much more than the actual data and then look at the zone maps and information for whether you need to look at the file but as we said last time like with s3 I can go get a range so whether the whether getting that metadata is the photo of the file or like the separate file from my perspective it’s the same.</p>
<p>169<br>00:31:10,000 –&gt; 00:31:25,000<br>Yeah yeah yeah yeah yeah. Okay so let’s look at all the encoding schemes that they have a bunch of these we’ve already seen to these what will cover more detail so we’ve already know about run like encoding one values like the extreme example or like literally your column of 64,000.</p>
<p>170<br>00:31:25,000 –&gt; 00:31:49,000<br>So you can see that the extreme case is RLE. Frequency encoding we didn’t talk about but this comes from IBM’s DB to blue system from a few years ago basically it’s like you store the you look at your column figure out what’s the most common value like what’s the one value that appears most often.</p>
<p>171<br>00:31:49,000 –&gt; 00:32:07,000<br>Or that’s separately and then you have a bit map to say how many times it where it occurs in the column and then all the other values that are not not that top value you just store them in an uncompressed in an uncompressed way but then you feed that back into the encoding scheme and compress it further.</p>
<p>172<br>00:32:07,000 –&gt; 00:32:17,000<br>So I think of like what’s good example of this.</p>
<p>173<br>00:32:17,000 –&gt; 00:32:35,000<br>You’re at a you’re at a everybody loves for like one person so you just store everyone loves to go yes store that they have a bit map where that occurs and then for the few people that don’t like to just store that separately right the stupid example that’s the basic idea.</p>
<p>174<br>00:32:35,000 –&gt; 00:32:53,000<br>From a reference a bit packing we talk about last time again it’s like delta encoding they’re not going to do a delta coding this is the variant of it we just store what’s the the min value of within a column chunk and then just store the delta from everyone that everyone’s delta to that that that global value.</p>
<p>175<br>00:32:53,000 –&gt; 00:33:14,000<br>Dictionary of the code covered pseudo decimals we I didn’t really talk about fixed point decimals but the basic ideas that they’re going to convert floating point numbers into to integers by just figuring out where the decimal point is and store the integer version of that and then what power of 10 you need to convert it back to a decimal right.</p>
<p>176<br>00:33:14,000 –&gt; 00:33:35,000<br>But I’ll briefly talk about these in a second but this is basically a FST comes from the Germans and the ducty people that allows you to do compression on strings but instead of doing dictionary coding where you have a code represents the entire value of that string you can do separate codes for individual bites.</p>
<p>177<br>00:33:35,000 –&gt; 00:33:50,000<br>I think if you have a column of a bunch of URLs and all the year all start with HTTPS so I could store the separate code just for HTTPS and then additional codes for the other parts of the URLs right.</p>
<p>178<br>00:33:50,000 –&gt; 00:34:11,000<br>So I’ll talk about that in a second and then roaring bitmaps is a way to do basic compressed bitmaps but they’re going to use these for nulls and exceptions like the the free-percent coding of I’m keeping track of like when you know what what locations is the most frequent value occurs I was sure that is a roaring bitmap and again we’ll cover that in a second.</p>
<p>179<br>00:34:11,000 –&gt; 00:34:18,000<br>So again no doubt on coding because it’s not simply friendly but then again the fast lines people fix this.</p>
<p>180<br>00:34:18,000 –&gt; 00:34:34,000<br>So the selection algorithm works like that so basically that you’re going to collect some sample data from your column and recall in case of orc orc was using this run ahead buffer to look at the next 512 bytes to figure out okay or sorry by 12 values and look out figure out what’s with the next encoding scheme I should use.</p>
<p>181<br>00:34:34,000 –&gt; 00:34:45,000<br>What they’re going to do is assuming you have the entire column chunk ahead of time and you’re going to sample from that uniformly and then use that to determine what’s the best encoding scheme for for this given column chunk.</p>
<p>182<br>00:34:45,000 –&gt; 00:35:12,000<br>But you just can’t do random sampling by just jumping different locations because that’ll make run like encoding look look terrible right because you’re going to miss that that continuity or repeated values in a sequence likewise if you just then grab the first you know 100 values then it’s going to make other schemes look bad because again you may just hit a bunch of repeated values in the beginning and therefore run like the code and looks great but that’s actually not the most optimal scheme.</p>
<p>183<br>00:35:12,000 –&gt; 00:35:37,000<br>So what they’re basically going to do is they’re going to do they’re going to jump to 10 different locations in a column chunk which is 64,000 values so basically 1% and then when they jump to that location they’re going to then grab 64 values so that gives you sort of the the spatial randomness within the the column term itself but also the continuity of the particularness that you need to figure out whether early makes sense.</p>
<p>184<br>00:35:37,000 –&gt; 00:35:50,000<br>So then you run the algorithm figure out what the best encoding scheme is and then as I said sometimes the encoding scheme is produce more outputs and then you can just feed those outputs back into the next encoding scheme.</p>
<p>185<br>00:35:50,000 –&gt; 00:35:51,000<br>Yes.</p>
<p>186<br>00:35:51,000 –&gt; 00:35:56,000<br>Is there something special about the greeting algorithm as opposed to what?</p>
<p>187<br>00:35:56,000 –&gt; 00:35:59,000<br>I’m trying to be a professional.</p>
<p>188<br>00:35:59,000 –&gt; 00:36:01,000<br>They’re trying all of them.</p>
<p>189<br>00:36:01,000 –&gt; 00:36:02,000<br>Or they’re trying all of them.</p>
<p>190<br>00:36:02,000 –&gt; 00:36:20,000<br>Yes so like so say my original data is this integer of this vector strings since common strings so this is the algorithm right it’s an integer so they’re literally going to try all of them on the sample and they say roughly it’s the it’s about 2% overhead of the compression cost.</p>
<p>191<br>00:36:20,000 –&gt; 00:36:46,000<br>So his comment is basically what are we doing this it’s when we’re loading the data into the database right and so the encoding is an expensive cost because that we’re willing to pay that cost upfront once because that’s going to make the common case of running queries run faster absolutely yes.</p>
<p>192<br>00:36:46,000 –&gt; 00:36:52,000<br>So they’re saying the running is the algorithm is a 2% overhead and I think that’s fair trade off.</p>
<p>193<br>00:36:52,000 –&gt; 00:36:55,000<br>Right.</p>
<p>194<br>00:36:55,000 –&gt; 00:37:10,000<br>So in this example here again they can just be raw uncompressed encoding there’s open sort of invitations to do vectorize partial frame of reference then part of the packing one value talked about in the dictionary.</p>
<p>195<br>00:37:10,000 –&gt; 00:37:24,000<br>So let’s say this is my stupid example here it picks that run like the coding is the fastest but then again this is going to produce out two columns now one for the actual values and then the next next column is the actual.</p>
<p>196<br>00:37:24,000 –&gt; 00:37:36,000<br>Right again though they’ll recursively try three times or every single output as long as is it something that can be compressed again though they’ll feed it back into the argument try again.</p>
<p>197<br>00:37:36,000 –&gt; 00:37:44,000<br>Right up to three tries in the case of like you know if you land with like bit packing there’s nothing you can do after that right so the algorithm terminates.</p>
<p>198<br>00:37:45,000 –&gt; 00:37:54,000<br>So my example here is for for integers but then they have basically decision trees for for strings and doubles and that’s good.</p>
<p>199<br>00:37:54,000 –&gt; 00:37:59,000<br>There’s the core data types that we care about in databases like yes.</p>
<p>200<br>00:37:59,000 –&gt; 00:38:19,000<br>Is question is like do I ever they ever backtrack and say oh like I have to recursively applying it turns out that what I’m doing is is the optimal choice is actually another path down no.</p>
<p>201<br>00:38:19,000 –&gt; 00:38:26,000<br>How do you know it’s not representative.</p>
<p>202<br>00:38:26,000 –&gt; 00:38:33,000<br>Oh yeah so like yeah I say it is basically if I started coding and I realized this kind of sucks this is not what it’s working.</p>
<p>203<br>00:38:33,000 –&gt; 00:38:42,000<br>It’s not working out as well as I thought it was going to do they ever go back and try again I don’t think they do but I don’t know.</p>
<p>204<br>00:38:42,000 –&gt; 00:38:43,000<br>That’s the same.</p>
<p>205<br>00:38:43,000 –&gt; 00:38:44,000<br>Okay.</p>
<p>206<br>00:38:44,000 –&gt; 00:38:49,000<br>What is the cost savings of like only like 10% of the data.</p>
<p>207<br>00:38:49,000 –&gt; 00:38:51,000<br>They’re looking at one percent.</p>
<p>208<br>00:38:51,000 –&gt; 00:38:58,000<br>So one down might be like one percent of the data we get the whole data set try all of them exhausted these off the search faces.</p>
<p>209<br>00:38:58,000 –&gt; 00:39:00,000<br>Wait across the entire data set.</p>
<p>210<br>00:39:00,000 –&gt; 00:39:01,000<br>Yeah.</p>
<p>211<br>00:39:01,000 –&gt; 00:39:08,000<br>I mean I guess like one percent of the data is like 100 times slower.</p>
<p>212<br>00:39:08,000 –&gt; 00:39:15,000<br>Wait I want to block a little one one terabyte of data you want to say one terabyte.</p>
<p>213<br>00:39:15,000 –&gt; 00:39:17,000<br>No say one terabyte.</p>
<p>214<br>00:39:17,000 –&gt; 00:39:19,000<br>No excuse one petabyte right.</p>
<p>215<br>00:39:19,000 –&gt; 00:39:22,000<br>So yeah that’s not feasible.</p>
<p>216<br>00:39:22,000 –&gt; 00:39:23,000<br>Right.</p>
<p>217<br>00:39:23,000 –&gt; 00:39:28,000<br>And also too someone’s got to pay for the compute.</p>
<p>218<br>00:39:28,000 –&gt; 00:39:29,000<br>Right.</p>
<p>219<br>00:39:29,000 –&gt; 00:39:34,000<br>So I’m.</p>
<p>220<br>00:39:34,000 –&gt; 00:39:37,000<br>Again it’s a trade off.</p>
<p>221<br>00:39:37,000 –&gt; 00:39:43,000<br>I’m going to pay this competition overhead two percent seems reasonable to me in order to make queries run faster.</p>
<p>222<br>00:39:43,000 –&gt; 00:39:47,000<br>And so if you do the his example or your example like just try everything or backtrack.</p>
<p>223<br>00:39:47,000 –&gt; 00:39:53,000<br>If I got to get another you know what what is going to be that that percentage improvement probably not worth it.</p>
<p>224<br>00:39:53,000 –&gt; 00:39:54,000<br>Yes.</p>
<p>225<br>00:39:54,000 –&gt; 00:39:55,000<br>Yes.</p>
<p>226<br>00:39:55,000 –&gt; 00:39:57,000<br>So they are.</p>
<p>227<br>00:39:57,000 –&gt; 00:40:00,000<br>They are all in one.</p>
<p>228<br>00:40:00,000 –&gt; 00:40:03,000<br>When I was running the call for some messages.</p>
<p>229<br>00:40:03,000 –&gt; 00:40:04,000<br>For this.</p>
<p>230<br>00:40:04,000 –&gt; 00:40:05,000<br>For this.</p>
<p>231<br>00:40:05,000 –&gt; 00:40:06,000<br>More.</p>
<p>232<br>00:40:06,000 –&gt; 00:40:07,000<br>The bigger size.</p>
<p>233<br>00:40:07,000 –&gt; 00:40:09,000<br>For example, you should know that it’s a very.</p>
<p>234<br>00:40:09,000 –&gt; 00:40:10,000<br>Yes.</p>
<p>235<br>00:40:10,000 –&gt; 00:40:12,000<br>So they are.</p>
<p>236<br>00:40:12,000 –&gt; 00:40:17,000<br>So the statement is when he ran the code locally.</p>
<p>237<br>00:40:17,000 –&gt; 00:40:22,000<br>Because I’m sorry that like they try and coding scheme and then they start encoding it like.</p>
<p>238<br>00:40:22,000 –&gt; 00:40:29,000<br>Like how far into it will they go like before this.</p>
<p>239<br>00:40:29,000 –&gt; 00:40:30,000<br>Yeah.</p>
<p>240<br>00:40:30,000 –&gt; 00:40:31,000<br>Yeah.</p>
<p>241<br>00:40:31,000 –&gt; 00:40:37,000<br>But it’s so to you.</p>
<p>242<br>00:40:37,000 –&gt; 00:40:40,000<br>If you say basically that you set set the recursion deaf.</p>
<p>243<br>00:40:40,000 –&gt; 00:40:42,000<br>The the default is three.</p>
<p>244<br>00:40:42,000 –&gt; 00:40:46,000<br>But then it’s it’s it’s the based on the sample right.</p>
<p>245<br>00:40:46,000 –&gt; 00:40:50,000<br>Not like he’s saying if you scan the data and realize you got it wrong.</p>
<p>246<br>00:40:50,000 –&gt; 00:40:53,000<br>Like the sample said one thing the real data looks something different.</p>
<p>247<br>00:40:53,000 –&gt; 00:40:54,000<br>Do you then roll it back?</p>
<p>248<br>00:40:54,000 –&gt; 00:40:55,000<br>They don’t do that.</p>
<p>249<br>00:40:55,000 –&gt; 00:40:59,000<br>You’re basically saying on the sample itself they can roll back.</p>
<p>250<br>00:40:59,000 –&gt; 00:41:00,000<br>Which is fine.</p>
<p>251<br>00:41:00,000 –&gt; 00:41:04,000<br>But on the sample of the real data.</p>
<p>252<br>00:41:04,000 –&gt; 00:41:05,000<br>Okay.</p>
<p>253<br>00:41:05,000 –&gt; 00:41:07,000<br>They roll back the whole thing.</p>
<p>254<br>00:41:07,000 –&gt; 00:41:08,000<br>Okay.</p>
<p>255<br>00:41:08,000 –&gt; 00:41:12,000<br>Again, they’re they’re they’re column size is 64 that.</p>
<p>256<br>00:41:12,000 –&gt; 00:41:13,000<br>64,000 values.</p>
<p>257<br>00:41:13,000 –&gt; 00:41:14,000<br>It’s not that big.</p>
<p>258<br>00:41:14,000 –&gt; 00:41:16,000<br>You do everything in in RAM.</p>
<p>259<br>00:41:16,000 –&gt; 00:41:19,000<br>Okay.</p>
<p>260<br>00:41:19,000 –&gt; 00:41:20,000<br>Okay.</p>
<p>261<br>00:41:20,000 –&gt; 00:41:21,000<br>All right.</p>
<p>262<br>00:41:21,000 –&gt; 00:41:24,000<br>So going back these are all the coding schemes that we had.</p>
<p>263<br>00:41:24,000 –&gt; 00:41:29,000<br>I want to briefly talk about FSST because we’ll see this when we talk about ductyb.</p>
<p>264<br>00:41:29,000 –&gt; 00:41:35,000<br>And we’ll see this in when we talk about how to like pass the pass</p>
<p>265<br>00:41:35,000 –&gt; 00:41:37,000<br>Intermediate results from one operative the next.</p>
<p>266<br>00:41:37,000 –&gt; 00:41:39,000<br>This will come up and then we’re in bitmaps.</p>
<p>267<br>00:41:39,000 –&gt; 00:41:44,000<br>This is just a better way to do bitmaps.</p>
<p>268<br>00:41:44,000 –&gt; 00:41:45,000<br>All right.</p>
<p>269<br>00:41:45,000 –&gt; 00:41:48,000<br>So FSST again comes from this 2020 paper.</p>
<p>270<br>00:41:48,000 –&gt; 00:41:51,000<br>It’s the it’s the fastening guy Peter Bonds.</p>
<p>271<br>00:41:51,000 –&gt; 00:41:54,000<br>It’s Victor Lice from from but better blocks.</p>
<p>272<br>00:41:54,000 –&gt; 00:41:58,000<br>And then Thomas Norman was probably the best data street research in the world.</p>
<p>273<br>00:41:58,000 –&gt; 00:42:01,000<br>We’ll read a lot of his papers.</p>
<p>274<br>00:42:01,000 –&gt; 00:42:09,000<br>Those three got together and decided let’s go build a compression scheme for strings that allow for fast random access.</p>
<p>275<br>00:42:09,000 –&gt; 00:42:11,000<br>And again, think of like dictionary coding.</p>
<p>276<br>00:42:11,000 –&gt; 00:42:15,000<br>You’re taking the entire string and representing with a single code.</p>
<p>277<br>00:42:15,000 –&gt; 00:42:20,000<br>But now you can’t actually do partial lookups on that code to find you know,</p>
<p>278<br>00:42:20,000 –&gt; 00:42:25,000<br>find prefixes and other things because you you have to go look at the entire string itself.</p>
<p>279<br>00:42:25,000 –&gt; 00:42:32,000<br>So the idea here is that they’re going to replace frequently couraged sub strings after eight bites with one bite codes.</p>
<p>280<br>00:42:32,000 –&gt; 00:42:39,000<br>And so all the values once they’re encoded in these these in the FSST symbols,</p>
<p>281<br>00:42:39,000 –&gt; 00:42:41,000<br>they all going to still be the same length.</p>
<p>282<br>00:42:41,000 –&gt; 00:42:47,000<br>And so you have to do you have to do some tricks to figure out that the record like this is the end of the string.</p>
<p>283<br>00:42:47,000 –&gt; 00:42:51,000<br>Therefore, don’t look at anymore more symbols.</p>
<p>284<br>00:42:51,000 –&gt; 00:42:54,000<br>So the way they’re going to generate the symbol tables actually kind of interesting, right?</p>
<p>285<br>00:42:54,000 –&gt; 00:42:59,000<br>Because it’s sort of an NP complete problem to figure out what’s the optimal.</p>
<p>286<br>00:42:59,000 –&gt; 00:43:06,000<br>The optimal set of symbols that will produce the smallest number of codes in the most compression of benefits.</p>
<p>287<br>00:43:06,000 –&gt; 00:43:11,000<br>So rather than try to do like they mentioned, send you a dynamic programming or something more fancy,</p>
<p>288<br>00:43:11,000 –&gt; 00:43:18,000<br>they just use what they call evolutionary algorithm that anytime you think you have a good symbol as you’re constructing the symbol table,</p>
<p>289<br>00:43:18,000 –&gt; 00:43:21,000<br>they’ll just they’ll put it in this hash table.</p>
<p>290<br>00:43:21,000 –&gt; 00:43:25,000<br>If it entries already there, they they they kick it out.</p>
<p>291<br>00:43:25,000 –&gt; 00:43:32,000<br>Right, so it’s not like the linear scan or linear programming hash tables that we talked about before or the chain hash table,</p>
<p>292<br>00:43:32,000 –&gt; 00:43:36,000<br>you can if someone’s in your slot, you keep going until you find a free position,</p>
<p>293<br>00:43:36,000 –&gt; 00:43:38,000<br>they immediately just kick out whatever’s there.</p>
<p>294<br>00:43:38,000 –&gt; 00:43:43,000<br>The idea is that as you’re constructing the symbol table, if the things that actually really matter a lot,</p>
<p>295<br>00:43:43,000 –&gt; 00:43:50,000<br>that the symbols that could provide a lot of benefit, if they keep getting kicked out, but then they’re still used again, then they’ll get added back.</p>
<p>296<br>00:43:50,000 –&gt; 00:43:55,000<br>And then over time you end up sort of roughly with a reasonably set good set of symbols.</p>
<p>297<br>00:43:55,000 –&gt; 00:43:56,000<br>Yes.</p>
<p>298<br>00:43:56,000 –&gt; 00:43:57,000<br>Is the output fixed length?</p>
<p>299<br>00:43:57,000 –&gt; 00:43:59,000<br>Is the output fixed length?</p>
<p>300<br>00:43:59,000 –&gt; 00:44:08,000<br>For the yes, the byte codes have to be the codes are one byte, but the substring could be variable length up to eight bytes.</p>
<p>301<br>00:44:08,000 –&gt; 00:44:11,000<br>Which is fine because again, the columns have to be fixed length.</p>
<p>302<br>00:44:11,000 –&gt; 00:44:17,000<br>Right, so we know exactly the number, you know, and so the question is like, if what if you have a, you know,</p>
<p>303<br>00:44:17,000 –&gt; 00:44:24,000<br>what if you have a symbol like HTTPS and so you have a bunch of URLs that use that same code, but then someone’s got, somebody’s got a weird URL that’s just HTTPS,</p>
<p>304<br>00:44:24,000 –&gt; 00:44:32,000<br>then you need to keep track of this thing is only, you need to wait to note that the string is actually terminated.</p>
<p>305<br>00:44:32,000 –&gt; 00:44:37,000<br>So don’t interpret any other bytes remaining in my fixed length portion of the value.</p>
<p>306<br>00:44:37,000 –&gt; 00:44:44,000<br>Otherwise you could go look up and add, start adding more symbols that aren’t actually in the original string.</p>
<p>307<br>00:44:45,000 –&gt; 00:44:47,000<br>So again, this is a better way to do it.</p>
<p>308<br>00:44:47,000 –&gt; 00:44:53,000<br>It’s actually the, this is basically what Z standard is or LZ4 or snappy.</p>
<p>309<br>00:44:53,000 –&gt; 00:44:57,000<br>They’re basically doing the same thing inside of their, you know, in their compression scheme.</p>
<p>310<br>00:44:57,000 –&gt; 00:44:59,000<br>But again, it’s opaque to the database system.</p>
<p>311<br>00:44:59,000 –&gt; 00:45:08,000<br>This is now an explicit scheme where we can expose the symbol table to the database system and we know exactly what the, how to match the codes to strings.</p>
<p>312<br>00:45:08,000 –&gt; 00:45:16,000<br>So you can do all the same tricks, you can, you can do dictionary encoding to find prefixes and other stuff by just looking at the symbol table with actually looking at the real values.</p>
<p>313<br>00:45:16,000 –&gt; 00:45:18,000<br>For some, some types of queries.</p>
<p>314<br>00:45:18,000 –&gt; 00:45:19,000<br>Yes.</p>
<p>315<br>00:45:29,000 –&gt; 00:45:34,000<br>Is the question, is, is it possible to have a code referred to another code?</p>
<p>316<br>00:45:35,000 –&gt; 00:45:36,000<br>Yes.</p>
<p>317<br>00:45:40,000 –&gt; 00:45:41,000<br>Oh, it’s good. Yes.</p>
<p>318<br>00:45:41,000 –&gt; 00:45:46,000<br>Questions. Could you have a situation where the inside the symbol table is another code.</p>
<p>319<br>00:45:46,000 –&gt; 00:45:54,000<br>So don’t interpret all of the bytes in the, in the original string as, as the string itself.</p>
<p>320<br>00:45:54,000 –&gt; 00:45:57,000<br>Interpret some of them as action another code that I don’t have a crystal look up.</p>
<p>321<br>00:45:57,000 –&gt; 00:46:03,000<br>Then how do you record that you should go that portion of the string, you know, should be another look up?</p>
<p>322<br>00:46:04,000 –&gt; 00:46:14,000<br>So a lot of the design suggestions they made for this is, is like, does the example of like, okay, you don’t do the linear probing to find a free slot, you immediately kick out whatever’s in there.</p>
<p>323<br>00:46:14,000 –&gt; 00:46:17,000<br>They did this because you can, now you can do this all in SIMD.</p>
<p>324<br>00:46:17,000 –&gt; 00:46:22,000<br>Because you can’t have conditionals, you can’t have loops in, in SIMD.</p>
<p>325<br>00:46:22,000 –&gt; 00:46:26,000<br>Right? So by just doing everything like, okay, here’s the exact instructions we’re always going to do.</p>
<p>326<br>00:46:26,000 –&gt; 00:46:29,000<br>If someone’s there, kick it out, just overwrite them.</p>
<p>327<br>00:46:30,000 –&gt; 00:46:32,000<br>Then like, you can, you can vector all of this.</p>
<p>328<br>00:46:32,000 –&gt; 00:46:43,000<br>So in your thing, you would have to have some bits that somewhere that says, oh, by the way, at this offset for this string, don’t interpret as a varchar, as an asking character, it’s actually a code that you want to feed back into it.</p>
<p>329<br>00:46:43,000 –&gt; 00:46:47,000<br>You wouldn’t be able to do it with the SIMD.</p>
<p>330<br>00:46:47,000 –&gt; 00:46:50,000<br>Okay, so again, I don’t have a demonstration of what this looks like.</p>
<p>331<br>00:46:50,000 –&gt; 00:46:55,000<br>I can post something on Slack from Peter gave it to me a few years ago.</p>
<p>332<br>00:46:55,000 –&gt; 00:47:00,000<br>One thing that is cool, that does show up a lot in data systems now these days are called roaring bitmaps.</p>
<p>333<br>00:47:00,000 –&gt; 00:47:03,000<br>Addicure acid, who here has heard of roaring bitmaps before?</p>
<p>334<br>00:47:03,000 –&gt; 00:47:05,000<br>Very, very few.</p>
<p>335<br>00:47:05,000 –&gt; 00:47:23,000<br>Basically, it’s a way to store a bitmap index in a, with different data structures based on the, how often bits are being set to true within some portion of the range that we’re trying to record.</p>
<p>336<br>00:47:23,000 –&gt; 00:47:29,000<br>So again, a bitmap index can tell you something that just, at some position, is a bit set, yes or no?</p>
<p>337<br>00:47:29,000 –&gt; 00:47:33,000<br>So you can use like a, like a bloom filter, like a for set membership and so forth.</p>
<p>338<br>00:47:33,000 –&gt; 00:47:41,000<br>So the, the dense chunks, we’re to store these as, on-couple-press bitmaps, because there really isn’t any way to make that better.</p>
<p>339<br>00:47:41,000 –&gt; 00:47:43,000<br>So literally just, just the bits.</p>
<p>340<br>00:47:43,000 –&gt; 00:47:48,000<br>Well, you can then turn back and recompress it again with nested and coating with RLE.</p>
<p>341<br>00:47:48,000 –&gt; 00:47:50,000<br>We’ll ignore that for now.</p>
<p>342<br>00:47:50,000 –&gt; 00:47:54,000<br>And then the sparse chunks will just store them as bit-packed arrays of 16 bit integers.</p>
<p>343<br>00:47:54,000 –&gt; 00:47:58,000<br>So there’s a lot of limitations of this and pick your favorite programming language.</p>
<p>344<br>00:47:58,000 –&gt; 00:48:02,000<br>There’s a lot of different data systems out there that are used this.</p>
<p>345<br>00:48:02,000 –&gt; 00:48:06,000<br>Palosa is the open source version of a system called feature-based.</p>
<p>346<br>00:48:06,000 –&gt; 00:48:11,000<br>And feature-based basically stores almost everything as, as, our lot of data is roaring bitmaps.</p>
<p>347<br>00:48:11,000 –&gt; 00:48:14,000<br>Using, in the bite slicing techniques, we’ll see in a second.</p>
<p>348<br>00:48:14,000 –&gt; 00:48:16,000<br>But, here’s the basic idea.</p>
<p>349<br>00:48:16,000 –&gt; 00:48:21,000<br>So say again, we’re going to split up the range of values that we’re going to support.</p>
<p>350<br>00:48:21,000 –&gt; 00:48:24,000<br>In this case here, I have four chunks.</p>
<p>351<br>00:48:24,000 –&gt; 00:48:29,000<br>So for every single key, I want to set to true or look up to see whether it’s set to true.</p>
<p>352<br>00:48:29,000 –&gt; 00:48:32,000<br>I’m just going to divide it by 2 to the 16.</p>
<p>353<br>00:48:32,000 –&gt; 00:48:35,000<br>And that basically tells me what path I want to go down.</p>
<p>354<br>00:48:35,000 –&gt; 00:48:39,000<br>And then within the container within that range, I’ll just, you know, I can set something to true.</p>
<p>355<br>00:48:39,000 –&gt; 00:48:42,000<br>Based on how it’s actually being stored.</p>
<p>356<br>00:48:42,000 –&gt; 00:48:49,000<br>So then what happens is in the default setting, if the number of values that have been set to true within that range is less than 4096,</p>
<p>357<br>00:48:49,000 –&gt; 00:48:52,000<br>then you just store it as uncompressed array.</p>
<p>358<br>00:48:52,000 –&gt; 00:48:54,000<br>Otherwise, then stored as a bitmap.</p>
<p>359<br>00:48:54,000 –&gt; 00:48:57,000<br>So say I want to do set to key equals 1,000.</p>
<p>360<br>00:48:57,000 –&gt; 00:48:59,000<br>I’m going to divide it by 2 to the 16.</p>
<p>361<br>00:48:59,000 –&gt; 00:49:01,000<br>I land in this partition here.</p>
<p>362<br>00:49:01,000 –&gt; 00:49:05,000<br>And then now I keep track of the number of bits that are set to true in this container.</p>
<p>363<br>00:49:05,000 –&gt; 00:49:07,000<br>At this point, it’s 0.</p>
<p>364<br>00:49:07,000 –&gt; 00:49:15,000<br>So I’ll just store the, you know, stored as a bitpact or a 16 bit integer with original value.</p>
<p>365<br>00:49:15,000 –&gt; 00:49:18,000<br>Now I’ll say I want to store this key here.</p>
<p>366<br>00:49:18,000 –&gt; 00:49:20,000<br>I do the same thing, divide it by 2 to the 16.</p>
<p>367<br>00:49:20,000 –&gt; 00:49:21,000<br>I land in partition 3.</p>
<p>368<br>00:49:21,000 –&gt; 00:49:25,000<br>But now I see that this is being stored as a bitmap.</p>
<p>369<br>00:49:25,000 –&gt; 00:49:32,000<br>So I just do the math and say, okay, what offset within that range should I set my bit to true?</p>
<p>370<br>00:49:32,000 –&gt; 00:49:35,000<br>So in this case here, just doing the math like this.</p>
<p>371<br>00:49:35,000 –&gt; 00:49:36,000<br>You get position 50.</p>
<p>372<br>00:49:36,000 –&gt; 00:49:39,000<br>So you just go jump in here and set bit to 50.</p>
<p>373<br>00:49:39,000 –&gt; 00:49:42,000<br>That’s it.</p>
<p>374<br>00:49:42,000 –&gt; 00:49:49,000<br>So as you delete and insert things, it’ll just back and forth between what data structure you want to use.</p>
<p>375<br>00:49:49,000 –&gt; 00:49:50,000<br>Yes?</p>
<p>376<br>00:49:50,000 –&gt; 00:49:56,000<br>What is the overhead of the every unit?</p>
<p>377<br>00:49:56,000 –&gt; 00:50:00,000<br>So what’s the overhead of storing everything as a bitmap?</p>
<p>378<br>00:50:00,000 –&gt; 00:50:04,000<br>So in this example here, what I have, 2 to the 16 different values.</p>
<p>379<br>00:50:04,000 –&gt; 00:50:09,000<br>So I need a bit and need to store 2 to the 16 bits that I can set to true.</p>
<p>380<br>00:50:09,000 –&gt; 00:50:12,000<br>That’s expensive.</p>
<p>381<br>00:50:12,000 –&gt; 00:50:16,000<br>That’s expensive.</p>
<p>382<br>00:50:16,000 –&gt; 00:50:18,000<br>So what’s the name of this key?</p>
<p>383<br>00:50:18,000 –&gt; 00:50:23,000<br>If I say I have 2 to the 16 and I now go beyond that, I’ll just re-mail it.</p>
<p>384<br>00:50:23,000 –&gt; 00:50:29,000<br>I’m going to start smaller.</p>
<p>385<br>00:50:29,000 –&gt; 00:50:33,000<br>You could do that, sure, but then it’s…</p>
<p>386<br>00:50:33,000 –&gt; 00:50:40,000<br>Well, you could do that, but for some values, if you’re treating everyone the same.</p>
<p>387<br>00:50:40,000 –&gt; 00:50:44,000<br>And so maybe the case that your data structure is…</p>
<p>388<br>00:50:44,000 –&gt; 00:50:47,000<br>Sorry, the domain range is wide.</p>
<p>389<br>00:50:47,000 –&gt; 00:50:50,000<br>But within that, it’s sparse.</p>
<p>390<br>00:50:50,000 –&gt; 00:50:55,000<br>So now I’m jumping to different cache lines or different jump commemorations to go see what I’ve set to true.</p>
<p>391<br>00:50:55,000 –&gt; 00:50:59,000<br>So there’s a bit pack array, which I can then compress it again.</p>
<p>392<br>00:50:59,000 –&gt; 00:51:03,000<br>This is better.</p>
<p>393<br>00:51:03,000 –&gt; 00:51:06,000<br>Yes.</p>
<p>394<br>00:51:06,000 –&gt; 00:51:09,000<br>No, this is from a French Canadian guy, Daniel Lamar.</p>
<p>395<br>00:51:09,000 –&gt; 00:51:12,000<br>And it’s been a lot of systems uses.</p>
<p>396<br>00:51:12,000 –&gt; 00:51:17,000<br>For bitmaps.</p>
<p>397<br>00:51:17,000 –&gt; 00:51:21,000<br>I got a bit.</p>
<p>398<br>00:51:21,000 –&gt; 00:51:25,000<br>It actually takes inspiration from…</p>
<p>399<br>00:51:25,000 –&gt; 00:51:28,000<br>A paper from the Germans called Art, which is not going to cover.</p>
<p>400<br>00:51:28,000 –&gt; 00:51:33,000<br>It’s basically Adaptive Red X Tri, where they can keep track of the population within some…</p>
<p>401<br>00:51:33,000 –&gt; 00:51:35,000<br>So pack down into the tri…</p>
<p>402<br>00:51:35,000 –&gt; 00:51:38,000<br>Or they’ll change the size of the note.</p>
<p>403<br>00:51:38,000 –&gt; 00:51:40,000<br>It’s sort of the same idea.</p>
<p>404<br>00:51:40,000 –&gt; 00:51:43,000<br>Someone tried to repeat this exact thing for a level down as well.</p>
<p>405<br>00:51:43,000 –&gt; 00:51:45,000<br>So you have some parts that we have told.</p>
<p>406<br>00:51:45,000 –&gt; 00:51:50,000<br>The question is, because anybody tried to do a hierarchal chunking?</p>
<p>407<br>00:51:50,000 –&gt; 00:51:54,000<br>Yes. There is hierarchal bitmaps.</p>
<p>408<br>00:51:54,000 –&gt; 00:51:56,000<br>You get screwed on super scaler CPUs.</p>
<p>409<br>00:51:56,000 –&gt; 00:51:59,000<br>It’s just too much in direction.</p>
<p>410<br>00:51:59,000 –&gt; 00:52:02,000<br>I have a slide for that, but we’re not covering that this semester.</p>
<p>411<br>00:52:02,000 –&gt; 00:52:04,000<br>That’s like an idea from the 1990s.</p>
<p>412<br>00:52:04,000 –&gt; 00:52:06,000<br>No one does that anymore.</p>
<p>413<br>00:52:06,000 –&gt; 00:52:10,000<br>In that case, also two, which you’re proposing, why bother doing the extra level?</p>
<p>414<br>00:52:10,000 –&gt; 00:52:14,000<br>Just make the top level larger.</p>
<p>415<br>00:52:14,000 –&gt; 00:52:15,000<br>Yes.</p>
<p>416<br>00:52:15,000 –&gt; 00:52:20,000<br>How do I interpret the bits?</p>
<p>417<br>00:52:20,000 –&gt; 00:52:23,000<br>It’s a bit mavenx, right?</p>
<p>418<br>00:52:23,000 –&gt; 00:52:29,000<br>So you want to say, is 50 set to true?</p>
<p>419<br>00:52:29,000 –&gt; 00:52:33,000<br>So after doing the division to figure out I’m going down this path,</p>
<p>420<br>00:52:33,000 –&gt; 00:52:37,000<br>I know that whatever the position is, what bit position in this,</p>
<p>421<br>00:52:37,000 –&gt; 00:52:47,000<br>is the offset to get the original key is this value plus the offset to reverse it back.</p>
<p>422<br>00:52:47,000 –&gt; 00:52:51,000<br>Not the key, but the actual, the starting point of the range.</p>
<p>423<br>00:52:51,000 –&gt; 00:52:55,000<br>So now within this, again, so say, I forgot how many things I have in here.</p>
<p>424<br>00:52:55,000 –&gt; 00:53:00,000<br>But if I want to know, is position 50 set to true?</p>
<p>425<br>00:53:00,000 –&gt; 00:53:04,000<br>Sorry, at position 50, I know that corresponds to my key here.</p>
<p>426<br>00:53:04,000 –&gt; 00:53:08,000<br>I can then check whether that bit set to true or not.</p>
<p>427<br>00:53:08,000 –&gt; 00:53:11,000<br>In this, I mean, it’s a PowerPoint.</p>
<p>428<br>00:53:11,000 –&gt; 00:53:13,000<br>I don’t know.</p>
<p>429<br>00:53:13,000 –&gt; 00:53:15,000<br>Yeah, but it’s a bit mavenx.</p>
<p>430<br>00:53:15,000 –&gt; 00:53:17,000<br>I think we covered it in the interclass.</p>
<p>431<br>00:53:17,000 –&gt; 00:53:18,000<br>We’re basically again.</p>
<p>432<br>00:53:18,000 –&gt; 00:53:25,000<br>If I want to know if is the value at 2,5 set to something,</p>
<p>433<br>00:53:25,000 –&gt; 00:53:27,000<br>ignoring how this actually is mapped to something,</p>
<p>434<br>00:53:27,000 –&gt; 00:53:32,000<br>I can then look to see whether a bit that corresponds to position 5 is set to true.</p>
<p>435<br>00:53:32,000 –&gt; 00:53:37,000<br>And then some higher level part of the system than interprets what does that mean.</p>
<p>436<br>00:53:37,000 –&gt; 00:53:40,000<br>Is this like a rudimentary version of a bloom filter?</p>
<p>437<br>00:53:40,000 –&gt; 00:53:43,000<br>Is this a rudimentary version of a bloom filter?</p>
<p>438<br>00:53:43,000 –&gt; 00:53:46,000<br>A bloom filter is a more than one thing.</p>
<p>439<br>00:53:46,000 –&gt; 00:53:50,000<br>So a bloom filter is a public data structure where you can get false positives.</p>
<p>440<br>00:53:50,000 –&gt; 00:53:51,000<br>You don’t get false positives.</p>
<p>441<br>00:53:51,000 –&gt; 00:53:54,000<br>You want to know something’s in there? This will tell you, yes or no?</p>
<p>442<br>00:53:54,000 –&gt; 00:53:59,000<br>Could you have more than one data value that matters in index?</p>
<p>443<br>00:53:59,000 –&gt; 00:54:00,000<br>No.</p>
<p>444<br>00:54:00,000 –&gt; 00:54:04,000<br>Because we’re dividing it by 2 to 16 to figure out what position we go to.</p>
<p>445<br>00:54:04,000 –&gt; 00:54:07,000<br>And then we take the mod, which is basically the remainder of that,</p>
<p>446<br>00:54:07,000 –&gt; 00:54:09,000<br>to figure out what bit it was in that.</p>
<p>447<br>00:54:09,000 –&gt; 00:54:11,000<br>So you won’t have any overlap.</p>
<p>448<br>00:54:11,000 –&gt; 00:54:16,000<br>What if the line is going to be like, what if the same here again?</p>
<p>449<br>00:54:16,000 –&gt; 00:54:18,000<br>What if the same here again?</p>
<p>450<br>00:54:18,000 –&gt; 00:54:22,000<br>What if that, what do you try to do with it?</p>
<p>451<br>00:54:22,000 –&gt; 00:54:27,000<br>Again, so the thing of like, if I’m storing the null bit map,</p>
<p>452<br>00:54:27,000 –&gt; 00:54:37,000<br>I can store it as this, and then I’m not going to set the two pool at offset 50 null multiple times.</p>
<p>453<br>00:54:37,000 –&gt; 00:54:38,000<br>It doesn’t make sense.</p>
<p>454<br>00:54:38,000 –&gt; 00:54:46,000<br>It’s not accounting data structure. It’s just a set membership.</p>
<p>455<br>00:54:46,000 –&gt; 00:54:50,000<br>Okay.</p>
<p>456<br>00:54:50,000 –&gt; 00:54:57,000<br>So, but better blocks, parkane, or generate variable length runs of values.</p>
<p>457<br>00:54:57,000 –&gt; 00:55:00,000<br>Parkane, better blocks is less susceptible to this,</p>
<p>458<br>00:55:00,000 –&gt; 00:55:05,000<br>but you could still have that within, you know, across the column chunks.</p>
<p>459<br>00:55:05,000 –&gt; 00:55:10,000<br>And then better blocks explicitly avoided delta encoding.</p>
<p>460<br>00:55:10,000 –&gt; 00:55:15,000<br>But again, you have this problem where the value of one given to pool would depend on the preceding value.</p>
<p>461<br>00:55:15,000 –&gt; 00:55:19,000<br>And again, you can’t use SIMD for that.</p>
<p>462<br>00:55:19,000 –&gt; 00:55:24,000<br>So, in the case of better blocks, they’re always going to use run length encoding the vectors.</p>
<p>463<br>00:55:24,000 –&gt; 00:55:30,000<br>Even if the data is the, would you end up encoding a small than the number of lanes you have in the SIMD register?</p>
<p>464<br>00:55:30,000 –&gt; 00:55:37,000<br>And so, the thing of like, if I, if I can, in my SIMD registers, I can put 16 values,</p>
<p>465<br>00:55:37,000 –&gt; 00:55:40,000<br>but I only have 12 values.</p>
<p>466<br>00:55:40,000 –&gt; 00:55:44,000<br>They’re still going to use all 16 positions in the SIMD register,</p>
<p>467<br>00:55:44,000 –&gt; 00:55:48,000<br>and then the last four just garbage, and they’ll clean that up afterwards.</p>
<p>468<br>00:55:49,000 –&gt; 00:55:57,000<br>And in the case of fast lines, we’ll see in a second, they align things such a way that you’re always guaranteed to always be doing useful work in your SIMD registers.</p>
<p>469<br>00:55:57,000 –&gt; 00:56:02,000<br>So, fast lines is not a complete file format, no same way that, that better blocks is,</p>
<p>470<br>00:56:02,000 –&gt; 00:56:10,000<br>it’s just a, you know, a low-level coding scheme that is going to achieve better data parallelism through reordering the tuples in such a way that,</p>
<p>471<br>00:56:10,000 –&gt; 00:56:18,000<br>can you always guaranteeing or always maximizing the amount of useful work you’re doing in your, in your, in your SIMD, SIMD registers or SIMD instructions.</p>
<p>472<br>00:56:19,000 –&gt; 00:56:25,000<br>So, the, they’re going to have all the same encoding schemes as better blocks, but again, with the addition of, of delta encoding.</p>
<p>473<br>00:56:25,000 –&gt; 00:56:37,000<br>And which really wild about this paper is that, as I said, they were rather than designing it for one, you know, instance or, or configuration of SIMD for one CPU vendor,</p>
<p>474<br>00:56:37,000 –&gt; 00:56:44,000<br>they basically say, hey, we’re going to make our own virtual ISA, and that’s going to have 10, 10, 24 SIMD registers.</p>
<p>475<br>00:56:44,000 –&gt; 00:56:53,000<br>Again, even though that hardware does not exist, well, they allude to, like, I think M1 has 10, 24 cache lines and so forth, right?</p>
<p>476<br>00:56:53,000 –&gt; 00:57:01,000<br>It’s a way to, you know, pretending or seeing, for seeing the, for shadowing the arrival of 10, 24 SIMD registers.</p>
<p>477<br>00:57:01,000 –&gt; 00:57:08,000<br>I remember seeing some talk from somebody at Intel saying, well, this is not happening anytime soon, but that was a few years ago, maybe things had changed.</p>
<p>478<br>00:57:08,000 –&gt; 00:57:16,000<br>But, but again, the idea is that they’re going to define all the operations on basic, basic constructs on these, this virtual ISA,</p>
<p>479<br>00:57:16,000 –&gt; 00:57:25,000<br>and then they can show how you can then map that to either scalar, siste code, which apparently still runs really well, or an existing SIMD instructions app.</p>
<p>480<br>00:57:26,000 –&gt; 00:57:31,000<br>So the key, key-coder thing that they’re doing is with the xenophore transphotos layout.</p>
<p>481<br>00:57:31,000 –&gt; 00:57:42,000<br>And again, the idea is that you’re going to reorder the values in a column, the tuples in the column, in such a way that you can do as much work as you can entirely on SIMD.</p>
<p>482<br>00:57:42,000 –&gt; 00:57:48,000<br>And the reason why we can get away with this, as I said before, is because we have this independence between the physical layer and the logical layer.</p>
<p>483<br>00:57:49,000 –&gt; 00:57:53,000<br>The relational model is based on order sets.</p>
<p>484<br>00:57:53,000 –&gt; 00:58:06,000<br>So you, as the application program, when you put data into a database, you should not expect that the data will be inserted in the same way that you, or the data will come back to you in your queries in the same way that you inserted it.</p>
<p>485<br>00:58:06,000 –&gt; 00:58:13,000<br>Most of the time, as you actually, for some cases, you know, depending on the system, you’ll usually get that.</p>
<p>486<br>00:58:14,000 –&gt; 00:58:17,000<br>But in case of postgres, as soon as you run the auto vacuum, that’s going to start moving tuples around.</p>
<p>487<br>00:58:17,000 –&gt; 00:58:20,000<br>And there’s no guarantee that you end up with the same ordering.</p>
<p>488<br>00:58:20,000 –&gt; 00:58:26,000<br>If you cared about ordering, you would explicitly have an order by call.</p>
<p>489<br>00:58:26,000 –&gt; 00:58:38,000<br>Because also, if you think about it too, what’s the optimal ordering for a set of column, for one given column versus another, that could depend based on what the query actually wants to do.</p>
<p>490<br>00:58:39,000 –&gt; 00:58:48,000<br>So instead, they’re going to make the choices. We’ll store this in the best way for us to process the data, and then let the query engine above it figure out how to do the stitch things back together.</p>
<p>491<br>00:58:48,000 –&gt; 00:58:59,000<br>If you wanted to record the order that things were inserted, you could add a selection vector that basically keeps track of the position of tuples when they arrived, but you ever had that sort of negates any dependant that you’re getting.</p>
<p>492<br>00:59:00,000 –&gt; 00:59:08,000<br>So again, all the algorithms are going to define, we’re going to be based on this virtual ISA, and then they just either emulate it on the AVX512 or scale instructions.</p>
<p>493<br>00:59:08,000 –&gt; 00:59:20,000<br>So in the second time, I’m going to show one example of how this works using a column that we’ll convert into run length encoding, and then we’ll convert that to dictionary coding with deltas.</p>
<p>494<br>00:59:20,000 –&gt; 00:59:25,000<br>And we’ll see how to do everything in a vectorized way with the reordering.</p>
<p>495<br>00:59:26,000 –&gt; 00:59:29,000<br>So say there’s our original column, but we have a bunch of extreme characters here.</p>
<p>496<br>00:59:29,000 –&gt; 00:59:32,000<br>And so we can first convert this to run length encoding.</p>
<p>497<br>00:59:32,000 –&gt; 00:59:42,000<br>So we have our original dictionary values here, cvca, our bcba, and then for each of those, you specify the run length as separate integers.</p>
<p>498<br>00:59:42,000 –&gt; 00:59:48,000<br>And the numbers on the bottom are just telling the positions within the vector where they correspond to.</p>
<p>499<br>00:59:49,000 –&gt; 00:59:51,000<br>So for this one now, we knew delton coding.</p>
<p>500<br>00:59:51,000 –&gt; 01:00:02,000<br>So we would have the starting base value here is 0, and then you could sort of read this as going across that we’re just adding, taking the deltas, whatever the seating value for us was.</p>
<p>501<br>01:00:02,000 –&gt; 01:00:17,000<br>And then the index vector then tells you how to take this materialization after you’ve done the reverse the delton coding to then tell you what the actual symbols that you want to get back.</p>
<p>502<br>01:00:17,000 –&gt; 01:00:25,000<br>So they’ll set things up like this, but then they go ahead and take this delta encoded vector because the index vector you don’t actually use, you just materialize it.</p>
<p>503<br>01:00:25,000 –&gt; 01:00:29,000<br>Sorry, you just materialize it and then do the delton coding on it.</p>
<p>504<br>01:00:29,000 –&gt; 01:00:39,000<br>They then order things in such a way that the continuous values aren’t going to be one after, sort of within the original data set, on going one after another.</p>
<p>505<br>01:00:39,000 –&gt; 01:00:44,000<br>They’re going to be in this example here, four elements away.</p>
<p>506<br>01:00:44,000 –&gt; 01:00:55,000<br>So now when you want to decode this vector like this, because it’s delton coding, we have the base vector is going to be now four elements instead of just one as before.</p>
<p>507<br>01:00:55,000 –&gt; 01:00:58,000<br>So as I start off, I take these four elements.</p>
<p>508<br>01:00:58,000 –&gt; 01:01:06,000<br>I do the SIMD edition now to apply it to this vector here, and then I produce the output here.</p>
<p>509<br>01:01:06,000 –&gt; 01:01:17,000<br>And they’re doing some extra steps to make sure that things are written out to the output and memory at these different locations because these correspond to the positions that they exist in the original index vector.</p>
<p>510<br>01:01:17,000 –&gt; 01:01:28,000<br>Because if I just have them be, this is right next to this, right next to that, then that’s going to screw up all my ordering that I need for the offsets to jump to other columns.</p>
<p>511<br>01:01:28,000 –&gt; 01:01:39,000<br>So even though things are coming out incrementally in out of order, we want to space things out so that it goes back into the right order.</p>
<p>512<br>01:01:39,000 –&gt; 01:01:44,000<br>And they talk about the bit shifting and other operations they do in SIMD to make this work.</p>
<p>513<br>01:01:44,000 –&gt; 01:01:52,000<br>So now we slide over the window to look at the next operations. And then in this case here, we’re taking the output of that was generated from this or these values here.</p>
<p>514<br>01:01:52,000 –&gt; 01:02:00,000<br>And then now we do SIMD to apply it to this next one to produce the next set of outputs. And likewise, we do this going down the line like that.</p>
<p>515<br>01:02:00,000 –&gt; 01:02:01,000<br>Yes.</p>
<p>516<br>01:02:01,000 –&gt; 01:02:03,000<br>So on this we store that off, right?</p>
<p>517<br>01:02:03,000 –&gt; 01:02:07,000<br>This question is, we store this top of the yellow one.</p>
<p>518<br>01:02:07,000 –&gt; 01:02:09,000<br>So the only yellow one on the whole, you’re not sure the whole thing.</p>
<p>519<br>01:02:09,000 –&gt; 01:02:11,000<br>You’re sort of the whole thing and then the yellow.</p>
<p>520<br>01:02:11,000 –&gt; 01:02:12,000<br>And the yellow.</p>
<p>521<br>01:02:12,000 –&gt; 01:02:13,000<br>Yes.</p>
<p>522<br>01:02:13,000 –&gt; 01:02:20,000<br>Isn’t that much worse than what we store for a next coding because it’s like, you look at a next coding much smaller?</p>
<p>523<br>01:02:20,000 –&gt; 01:02:27,000<br>So the statement is, isn’t this much worse than running a coding because the size is smaller.</p>
<p>524<br>01:02:27,000 –&gt; 01:02:30,000<br>Yes, but the decompression is bigger than the size.</p>
<p>525<br>01:02:30,000 –&gt; 01:02:32,000<br>The decompoding is faster, yes.</p>
<p>526<br>01:02:32,000 –&gt; 01:02:35,000<br>Again, classic computer science, computers are storage.</p>
<p>527<br>01:02:35,000 –&gt; 01:02:47,000<br>So I can store less data, but it’s going to make more work for me to decompress it.</p>
<p>528<br>01:02:47,000 –&gt; 01:02:51,000<br>Again, nobody does this as far as there’s no home source system that stores data like this.</p>
<p>529<br>01:02:51,000 –&gt; 01:02:54,000<br>This is wild.</p>
<p>530<br>01:02:54,000 –&gt; 01:02:59,000<br>And again, the paper type of other ways to handle this for other coding schemes.</p>
<p>531<br>01:02:59,000 –&gt; 01:03:08,000<br>But again, the basic ideas that were sort of spraying bits out into these vectors so that when we go to decode them,</p>
<p>532<br>01:03:08,000 –&gt; 01:03:12,000<br>they line up nicely into our SIMD registers.</p>
<p>533<br>01:03:12,000 –&gt; 01:03:18,000<br>We don’t have to do this scatter gather stuff to move things around to put it in the form that we actually need.</p>
<p>534<br>01:03:18,000 –&gt; 01:03:22,000<br>So you can’t actually decode this, the run-like encoding was SIMD, right?</p>
<p>535<br>01:03:22,000 –&gt; 01:03:27,000<br>Because you basically need conditional loops now to say, okay, I look at the run-line tier at 7.</p>
<p>536<br>01:03:27,000 –&gt; 01:03:30,000<br>Let me loop through and SIMD seven times.</p>
<p>537<br>01:03:30,000 –&gt; 01:03:33,000<br>You can co-genit and do it, right?</p>
<p>538<br>01:03:33,000 –&gt; 01:03:37,000<br>But we’ll see this in a week or so.</p>
<p>539<br>01:03:37,000 –&gt; 01:03:41,000<br>That co-genning brings a whole bunch of other problems that make lives harder.</p>
<p>540<br>01:03:41,000 –&gt; 01:03:42,000<br>Yes?</p>
<p>541<br>01:03:42,000 –&gt; 01:03:51,000<br>Can you also compress this?</p>
<p>542<br>01:03:51,000 –&gt; 01:03:54,000<br>Can you also compress this?</p>
<p>543<br>01:03:55,000 –&gt; 01:03:57,000<br>So better blocks would?</p>
<p>544<br>01:03:57,000 –&gt; 01:03:59,000<br>I don’t, these guys don’t.</p>
<p>545<br>01:03:59,000 –&gt; 01:04:09,000<br>Because if you do run the encoding on this, you’re back to this problem.</p>
<p>546<br>01:04:09,000 –&gt; 01:04:11,000<br>Okay?</p>
<p>547<br>01:04:11,000 –&gt; 01:04:12,000<br>All right.</p>
<p>548<br>01:04:12,000 –&gt; 01:04:15,000<br>I want to finish up talking about bits slicing that we can work with.</p>
<p>549<br>01:04:15,000 –&gt; 01:04:18,000<br>So all of the schemes we’ve talked about so far,</p>
<p>550<br>01:04:19,000 –&gt; 01:04:25,000<br>parking or better blocks, fast lanes, they are all about, you scan a column,</p>
<p>551<br>01:04:25,000 –&gt; 01:04:32,000<br>you’re looking at the entire value for each tuple in its entirety every single time.</p>
<p>552<br>01:04:35,000 –&gt; 01:04:43,000<br>And that means that you can’t, you can’t short-circuit the scan of the filter.</p>
<p>553<br>01:04:44,000 –&gt; 01:04:48,000<br>If you recognize early on that this data is never going to match.</p>
<p>554<br>01:04:48,000 –&gt; 01:04:51,000<br>So I mean, you can do this for strings, the string is decoded.</p>
<p>555<br>01:04:51,000 –&gt; 01:04:54,000<br>Like, if you ever look at the string-compare operation or ellipse,</p>
<p>556<br>01:04:54,000 –&gt; 01:04:56,000<br>it’s just a four-litre looks at everything element.</p>
<p>557<br>01:04:56,000 –&gt; 01:05:00,000<br>And then if it doesn’t match the thing you’re looking for, then it breaks out of the loop.</p>
<p>558<br>01:05:00,000 –&gt; 01:05:02,000<br>That’s what short-circuiting is.</p>
<p>559<br>01:05:02,000 –&gt; 01:05:09,000<br>But if we’re comparing two integers, right, ignoring SIMD, it’s a single instruction,</p>
<p>560<br>01:05:10,000 –&gt; 01:05:12,000<br>is this equal to this?</p>
<p>561<br>01:05:12,000 –&gt; 01:05:15,000<br>You’re at the lowest level of the hardware, you’re looking at these primitive data types.</p>
<p>562<br>01:05:15,000 –&gt; 01:05:20,000<br>You can’t do any tricks to say, oh, I recognize that the first bit of these two values</p>
<p>563<br>01:05:20,000 –&gt; 01:05:21,000<br>are going to match.</p>
<p>564<br>01:05:21,000 –&gt; 01:05:24,000<br>So why compare the other 31 bits?</p>
<p>565<br>01:05:24,000 –&gt; 01:05:30,000<br>Because that’s the interface that the hardware provides you.</p>
<p>566<br>01:05:30,000 –&gt; 01:05:32,000<br>The API that hardware provides you.</p>
<p>567<br>01:05:32,000 –&gt; 01:05:35,000<br>So, what we’re data-see, we can do every one, right?</p>
<p>568<br>01:05:35,000 –&gt; 01:05:37,000<br>So what if we could do this?</p>
<p>569<br>01:05:37,000 –&gt; 01:05:44,000<br>Is there a way to be able to recognize that we can just look at a subset of a value</p>
<p>570<br>01:05:44,000 –&gt; 01:05:49,000<br>and do comparisons based on that and only look at the rest of the data for that value</p>
<p>571<br>01:05:49,000 –&gt; 01:05:54,000<br>if we think it’s going to be meaningful or still match, if we need to.</p>
<p>572<br>01:05:54,000 –&gt; 01:05:57,000<br>So this is what basic idea is called bit slicing.</p>
<p>573<br>01:05:57,000 –&gt; 01:06:01,000<br>And this is an old idea from 1990s.</p>
<p>574<br>01:06:01,000 –&gt; 01:06:03,000<br>There was a system called Sybase, or it goes to still-around.</p>
<p>575<br>01:06:03,000 –&gt; 01:06:06,000<br>Sybase IQ that does this.</p>
<p>576<br>01:06:06,000 –&gt; 01:06:09,000<br>The Palosa or feature-based system I mentioned does this now.</p>
<p>577<br>01:06:09,000 –&gt; 01:06:13,000<br>The basic idea is that we’re going to store, instead of storing the actual integers,</p>
<p>578<br>01:06:13,000 –&gt; 01:06:17,000<br>all the bits contiguously, it’s like an extreme case of the column store.</p>
<p>579<br>01:06:17,000 –&gt; 01:06:20,000<br>So the column store was taking the rows, the rows breaking up to column store,</p>
<p>580<br>01:06:20,000 –&gt; 01:06:21,000<br>all the columns contiguously.</p>
<p>581<br>01:06:21,000 –&gt; 01:06:26,000<br>Now with bit slicing, we’re going to take the bits within a column,</p>
<p>582<br>01:06:26,000 –&gt; 01:06:29,000<br>store those things contiguously.</p>
<p>583<br>01:06:29,000 –&gt; 01:06:34,000<br>So the first bit for every single value in for all tuples, store that contiguously,</p>
<p>584<br>01:06:34,000 –&gt; 01:06:36,000<br>and so forth the other bits.</p>
<p>585<br>01:06:36,000 –&gt; 01:06:37,000<br>So let’s see an example here.</p>
<p>586<br>01:06:37,000 –&gt; 01:06:39,000<br>So there’s all places I lived in my life.</p>
<p>587<br>01:06:39,000 –&gt; 01:06:41,000<br>I grew up in Maryland, 21042.</p>
<p>588<br>01:06:41,000 –&gt; 01:06:45,000<br>It’s Compton, it’s Pittsburgh, it was constant in a bunch of places.</p>
<p>589<br>01:06:45,000 –&gt; 01:06:49,000<br>So we’re going to take say 21042, convert it to its binary form,</p>
<p>590<br>01:06:49,000 –&gt; 01:06:56,000<br>and then now we’re going to store a separate column of bits for every single one of those,</p>
<p>591<br>01:06:56,000 –&gt; 01:06:58,000<br>every single one of these positions.</p>
<p>592<br>01:06:58,000 –&gt; 01:07:02,000<br>Now these are 30 jubit integers, I’m showing the 17 bits because it has to fit on PowerPoint,</p>
<p>593<br>01:07:02,000 –&gt; 01:07:07,000<br>so then we always have a null bitmap, but then we just can scan along,</p>
<p>594<br>01:07:07,000 –&gt; 01:07:11,000<br>look at all the bits, and now store them across in separate vectors.</p>
<p>595<br>01:07:11,000 –&gt; 01:07:15,000<br>And we’ll do the same thing for all the other ones, like this.</p>
<p>596<br>01:07:15,000 –&gt; 01:07:19,000<br>Again, think of these as again, these are contiguously bitmaps.</p>
<p>597<br>01:07:19,000 –&gt; 01:07:22,000<br>Again, I can use voting bitmaps now to represent this.</p>
<p>598<br>01:07:22,000 –&gt; 01:07:26,000<br>In some cases, make the least significant bits, maybe those are not,</p>
<p>599<br>01:07:26,000 –&gt; 01:07:29,000<br>those are spars, but the most significant bits are dense.</p>
<p>600<br>01:07:29,000 –&gt; 01:07:34,000<br>So now I want to look up queries.</p>
<p>601<br>01:07:34,000 –&gt; 01:07:41,000<br>Select star from a customer table where zip code is less than 15, 15, 21, 7.</p>
<p>602<br>01:07:41,000 –&gt; 01:07:47,000<br>I can now walk across each slice and construct a result bitmap to see what tuples</p>
<p>603<br>01:07:47,000 –&gt; 01:07:52,000<br>that different offsets at the bit level are matching my predicate,</p>
<p>604<br>01:07:52,000 –&gt; 01:07:58,000<br>and then I can determine if I don’t see any more matches as I’m going along, I stop.</p>
<p>605<br>01:07:59,000 –&gt; 01:08:04,000<br>So this is the bit representation for 15, 21, 7.</p>
<p>606<br>01:08:04,000 –&gt; 01:08:08,000<br>So say some simplicity, maybe I just look at the first three bits,</p>
<p>607<br>01:08:08,000 –&gt; 01:08:09,000<br>because these are all zeros.</p>
<p>608<br>01:08:09,000 –&gt; 01:08:16,000<br>So that means that if there’s any tuple that has a bit set in these first three vectors,</p>
<p>609<br>01:08:16,000 –&gt; 01:08:21,000<br>then I know I can’t match my tuple, because it’s going to be greater than 15, 15, 15, 21, 7.</p>
<p>610<br>01:08:21,000 –&gt; 01:08:27,000<br>So I know I don’t need to look at that position anymore.</p>
<p>611<br>01:08:28,000 –&gt; 01:08:30,000<br>That’s the basic idea of bit slicing.</p>
<p>612<br>01:08:30,000 –&gt; 01:08:34,000<br>The original algorithm was all scale instructions, we’ll see bit weaving in a second</p>
<p>613<br>01:08:34,000 –&gt; 01:08:36,000<br>that can do this in Cindy.</p>
<p>614<br>01:08:36,000 –&gt; 01:08:40,000<br>But bit slicing can do some other interesting things, like some queries,</p>
<p>615<br>01:08:40,000 –&gt; 01:08:45,000<br>like aggregate queries, there’s actually really simple operations to compute these things quickly.</p>
<p>616<br>01:08:45,000 –&gt; 01:08:49,000<br>So if you want to compute the sum of integers,</p>
<p>617<br>01:08:49,000 –&gt; 01:08:54,000<br>well I could use the hammy weight or the hammy count for just counting the number of bits</p>
<p>618<br>01:08:55,000 –&gt; 01:08:58,000<br>that are set to one in a column.</p>
<p>619<br>01:08:58,000 –&gt; 01:09:01,000<br>And Intel and Cindy, they’re sorry,</p>
<p>620<br>01:09:01,000 –&gt; 01:09:05,000<br>the Intel-Prized Instructions that do this very quickly using pop count.</p>
<p>621<br>01:09:05,000 –&gt; 01:09:10,000<br>So there’s one instruction to go compute the number of bits that are set within some vector.</p>
<p>622<br>01:09:10,000 –&gt; 01:09:13,000<br>So now I just count all the bits in the first slice,</p>
<p>623<br>01:09:13,000 –&gt; 01:09:15,000<br>and then multiply that by two to the 17,</p>
<p>624<br>01:09:15,000 –&gt; 01:09:17,000<br>go to the next slice, count all the bits,</p>
<p>625<br>01:09:17,000 –&gt; 01:09:20,000<br>multiply that by two to the 16, and two go all the way down,</p>
<p>626<br>01:09:20,000 –&gt; 01:09:27,000<br>and then I end up with the aggregation for all my columns,</p>
<p>627<br>01:09:27,000 –&gt; 01:09:30,000<br>for my column here.</p>
<p>628<br>01:09:30,000 –&gt; 01:09:37,000<br>Again, that’s way faster than just doing integer instructions to add the sum together.</p>
<p>629<br>01:09:40,000 –&gt; 01:09:44,000<br>So bit slicing extent, there was original ideas from 1990s,</p>
<p>630<br>01:09:44,000 –&gt; 01:09:47,000<br>Jignesh was exploring this topic in the previous decade,</p>
<p>631<br>01:09:48,000 –&gt; 01:09:51,000<br>and I think he’s looking at it again now, of this technique called bit weaving.</p>
<p>632<br>01:09:51,000 –&gt; 01:09:55,000<br>The idea here is that it’s an alternative coding scheme for column databases</p>
<p>633<br>01:09:55,000 –&gt; 01:09:58,000<br>that’s going to be predicated on this idea of bit slicing,</p>
<p>634<br>01:09:58,000 –&gt; 01:10:04,000<br>but you’re going to do it in such a way that you can maximize the amount of Cindy prospects</p>
<p>635<br>01:10:04,000 –&gt; 01:10:06,000<br>or opportunities that you actually have.</p>
<p>636<br>01:10:06,000 –&gt; 01:10:09,000<br>What’s wild is that he did this work in 2013,</p>
<p>637<br>01:10:09,000 –&gt; 01:10:12,000<br>when Cindy was the ADX2,</p>
<p>638<br>01:10:12,000 –&gt; 01:10:15,000<br>didn’t have all the scattergather features</p>
<p>639<br>01:10:15,000 –&gt; 01:10:19,000<br>or the ADX512 stuff we’ll see in two weeks.</p>
<p>640<br>01:10:19,000 –&gt; 01:10:24,000<br>So the horizontal bit weaving approach we’ll see is highly scalar,</p>
<p>641<br>01:10:24,000 –&gt; 01:10:26,000<br>but then for the vertical one,</p>
<p>642<br>01:10:26,000 –&gt; 01:10:28,000<br>it’s basically same as bit slicing,</p>
<p>643<br>01:10:28,000 –&gt; 01:10:31,000<br>but it shows you how you can use Cindy for this.</p>
<p>644<br>01:10:31,000 –&gt; 01:10:32,000<br>Even though back in the day,</p>
<p>645<br>01:10:32,000 –&gt; 01:10:35,000<br>they didn’t have all the Cindy capabilities that we have now.</p>
<p>646<br>01:10:35,000 –&gt; 01:10:38,000<br>So Jignesh was building this in a project called QuickStep.</p>
<p>647<br>01:10:38,000 –&gt; 01:10:41,000<br>Think of this as like ductive E for ductive E,</p>
<p>648<br>01:10:41,000 –&gt; 01:10:43,000<br>like it was an embedded OLAP engine,</p>
<p>649<br>01:10:43,000 –&gt; 01:10:45,000<br>but it didn’t have a SQL front end.</p>
<p>650<br>01:10:45,000 –&gt; 01:10:47,000<br>It was just like a storage manager,</p>
<p>651<br>01:10:47,000 –&gt; 01:10:48,000<br>it could run OLAP queries,</p>
<p>652<br>01:10:48,000 –&gt; 01:10:50,000<br>and store things as column or data.</p>
<p>653<br>01:10:50,000 –&gt; 01:10:53,000<br>So I think it almost rocks DB, but for OLAP queries.</p>
<p>654<br>01:10:53,000 –&gt; 01:10:56,000<br>And so he spun a lot as an Apache project,</p>
<p>655<br>01:10:56,000 –&gt; 01:10:58,000<br>but then he could dive in 2018.</p>
<p>656<br>01:10:58,000 –&gt; 01:10:59,000<br>The code is still there.</p>
<p>657<br>01:10:59,000 –&gt; 01:11:01,000<br>I think he’s still working on it, roughly I think, right?</p>
<p>658<br>01:11:01,000 –&gt; 01:11:02,000<br>Somebody’s working on it.</p>
<p>659<br>01:11:02,000 –&gt; 01:11:05,000<br>But I don’t think the bit weaving stuff is actually in any of this,</p>
<p>660<br>01:11:05,000 –&gt; 01:11:08,000<br>but the open source version did not have it.</p>
<p>661<br>01:11:08,000 –&gt; 01:11:09,000<br>The academic version did.</p>
<p>662<br>01:11:09,000 –&gt; 01:11:12,000<br>But as far as I know, no other system implements this.</p>
<p>663<br>01:11:13,000 –&gt; 01:11:14,000<br>All right, so the two ways,</p>
<p>664<br>01:11:14,000 –&gt; 01:11:16,000<br>the two are encoding schemes that they propose.</p>
<p>665<br>01:11:16,000 –&gt; 01:11:18,000<br>The horizontal one is basically a row storage at the bit level,</p>
<p>666<br>01:11:18,000 –&gt; 01:11:20,000<br>and the vertical one is going to be like bit slicing,</p>
<p>667<br>01:11:20,000 –&gt; 01:11:23,000<br>but you’ll do this in such a way for,</p>
<p>668<br>01:11:23,000 –&gt; 01:11:26,000<br>that you can be clever about how to get better parallelism</p>
<p>669<br>01:11:26,000 –&gt; 01:11:28,000<br>through vectorization.</p>
<p>670<br>01:11:28,000 –&gt; 01:11:29,000<br>So I’m going to kind of rush into this,</p>
<p>671<br>01:11:29,000 –&gt; 01:11:31,000<br>but I just want to keep the flavor of what’s going on.</p>
<p>672<br>01:11:31,000 –&gt; 01:11:32,000<br>So with horizontal storage,</p>
<p>673<br>01:11:32,000 –&gt; 01:11:34,000<br>the idea is that here’s all our troopers who want to store,</p>
<p>674<br>01:11:34,000 –&gt; 01:11:36,000<br>and here’s the bit representation of the values,</p>
<p>675<br>01:11:36,000 –&gt; 01:11:38,000<br>and the red is their values.</p>
<p>676<br>01:11:38,000 –&gt; 01:11:40,000<br>So we’re going to break this up into segments.</p>
<p>677<br>01:11:41,000 –&gt; 01:11:48,000<br>And think of this as like a row group within our data file.</p>
<p>678<br>01:11:48,000 –&gt; 01:11:50,000<br>And then within a segment,</p>
<p>679<br>01:11:50,000 –&gt; 01:11:55,000<br>we’re going to store the data in order going from the top to the bottom.</p>
<p>680<br>01:11:55,000 –&gt; 01:11:57,000<br>So this is in the first vector,</p>
<p>681<br>01:11:57,000 –&gt; 01:11:58,000<br>we’ll have t0.</p>
<p>682<br>01:11:58,000 –&gt; 01:12:00,000<br>Second vector, the starting point is t1,</p>
<p>683<br>01:12:00,000 –&gt; 01:12:03,000<br>2, 3, and then wrap around in four.</p>
<p>684<br>01:12:03,000 –&gt; 01:12:07,000<br>And then we have the same thing for the other segment,</p>
<p>685<br>01:12:07,000 –&gt; 01:12:09,000<br>but because we don’t have additional entries,</p>
<p>686<br>01:12:09,000 –&gt; 01:12:12,000<br>we don’t need to store other vectors.</p>
<p>687<br>01:12:12,000 –&gt; 01:12:14,000<br>And so in my demonstration here,</p>
<p>688<br>01:12:14,000 –&gt; 01:12:16,000<br>I’m showing these are eight bit vectors,</p>
<p>689<br>01:12:16,000 –&gt; 01:12:18,000<br>but this would be like a processor word,</p>
<p>690<br>01:12:18,000 –&gt; 01:12:22,000<br>which I think for x86 is 16 bits,</p>
<p>691<br>01:12:22,000 –&gt; 01:12:23,000<br>because it’s from the 80s,</p>
<p>692<br>01:12:23,000 –&gt; 01:12:25,000<br>but arm is 32 bits.</p>
<p>693<br>01:12:25,000 –&gt; 01:12:30,000<br>Basically, this is the large representation</p>
<p>694<br>01:12:30,000 –&gt; 01:12:33,000<br>that the processor can operate on.</p>
<p>695<br>01:12:33,000 –&gt; 01:12:36,000<br>So then you know, in addition to destroying the values</p>
<p>696<br>01:12:36,000 –&gt; 01:12:39,000<br>as three bits, there’s going to be this padding value here</p>
<p>697<br>01:12:39,000 –&gt; 01:12:42,000<br>that’s going to use as a place to record</p>
<p>698<br>01:12:42,000 –&gt; 01:12:46,000<br>for a given operation, was it true or false?</p>
<p>699<br>01:12:46,000 –&gt; 01:12:49,000<br>So when you store things in this bit-leading approach,</p>
<p>700<br>01:12:49,000 –&gt; 01:12:51,000<br>you always have to have this extra space.</p>
<p>701<br>01:12:51,000 –&gt; 01:12:54,000<br>So you’re paying a one bit penalty per tuple</p>
<p>702<br>01:12:54,000 –&gt; 01:12:57,000<br>to store it in this manner.</p>
<p>703<br>01:12:57,000 –&gt; 01:12:59,000<br>But if that’s going to allow us to do Cindy operations</p>
<p>704<br>01:12:59,000 –&gt; 01:13:03,000<br>or do operations where we just store what happened to our,</p>
<p>705<br>01:13:04,000 –&gt; 01:13:06,000<br>whether again, the filter or whatever</p>
<p>706<br>01:13:06,000 –&gt; 01:13:08,000<br>we’re trying to do, if it applies to true,</p>
<p>707<br>01:13:08,000 –&gt; 01:13:12,000<br>we’ll store it here rather than some other location in memory.</p>
<p>708<br>01:13:12,000 –&gt; 01:13:14,000<br>So let’s see an example here.</p>
<p>709<br>01:13:14,000 –&gt; 01:13:16,000<br>We have a query, we want to find on our table,</p>
<p>710<br>01:13:16,000 –&gt; 01:13:18,000<br>find all the values less than five.</p>
<p>711<br>01:13:18,000 –&gt; 01:13:22,000<br>So say we’ll just start with the first vector,</p>
<p>712<br>01:13:22,000 –&gt; 01:13:25,000<br>so that’s going to have t0 and t4.</p>
<p>713<br>01:13:25,000 –&gt; 01:13:30,000<br>And then we have now our encoding for the value five,</p>
<p>714<br>01:13:30,000 –&gt; 01:13:32,000<br>is this one zero one.</p>
<p>715<br>01:13:32,000 –&gt; 01:13:34,000<br>We’ll have repeated versions of that,</p>
<p>716<br>01:13:34,000 –&gt; 01:13:37,000<br>repeated values for instances of those bits,</p>
<p>717<br>01:13:37,000 –&gt; 01:13:40,000<br>corresponding to all the lanes above for the tuples</p>
<p>718<br>01:13:40,000 –&gt; 01:13:42,000<br>are trying to compare against.</p>
<p>719<br>01:13:42,000 –&gt; 01:13:46,000<br>And then there’s some mass vector where they define formulas</p>
<p>720<br>01:13:46,000 –&gt; 01:13:48,000<br>that specify how to actually do this arithmetic,</p>
<p>721<br>01:13:48,000 –&gt; 01:13:51,000<br>just using bit operations, bit level operations.</p>
<p>722<br>01:13:51,000 –&gt; 01:13:53,000<br>So I guess to do addition,</p>
<p>723<br>01:13:53,000 –&gt; 01:13:56,000<br>so whatever this formula is here, so it says all ones.</p>
<p>724<br>01:13:56,000 –&gt; 01:13:58,000<br>So then now I can just do,</p>
<p>725<br>01:13:58,000 –&gt; 01:14:01,000<br>I do the operation, produces the selection vector</p>
<p>726<br>01:14:01,000 –&gt; 01:14:07,000<br>that determines whether the predicated value of the true,</p>
<p>727<br>01:14:07,000 –&gt; 01:14:10,000<br>if the padding bit is set to zero one.</p>
<p>728<br>01:14:10,000 –&gt; 01:14:12,000<br>So in this case, t0 is what?</p>
<p>729<br>01:14:12,000 –&gt; 01:14:15,000<br>Is one, so that’s less than five, that’s set to true,</p>
<p>730<br>01:14:15,000 –&gt; 01:14:18,000<br>and then t4 was, what is that?</p>
<p>731<br>01:14:18,000 –&gt; 01:14:22,000<br>Seven, so that’s set to, that’s greater than five,</p>
<p>732<br>01:14:22,000 –&gt; 01:14:24,000<br>so that’s set to zero.</p>
<p>733<br>01:14:24,000 –&gt; 01:14:25,000<br>Right?</p>
<p>734<br>01:14:25,000 –&gt; 01:14:27,000<br>Six, sorry.</p>
<p>735<br>01:14:27,000 –&gt; 01:14:32,000<br>Right, yeah.</p>
<p>736<br>01:14:32,000 –&gt; 01:14:36,000<br>So what’s nice about this is that it only requires three instructions</p>
<p>737<br>01:14:36,000 –&gt; 01:14:38,000<br>to evaluate a single word.</p>
<p>738<br>01:14:38,000 –&gt; 01:14:41,000<br>So I can compare two values within a single instruction,</p>
<p>739<br>01:14:41,000 –&gt; 01:14:44,000<br>whereas if I’m just running this in a columnar data,</p>
<p>740<br>01:14:44,000 –&gt; 01:14:47,000<br>ignoring compression and all that other stuff and coding seems,</p>
<p>741<br>01:14:47,000 –&gt; 01:14:51,000<br>I would basically say, okay, is one less than the five,</p>
<p>742<br>01:14:51,000 –&gt; 01:14:54,000<br>true of false, it’s five less than six, true of false.</p>
<p>743<br>01:14:54,000 –&gt; 01:14:56,000<br>But even without, I can send you,</p>
<p>744<br>01:14:56,000 –&gt; 01:14:58,000<br>you can vectorize that, make that run fast,</p>
<p>745<br>01:14:58,000 –&gt; 01:15:02,000<br>but even without send if I store the data in this bit-read pattern,</p>
<p>746<br>01:15:02,000 –&gt; 01:15:10,000<br>I can just use regular, sistine instructions to get the same kind of data parallelism we would get otherwise.</p>
<p>747<br>01:15:10,000 –&gt; 01:15:13,000<br>So now we got to, though, you know, if you apply to all our vectors,</p>
<p>748<br>01:15:13,000 –&gt; 01:15:16,000<br>we’re going to end up with a bunch of these different,</p>
<p>749<br>01:15:16,000 –&gt; 01:15:18,000<br>these selection vectors, right?</p>
<p>750<br>01:15:18,000 –&gt; 01:15:23,000<br>But now we got to put this back together to get back the offsets of our tuples,</p>
<p>751<br>01:15:23,000 –&gt; 01:15:26,000<br>in our column, that actually were set to true,</p>
<p>752<br>01:15:26,000 –&gt; 01:15:28,000<br>or were satisfied our predicate.</p>
<p>753<br>01:15:28,000 –&gt; 01:15:33,000<br>So to do this, all you need to do is just bit shifting to sliding everything over,</p>
<p>754<br>01:15:33,000 –&gt; 01:15:39,000<br>so many steps, and then I can then collapse it with an OR operation</p>
<p>755<br>01:15:39,000 –&gt; 01:15:44,000<br>to generate the selection vector that corresponds to, you know,</p>
<p>756<br>01:15:44,000 –&gt; 01:15:47,000<br>whether the tuple match had a given offset.</p>
<p>757<br>01:15:47,000 –&gt; 01:15:50,000<br>And then if I need to go back to the original value,</p>
<p>758<br>01:15:50,000 –&gt; 01:15:55,000<br>I can use that to figure out, I’ll go get the original tuple.</p>
<p>759<br>01:15:55,000 –&gt; 01:15:59,000<br>The problem with the selection vector is that it’s just bits, right?</p>
<p>760<br>01:15:59,000 –&gt; 01:16:02,000<br>We need a way to reverse that and say, you know,</p>
<p>761<br>01:16:02,000 –&gt; 01:16:04,000<br>what position is the bit set to true?</p>
<p>762<br>01:16:04,000 –&gt; 01:16:07,000<br>To know, again, what offset in our, in our, in our original vector,</p>
<p>763<br>01:16:07,000 –&gt; 01:16:09,000<br>match the true.</p>
<p>764<br>01:16:09,000 –&gt; 01:16:12,000<br>So the easiest thing to do is just iterate like a simple for loop, right?</p>
<p>765<br>01:16:12,000 –&gt; 01:16:16,000<br>If the selection vector is set to true, then add it to an output buffer.</p>
<p>766<br>01:16:16,000 –&gt; 01:16:19,000<br>But that sucks, right? That’s a for loop.</p>
<p>767<br>01:16:19,000 –&gt; 01:16:23,000<br>That’s slow, again, just convert bit offsets into values.</p>
<p>768<br>01:16:23,000 –&gt; 01:16:26,000<br>As far as I know, there isn’t a SIMD instruction.</p>
<p>769<br>01:16:26,000 –&gt; 01:16:29,000<br>There isn’t a CPU instruction to do this for us.</p>
<p>770<br>01:16:29,000 –&gt; 01:16:32,000<br>So the alternative is to use a trick called,</p>
<p>771<br>01:16:32,000 –&gt; 01:16:35,000<br>came from the vector wise paper from Peter Bonson,</p>
<p>772<br>01:16:35,000 –&gt; 01:16:37,000<br>the paper you guys read next Monday.</p>
<p>773<br>01:16:37,000 –&gt; 01:16:41,000<br>We pre-compute all the positions,</p>
<p>774<br>01:16:41,000 –&gt; 01:16:44,000<br>so you pre-compute all the selection vectors ahead of time.</p>
<p>775<br>01:16:44,000 –&gt; 01:16:47,000<br>And then now you just have a simple array that says,</p>
<p>776<br>01:16:47,000 –&gt; 01:16:51,000<br>OK, well, if I take this binary encoding and convert it to the actual number,</p>
<p>777<br>01:16:51,000 –&gt; 01:16:55,000<br>in this case it’s 150, I jump into my array at offset 150,</p>
<p>778<br>01:16:55,000 –&gt; 01:16:58,000<br>and then now I’m storing my selection vector.</p>
<p>779<br>01:16:58,000 –&gt; 01:17:01,000<br>They tell you what position is set to true.</p>
<p>780<br>01:17:01,000 –&gt; 01:17:03,000<br>And again, in my simple example here,</p>
<p>781<br>01:17:03,000 –&gt; 01:17:06,000<br>the size selection vector is a bit.</p>
<p>782<br>01:17:06,000 –&gt; 01:17:08,000<br>So with 2 to the 8 possible values,</p>
<p>783<br>01:17:08,000 –&gt; 01:17:11,000<br>like this thing is easily sitting in L2 cache.</p>
<p>784<br>01:17:11,000 –&gt; 01:17:15,000<br>So it’s not, it’s not, you know, this big chunk of memory I got to maintain</p>
<p>785<br>01:17:15,000 –&gt; 01:17:19,000<br>just to convert bit maps into values.</p>
<p>786<br>01:17:19,000 –&gt; 01:17:25,000<br>All right, last one, bit leaving vertical.</p>
<p>787<br>01:17:25,000 –&gt; 01:17:31,000<br>So for this one, we’re going to store the bits that are all within some offset,</p>
<p>788<br>01:17:31,000 –&gt; 01:17:33,000<br>continuously.</p>
<p>789<br>01:17:33,000 –&gt; 01:17:36,000<br>So we’re going to have one vector for all the bits at position 0,</p>
<p>790<br>01:17:36,000 –&gt; 01:17:39,000<br>next vector of position 1, 2, and so forth.</p>
<p>791<br>01:17:39,000 –&gt; 01:17:41,000<br>And then now we can down this other segment here,</p>
<p>792<br>01:17:41,000 –&gt; 01:17:43,000<br>because only has two values, we still have to put,</p>
<p>793<br>01:17:43,000 –&gt; 01:17:45,000<br>we still have to record the entire vector,</p>
<p>794<br>01:17:45,000 –&gt; 01:17:47,000<br>but we just have bunch of zeros in there.</p>
<p>795<br>01:17:47,000 –&gt; 01:17:49,000<br>So it’s wasted space, it’s going to waste instructions,</p>
<p>796<br>01:17:49,000 –&gt; 01:17:51,000<br>the way that the fastening guys don’t like,</p>
<p>797<br>01:17:51,000 –&gt; 01:17:55,000<br>but it makes our life easier when we want to do the calculations.</p>
<p>798<br>01:17:55,000 –&gt; 01:17:57,000<br>All right, so this is vector here, and so forth.</p>
<p>799<br>01:17:57,000 –&gt; 01:17:59,000<br>And again, same thing as a processor word.</p>
<p>800<br>01:17:59,000 –&gt; 01:18:01,000<br>But now we don’t have this padding bit anymore,</p>
<p>801<br>01:18:01,000 –&gt; 01:18:03,000<br>right, to be able to record things.</p>
<p>802<br>01:18:03,000 –&gt; 01:18:05,000<br>We can do everything here in Cindy.</p>
<p>803<br>01:18:05,000 –&gt; 01:18:07,000<br>So I want to look up and say,</p>
<p>804<br>01:18:07,000 –&gt; 01:18:09,000<br>find me all the two boos we’re value equals 2.</p>
<p>805<br>01:18:09,000 –&gt; 01:18:12,000<br>Again, 2 is just that bit, not like that.</p>
<p>806<br>01:18:12,000 –&gt; 01:18:16,000<br>I take the first vector, I generate a mass vector,</p>
<p>807<br>01:18:16,000 –&gt; 01:18:18,000<br>that I’m going to use for my comparison,</p>
<p>808<br>01:18:18,000 –&gt; 01:18:22,000<br>because these are all zeros, I want to see whether these are</p>
<p>809<br>01:18:22,000 –&gt; 01:18:26,000<br>sets of true across this, and I get my selected vector like this.</p>
<p>810<br>01:18:26,000 –&gt; 01:18:28,000<br>And then now I run pop count and say,</p>
<p>811<br>01:18:28,000 –&gt; 01:18:30,000<br>is there at least one bit set to 1,</p>
<p>812<br>01:18:30,000 –&gt; 01:18:32,000<br>if yes, then I keep going.</p>
<p>813<br>01:18:32,000 –&gt; 01:18:35,000<br>If there’s no bit set to 0, then I short circuit, I terminate.</p>
<p>814<br>01:18:35,000 –&gt; 01:18:37,000<br>Now I have to look at the other vectors.</p>
<p>815<br>01:18:37,000 –&gt; 01:18:41,000<br>So I only need to look at the subset of the data within a given</p>
<p>816<br>01:18:42,000 –&gt; 01:18:44,000<br>value at the bit level.</p>
<p>817<br>01:18:44,000 –&gt; 01:18:46,000<br>In this case here, there’s some bits set to 1.</p>
<p>818<br>01:18:46,000 –&gt; 01:18:48,000<br>So I go down to the next vector.</p>
<p>819<br>01:18:48,000 –&gt; 01:18:50,000<br>Now I do comparison with my mass, that says,</p>
<p>820<br>01:18:50,000 –&gt; 01:18:53,000<br>find me all the values that are equal to 1 at different positions.</p>
<p>821<br>01:18:53,000 –&gt; 01:18:55,000<br>Now my selection vector is all zeros.</p>
<p>822<br>01:18:55,000 –&gt; 01:18:58,000<br>So I know there’s nothing else that could ever match my predicate,</p>
<p>823<br>01:18:58,000 –&gt; 01:19:00,000<br>and I stop.</p>
<p>824<br>01:19:00,000 –&gt; 01:19:01,000<br>Right?</p>
<p>825<br>01:19:01,000 –&gt; 01:19:04,000<br>So in this stupid example here, I have three bit values.</p>
<p>826<br>01:19:04,000 –&gt; 01:19:09,000<br>If I had 64 bit values, or 30 bit values, I could stop early.</p>
<p>827<br>01:19:10,000 –&gt; 01:19:15,000<br>And comparing multiple, again, within these structures that I’m doing</p>
<p>828<br>01:19:15,000 –&gt; 01:19:18,000<br>simddy, I’m looking at way more values than I would otherwise,</p>
<p>829<br>01:19:18,000 –&gt; 01:19:23,000<br>if I were looking at the entire values of the integers.</p>
<p>830<br>01:19:23,000 –&gt; 01:19:25,000<br>So we do all the early printing.</p>
<p>831<br>01:19:25,000 –&gt; 01:19:27,000<br>We do like a bit slicing.</p>
<p>832<br>01:19:27,000 –&gt; 01:19:32,000<br>Again, skip last vector if all the bits are pretty 0.</p>
<p>833<br>01:19:32,000 –&gt; 01:19:34,000<br>And then the algorithm has a bunch of,</p>
<p>834<br>01:19:34,000 –&gt; 01:19:36,000<br>the paper has a bunch of algorithms to handle all the other operations</p>
<p>835<br>01:19:36,000 –&gt; 01:19:37,000<br>you want to do.</p>
<p>836<br>01:19:37,000 –&gt; 01:19:43,000<br>I kind of rush this, but we’re not going to see this technique used in other papers,</p>
<p>837<br>01:19:43,000 –&gt; 01:19:46,000<br>but it’s a different way to think about how to store data in database.</p>
<p>838<br>01:19:46,000 –&gt; 01:19:48,000<br>Which I like.</p>
<p>839<br>01:19:48,000 –&gt; 01:19:51,000<br>All right, so I said this multiple times about today’s lecture.</p>
<p>840<br>01:19:51,000 –&gt; 01:19:57,000<br>This is really showing you that the logical and physical data in penance is super important.</p>
<p>841<br>01:19:57,000 –&gt; 01:20:00,000<br>He was starting to say things like, oh, what do you have pointers to data?</p>
<p>842<br>01:20:00,000 –&gt; 01:20:03,000<br>And that, like, as someone who’s like,</p>
<p>843<br>01:20:03,000 –&gt; 01:20:05,000<br>it hears the relational model, that gives me nightmares.</p>
<p>844<br>01:20:05,000 –&gt; 01:20:07,000<br>Like pointers to what? Why?</p>
<p>845<br>01:20:07,000 –&gt; 01:20:08,000<br>That’s a bad idea.</p>
<p>846<br>01:20:08,000 –&gt; 01:20:11,000<br>We want to be able to use just fixed length all sets and do anything we want on the</p>
<p>847<br>01:20:11,000 –&gt; 01:20:15,000<br>covers and not worry about, you know,</p>
<p>848<br>01:20:15,000 –&gt; 01:20:20,000<br>be able to not worry about explicit pointers or different things,</p>
<p>849<br>01:20:20,000 –&gt; 01:20:24,000<br>and not worry about how programmers actually see those pointers.</p>
<p>850<br>01:20:24,000 –&gt; 01:20:26,000<br>Everything’s done on the cover.</p>
<p>851<br>01:20:26,000 –&gt; 01:20:28,000<br>And that way they can do his right sequel, right,</p>
<p>852<br>01:20:28,000 –&gt; 01:20:30,000<br>whatever Python code that they want,</p>
<p>853<br>01:20:30,000 –&gt; 01:20:33,000<br>operates on our system, and nothing changes.</p>
<p>854<br>01:20:33,000 –&gt; 01:20:36,000<br>And then the data parallelism through Symbi is going to be really important tool.</p>
<p>855<br>01:20:36,000 –&gt; 01:20:38,000<br>We’ll see throughout the entire semester, right?</p>
<p>856<br>01:20:38,000 –&gt; 01:20:43,000<br>The paper on Monday next week will be the precursor to using Symbi for stuff.</p>
<p>857<br>01:20:43,000 –&gt; 01:20:46,000<br>It was written in 2006 or 2007.</p>
<p>858<br>01:20:46,000 –&gt; 01:20:51,000<br>So Symbi wasn’t as useful for database as it is now,</p>
<p>859<br>01:20:51,000 –&gt; 01:20:58,000<br>but it’s designing the query processing model for the database system in such a way that you can vectorize a bunch of stuff.</p>
<p>860<br>01:20:58,000 –&gt; 01:20:59,000<br>Okay?</p>
<p>861<br>01:20:59,000 –&gt; 01:21:01,000<br>But we’ll see algorithms how to do joins,</p>
<p>862<br>01:21:01,000 –&gt; 01:21:04,000<br>filters and other things using Symbi going forward.</p>
<p>863<br>01:21:31,000 –&gt; 01:21:32,000<br>You can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say, you can’t just say</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CMU15721 P4S202403 DataFormatsEncodingPart2CMUAdvancedDatabaseSystems</div>
      <div>http://example.com/2025/10/25/CMU15721 P4S202403-DataFormatsEncodingPart2CMUAdvancedDatabaseSystems/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/25/CMU15721%20P6S202405-QueryExecutionProcessingPart2CMUAdvancedDatabaseSystems/" title="CMU15721 P6S202405 QueryExecutionProcessingPart2CMUAdvancedDatabaseSystems">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CMU15721 P6S202405 QueryExecutionProcessingPart2CMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/25/CMU15721%20P3S202402-DataFormatsEncodingPart1CMUAdvancedDatabaseSystems/" title="CMU15721 P3S202402 DataFormatsEncodingPart1CMUAdvancedDatabaseSystems">
                        <span class="hidden-mobile">CMU15721 P3S202402 DataFormatsEncodingPart1CMUAdvancedDatabaseSystems</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
