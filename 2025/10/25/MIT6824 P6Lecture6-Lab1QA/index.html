

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="100:00:00,000 –&gt; 00:00:11,279All right. Well, it’s five after so I’ll just go ahead and get started. So today’s lecture 200:00:11,279 –&gt; 00:00:18,480is a Q&amp;A on the first lab, the MapReduce">
<meta property="og:type" content="article">
<meta property="og:title" content="MIT6824 P6Lecture6 Lab1QA">
<meta property="og:url" content="http://example.com/2025/10/25/MIT6824%20P6Lecture6-Lab1QA/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="100:00:00,000 –&gt; 00:00:11,279All right. Well, it’s five after so I’ll just go ahead and get started. So today’s lecture 200:00:11,279 –&gt; 00:00:18,480is a Q&amp;A on the first lab, the MapReduce">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-25T05:03:39.807Z">
<meta property="article:modified_time" content="2025-10-25T05:03:39.808Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>MIT6824 P6Lecture6 Lab1QA - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="MIT6824 P6Lecture6 Lab1QA"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-10-25 13:03" pubdate>
          2025年10月25日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          55 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">MIT6824 P6Lecture6 Lab1QA</h1>
            
            
              <div class="markdown-body">
                
                <p>1<br>00:00:00,000 –&gt; 00:00:11,279<br>All right. Well, it’s five after so I’ll just go ahead and get started. So today’s lecture</p>
<p>2<br>00:00:11,279 –&gt; 00:00:18,480<br>is a Q&amp;A on the first lab, the MapReduce lab, and also some just general coding Q&amp;A’s</p>
<p>3<br>00:00:18,480 –&gt; 00:00:24,000<br>for go programming that might help in future labs. So feel free to stop at any time or put questions</p>
<p>4<br>00:00:24,000 –&gt; 00:00:30,480<br>in the chat and I’ll be checking it out occasionally. And I’m sure like other QAs can also tell</p>
<p>5<br>00:00:30,480 –&gt; 00:00:35,840<br>this well. If you are unmuted and typing, it would be helpful if you meet yourself.</p>
<p>6<br>00:00:37,759 –&gt; 00:00:43,039<br>But yeah. All right. So agenda for today, the first thing I’m going to do is actually walk</p>
<p>7<br>00:00:43,039 –&gt; 00:00:49,359<br>through a solution of lab one. And this is my personal solution. It’s probably not perfect,</p>
<p>8<br>00:00:49,359 –&gt; 00:00:55,119<br>but it’s an example of what you could have done. So I think we’re going to discuss some alternative</p>
<p>9<br>00:00:55,119 –&gt; 00:01:04,799<br>solution designs. So I’m just still typing. Jay, stop typing. Or if it’s not supposed to be</p>
<p>10<br>00:01:06,560 –&gt; 00:01:12,400<br>nervous. Third, we’re going to discuss some of the Coleman design mistakes and some of the bugs that</p>
<p>11<br>00:01:12,400 –&gt; 00:01:19,760<br>you guys had in your solutions for just go over some general tips. And then finally, we’re going</p>
<p>12<br>00:01:19,760 –&gt; 00:01:26,719<br>to, if there’s time, go through some Q&amp;As both questions you might have right now. And also</p>
<p>13<br>00:01:26,719 –&gt; 00:01:34,880<br>questions that you submitted before lecture. So first, for the lab solution walk through,</p>
<p>14<br>00:01:35,839 –&gt; 00:01:40,000<br>let me know if the font is too small. I’ll just stick with this.</p>
<p>15<br>00:01:40,959 –&gt; 00:01:48,879<br>All right. So I basically went step by step and I’ll show how I developed my solution.</p>
<p>16<br>00:01:48,879 –&gt; 00:01:57,120<br>So the first thing I did was this is rtc.go. And the first thing I did was figure out the API in</p>
<p>17<br>00:01:57,120 –&gt; 00:02:04,399<br>which I wanted my workroom coordinator to communicate. And so the first thing I did was define</p>
<p>18<br>00:02:04,480 –&gt; 00:02:10,560<br>what types of tests there are. And so they are mapping, reduce tests. And in order to signal that</p>
<p>19<br>00:02:10,560 –&gt; 00:02:16,640<br>the coordinator has things that John has done, there’s a done test. And so these are the types of</p>
<p>20<br>00:02:16,719 –&gt; 00:02:20,319<br>tests that I’ve done. So I’m going to talk about the top. Can you zoom in a bit? Can you zoom in a bit?</p>
<p>21<br>00:02:20,319 –&gt; 00:02:27,759<br>Oh yeah. The fonts. Yeah. So that good? All right. Yeah. Thanks.</p>
<p>22<br>00:02:29,119 –&gt; 00:02:32,239<br>Cool. Yeah, it’s hard for me to tell how it looks.</p>
<p>23<br>00:02:34,239 –&gt; 00:02:44,319<br>So hopefully this is good. And so there are two rpcs I decided to implement. The first is a worker</p>
<p>24<br>00:02:44,319 –&gt; 00:02:49,840<br>asking the coordinator to give it a task. So one of map, reduce or done and please exit.</p>
<p>25<br>00:02:50,479 –&gt; 00:02:54,719<br>And basically there’s like the arguments you don’t really have to</p>
<p>26<br>00:02:54,719 –&gt; 00:03:01,439<br>point out arguments are just asking for a task. And the coordinator replies with what task is this</p>
<p>27<br>00:03:01,439 –&gt; 00:03:09,439<br>which task of that type to do do. And also some extra data that’s needed for the map or</p>
<p>28<br>00:03:09,439 –&gt; 00:03:14,079<br>reduce tasks such as the number of map tasks in the system or the number of reduced tasks.</p>
<p>29<br>00:03:15,439 –&gt; 00:03:21,919<br>And the second rpc is a finished task rpc that the worker uses to notify the coordinator</p>
<p>30<br>00:03:21,919 –&gt; 00:03:28,879<br>that it has finished the task. And it passes in as arguments which task it has finished. And they</p>
<p>31<br>00:03:28,879 –&gt; 00:03:34,560<br>don’t actually really need to get a reply for this. So that’s the first step of the implementation.</p>
<p>32<br>00:03:35,439 –&gt; 00:03:45,599<br>So hi. All right. So as a second step, why did is implement the handlers for all these rpcs.</p>
<p>33<br>00:03:46,159 –&gt; 00:03:52,879<br>And so that’s an coordinator. So first I had to actually populate the coordinator with the</p>
<p>34<br>00:03:52,879 –&gt; 00:03:58,080<br>coordinator state. And so there’s the mutex which protects the state from concurrent access because</p>
<p>35<br>00:03:58,080 –&gt; 00:04:05,120<br>the coordinator will have multiple threads running concurrently. Then the second part is to keep</p>
<p>36<br>00:04:05,120 –&gt; 00:04:09,760<br>track of just like the files that we need for map tests and the number of map and reduced tasks.</p>
<p>37<br>00:04:10,720 –&gt; 00:04:18,400<br>And this metadata is used to track which tasks have we issued and which tasks has finished.</p>
<p>38<br>00:04:20,240 –&gt; 00:04:24,879<br>The ones that we’ve issued we keep track of a timestamps that we know if these tasks haven’t</p>
<p>39<br>00:04:24,879 –&gt; 00:04:32,079<br>completed within a certain amount of time to reissue them. And finally we have the like has all</p>
<p>40<br>00:04:32,639 –&gt; 00:04:42,560<br>has the coordinator finished Boolean. So to handle the get task rpc we have a handler that essentially</p>
<p>41<br>00:04:42,560 –&gt; 00:04:50,159<br>what it does is it will set the reply fields. Right now I haven’t yet implemented the part that</p>
<p>42<br>00:04:50,160 –&gt; 00:04:56,000<br>actually issues the tests. And if all the map and reduced tests are done it will send a</p>
<p>43<br>00:04:56,000 –&gt; 00:05:06,960<br>done task to the worker and then we have the handler for the finished task rpc. And what this does</p>
<p>44<br>00:05:06,960 –&gt; 00:05:16,160<br>is it basically depending on what task it was sets that flag to true that has that task has finished.</p>
<p>45<br>00:05:16,560 –&gt; 00:05:21,120<br>So that’s the second step which is implementing the handlers for the rpcs.</p>
<p>46<br>00:05:24,160 –&gt; 00:05:30,880<br>So the third step I have is actually sending the rpcs. And so that</p>
<p>47<br>00:05:32,640 –&gt; 00:05:36,160<br>is the work here. So</p>
<p>48<br>00:05:36,160 –&gt; 00:05:48,560<br>the top of this book we provided it does is it starts up the loop that basically for every elube it</p>
<p>49<br>00:05:48,560 –&gt; 00:05:55,200<br>calls the handler for get task in the coordinator. And depending on what task it gets it will either</p>
<p>50<br>00:05:55,200 –&gt; 00:06:00,879<br>perform the map task with the relevant data or admitted data that needs perform the reduced</p>
<p>51<br>00:06:00,879 –&gt; 00:06:06,560<br>task or in the case of done it will exit. And so that’s very simple and once it’s finished that</p>
<p>52<br>00:06:06,560 –&gt; 00:06:14,959<br>task it will send a finished task rpc to the coordinator. So this is just the skeleton code for</p>
<p>53<br>00:06:15,600 –&gt; 00:06:22,879<br>the worker sending rpcs. Right so we have rpcs we have the handlers we have the senders and so now</p>
<p>54<br>00:06:22,879 –&gt; 00:06:34,959<br>let’s actually implement some stuff. So in step 4 I just added a ton of handlers to manage this</p>
<p>55<br>00:06:34,959 –&gt; 00:06:42,399<br>intermediate file stuff which a lot of you also did. And basically that uses OS rename it gets</p>
<p>56<br>00:06:42,399 –&gt; 00:06:50,240<br>a temporary file so it’s not super interesting. And then the next step let’s actually implement</p>
<p>57<br>00:06:50,319 –&gt; 00:06:58,079<br>some of the worker functionality. So we’re back in the worker and now let’s implement the perform</p>
<p>58<br>00:06:58,079 –&gt; 00:07:07,840<br>map function. And what this does is as many of you have to do is read the file, maps them to keys,</p>
<p>59<br>00:07:07,840 –&gt; 00:07:14,079<br>and then create separate files, read them to the intermediate files, and then we use an atomic</p>
<p>60<br>00:07:14,399 –&gt; 00:07:19,439<br>rename to ensure that maps aren’t conflicting as they process the keys and write them.</p>
<p>61<br>00:07:20,639 –&gt; 00:07:26,959<br>So this is pretty much taken from the sequential implementation and how you would apply the map</p>
<p>62<br>00:07:26,959 –&gt; 00:07:37,519<br>function. And then similarly we implement the reduced function. So here’s a format and then we</p>
<p>63<br>00:07:37,519 –&gt; 00:07:43,839<br>have perform reduced. And so what that does is it gets all the intermediate files with the appropriate</p>
<p>64<br>00:07:45,039 –&gt; 00:07:52,240<br>from all the map tests for this reduced task and sorts them. So the sorting happens in the</p>
<p>65<br>00:07:53,759 –&gt; 00:08:00,879<br>in the worker because the worker needs the reducer needs access to all keys of that type and then</p>
<p>66<br>00:08:00,879 –&gt; 00:08:07,120<br>to sort them. I wouldn’t make sense for the mapper to sort them before because the mapper only</p>
<p>67<br>00:08:07,120 –&gt; 00:08:13,439<br>has access to a subset of the keys. And then we apply the reduced function to all values of the same</p>
<p>68<br>00:08:13,439 –&gt; 00:08:19,040<br>key and then we automatically rename the temporary reduced file to the final reduced file.</p>
<p>69<br>00:08:20,560 –&gt; 00:08:29,199<br>So now the loop we’ve implemented basically the actual performance of the task and we’re basically</p>
<p>70<br>00:08:29,199 –&gt; 00:08:35,519<br>done with the worker implementation. So one last step remains and that’s actually implementing</p>
<p>71<br>00:08:35,519 –&gt; 00:08:43,279<br>how this coordinator tells the worker which task to do. And this is probably where you ran into</p>
<p>72<br>00:08:43,279 –&gt; 00:08:50,319<br>the most complexity with synchronization in the coordinator. So let’s go back to the coordinator.</p>
<p>73<br>00:08:51,519 –&gt; 00:08:57,919<br>So nothing has changed in the state. So but now what we’ve done is we’ve added a loop in the</p>
<p>74<br>00:08:57,919 –&gt; 00:09:07,199<br>coordinator that handles sending the tests to the worker. And when we’re issuing the map tests,</p>
<p>75<br>00:09:07,199 –&gt; 00:09:14,959<br>so first we want to issue all the map tests. And so essentially what this loop does here is until</p>
<p>76<br>00:09:14,959 –&gt; 00:09:23,199<br>there’s a task to issue, the coordinator will just iterate through this loop and if we’re done with</p>
<p>77<br>00:09:23,200 –&gt; 00:09:28,800<br>all the map tests, then we’ll break out the loop. And then if all the map tests are done, then we</p>
<p>78<br>00:09:28,800 –&gt; 00:09:40,879<br>issue a reduced test, which is what’s done here. So oh yeah, I have I guess I have one last step,</p>
<p>79<br>00:09:40,879 –&gt; 00:09:48,640<br>which is actually what we do when the maps are the reduces, when there’s no test to issue. And so</p>
<p>80<br>00:09:48,639 –&gt; 00:09:54,879<br>what we want to do then is the coordinator should just wait for a test to issue. And once it</p>
<p>81<br>00:09:55,679 –&gt; 00:10:00,799<br>there’s a test issue, it’ll do another iteration to the loop and then actually issue the task.</p>
<p>82<br>00:10:01,840 –&gt; 00:10:04,879<br>And I’ll continue until all the map or all the reduced tests are done.</p>
<p>83<br>00:10:06,799 –&gt; 00:10:10,720<br>And if they’re done, it’ll return again. So let’s go to</p>
<p>84<br>00:10:10,879 –&gt; 00:10:12,879<br>the next one.</p>
<p>85<br>00:10:14,399 –&gt; 00:10:23,279<br>So in order to support that waiting, what my solution does is it uses a condition variable.</p>
<p>86<br>00:10:26,240 –&gt; 00:10:34,639<br>And essentially what that does is if there are no map tests to issue, but the mavers,</p>
<p>87<br>00:10:35,519 –&gt; 00:10:42,240<br>but they’re because we’ve assigned all them, for example, and we’re waiting for them, and they</p>
<p>88<br>00:10:42,240 –&gt; 00:10:49,360<br>haven’t timed out yet, then what we want to do is wait because we cannot issue a reduced task if</p>
<p>89<br>00:10:49,360 –&gt; 00:10:55,600<br>all the mavers have not finished. So we’re just going to wait here. And then once we get some type</p>
<p>90<br>00:10:55,600 –&gt; 00:11:00,559<br>of signal, we’re just going to go back to the top of the loop and check whether we can issue a task</p>
<p>91<br>00:11:00,719 –&gt; 00:11:09,119<br>again. Similarly, if all the reducers aren’t done, but we can’t actually issue the worker a task,</p>
<p>92<br>00:11:09,119 –&gt; 00:11:14,559<br>we’re going to wait for there to be some type of signal. So when does the signal actually happen?</p>
<p>93<br>00:11:15,359 –&gt; 00:11:22,959<br>Well, we want to signal anytime either a task has gone on for too long and we haven’t heard</p>
<p>94<br>00:11:23,040 –&gt; 00:11:29,920<br>back, so there might have been a failure. Or if the if a worker has actually completed a task,</p>
<p>95<br>00:11:29,920 –&gt; 00:11:34,160<br>because for example, that might mean all the map tests have finished and we can move on to a reduced</p>
<p>96<br>00:11:34,160 –&gt; 00:11:51,200<br>task. So in order to do that, what we have are we have a guroutine here that’s kind of spun off</p>
<p>97<br>00:11:51,200 –&gt; 00:11:56,080<br>immediately as the coordinator starts. And what this does is every once in a while,</p>
<p>98<br>00:11:57,520 –&gt; 00:12:04,400<br>after some maybe every second or so, when a task might not have finished, or maybe this is 10</p>
<p>99<br>00:12:04,400 –&gt; 00:12:08,720<br>seconds I can’t remember. Actually, it doesn’t really matter. It just wants to wake up the coordinator</p>
<p>100<br>00:12:08,720 –&gt; 00:12:14,160<br>every so often so that the coordinator will do another check to see whether there’s a task to issue.</p>
<p>101<br>00:12:14,160 –&gt; 00:12:19,600<br>And so this just loops around and every second it’ll broadcast to wake up the coordinator.</p>
<p>102<br>00:12:21,680 –&gt; 00:12:29,280<br>And the other time we want to signal is when a task is finished. So that’s actually going to happen</p>
<p>103<br>00:12:29,280 –&gt; 00:12:36,960<br>in this handle finished task, which is called when a worker like sends a I finished a task RPC.</p>
<p>104<br>00:12:37,759 –&gt; 00:12:47,040<br>And so here we have a broadcast right after we set the fields to done or to complete it to done.</p>
<p>105<br>00:12:47,759 –&gt; 00:12:54,319<br>And when the coordinator goes back to go check one of these loops and see whether there’s a task to</p>
<p>106<br>00:12:54,319 –&gt; 00:13:05,519<br>finish, it will see that updated done status. So that’s essentially my solution. It uses convars and</p>
<p>107<br>00:13:05,519 –&gt; 00:13:12,799<br>mutexes to protect shared state of the coordinator. So this is only one possible solution.</p>
<p>108<br>00:13:13,519 –&gt; 00:13:21,759<br>And I’ll get back to here. And so this is the kind of layout of the steps I took.</p>
<p>109<br>00:13:23,199 –&gt; 00:13:27,199<br>Are there any questions on that particular solution before I move on?</p>
<p>110<br>00:13:31,039 –&gt; 00:13:35,039<br>Can you please elaborate a little more on the conditional variable?</p>
<p>111<br>00:13:35,919 –&gt; 00:13:50,480<br>Sure. So I guess like a conditional variable is very useful for when you want to wait for a</p>
<p>112<br>00:13:50,480 –&gt; 00:13:58,959<br>particular predicate or particular condition to become true. So in this case, a condition variable</p>
<p>113<br>00:13:58,960 –&gt; 00:14:08,879<br>is a natural, let me just go to wherever I use this. It’s a natural way to implement waiting</p>
<p>114<br>00:14:08,879 –&gt; 00:14:19,280<br>for there to be a task available because it’s a particular condition and it occurs asynchronously.</p>
<p>115<br>00:14:19,280 –&gt; 00:14:28,080<br>So for example, a task is available when a worker has finished a task or a task might be available</p>
<p>116<br>00:14:28,879 –&gt; 00:14:39,360<br>when a failure occurs and we need to reissue the task. So you can think of any case in which</p>
<p>117<br>00:14:42,639 –&gt; 00:14:47,759<br>you need to wait for a particular condition. That’s where condition variables become very helpful.</p>
<p>118<br>00:14:49,200 –&gt; 00:14:52,960<br>Does that help a little bit? Yeah, thank you.</p>
<p>119<br>00:14:53,120 –&gt; 00:15:02,160<br>You can also like all of these higher level like channels, condition variables.</p>
<p>120<br>00:15:03,040 –&gt; 00:15:08,000<br>All these higher level synchronization primitives are actually built on top of locks.</p>
<p>121<br>00:15:08,000 –&gt; 00:15:14,080<br>So they’re all implemented using locks. It’s just they’re kind of like a higher level way of</p>
<p>122<br>00:15:14,080 –&gt; 00:15:17,920<br>thinking about synchronization that allows you to reason, for example, about conditions.</p>
<p>123<br>00:15:18,000 –&gt; 00:15:29,120<br>Would that have the same effect as for example, sleeping in that loop that you have in the</p>
<p>124<br>00:15:30,479 –&gt; 00:15:39,199<br>get task function instead of like having a condition variable that makes their loop run every second?</p>
<p>125<br>00:15:40,319 –&gt; 00:15:45,679<br>I guess. Yeah, so it is like it’s essentially the same as sleeping.</p>
<p>126<br>00:15:45,759 –&gt; 00:16:01,679<br>So the loop here, the timeout loop here, the difference is that for example, the condition variable</p>
<p>127<br>00:16:01,679 –&gt; 00:16:08,559<br>or you could be woken up by a task that has completed. Whereas in a loop in which you sleep,</p>
<p>128<br>00:16:08,559 –&gt; 00:16:15,679<br>for example, a second every single loop, you have to wait a second. Whereas with a condition variable,</p>
<p>129<br>00:16:15,679 –&gt; 00:16:21,119<br>you could be woken up after like 10 milliseconds because the worker has completed a task.</p>
<p>130<br>00:16:21,679 –&gt; 00:16:25,519<br>So it potentially has better live-ness properties.</p>
<p>131<br>00:16:28,159 –&gt; 00:16:35,599<br>But in this case, we do like say if every task always takes over like five seconds or something,</p>
<p>132<br>00:16:35,600 –&gt; 00:16:41,680<br>then yes, this is essentially very similar to sleeping for one second every loop.</p>
<p>133<br>00:16:43,680 –&gt; 00:16:47,600<br>Thanks. I have a question. I think I missed a part where you will</p>
<p>134<br>00:16:48,879 –&gt; 00:16:55,840<br>how you handle when a request comes for a task, but you’re like there’s no tasks to give out currently.</p>
<p>135<br>00:16:55,840 –&gt; 00:17:01,759<br>Like do you, how do you tell the worker to like sort of either come back or do you keep them waiting?</p>
<p>136<br>00:17:01,840 –&gt; 00:17:10,480<br>And sort of tangentially to that, I’m curious why you chose this like sleep way of doing it instead of</p>
<p>137<br>00:17:10,480 –&gt; 00:17:17,519<br>just like checking the time when you get a request for tasks and seeing like when you get a request,</p>
<p>138<br>00:17:17,519 –&gt; 00:17:23,359<br>what has timed out and re-issuing it then instead of like possibly checking.</p>
<p>139<br>00:17:24,559 –&gt; 00:17:29,759<br>Yeah, okay. So yeah, so I’ll just your first question first.</p>
<p>140<br>00:17:29,920 –&gt; 00:17:42,079<br>So basically how I handle the, I’ve completed the task is once all map tasks have finished,</p>
<p>141<br>00:17:42,079 –&gt; 00:17:49,200<br>once all reduced tasks have finished, then the task that we return to the worker because the</p>
<p>142<br>00:17:49,200 –&gt; 00:17:55,440<br>worker has called us, task for a task, is this extra task type that I called done.</p>
<p>143<br>00:17:55,759 –&gt; 00:18:04,559<br>And then I also said the coordinator is done to true. And so in the worker, so I’ll go to the worker now.</p>
<p>144<br>00:18:05,519 –&gt; 00:18:15,279<br>In the worker, we have this loop that basically as the worker is asking for tasks, if it gets</p>
<p>145<br>00:18:15,279 –&gt; 00:18:22,480<br>returned to tasks is a done task, then it exits. So that’s how I handle conveying to the worker that</p>
<p>146<br>00:18:22,480 –&gt; 00:18:28,880<br>it should exit. I guess I was asking like, sorry, if, you know, let’s say you’re still finishing</p>
<p>147<br>00:18:28,880 –&gt; 00:18:34,640<br>up all your map tasks and you get requests for a task and you still can’t give out your reduced</p>
<p>148<br>00:18:34,640 –&gt; 00:18:45,279<br>tasks, how do you tell the worker? Oh, so that’s a lot of you are, an alternative design is to,</p>
<p>149<br>00:18:45,920 –&gt; 00:18:52,160<br>basically if the worker, if there’s no task to give the worker, then the coordinator returns</p>
<p>150<br>00:18:52,160 –&gt; 00:18:58,560<br>or apply to the worker immediately and the worker sleeps in that’s loop. But you can see here,</p>
<p>151<br>00:18:58,560 –&gt; 00:19:06,240<br>right, the worker loop, there is no sleep. And the reason for this is because this call will block</p>
<p>152<br>00:19:06,240 –&gt; 00:19:14,320<br>until the coordinator replies. And in my solution, going back to the coordinator, for example,</p>
<p>153<br>00:19:14,399 –&gt; 00:19:23,679<br>if you look at map done, in this solution, the coordinator handler will not return that,</p>
<p>154<br>00:19:23,679 –&gt; 00:19:32,879<br>reply to that call unless it has a task to return. So we’re waiting in the coordinator rather than</p>
<p>155<br>00:19:32,879 –&gt; 00:19:41,359<br>in the worker. So the coordinator is the one that is constantly checking to see whether there’s a task</p>
<p>156<br>00:19:41,359 –&gt; 00:19:49,039<br>and sleeping, whereas the worker just simply walks on this call until the coordinator returns to it.</p>
<p>157<br>00:19:49,679 –&gt; 00:19:54,319<br>Is there any advantage to doing it in the coordinator?</p>
<p>158<br>00:19:59,759 –&gt; 00:20:09,119<br>So I think one advantage is that all the workers aren’t constantly sending RPCs.</p>
<p>159<br>00:20:09,599 –&gt; 00:20:15,919<br>You send an RPC, it’s one RPC per task, right? Whereas if the worker is constantly</p>
<p>160<br>00:20:15,919 –&gt; 00:20:19,679<br>living and sleeping and constantly replying, you have a lot more network traffic.</p>
<p>161<br>00:20:20,559 –&gt; 00:20:27,439<br>Okay. Yeah. I think that’s, but definitely both solutions are feasible and they both work.</p>
<p>162<br>00:20:28,559 –&gt; 00:20:38,479<br>Right. I had one other question, which is I see you use a deferred for the for unlocking quite a bit.</p>
<p>163<br>00:20:39,919 –&gt; 00:20:47,199<br>While I was doing my implementation, I realized, I mean, in a straightforward function, it’s clear</p>
<p>164<br>00:20:47,199 –&gt; 00:20:58,559<br>when it gives out control of the lock, but for example, if you have a go routine created from within the</p>
<p>165<br>00:20:58,559 –&gt; 00:21:07,759<br>function, it’s not very clear when it gives up control. So a go routine runs on a separate thread.</p>
<p>166<br>00:21:07,759 –&gt; 00:21:13,519<br>So the go routine never starts with the lock acquired, even if you spin off the go routine while you</p>
<p>167<br>00:21:13,519 –&gt; 00:21:23,039<br>hold the lock. Okay. Yeah. If we issue like a go, if we create a go routine, it’ll just spin up a thread</p>
<p>168<br>00:21:23,039 –&gt; 00:21:29,440<br>and from the beginning, it will not have a lock, right? Yeah. Yeah. It’s essentially just like, you know,</p>
<p>169<br>00:21:29,440 –&gt; 00:21:34,000<br>you can think about another thread just starting to run that go like go funk that function.</p>
<p>170<br>00:21:34,720 –&gt; 00:21:43,920<br>Okay. Yeah. Then yeah. Go on the defer on locks at any return, like any return statement or</p>
<p>171<br>00:21:44,720 –&gt; 00:21:53,200<br>yep. Yeah. It’s pushed onto a like basically like the functions to run when the there’s a stack of</p>
<p>172<br>00:21:53,200 –&gt; 00:22:01,839<br>functions that the returning from like handle get task will run. So I also have this in the slide.</p>
<p>173<br>00:22:01,839 –&gt; 00:22:07,199<br>So you’ll be else referred to this later, but the fur just ensures that when this function exits,</p>
<p>174<br>00:22:07,759 –&gt; 00:22:11,759<br>you will over you’ll run a lock and then I could also do something like</p>
<p>175<br>00:22:15,039 –&gt; 00:22:25,439<br>like unlocking and like I could just do something like before the last project or print one. So</p>
<p>176<br>00:22:26,160 –&gt; 00:22:32,000<br>these are all pushed onto a stack and then they’re popped off in a five four. No, like.</p>
<p>177<br>00:22:36,559 –&gt; 00:22:46,000<br>First in first out. No, they’re run in last and first out. Yeah. So the stack, right? So</p>
<p>178<br>00:22:48,000 –&gt; 00:22:54,240<br>this will run before unlocking, which won’t actually run before the lock. So if you’re right to</p>
<p>179<br>00:22:54,240 –&gt; 00:22:59,920<br>use multiple deferers, just be careful in order to use them. But deferring the unlock at least</p>
<p>180<br>00:22:59,920 –&gt; 00:23:11,279<br>is a very useful strategy that will come in handy. Okay. So the last thing is if we call up function within</p>
<p>181<br>00:23:14,400 –&gt; 00:23:20,480<br>within our function where we acquired the lock, it doesn’t return the lock, right?</p>
<p>182<br>00:23:21,440 –&gt; 00:23:27,680<br>when it goes to the other function, the other function returns to this function and then until we</p>
<p>183<br>00:23:27,680 –&gt; 00:23:32,400<br>like the thread keeps the lock through like jumping around. Yeah.</p>
<p>184<br>00:23:34,960 –&gt; 00:23:40,559<br>Yeah. So like a function that’s just like a normal function called within one thread will be called</p>
<p>185<br>00:23:40,639 –&gt; 00:23:51,119<br>with the lock held. Yes. Thanks. Yep. All right. So you guys have already kind of discussed some</p>
<p>186<br>00:23:51,119 –&gt; 00:23:56,319<br>of the alternate synchronization designs like waiting in the worker rather than the coordinator.</p>
<p>187<br>00:23:56,319 –&gt; 00:24:01,119<br>And we’ve talked about some of the pros and cons of that using time. Actually, I think you covered all</p>
<p>188<br>00:24:01,119 –&gt; 00:24:07,759<br>of these except for channels maybe. So just one thing I wanted to know because there are a couple</p>
<p>189<br>00:24:07,759 –&gt; 00:24:14,799<br>questions about this. So waiting for map tasks to be done or like any synchronization that we’ve shown</p>
<p>190<br>00:24:15,359 –&gt; 00:24:21,279<br>is on a single server. So cross-server communication between the worker and the coordinator</p>
<p>191<br>00:24:22,319 –&gt; 00:24:28,079<br>are there only it’s only done ever by RPCs. So for example, like locking in the coordinator has</p>
<p>192<br>00:24:28,079 –&gt; 00:24:33,359<br>nothing to do with locking on the worker or on interactive implementation locking on different servers</p>
<p>193<br>00:24:34,000 –&gt; 00:24:38,399<br>like don’t interfere with each other. So I just wanted to be clear about that.</p>
<p>194<br>00:24:39,679 –&gt; 00:24:47,119<br>So one thing I thought would be interesting is for you to see a kind of an example using channels</p>
<p>195<br>00:24:47,119 –&gt; 00:24:54,639<br>because there are also some questions using channels about using channels. So this is kind of it’s a</p>
<p>196<br>00:24:55,600 –&gt; 00:25:04,080<br>not complete implementation of using channels but it’s a potential way to that you could think about</p>
<p>197<br>00:25:04,080 –&gt; 00:25:11,440<br>having used channels in MapReduce. And so in this example, the input to the coordinator actually</p>
<p>198<br>00:25:11,440 –&gt; 00:25:21,120<br>includes a channel in which the coordinator is told of what workers exist. And this is to handle</p>
<p>199<br>00:25:22,079 –&gt; 00:25:28,639<br>the possibility that workers are failing. And then some client is telling the coordinator,</p>
<p>200<br>00:25:28,639 –&gt; 00:25:33,279<br>hey, this other worker joined our cluster. Here’s a new worker that you can give tasks to.</p>
<p>201<br>00:25:33,279 –&gt; 00:25:36,719<br>So that’s slightly different than what we had in the lab.</p>
<p>202<br>00:25:39,119 –&gt; 00:25:49,439<br>So the coordinator has two channels. One in which it will send tasks to workers or it won’t send</p>
<p>203<br>00:25:49,440 –&gt; 00:25:53,920<br>tasks to workers. It will send tasks to a thread that will issue tasks to workers.</p>
<p>204<br>00:25:54,880 –&gt; 00:26:03,519<br>And then it has a done channel. So again, just like I know I said something a little strange,</p>
<p>205<br>00:26:03,519 –&gt; 00:26:07,840<br>which is I was like, oh, you can send tasks to workers over the channel, but you actually can’t.</p>
<p>206<br>00:26:07,840 –&gt; 00:26:12,559<br>The channel is only on the coordinator server. And we’ll see how that works in a second.</p>
<p>207<br>00:26:13,519 –&gt; 00:26:20,399<br>So the first thread of the coordinator that we create is a go routine that basically will for</p>
<p>208<br>00:26:20,399 –&gt; 00:26:31,279<br>every worker start the issue worker task thread. So what this does is as workers are coming and going</p>
<p>209<br>00:26:31,279 –&gt; 00:26:36,480<br>because they’re failing and then restarting, this channel basically says, okay, we want to for</p>
<p>210<br>00:26:36,559 –&gt; 00:26:45,039<br>every of these workers start a thread that will issue this worker tasks. So this is one go routine here.</p>
<p>211<br>00:26:46,640 –&gt; 00:26:52,240<br>Then the coordinator, what it does is it for all the tasks that we’re given, it’ll just push those</p>
<p>212<br>00:26:52,240 –&gt; 00:26:58,319<br>tasks onto this task channel. And this task channel, we actually made it a buffer channel.</p>
<p>213<br>00:26:58,880 –&gt; 00:27:06,240<br>So we know it will hold exactly non-task tasks, which are the, that’s the limit of the number of tasks.</p>
<p>214<br>00:27:06,640 –&gt; 00:27:12,960<br>That will exist on the system. So what this also means is that we can push the number of tasks</p>
<p>215<br>00:27:14,000 –&gt; 00:27:20,480<br>tasks onto this channel without blocking. So the coordinator will not block on pushing tasks to</p>
<p>216<br>00:27:20,480 –&gt; 00:27:29,759<br>the task channel. And then the coordinator will read from this done channel until it has done so</p>
<p>217<br>00:27:29,759 –&gt; 00:27:36,160<br>number of tasks times, in which case it knows it’s done. In this case, I’m not separating</p>
<p>218<br>00:27:36,160 –&gt; 00:27:40,799<br>map and reduce tasks. Let’s just imagine that there are some number of tasks that the coordinator</p>
<p>219<br>00:27:40,799 –&gt; 00:27:47,599<br>needs to run. And once it’s knows the task, all the tasks have finished, it closes the task channel.</p>
<p>220<br>00:27:48,480 –&gt; 00:27:59,519<br>And then basically will exit. And so the, whereas some of the interesting part comes in is these</p>
<p>221<br>00:27:59,519 –&gt; 00:28:06,240<br>worker tasks threads, which I’ve separated out into a function here. So these all run on</p>
<p>222<br>00:28:06,240 –&gt; 00:28:14,319<br>separate go routines. And what it does is for as long as there are tasks in the task queue,</p>
<p>223<br>00:28:14,960 –&gt; 00:28:25,839<br>it will pull a task out. And then, oops, I didn’t mean to that. And then call basically an RPC that</p>
<p>224<br>00:28:25,839 –&gt; 00:28:33,119<br>will send the tasks to the worker. So note that this channel actually is talking to another thread</p>
<p>225<br>00:28:33,119 –&gt; 00:28:40,799<br>of the coordinator. And that thread is actually the one that’s in charge of calling the worker.</p>
<p>226<br>00:28:42,399 –&gt; 00:28:49,519<br>And then once it’s done with the task, it says it’s done. If it’s not able to, if the call fails</p>
<p>227<br>00:28:49,519 –&gt; 00:28:56,160<br>for some reason, for example, it times out, then what this loop does is it’ll push that task back</p>
<p>228<br>00:28:56,160 –&gt; 00:29:01,839<br>onto the task channel. So another worker, or potentially this thread again, could pick up that task.</p>
<p>229<br>00:29:03,359 –&gt; 00:29:09,839<br>So just to clarify how the channel communication works, so the worker sends tasks on the task channel,</p>
<p>230<br>00:29:09,839 –&gt; 00:29:18,319<br>which is read through these loops. And this loop will exit when the coordinator closes the channel.</p>
<p>231<br>00:29:20,319 –&gt; 00:29:28,639<br>Done. It’s sent on these worker issue worker threads. And it’s read by the coordinator, the original</p>
<p>232<br>00:29:28,639 –&gt; 00:29:36,160<br>coordinator thread. And this exit equals true, will basically tell the coordinator like, oh, I don’t</p>
<p>233<br>00:29:36,160 –&gt; 00:29:43,119<br>need to listen for anymore workers coming or workers starting up. So it’ll cause this other go routine</p>
<p>234<br>00:29:43,119 –&gt; 00:29:49,039<br>to exit. So I know that this is a pretty complex example. It’s also not quite what we</p>
<p>235<br>00:29:50,479 –&gt; 00:29:55,039<br>specified in the lab, but it’s an example of how channels could be used to implement something</p>
<p>236<br>00:29:55,039 –&gt; 00:30:03,679<br>like MapReduce, or something similar to MapReduce. That is a question in the chat about where is exit</p>
<p>237<br>00:30:03,680 –&gt; 00:30:15,039<br>defined in this code? That is a good question. It’s not. So it will be exactly the same thing is</p>
<p>238<br>00:30:15,039 –&gt; 00:30:25,360<br>done. You’ll just be another channel that’s a Boolean. Yeah. That’s a good catch.</p>
<p>239<br>00:30:27,039 –&gt; 00:30:32,480<br>Oh, can I ask you how do you add things to the worker channel, or when do you add things to the</p>
<p>240<br>00:30:32,480 –&gt; 00:30:39,759<br>worker’s channel? How would you handle them this gives? Yeah. So in this case, the worker’s channel is</p>
<p>241<br>00:30:39,759 –&gt; 00:30:47,920<br>provided to the coordinator. So imagine that, for example, in how your coordinator was actually</p>
<p>242<br>00:30:47,920 –&gt; 00:30:58,880<br>called or created by the MR coordinator in Maine in the back folder. So we would imagine that</p>
<p>243<br>00:30:59,520 –&gt; 00:31:06,800<br>in an MR coordinator, we would create a worker’s channel. And MR coordinator would basically</p>
<p>244<br>00:31:06,800 –&gt; 00:31:15,200<br>be in charge of tracking when workers crash and when workers join. So this is, for example, in a case</p>
<p>245<br>00:31:15,200 –&gt; 00:31:22,400<br>where maybe new servers are added to our cluster at some later point, or some worker crash and then</p>
<p>246<br>00:31:22,400 –&gt; 00:31:30,000<br>came back. And MR coordinator would be constantly sending like these worker IDs to our coordinator</p>
<p>247<br>00:31:30,960 –&gt; 00:31:36,880<br>in order to tell it, hey, like there’s new worker, you should start issuing a test. So that part</p>
<p>248<br>00:31:36,880 –&gt; 00:31:43,840<br>is not shown. Got it. Yeah. I just, I just, uh, was wondering like, so it’s really cool. I was</p>
<p>249<br>00:31:43,840 –&gt; 00:31:49,600<br>just wondering like inside like the lab one, like how, I think it’s like call worker and you’ve</p>
<p>250<br>00:31:49,599 –&gt; 00:31:54,319<br>decided RPC to the worker. If that’s something we could have done in the lab one.</p>
<p>251<br>00:31:57,119 –&gt; 00:32:04,079<br>It’s possible, but it definitely was not what we pushed you toward. Because you would basically</p>
<p>252<br>00:32:04,079 –&gt; 00:32:09,599<br>insist setting up the coordinator as being the RPC server, you would have to set up like RPC servers</p>
<p>253<br>00:32:09,599 –&gt; 00:32:18,399<br>on the workers. You could also think of in this implementation, call worker could have handlers</p>
<p>254<br>00:32:18,480 –&gt; 00:32:26,000<br>actually for each worker. And each worker could be sending the coordinator, like get task RPCs.</p>
<p>255<br>00:32:26,000 –&gt; 00:32:33,360<br>That’s a little, that’s a little funky. So in this example, it’s actually more natural to imagine</p>
<p>256<br>00:32:33,360 –&gt; 00:32:39,840<br>that call worker, that the coordinator is a client and the workers are the ones that are handling</p>
<p>257<br>00:32:39,919 –&gt; 00:32:48,720<br>RPCs. Got it. Yeah. Okay. Thanks. Really cool. I have two questions. First is just a general,</p>
<p>258<br>00:32:48,720 –&gt; 00:32:55,519<br>like go question. So in that second for loop on the left, at the bottom, if you don’t use I will go</p>
<p>259<br>00:32:55,519 –&gt; 00:33:07,679<br>complain or in a for loop. Uh, so I run like all the go, linter and all that stuff. And it’s fine. I think,</p>
<p>260<br>00:33:07,680 –&gt; 00:33:16,480<br>like in this case, you do need to have I because you’re incrementing and keeping the state of I</p>
<p>261<br>00:33:16,480 –&gt; 00:33:23,920<br>around through the, can you do the same thing with like a, like just a, like a while loop, like a</p>
<p>262<br>00:33:23,920 –&gt; 00:33:32,799<br>just for empty for loop with a select, where it’s like popping off of done. So</p>
<p>263<br>00:33:33,359 –&gt; 00:33:42,399<br>you can’t actually, well, you still need to keep track of how many times you’ve read from done,</p>
<p>264<br>00:33:42,399 –&gt; 00:33:48,559<br>right? Because you can’t just read once. You have to read number of tasks times.</p>
<p>265<br>00:33:52,079 –&gt; 00:33:59,200<br>I see. Yeah. So you do need some type of state that will track that.</p>
<p>266<br>00:34:02,799 –&gt; 00:34:06,720<br>And then it’s for the for the one on the right, like the where you’re like reading from</p>
<p>267<br>00:34:06,720 –&gt; 00:34:13,920<br>ask and repopulating it. Is there like any downside to that or if you’re like just constantly reading</p>
<p>268<br>00:34:13,920 –&gt; 00:34:23,119<br>and adding back and forth the same channel? Uh, I don’t, I can’t think of it off the top of my head. So</p>
<p>269<br>00:34:23,119 –&gt; 00:34:29,279<br>in this case, at least, you won’t block because every time you read it, you’re popping something off</p>
<p>270<br>00:34:29,280 –&gt; 00:34:36,160<br>the channel, every time you, um, add it, you’re putting something. So because we have that,</p>
<p>271<br>00:34:36,160 –&gt; 00:34:44,720<br>the task is a buffer channel, like you’ll never block on that. So in terms of like performance,</p>
<p>272<br>00:34:45,440 –&gt; 00:34:51,680<br>I think, I mean, channels are built using locks. So locks are usually more lightweight.</p>
<p>273<br>00:34:52,880 –&gt; 00:34:58,560<br>But I don’t think, I don’t think you’ll see like a huge performance impact. I’m doing something</p>
<p>274<br>00:34:58,559 –&gt; 00:35:04,079<br>like this. Okay. I guess I have like a, sorry, just like a general question of like,</p>
<p>275<br>00:35:04,799 –&gt; 00:35:11,840<br>what’s your like calculus for choosing between mutex’s and channels or like a hybrid or like at the very</p>
<p>276<br>00:35:11,840 –&gt; 00:35:19,759<br>beginning? Yeah. So mutex’s are very natural for just protecting a piece of state. So like,</p>
<p>277<br>00:35:20,320 –&gt; 00:35:26,239<br>your coordinator or like your rough servers have a log. I want to protect every time I append to the</p>
<p>278<br>00:35:26,239 –&gt; 00:35:34,079<br>log. Um, that seems very difficult or it seems very unnatural to try and do using channels.</p>
<p>279<br>00:35:34,719 –&gt; 00:35:40,159<br>Because essentially, you’d be using the channels lock. You’d want to ensure that no one else is</p>
<p>280<br>00:35:40,159 –&gt; 00:35:45,199<br>modifying the state while you’re modifying it. And then you would have to essentially before you</p>
<p>281<br>00:35:45,199 –&gt; 00:35:50,479<br>modify it, try to read on the channel to ensure that no one else or like someone would have to</p>
<p>282<br>00:35:50,479 –&gt; 00:35:54,799<br>send something on the channel to show that they’ve done, they’ve been finished modifying and so on</p>
<p>283<br>00:35:54,880 –&gt; 00:36:01,120<br>so forth. So in that case, it’s actually very hard to imagine how you would do a channels, whereas</p>
<p>284<br>00:36:01,120 –&gt; 00:36:08,640<br>mutex’s would make that completely straightforward. Uh, where channels come in very handy is like,</p>
<p>285<br>00:36:08,640 –&gt; 00:36:14,960<br>I think our implementation already has this like apply channel is where you have to wait for</p>
<p>286<br>00:36:16,880 –&gt; 00:36:23,360<br>in some ways, it’s like almost like a specific instance of a condition variable. And what you</p>
<p>287<br>00:36:23,360 –&gt; 00:36:34,800<br>want to wait for something to be ready, or a, um, like a very specific type of command to be finished.</p>
<p>288<br>00:36:36,320 –&gt; 00:36:42,480<br>So for something like issuing tasks, it’s actually not a bad example. Or something like</p>
<p>289<br>00:36:43,440 –&gt; 00:36:49,120<br>blocking until you have something on a queue. It like, you can almost think of it as like a queueing</p>
<p>290<br>00:36:49,119 –&gt; 00:36:55,759<br>system. Or at least that’s how I like to think about it. But for almost all modifications to shared</p>
<p>291<br>00:36:55,759 –&gt; 00:37:03,759<br>state or like the race conditions, you’ll encounter locks are much simpler and in some ways a lot</p>
<p>292<br>00:37:03,759 –&gt; 00:37:14,159<br>easier to reason about. But yeah. Thank you. Sorry, I have a follow up question to this slide.</p>
<p>293<br>00:37:14,319 –&gt; 00:37:22,000<br>Um, what happens if the, so you call the go issue worker task thread, which spins up another go</p>
<p>294<br>00:37:22,000 –&gt; 00:37:28,639<br>routine, I mean it goes through all the tasks in the channel. What if it fails when it’s, what if</p>
<p>295<br>00:37:28,639 –&gt; 00:37:42,079<br>the go routine fails when it’s sitting on the if call worker? So if it fails, then I guess you’ve</p>
<p>296<br>00:37:42,079 –&gt; 00:37:54,799<br>taken a task out and not put it back. Hmm, I’m actually not sure that seems like a, like you’re not,</p>
<p>297<br>00:37:54,799 –&gt; 00:38:01,440<br>you’re saying like the entire thread crashes, rather than has call worker not like returning</p>
<p>298<br>00:38:01,440 –&gt; 00:38:07,759<br>falls or something. Yeah, like the go routine crashes. Or is that possible for us,</p>
<p>299<br>00:38:07,840 –&gt; 00:38:11,920<br>single go routine to fail or what like the entire thing just blow up?</p>
<p>300<br>00:38:14,160 –&gt; 00:38:20,000<br>So you’ve run Cena? I think the model you should have is that if go routine crashes to process crashes.</p>
<p>301<br>00:38:21,760 –&gt; 00:38:34,240<br>Yeah, that would solve it. Oh, sorry. So if just the worker crashes, then you pick a different task,</p>
<p>302<br>00:38:34,239 –&gt; 00:38:42,559<br>but should you, I guess you would still have the same worker, like worker number.</p>
<p>303<br>00:38:44,719 –&gt; 00:38:48,959<br>So we still connect to the same worker, even though they have failed.</p>
<p>304<br>00:38:49,919 –&gt; 00:38:54,399<br>Yeah, so in this case, basically call worker, we’re just continued returning falls.</p>
<p>305<br>00:38:55,119 –&gt; 00:39:01,279<br>And you know, this go routine that’s specific for this worker, we just continue to loop.</p>
<p>306<br>00:39:01,440 –&gt; 00:39:09,840<br>And eventually when the, when the coordinator has determined that all the tasks have finished,</p>
<p>307<br>00:39:09,840 –&gt; 00:39:16,160<br>it’ll close the channel and then this go routine will exit. So there could potentially like if all your</p>
<p>308<br>00:39:16,160 –&gt; 00:39:21,600<br>workers continue crashing, you have like hundreds of new workers joining, like you could potentially</p>
<p>309<br>00:39:21,600 –&gt; 00:39:26,320<br>have a lot of go routines just that are just like, I can’t contact my worker, I can’t contact my worker.</p>
<p>310<br>00:39:26,800 –&gt; 00:39:30,640<br>But once the task has finished, this all them will exit.</p>
<p>311<br>00:39:31,200 –&gt; 00:39:31,760<br>Carverly.</p>
<p>312<br>00:39:39,519 –&gt; 00:39:47,120<br>Cool. All right. So that’s an example with channels. And now let’s move on to some of the more like</p>
<p>313<br>00:39:47,680 –&gt; 00:39:52,720<br>your questions and bugs and things like that. So some common but casting design mistakes that we saw</p>
<p>314<br>00:39:52,959 –&gt; 00:39:58,239<br>was pushing too much work to the coordinator. So essentially making the coordinator bottleneck.</p>
<p>315<br>00:39:59,039 –&gt; 00:40:05,279<br>And this included both like the coordinator and sorting the results or the coordinator,</p>
<p>316<br>00:40:05,279 –&gt; 00:40:11,439<br>like reading file contents, whereas a lot of the kind of beauty of MACReduce is that</p>
<p>317<br>00:40:12,159 –&gt; 00:40:19,279<br>all the state, all the computation happens on the workers. And another common,</p>
<p>318<br>00:40:19,280 –&gt; 00:40:25,280<br>it’s not really a mistake, but potentially something that you could think about is how many RPCs</p>
<p>319<br>00:40:25,280 –&gt; 00:40:32,800<br>are you sending? And like, do you really need to send that many RPCs? So for example, sending an RPC</p>
<p>320<br>00:40:32,800 –&gt; 00:40:38,240<br>to check whether there’s a MAC task available and then sending another RPC to ask like, give me a task,</p>
<p>321<br>00:40:38,800 –&gt; 00:40:46,080<br>is a little overdone and you want to try and like reduce the number and types of like, reduce the</p>
<p>322<br>00:40:46,079 –&gt; 00:40:53,279<br>API between the master or the coordinator and the worker. But these were like they would pass the test</p>
<p>323<br>00:40:53,279 –&gt; 00:41:01,039<br>and it’s just things we wanted to point out. So now, okay, cool. We’re about like halfway through</p>
<p>324<br>00:41:01,039 –&gt; 00:41:07,920<br>lecture. So for the next say like five, six minutes, why don’t we’re going to do breakout rooms?</p>
<p>325<br>00:41:08,880 –&gt; 00:41:13,200<br>Let me stop sharing actually. All right, so we’ll do breakout rooms and</p>
<p>326<br>00:41:14,000 –&gt; 00:41:23,200<br>Oh shoot. Let’s see. I think Sam just crashed on me.</p>
<p>327<br>00:41:28,000 –&gt; 00:41:34,480<br>We can still hear you. I’ll see you. All right, I’m back. Yeah, I upgraded to do right</p>
<p>328<br>00:41:34,480 –&gt; 00:41:38,240<br>before this lecture. That was a bad idea. But all right, for the next five or six minutes,</p>
<p>329<br>00:41:38,800 –&gt; 00:41:44,719<br>you should talk about just like, you know, any interesting bugs or observations you had about</p>
<p>330<br>00:41:44,719 –&gt; 00:41:50,320<br>love or you could, you know, complain about how long it took you to find a certain bug or ask</p>
<p>331<br>00:41:50,320 –&gt; 00:41:56,240<br>questions to each other and then we’ll come back and go over some of your questions. All right.</p>
<p>332<br>00:41:56,239 –&gt; 00:42:04,319<br>All right. All right. Let’s see you in a bit.</p>
<p>333<br>00:42:27,199 –&gt; 00:42:30,239<br>Oh, so I start here with Franz. Do you want me to review somewhere else?</p>
<p>334<br>00:42:30,879 –&gt; 00:42:36,159<br>Probably best. Let me see if I can do it myself. Okay, I’m going to be right back.</p>
<p>335<br>00:49:26,559 –&gt; 00:49:38,399<br>All right. All right.</p>
<p>336<br>00:49:39,199 –&gt; 00:49:49,679<br>Are we mostly back? Thanks. All right. Cool. All right. So I hope that was pretty fun. Or at least</p>
<p>337<br>00:49:49,679 –&gt; 00:49:52,319<br>you got to talk about some of your observations. Thank you, Billette.</p>
<p>338<br>00:49:52,480 –&gt; 00:49:58,000<br>Yeah. So for the rest of the lecture, we’re going to go through, oh, right.</p>
<p>339<br>00:49:58,000 –&gt; 00:50:02,880<br>First, before questions, some general tips that you’ll want to look out for for future lots.</p>
<p>340<br>00:50:04,320 –&gt; 00:50:10,800<br>So first of all, the one thing you’ll find very handy for debugging is just, you know,</p>
<p>341<br>00:50:10,800 –&gt; 00:50:16,640<br>classic printups. And so you can have conditional printups, which only print when you want to</p>
<p>342<br>00:50:16,640 –&gt; 00:50:20,800<br>debug. So for example, you don’t have to go through your code and comment them all out before you</p>
<p>343<br>00:50:20,800 –&gt; 00:50:28,560<br>submit or something like that. And so in the Wrath Lab, we provide this deep printf in the utils.go file.</p>
<p>344<br>00:50:29,680 –&gt; 00:50:36,080<br>And you can modify that to, for example, also print out like the server ID every single time you</p>
<p>345<br>00:50:36,080 –&gt; 00:50:42,160<br>call it deep printf or something like that. So, you know, customize it to, you know, print out in</p>
<p>346<br>00:50:42,160 –&gt; 00:50:48,160<br>different colors for different RPCs, things like that. And also, like redirecting your output to</p>
<p>347<br>00:50:48,159 –&gt; 00:50:54,879<br>files just so that you can like search for the files will come in handy. Another trick that you</p>
<p>348<br>00:50:54,879 –&gt; 00:51:01,039<br>probably want to keep in mind is you can look at all the go routines to see where and their, like,</p>
<p>349<br>00:51:01,039 –&gt; 00:51:07,119<br>execution they’re running. And so just type control backslash in order to do that.</p>
<p>350<br>00:51:08,319 –&gt; 00:51:13,119<br>And the final thing which we’ve already sort of talked about are these to first. And these slides</p>
<p>351<br>00:51:13,119 –&gt; 00:51:20,400<br>will be uploaded also so you can refer back to them. But essentially you can push multiple functions</p>
<p>352<br>00:51:20,400 –&gt; 00:51:26,400<br>to run right before the function returns. And they just be careful of the ordering.</p>
<p>353<br>00:51:28,000 –&gt; 00:51:34,639<br>All right, so now let’s get to some of your questions. A lot of you submitted also questions</p>
<p>354<br>00:51:34,639 –&gt; 00:51:41,359<br>about Wrath. So those will get to for like the Wrath Q&amp;A or like maybe office hours or even the</p>
<p>355<br>00:51:41,360 –&gt; 00:51:46,000<br>on Piazza. But I’m going to focus mostly on the ones from MapReduce or maybe you have time</p>
<p>356<br>00:51:46,000 –&gt; 00:51:54,160<br>then we can also get to the Wrath questions. All right, so the first category of questions kind of</p>
<p>357<br>00:51:54,160 –&gt; 00:52:02,160<br>falls under questions specifically about MapReduce. So some more complex tasks that you might want to</p>
<p>358<br>00:52:02,160 –&gt; 00:52:08,480<br>use MapReduce for. It’s actually used a lot in ML or like data mining statistical applications.</p>
<p>359<br>00:52:09,280 –&gt; 00:52:16,559<br>I linked here to Piazza, which is the implements MapReduce and a lot of people use it to run</p>
<p>360<br>00:52:16,559 –&gt; 00:52:26,639<br>these type of tasks. And for example, here’s a simple or maybe not so simple but basically matrix</p>
<p>361<br>00:52:26,639 –&gt; 00:52:34,400<br>multiplication example of how you would run that using MapReduce. So I need like you for full</p>
<p>362<br>00:52:34,400 –&gt; 00:52:42,000<br>tolerance with the coordinator. The paper booth is a very simple check pointing mechanism in which</p>
<p>363<br>00:52:42,000 –&gt; 00:52:47,760<br>you’ll just start up the a new coordinator using the last checkpointed state. And in some ways this</p>
<p>364<br>00:52:47,760 –&gt; 00:52:54,880<br>is a very natural design for MapReduce because everything is deterministic. There’s no. The coordinator</p>
<p>365<br>00:52:54,880 –&gt; 00:52:58,559<br>really doesn’t have that much state to hold. All it needs to know is like which tasks have finished and</p>
<p>366<br>00:52:58,559 –&gt; 00:53:06,239<br>which tasks have happened. So you could use Wrath of course to like enable full tolerance and have</p>
<p>367<br>00:53:07,759 –&gt; 00:53:14,000<br>set of coordinators that all agree on like the commands that is issued so far and their current state.</p>
<p>368<br>00:53:14,000 –&gt; 00:53:22,400<br>But in some ways this is a little overkill for the coordinator for something that’s more</p>
<p>369<br>00:53:22,400 –&gt; 00:53:28,320<br>stateful. It’s like a key value store or something. It’s much more natural to use like Wrath.</p>
<p>370<br>00:53:31,039 –&gt; 00:53:36,320<br>So some other questions about MapReduce, the shuffle or combine or step when does it happen and</p>
<p>371<br>00:53:36,320 –&gt; 00:53:42,000<br>what does it do. So combining occurs like right after the map functions applied. For example,</p>
<p>372<br>00:53:42,000 –&gt; 00:53:47,280<br>in combining the word counts of a particular word because having a lot of entries that you know like</p>
<p>373<br>00:53:47,280 –&gt; 00:53:56,080<br>the one you could combine them and then write only that to the immediate file or intermediate file.</p>
<p>374<br>00:53:57,120 –&gt; 00:54:02,160<br>Sorting occurs at the reduce after all the outputs of the map are read by the reducer.</p>
<p>375<br>00:54:04,080 –&gt; 00:54:09,040<br>Let’s see, a successor to MapReduce. Yeah, so actually I’m not super familiar with it but you</p>
<p>376<br>00:54:09,039 –&gt; 00:54:17,119<br>can look at stuff like Google Cloud Data Flow and other sort of directed graph computations where</p>
<p>377<br>00:54:17,119 –&gt; 00:54:22,320<br>inputs flow into a node. So you can think of it as a graph and then they might flow out to other</p>
<p>378<br>00:54:22,320 –&gt; 00:54:28,400<br>nodes and that node in the middle that performs for example on map computation and produces intermediate</p>
<p>379<br>00:54:28,400 –&gt; 00:54:35,440<br>data that is then sent to other like reducer nodes in the graph. So it’s a interesting way,</p>
<p>380<br>00:54:35,440 –&gt; 00:54:42,639<br>it’s like a data flow way to think about MapReduce. And I’m sure that there’s others that I’m not</p>
<p>381<br>00:54:42,639 –&gt; 00:54:48,400<br>necessarily like that word. One of them is Spark which we’ll read later about.</p>
<p>382<br>00:54:52,880 –&gt; 00:54:58,320<br>Yeah, so but I like the graph way of thinking about MapReduce because right now we’re only</p>
<p>383<br>00:54:58,320 –&gt; 00:55:04,720<br>really thinking about like a two-step operation where it could actually be like you know many many steps.</p>
<p>384<br>00:55:06,880 –&gt; 00:55:14,000<br>Oh yeah, and then how our inputs partition and practice so usually because the input space is</p>
<p>385<br>00:55:14,000 –&gt; 00:55:19,600<br>very application specific and the output space is also application specific. It’s really up to the</p>
<p>386<br>00:55:19,599 –&gt; 00:55:32,559<br>programmer to specify. There’s sometimes our natural inputs for example like maybe the local</p>
<p>387<br>00:55:33,199 –&gt; 00:55:39,679<br>matrix computations and you want to combine them or so on and so forth. Or you could if it’s just</p>
<p>388<br>00:55:39,679 –&gt; 00:55:45,440<br>like an enormous document or like enormous text files you can just split it up into a reasonable</p>
<p>389<br>00:55:45,440 –&gt; 00:55:50,400<br>size of the work so that you know like applying the map function isn’t going to take forever. And</p>
<p>390<br>00:55:50,400 –&gt; 00:55:53,760<br>also it depends on the size of your cluster. So how many workers you have.</p>
<p>391<br>00:55:57,280 –&gt; 00:56:02,720<br>So some further MapReduce questions. Why do macros for files locally? So in the paper,</p>
<p>392<br>00:56:02,720 –&gt; 00:56:09,840<br>this is because at that time the network bandwidth was their bottleneck. That’s why they don’t</p>
<p>393<br>00:56:09,840 –&gt; 00:56:20,079<br>use GFS and they only use GFS to write the yeah to write the output files. Our leaders necessary</p>
<p>394<br>00:56:20,079 –&gt; 00:56:27,519<br>for distributed systems not necessarily. They’re like think of Bitcoin or like other decentralized</p>
<p>395<br>00:56:27,519 –&gt; 00:56:32,880<br>systems in which all the nodes sort of perform computation and some random node or like some node</p>
<p>396<br>00:56:32,880 –&gt; 00:56:37,920<br>in the network is responsible for committing that. So they’re definitely more like egalitarian designs.</p>
<p>397<br>00:56:40,160 –&gt; 00:56:44,880<br>But yeah, and then our challenge was actually to run MapReduce on like actual different servers</p>
<p>398<br>00:56:44,880 –&gt; 00:56:52,320<br>rather than what we kind of had you do in the lab. And so in order to do this like you would just</p>
<p>399<br>00:56:52,960 –&gt; 00:57:00,720<br>instead of using sockets to communicate over for like the RPCs, you would use like TZPID basically</p>
<p>400<br>00:57:00,720 –&gt; 00:57:08,880<br>like normal like over the network communication. And you would use a share file system like</p>
<p>401<br>00:57:08,960 –&gt; 00:57:15,360<br>GFS. So the equivalent I think all of you have access to Athena if at least if you’re MIT and you could</p>
<p>402<br>00:57:16,400 –&gt; 00:57:23,440<br>association to multiple Athena machines and use AFS which is the share file system that Athena uses</p>
<p>403<br>00:57:23,440 –&gt; 00:57:30,800<br>to. Basically you can access your files on Athena from any machine. Similarly, you could do the</p>
<p>404<br>00:57:30,800 –&gt; 00:57:38,559<br>same thing by renting AWS instances and using S3. But we didn’t expect you to spend any money to</p>
<p>405<br>00:57:39,280 –&gt; 00:57:47,599<br>run our lab. Right, so some questions that came up about just like general code design. So some of</p>
<p>406<br>00:57:47,599 –&gt; 00:57:54,960<br>these we’ve discussed as well. So lab one was pretty small. Lab two is going to be much louder</p>
<p>407<br>00:57:55,599 –&gt; 00:58:00,880<br>especially as you get to the later stages and as lab three and lab four come along as well.</p>
<p>408<br>00:58:01,760 –&gt; 00:58:08,880<br>And one thing that I personally find very handy is to separate different chunks of code by their</p>
<p>409<br>00:58:08,880 –&gt; 00:58:18,559<br>purpose. So and also in how I implement each step of my code. So separating them out by for example</p>
<p>410<br>00:58:18,559 –&gt; 00:58:25,920<br>RPCs and the sellers and handlers and feel free to actually separate these out like physically in</p>
<p>411<br>00:58:26,000 –&gt; 00:58:33,760<br>different files. That won’t like that’s fine for a test and it will probably help you like not have</p>
<p>412<br>00:58:33,760 –&gt; 00:58:41,840<br>thousands of lines of code in one gigantic file. I personally like to put all definitions of state</p>
<p>413<br>00:58:41,840 –&gt; 00:58:48,000<br>together and then functions are like sort of separate but that’s my personal preference.</p>
<p>414<br>00:58:48,960 –&gt; 00:59:00,639<br>So for example, every single RPC you will get in RAP you need to check for a sale term. So putting</p>
<p>415<br>00:59:00,639 –&gt; 00:59:05,360<br>all that logic so that we set all the state properly and everything into one function that you</p>
<p>416<br>00:59:05,360 –&gt; 00:59:11,679<br>just call will help because you know you don’t want to accidentally forget just like reset your</p>
<p>417<br>00:59:11,679 –&gt; 00:59:18,000<br>election timer like we said voted for or something. Although you should have reset the</p>
<p>418<br>00:59:18,000 –&gt; 00:59:24,639<br>election timer so don’t do that. That was an example I pulled off the top of my head. And also finally</p>
<p>419<br>00:59:24,639 –&gt; 00:59:29,759<br>having a good environment with like autocomplete or like being able to search for certain keywords</p>
<p>420<br>00:59:29,759 –&gt; 00:59:36,399<br>in your code and so forth can help a lot. So if you need any help setting this up like comes</p>
<p>421<br>00:59:36,400 –&gt; 00:59:42,720<br>off as ours or this tons of tutorials online you can look up you know a good editor but it’s</p>
<p>422<br>00:59:42,720 –&gt; 00:59:49,599<br>not necessary it’s definitely not necessary but it does help. And then oh yeah so someone asked</p>
<p>423<br>00:59:49,599 –&gt; 00:59:54,160<br>how’s using Go decreased the amount of time students spend debugging. So I’ve never actually</p>
<p>424<br>00:59:54,160 –&gt; 01:00:01,680<br>implemented the labs in C++ but according to friends like well the one huge advantage of Go</p>
<p>425<br>01:00:01,679 –&gt; 01:00:07,359<br>is it’s memory management. So it uses garbage collection and you don’t have to deal with like you know</p>
<p>426<br>01:00:08,319 –&gt; 01:00:12,719<br>there are pointers but you don’t have to deal with them in the same way that you would in C or C++</p>
<p>427<br>01:00:13,839 –&gt; 01:00:19,839<br>so like I don’t know how many of you run into cycle so far but I’m guessing very few of you or</p>
<p>428<br>01:00:19,839 –&gt; 01:00:27,599<br>they were very easy to fix and this definitely makes it easier to debug or they’re just certain types</p>
<p>429<br>01:00:27,599 –&gt; 01:00:34,079<br>of bugs that you don’t need to worry about. Sorry I have a question. Yeah and this is like a more</p>
<p>430<br>01:00:34,079 –&gt; 01:00:41,440<br>go specific question but when you have a function that can take in let’s say you have like a</p>
<p>431<br>01:00:41,440 –&gt; 01:00:46,960<br>you have like that pen entries arc and you also have like the request vote arc both of them have</p>
<p>432<br>01:00:46,960 –&gt; 01:00:53,119<br>a term variable inside but when you pass it to a function how do you tell the function that’s like</p>
<p>433<br>01:00:53,119 –&gt; 01:01:05,679<br>hey I expect a struct that has a term field. Is that possible? So you you define the types right</p>
<p>434<br>01:01:05,679 –&gt; 01:01:12,880<br>so it’s like any other type you’re when you pass it into the function the function expects</p>
<p>435<br>01:01:12,880 –&gt; 01:01:19,839<br>an argument of a particular type and those types yeah yeah let’s say I want to share one function</p>
<p>436<br>01:01:19,840 –&gt; 01:01:25,519<br>across both types. I believe you can use an interface but I’m not sure. Oh yeah.</p>
<p>437<br>01:01:26,640 –&gt; 01:01:32,240<br>So I tried using it. Yeah I tried using it. But when I do dot term it says I don’t know this field</p>
<p>438<br>01:01:32,240 –&gt; 01:01:38,160<br>or like it doesn’t want to say. I think you need to convert it or you need to still have casting</p>
<p>439<br>01:01:38,160 –&gt; 01:01:43,840<br>I can’t ever but there’s a way to coerce. You have to type catch the back you know to whatever</p>
<p>440<br>01:01:43,840 –&gt; 01:01:53,360<br>you want to access. Like you basically need to tell go that by the time I actually use this</p>
<p>441<br>01:01:53,360 –&gt; 01:01:59,519<br>variable it is of a particular type. Got it thank you. So one thing if you want to reuse the</p>
<p>442<br>01:01:59,519 –&gt; 01:02:05,280<br>function for multiple different types you can pass in an interface but you might also need to pass</p>
<p>443<br>01:02:05,280 –&gt; 01:02:12,960<br>in for example a like a enamel or a bull or something that tells it like hey this is going to be</p>
<p>444<br>01:02:12,960 –&gt; 01:02:17,599<br>this type and then you need to cast that interface into the right type before you use it.</p>
<p>445<br>01:02:19,920 –&gt; 01:02:26,159<br>I think the way people usually handle this is by putting setters and getters in the interface</p>
<p>446<br>01:02:26,159 –&gt; 01:02:31,760<br>so you don’t actually need to know which type it is in actuality you can just access the variable</p>
<p>447<br>01:02:31,760 –&gt; 01:02:42,720<br>using interface. Yeah but yeah I don’t think it you should need to use interfaces</p>
<p>448<br>01:02:42,960 –&gt; 01:02:48,720<br>that much in raft like I don’t think I used it all other than the command which is provided.</p>
<p>449<br>01:02:53,440 –&gt; 01:02:59,119<br>Yeah like I guess Dr. Neal column pieces of code is good unless it adds additional complexity.</p>
<p>450<br>01:03:02,159 –&gt; 01:03:09,039<br>Or like I wouldn’t try and force your types to all be able to run the same function like it might</p>
<p>451<br>01:03:09,039 –&gt; 01:03:15,119<br>just be simpler to two slightly different functions. Or if the only like shared piece you’re using</p>
<p>452<br>01:03:15,119 –&gt; 01:03:20,320<br>is the term you can have like the same function taken just the term and in both cases pass in the</p>
<p>453<br>01:03:20,320 –&gt; 01:03:30,559<br>dot term of the structure we’re using. Yeah. All right some other code design questions. This is your</p>
<p>454<br>01:03:30,559 –&gt; 01:03:37,279<br>two museum point. Once separating the code into multiple files is their naming conventional</p>
<p>455<br>01:03:38,000 –&gt; 01:03:43,840<br>required because when we make the lab it seems like it’s copying the source file so is there any</p>
<p>456<br>01:03:43,840 –&gt; 01:03:51,600<br>naming commission? Yeah. I mean I would put them in raft the raft folder but there’s no naming</p>
<p>457<br>01:03:51,600 –&gt; 01:03:57,840<br>convention like you can name your files whatever you want. Okay. Our grading script will replace</p>
<p>458<br>01:03:57,840 –&gt; 01:04:05,519<br>anything that’s necessary or like anything that belongs to the testing framework. So the config file</p>
<p>459<br>01:04:05,599 –&gt; 01:04:09,679<br>or like the test file anything that you change in there will be wiped out.</p>
<p>460<br>01:04:12,480 –&gt; 01:04:18,159<br>Yeah there’s like also be slightly careful about using external dependencies.</p>
<p>461<br>01:04:20,239 –&gt; 01:04:26,559<br>I ran into a couple of issues with grading some scripts that had external dependencies like</p>
<p>462<br>01:04:26,559 –&gt; 01:04:33,440<br>using some GitHub package, go package but those were I was able to like fix it just be a little</p>
<p>463<br>01:04:33,440 –&gt; 01:04:38,800<br>careful if you do that. But yeah create as many dog go files and raft is one.</p>
<p>464<br>01:04:42,000 –&gt; 01:04:48,480<br>Yeah so a pointer versus a value while passing by reference can be cheaper because go won’t</p>
<p>465<br>01:04:48,480 –&gt; 01:04:57,519<br>just like copy the struct. This was this question was asked in particular for why call takes the</p>
<p>466<br>01:04:57,599 –&gt; 01:05:04,639<br>arguments and the reply as pointers and so yeah those could be potentially extremely large and</p>
<p>467<br>01:05:04,639 –&gt; 01:05:09,440<br>so good doesn’t have to copy them when you call the function that’s the main reason. Using</p>
<p>468<br>01:05:09,440 –&gt; 01:05:15,280<br>bug lots and channels are possible yes you’ll use them both in raft so you will definitely see</p>
<p>469<br>01:05:15,280 –&gt; 01:05:23,360<br>how it’s possible. Oh yeah and then we’re getting a lot of questions about timeouts. So in math</p>
<p>470<br>01:05:24,079 –&gt; 01:05:29,200<br>the map reduced a lot the timeout was sort of what we gave you a set 10 seconds for the worker</p>
<p>471<br>01:05:29,200 –&gt; 01:05:33,599<br>task when they fail but in terms of like how long do you sleep and stuff you were pretty much</p>
<p>472<br>01:05:33,599 –&gt; 01:05:39,280<br>able to choose anything under that. For raft you have to choose timeouts a little more carefully</p>
<p>473<br>01:05:39,280 –&gt; 01:05:45,120<br>and our tests are like kind of sensitive but not super sensitive like you’ll be always</p>
<p>474<br>01:05:45,120 –&gt; 01:05:50,559<br>for example probably be within a range of like one to 100 to 200 milliseconds and be fine.</p>
<p>475<br>01:05:51,519 –&gt; 01:06:02,159<br>Yeah in terms of choosing them it probably helps to first think about why you’re waiting at all</p>
<p>476<br>01:06:03,440 –&gt; 01:06:11,840<br>and for example in the for raft your leader is sending hard beads and your timeout is to detect</p>
<p>477<br>01:06:11,840 –&gt; 01:06:19,679<br>when the leader is dead. So you kind of want to give the leader a couple chances to tell you that</p>
<p>478<br>01:06:19,679 –&gt; 01:06:27,440<br>it’s alive otherwise you’ll just continuously think it’s dead. So depending on what you set your</p>
<p>479<br>01:06:27,440 –&gt; 01:06:32,159<br>heartbeat timeout to be or your heartbeat interval to be which I think we give you some guidelines</p>
<p>480<br>01:06:32,159 –&gt; 01:06:38,960<br>if it can’t be more than 10 times per second or sign like that. Depending on what you set your</p>
<p>481<br>01:06:38,960 –&gt; 01:06:43,599<br>heartbeat to be you’ll want your timeout to be something like pretty reasonable like maybe allow</p>
<p>482<br>01:06:44,319 –&gt; 01:06:50,880<br>the chance to get two to three hard beads and then you’ll have to randomize some like range</p>
<p>483<br>01:06:50,880 –&gt; 01:06:56,319<br>because you don’t want all your service to start elections at the same time and to do that you can</p>
<p>484<br>01:06:57,119 –&gt; 01:07:06,880<br>you know like a range of maybe like two to five hard beads some timeout between there is reasonable</p>
<p>485<br>01:07:07,599 –&gt; 01:07:14,480<br>but in terms of the test you’ll see whether you’re sending too many RPCs or too many bites are going</p>
<p>486<br>01:07:14,480 –&gt; 01:07:21,680<br>over the network as the test goes in later lives and you can tweak your timeouts very easily. It’s</p>
<p>487<br>01:07:22,240 –&gt; 01:07:29,920<br>slightly implementation dependent so I can’t tell you like what’s the perfect number for you</p>
<p>488<br>01:07:29,920 –&gt; 01:07:36,559<br>but think of it in terms of like why am I timing out in the first place and how many RPCs do I want</p>
<p>489<br>01:07:36,559 –&gt; 01:07:41,440<br>to get from like other servers before I timeout is a good metric to keep in mind.</p>
<p>490<br>01:07:43,920 –&gt; 01:07:50,079<br>Hopefully that helps a little timeouts. Okay yeah so some implementation questions that</p>
<p>491<br>01:07:51,279 –&gt; 01:07:59,119<br>came up about the MapReduce Lab and also the labs in general. So some people actually did</p>
<p>492<br>01:07:59,119 –&gt; 01:08:03,679<br>implement backup tests which is pretty cool and we definitely did not require that for this lab.</p>
<p>493<br>01:08:04,399 –&gt; 01:08:09,759<br>And I think something that that was important to keep in mind is that the paper</p>
<p>494<br>01:08:10,399 –&gt; 01:08:17,519<br>has makes a distinction between starting restarting a task because a worker has failed and</p>
<p>495<br>01:08:18,720 –&gt; 01:08:26,399<br>issuing the task again to speed up a lagging task that the worker hasn’t failed but you want the</p>
<p>496<br>01:08:26,399 –&gt; 01:08:31,759<br>task to complete faster. And so backup tasks are used for the latter when tasks aren’t</p>
<p>497<br>01:08:31,759 –&gt; 01:08:38,879<br>haven’t failed yet but they’re they’re just slow and timeouts we start tasks when workers are</p>
<p>498<br>01:08:38,879 –&gt; 01:08:45,039<br>actually detected to fail. So in the paper the coordinator actually gets heartbeat from the workers</p>
<p>499<br>01:08:45,759 –&gt; 01:08:52,559<br>whereas in the design that we propose for your lab we use timeouts both to detect that worker</p>
<p>500<br>01:08:52,560 –&gt; 01:08:59,600<br>has probably failed and also to detect slow tasks. So in some ways we make that just we don’t have</p>
<p>501<br>01:08:59,600 –&gt; 01:09:05,360<br>that distinction. We just assume that like if this task hasn’t completed in this set of time</p>
<p>502<br>01:09:05,360 –&gt; 01:09:09,760<br>that you know like probably the worker has failed or maybe it’s just insanely slow and let’s reissue</p>
<p>503<br>01:09:09,760 –&gt; 01:09:20,640<br>it. So that’s why our labs don’t really mention backup tasks. So and then yeah so this is again</p>
<p>504<br>01:09:20,640 –&gt; 01:09:26,320<br>going back to the confusion the next question about like synchronization if the servers are in</p>
<p>505<br>01:09:26,320 –&gt; 01:09:32,560<br>different machines so the servers are on different machines and they only communicate using RPCs.</p>
<p>506<br>01:09:32,560 –&gt; 01:09:37,280<br>All synchronization is just protecting or like synchronizing the threads on one server.</p>
<p>507<br>01:09:38,880 –&gt; 01:09:40,880<br>I just wanted to emphasize that one more time.</p>
<p>508<br>01:09:40,960 –&gt; 01:09:53,840<br>Common sources of race conditions just you know locking. In some ways I think someone’s talking about</p>
<p>509<br>01:09:53,840 –&gt; 01:09:59,440<br>like you know how do you know when to lock and how do you know when to you know using synchronization.</p>
<p>510<br>01:09:59,440 –&gt; 01:10:06,720<br>So anytime you’re modifying the state of the you know like your RAP server or the coordinator</p>
<p>511<br>01:10:06,720 –&gt; 01:10:12,400<br>anytime you modify the state you want to lock and what you’ll notice is that</p>
<p>512<br>01:10:14,000 –&gt; 01:10:20,720<br>for almost every function in your RAP implementation for example you will have a lock and then</p>
<p>513<br>01:10:20,720 –&gt; 01:10:27,520<br>a defer a lock like right after that. The only times you need to make sure that you’re not locked</p>
<p>514<br>01:10:27,520 –&gt; 01:10:35,440<br>is when you make a call that might block. So sending an RPC you know sending something over a channel</p>
<p>515<br>01:10:36,079 –&gt; 01:10:40,719<br>those type of operations you shouldn’t lock around because then your that thread will just be</p>
<p>516<br>01:10:40,719 –&gt; 01:10:46,399<br>blocked and hold the lock and stop the server any thread on the server from making progress.</p>
<p>517<br>01:10:48,479 –&gt; 01:10:53,839<br>Yeah and then there are also some questions about like there are some data races that have been</p>
<p>518<br>01:10:53,839 –&gt; 01:10:59,439<br>iron like for example you could set is done to be true and you know like you don’t really need</p>
<p>519<br>01:10:59,439 –&gt; 01:11:05,519<br>to lock around up but the race detector is complaining. You could use an atomic pool which has the</p>
<p>520<br>01:11:05,519 –&gt; 01:11:11,919<br>same behavior as like walking before and unlocking after but even though you might think this data</p>
<p>521<br>01:11:11,919 –&gt; 01:11:19,039<br>races benign it’s undefined behavior so it just so happens that you know eventually the next read</p>
<p>522<br>01:11:19,679 –&gt; 01:11:25,039<br>like your read might miss the fact that it’s done but the next time you call is done it’ll say true</p>
<p>523<br>01:11:25,039 –&gt; 01:11:32,159<br>and then you’re fine but undefined behavior could technically be implemented as anything like it’s</p>
<p>524<br>01:11:32,159 –&gt; 01:11:37,680<br>just so happens that you’re compiler and you’re a processor does something reasonable when there’s</p>
<p>525<br>01:11:37,680 –&gt; 01:11:43,359<br>a data race so you should handle them especially when they’re this simple and they don’t really</p>
<p>526<br>01:11:43,359 –&gt; 01:11:54,319<br>affect performance that much. Another thing is well in in theory you could have this like is done</p>
<p>527<br>01:11:54,319 –&gt; 01:12:00,880<br>data race could potentially mean that your process would never exit because you know the right to</p>
<p>528<br>01:12:00,880 –&gt; 01:12:07,199<br>is done setting it to true might never actually propagate to the thread that’s reading what whether</p>
<p>529<br>01:12:07,199 –&gt; 01:12:12,319<br>it’s true or not because it could be stored in some like buffer and never flushed. What locks and</p>
<p>530<br>01:12:12,319 –&gt; 01:12:22,799<br>sure is that you’re right the next thread that reads is done we’ll see the last right to is done</p>
<p>531<br>01:12:22,800 –&gt; 01:12:27,680<br>and it’ll actually flush it from for example a potential buffer that the right could be stored in</p>
<p>532<br>01:12:28,480 –&gt; 01:12:34,239<br>so yeah that’s just emphasizing like you don’t want data races even if you think that they’re really</p>
<p>533<br>01:12:34,239 –&gt; 01:12:44,880<br>friendly. Clean way to exit so sending exit RBC from a coordinator to worker works also like the</p>
<p>534<br>01:12:45,840 –&gt; 01:12:53,119<br>Quonco like messy exits where the worker like tries to send an RBC and sees the socket is closed like those are</p>
<p>535<br>01:12:53,119 –&gt; 01:13:04,800<br>also fine we like both solutions are equally acceptable and then I’m expected end of file errors so</p>
<p>536<br>01:13:05,680 –&gt; 01:13:10,800<br>you can look I have a link here that shows when it’s invoked in the client but it’s a little</p>
<p>537<br>01:13:10,800 –&gt; 01:13:18,159<br>confusing as to when that actually happens so I would not worry about it too much if anyone has</p>
<p>538<br>01:13:18,159 –&gt; 01:13:27,039<br>insights into if they got this error at a very like strange moment then we could look into it</p>
<p>539<br>01:13:27,039 –&gt; 01:13:31,680<br>but I think it’s a very specific on your implementation so I would have to look at that in particular</p>
<p>540<br>01:13:31,680 –&gt; 01:13:39,119<br>where we got a bunch of questions about that. Yeah I think so that’s basically most of the questions</p>
<p>541<br>01:13:39,119 –&gt; 01:13:45,920<br>that came up and I think now if you have any questions about you know go map reduce or if you</p>
<p>542<br>01:13:45,920 –&gt; 01:13:52,880<br>want to ask some stuff about the labs. I had a question about the clean way to exit</p>
<p>543<br>01:13:55,119 –&gt; 01:14:00,319<br>so you’re saying like send an X to RBC I was just wondering if there were like if there was like</p>
<p>544<br>01:14:00,960 –&gt; 01:14:07,840<br>a case where like a worker for some reason just takes a very like a very long time to reach the</p>
<p>545<br>01:14:07,840 –&gt; 01:14:16,560<br>server right like how does the server know like when to like shut down because because the</p>
<p>546<br>01:14:16,560 –&gt; 01:14:22,159<br>coordinator shuts down at some point right like when when it says like done when done returns true</p>
<p>547<br>01:14:23,920 –&gt; 01:14:30,800<br>it shuts down and so it stops replying to the workers. How does it decide when to do that if</p>
<p>548<br>01:14:30,800 –&gt; 01:14:40,320<br>it’s waiting for for workers to to shut down themselves? Oh so in this case the coordinator</p>
<p>549<br>01:14:40,960 –&gt; 01:14:47,279<br>isn’t oh I guess so send us the wrong word the coordinator isn’t waiting for the workers to</p>
<p>550<br>01:14:47,279 –&gt; 01:14:54,400<br>respond the coordinator is it’s not sending it’s replying to the request from workers with a</p>
<p>551<br>01:14:55,039 –&gt; 01:15:01,359<br>like the task is done please exit. So the coordinator isn’t actually waiting for the workers</p>
<p>552<br>01:15:01,359 –&gt; 01:15:07,119<br>at all and so in this case the coordinator could actually still exit before the workers and cause</p>
<p>553<br>01:15:07,119 –&gt; 01:15:15,839<br>the workers to like you know have a disconnected socket error and exit. Yeah I guess that was my</p>
<p>554<br>01:15:15,840 –&gt; 01:15:23,680<br>question right like like if if it like the coordinator is replying to workers right that are</p>
<p>555<br>01:15:23,680 –&gt; 01:15:32,640<br>like potentially like asking for get task but what happens if the worker shuts down or say</p>
<p>556<br>01:15:32,640 –&gt; 01:15:39,279<br>or shy the coordinator shuts down before it gets a reply got a request I get a get task RPC from</p>
<p>557<br>01:15:39,279 –&gt; 01:15:44,400<br>the worker. Well then the next time that the worker tries to contact the coordinator the worker</p>
<p>558<br>01:15:44,399 –&gt; 01:15:52,319<br>will see that the connection is closed and then exit. Okay yeah that’s as clean a shut down as well</p>
<p>559<br>01:15:52,319 –&gt; 01:16:01,519<br>get essentially I mean you could imagine that you know if you could set up the workers to be</p>
<p>560<br>01:16:02,239 –&gt; 01:16:07,759<br>RBC servers and then you would actually have the coordinator be sending these like please exit</p>
<p>561<br>01:16:07,760 –&gt; 01:16:16,480<br>and the coordinator would have to wait for the worker to exit but it’s not or it doesn’t seem like</p>
<p>562<br>01:16:16,480 –&gt; 01:16:28,640<br>you would get any utility of that. Yeah Cat I see you Hagar. Yeah something that I was wondering</p>
<p>563<br>01:16:28,640 –&gt; 01:16:33,440<br>about is for the future labs are we allowed to have more files visiting explicitly in the map</p>
<p>564<br>01:16:33,439 –&gt; 01:16:39,759<br>produce lab we were only supposed to have three and it didn’t read something where it was like</p>
<p>565<br>01:16:39,759 –&gt; 01:16:46,399<br>hey you should have all of your stuff contained in one. Oh yeah so you can definitely have more files</p>
<p>566<br>01:16:47,439 –&gt; 01:16:56,159<br>but that’s like I would almost encourage that. Did we say that about that for days? I don’t I can’t</p>
<p>567<br>01:16:56,159 –&gt; 01:17:01,439<br>remember whether we did. What was it you couldn’t edit any of the other main files? Yeah you</p>
<p>568<br>01:17:01,439 –&gt; 01:17:08,479<br>could edit the files and yeah okay I misread that thanks this makes me feel a lot better. Yeah yeah</p>
<p>569<br>01:17:09,759 –&gt; 01:17:19,039<br>but definitely like bring your code will be useful. I have a question about the benign data races.</p>
<p>570<br>01:17:21,039 –&gt; 01:17:26,319<br>I guess like because sometimes there’s for example a raft you just want to like read the current state</p>
<p>571<br>01:17:26,880 –&gt; 01:17:34,960<br>of the raft server. Why would multiple routes, multiple routes, writing to it and one reading.</p>
<p>572<br>01:17:34,960 –&gt; 01:17:41,039<br>So why would a read and a write to the same variable end up cause undefined behavior because</p>
<p>573<br>01:17:41,039 –&gt; 01:17:49,679<br>the read either comes before or after the write. So one thing that can happen and most processors</p>
<p>574<br>01:17:49,680 –&gt; 01:17:59,920<br>don’t do this but every time you have a like so any thread can run on it like a separate core</p>
<p>575<br>01:18:01,520 –&gt; 01:18:09,600<br>and every core has a buffer for the data that it’s reading or writing or writing I guess like a</p>
<p>576<br>01:18:09,600 –&gt; 01:18:18,880<br>store buffer. So for example thread one could write one value to the state and thread two could try</p>
<p>577<br>01:18:18,880 –&gt; 01:18:26,079<br>to read it or like multiple threads could be writing and thread one without a lock so locks</p>
<p>578<br>01:18:26,079 –&gt; 01:18:34,400<br>essentially flush the buffer without that lock this write might just like stay in thread ones</p>
<p>579<br>01:18:35,199 –&gt; 01:18:44,000<br>like store buffer forever and the read will never return the updated value. So this behavior</p>
<p>580<br>01:18:44,239 –&gt; 01:18:50,159<br>doesn’t quite happen in practice but it’s an allowable behavior because you do not have the lock.</p>
<p>581<br>01:18:51,279 –&gt; 01:18:57,760<br>Sorry so what happens if the write has a lock but the read doesn’t like doesn’t read always need a lock?</p>
<p>582<br>01:19:03,279 –&gt; 01:19:07,199<br>Yes because</p>
<p>583<br>01:19:07,199 –&gt; 01:19:18,000<br>I think I’ll read. I googled it a little bit and people are like yeah don’t even try</p>
<p>584<br>01:19:18,000 –&gt; 01:19:22,399<br>lock less shared data but I don’t really understand why that would be a problem.</p>
<p>585<br>01:19:25,599 –&gt; 01:19:30,559<br>Go ahead. You could like be doing something that assumes the thing was true and then like when</p>
<p>586<br>01:19:30,560 –&gt; 01:19:37,360<br>you read it’s not actually true yet like there might be multiple things right. That’s why you don’t</p>
<p>587<br>01:19:37,360 –&gt; 01:19:46,400<br>want to lock this read. So the only time you might be able to even get away with this is if you</p>
<p>588<br>01:19:46,400 –&gt; 01:19:54,560<br>only read a single word and that’s all the thread does and it never does multiple reads but I think</p>
<p>589<br>01:19:54,560 –&gt; 01:20:05,920<br>you still have some issues with one of the other things is if you’re reading more than one piece of</p>
<p>590<br>01:20:05,920 –&gt; 01:20:14,000<br>data like if on one thread you take a lock assign a assign b another thread it doesn’t take a lock</p>
<p>591<br>01:20:14,000 –&gt; 01:20:20,080<br>might see b the new value of b before it sees the new value of a the ordering like in that stuff</p>
<p>592<br>01:20:20,159 –&gt; 01:20:27,920<br>and so if you read like a term from one that from one variable and like whether or not the</p>
<p>593<br>01:20:27,920 –&gt; 01:20:34,079<br>leader from another variable you might read a pair of values that never actually existed because</p>
<p>594<br>01:20:35,119 –&gt; 01:20:40,800<br>there are sort of art the guarantees like when you’re working with concurrent systems you need to</p>
<p>595<br>01:20:40,800 –&gt; 01:20:46,239<br>build everything based off what the guarantees are the platform provides to you and if you don’t there’s</p>
<p>596<br>01:20:46,239 –&gt; 01:20:54,719<br>all kinds of weird edge cases that can throw you off and yeah. Yeah so I think the only case in which</p>
<p>597<br>01:20:54,719 –&gt; 01:21:02,559<br>you can even like try to reason about this is that is if there’s only ever one like you know word in</p>
<p>598<br>01:21:02,559 –&gt; 01:21:09,840<br>the system that you’re ever trying to read and write to as soon as you try to write or read multiple</p>
<p>599<br>01:21:10,800 –&gt; 01:21:15,840<br>pieces of data then it’s like you won’t be all too reason about anything without locks.</p>
<p>600<br>01:21:17,680 –&gt; 01:21:24,000<br>Basically if you want to play games with this you have to really understand the compiler the</p>
<p>601<br>01:21:24,000 –&gt; 01:21:29,600<br>whole coding language and memory model the processor you’re using and it’s like member go here and see</p>
<p>602<br>01:21:29,600 –&gt; 01:21:37,199<br>system it gets complicated incredibly quickly. Yeah it’s also like I mean this is all undefined</p>
<p>603<br>01:21:37,199 –&gt; 01:21:42,720<br>behavior so even if it works now like you know I could someone could write just like a new compiler</p>
<p>604<br>01:21:42,720 –&gt; 01:21:49,439<br>and then you’re like that’s where the whole thing about like demons can fly up your nose like it can</p>
<p>605<br>01:21:49,439 –&gt; 01:21:53,760<br>literally do anything if you have a data race because it’s like oh this program’s like doesn’t</p>
<p>606<br>01:21:53,760 –&gt; 01:21:59,679<br>have any semantic so we can like you know go crazy so I would I would not risk it.</p>
<p>607<br>01:21:59,680 –&gt; 01:22:08,000<br>Okay it makes sense thank you. So even when we’re accessing like anything just reading like let’s</p>
<p>608<br>01:22:08,000 –&gt; 01:22:14,480<br>say a raf server state we should still wrap it in a lock. Yeah it just gets annoying sometimes</p>
<p>609<br>01:22:14,480 –&gt; 01:22:22,079<br>because you have to like wrap the single read in a lock and unlock but I’m not sure if like</p>
<p>610<br>01:22:22,559 –&gt; 01:22:32,640<br>that shouldn’t happen super often. Like I mean maybe if you want to for example check that you’re</p>
<p>611<br>01:22:32,640 –&gt; 01:22:43,439<br>so leader and if you’re not ex there or something like that but yeah I don’t like I forget do you use</p>
<p>612<br>01:22:43,519 –&gt; 01:22:51,839<br>like atomic goals for like killed state for example. But like you could use an atomic goal which</p>
<p>613<br>01:22:51,839 –&gt; 01:23:00,319<br>essentially is like locking in a locking right before accessing it and right after but yeah I</p>
<p>614<br>01:23:03,919 –&gt; 01:23:11,039<br>I think you’ll like having in some ways very like coarse grain locks and knowing that you’re the only</p>
<p>615<br>01:23:11,039 –&gt; 01:23:16,399<br>one touching a piece of state will become very handy as you reason about your limitations.</p>
<p>616<br>01:23:17,920 –&gt; 01:23:28,159<br>Thank you. I have a question about the channels so when you make a channel it’s only between</p>
<p>617<br>01:23:28,159 –&gt; 01:23:35,359<br>two threads right or it can be between multiple threads but like if you not if you don’t have it</p>
<p>618<br>01:23:35,519 –&gt; 01:23:41,839<br>um buffered it can potentially just lock and block forever right so for example if you want to do</p>
<p>619<br>01:23:41,839 –&gt; 01:23:47,599<br>something raf and then you have like election you have a channel that like does something about</p>
<p>620<br>01:23:47,599 –&gt; 01:23:53,199<br>election timeouts you would need a buffer channel that’s like the size of the amount of servers correct</p>
<p>621<br>01:23:53,199 –&gt; 01:23:59,279<br>because like you could like send something and then like it blocks because you can be you can have</p>
<p>622<br>01:23:59,359 –&gt; 01:24:07,039<br>multiple like election things election messages sent between the channels correct so if you want</p>
<p>623<br>01:24:07,039 –&gt; 01:24:12,319<br>a on-buffered channel it should only between it should only be between two threads only correct.</p>
<p>624<br>01:24:13,439 –&gt; 01:24:17,920<br>Um I mean not necessarily like if two threads are consumers and one threads are produced at the back</p>
<p>625<br>01:24:20,239 –&gt; 01:24:24,000<br>okay but multiple producers I guess that you would need that correct.</p>
<p>626<br>01:24:24,000 –&gt; 01:24:31,039<br>Well not necessarily I mean if the consumer is you know just doing a loop and constantly</p>
<p>627<br>01:24:31,039 –&gt; 01:24:40,720<br>reading then all the producers would just like I guess it depends on how they’re scheduled but if</p>
<p>628<br>01:24:41,600 –&gt; 01:24:46,720<br>you like you would eventually have someone reading from the channel so you can have multiple</p>
<p>629<br>01:24:46,720 –&gt; 01:24:55,039<br>producers and one consumer. Actually does anyone know about the like run cell um do you know about</p>
<p>630<br>01:24:55,039 –&gt; 01:24:58,880<br>the ordering guarantees of channels like is there a live miss guarantee or are you</p>
<p>631<br>01:25:02,560 –&gt; 01:25:08,240<br>I feel like there is an aliveness guarantee so I guess if you have uh it’s kind of like locks right</p>
<p>632<br>01:25:08,240 –&gt; 01:25:11,280<br>like if you’re always trying to acquire the locks and another thread is like</p>
<p>633<br>01:25:11,359 –&gt; 01:25:17,359<br>also spending and like trying to acquire the lock there’s no guarantee that you will ever acquire it</p>
<p>634<br>01:25:17,359 –&gt; 01:25:20,880<br>which is why like randomization might be necessary in that case.</p>
<p>635<br>01:25:26,079 –&gt; 01:25:32,319<br>Also I realize I think lecture is technically over. I am holding office hours right now so if you</p>
<p>636<br>01:25:32,319 –&gt; 01:25:37,359<br>have questions on love too or want to continue asking questions I’ll be there um and I think like</p>
<p>637<br>01:25:37,359 –&gt; 01:25:44,719<br>maybe Franz if you want to stick around or other others but I will move to to office hours now</p>
<p>638<br>01:25:46,719 –&gt; 01:25:53,519<br>so thank you all so much for coming. Thank you. Thank you.</p>
<p>639<br>01:25:59,519 –&gt; 01:26:01,599<br>Oh can I just ask a quick question?</p>
<p>640<br>01:26:01,600 –&gt; 01:26:07,360<br>Yeah. Alright Franz you’re the host now so I’m going to just hop off to my office.</p>
<p>641<br>01:26:07,360 –&gt; 01:26:12,960<br>Thanks Lily what’s the theme? I’m the Do you have an event? Oh what’s the theme?</p>
<p>642<br>01:26:12,960 –&gt; 01:26:18,000<br>Like my color scheme? Yeah. That’s a good question. I’m not actually sure.</p>
<p>643<br>01:26:19,680 –&gt; 01:26:20,400<br>Let me check.</p>
<p>644<br>01:26:24,800 –&gt; 01:26:25,520<br>Peak C.</p>
<p>645<br>01:26:25,520 –&gt; 01:26:29,920<br>It’s all time in the chat.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>MIT6824 P6Lecture6 Lab1QA</div>
      <div>http://example.com/2025/10/25/MIT6824 P6Lecture6-Lab1QA/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年10月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/10/25/MIT6824%20P4Lecture4Primary-BackupReplication/" title="MIT6824 P4Lecture4Primary BackupReplication">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">MIT6824 P4Lecture4Primary BackupReplication</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/10/25/MIT6824%20P5Lecture5FaultToleranceRaft1/" title="MIT6824 P5Lecture5FaultToleranceRaft1">
                        <span class="hidden-mobile">MIT6824 P5Lecture5FaultToleranceRaft1</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
