---
title: 深入理解计算机系统 021-Dynamic Memory Allocation, Advanced Concepts
date: 2025-10-12 10:00:20
---

发言人   00:00
Well, good afternoon, everybody. Welcome, good to see you and welcome to all those who are watching on videotape as well. I want to clear up. I realized after the last lecture that I didn't explain the idea of peak memory utilization very well to you. So I want to just explain that it's an important idea, and I want to make sure that that we have it clear. If you recall, you recall from we're executing a series, a sequence of requests r 0, real R 1 real. R2 real. Rk up to RN -1. And at any point in time after k 1K plus one requests. We have HK, which is the heap size. After k plus one requests. 
下午好，大家。欢迎，很高兴见到你，也欢迎所有观看录像带的人。我想澄清一下。我在上次讲座后意识到我没有向你们很好地解释峰值内存利用率的概念。所以我想解释一下这是一个重要的想法，我想确保我们已经清楚了。如果你还记得的话，你记得我们正在执行一系列请求，序列r 0，实际R 1实际。R2是真实的。Rk到RN -1。在k 1k加1个请求之后的任何时间点。我们有香港，即堆大小。在k加1个请求之后。


发言人   01:18
Now we have PK, which is the aggregate. 
现在我们有了PK，它是聚合。

发言人   01:28
The sum of all of the payloads. After k plus one requests. So what we're trying to do with this PK measure, this aggregate payload, is at any point in time. So as we execute requests one after the other, the sum of all the payloads in the heap is going to either increase or decrease. So if we execute on and allocate, then the size of the payloads will increase. If we execute a free, the size of all those allocated payloads will decrease. So as we're executing this sequence of requests, the aggregate, the sum of all the payloads is going to be increasing and decreasing. And so what we're capturing with the sum of all these payloads is like a perfect allocator that has no overheads and even more so, one that we can, where we're allowed to compact, blocks the sum of all of the payloads is the minimum possible heap size. 
所有有效载荷的总和。在k加1个请求之后。所以我们试图通过这个PK度量，这个聚合有效负载，在任何时间点做什么。因此，当我们一个接一个地执行请求时，堆中所有负载的总和将会增加或减少。因此，如果我们执行并分配，那么有效负载的大小将会增加。如果我们执行自由，所有分配的有效负载的大小将会减少。所以当我们执行这个请求序列时，聚合，所有有效负载的总和将会增加和减少。因此，我们通过所有这些有效负载的总和捕获的东西就像一个完美的分配器，没有开销，甚至更多，我们可以在允许压缩的情况下，将所有有效负载的总和块为最小可能的堆大小。


发言人   02:37
It's the minimum possible number of bytes required by those allocated blocks. So it's very, very aggressive and it's impossible to achieve, but we're going to use that as sort of our best case and to measure. Peak? Peak memory utilization. 
它是那些分配的块所需的最小可能字节数。所以这是非常非常激进的，不可能实现，但我们将把它作为我们最好的情况和衡量标准。巅峰？内存利用率峰值。


发言人   03:06
After k plus one requests, which we'll denote u of k, that's going to be equal to the max. For all I less than or equal to k? 
在k加上一个请求之后，我们将表示k中的u，这将等于最大值。对于所有I小于或等于k？

发言人   03:33
Of our aggregate payloads divided by the size of the heap after k plus one requests. So what we're doing with this max is we're remembering the high water mark. As our aggregate payloads increase and decrease, we're remembering the high water mark. So that was sort of the worst. That was like the biggest set of payloads that we had. And then so the max is remembering. That high water mark. And then we're dividing by the total size of the heap in order to get an efficiency measure. Ma PK is kind of this is the best we could have done divided by the total heap size. So yes. 
我们聚合负载的总和除以k加1个请求后的堆大小。所以我们对这个最大值所做的是记住高水位标记。随着我们的总有效载荷的增加和减少，我们记住了高水位线。所以这是最糟糕的情况。这就像是我们拥有的最大的有效载荷集。然后，最大的人正在回忆。那个高水位线。然后我们将除以堆的总大小，以获得效率度量。马某某PK有点像这是我们可以做的最好结果除以总堆大小。所以是的。




发言人   04:31
Well, the allocator keeps track of how big the heap is. So that's pretty easy. So does every time it. Calls s break that adds to the size of the heap. And remember, we're assuming that the heap in this case is always increasing. But even even if we allowed the heap size to decrease, it could just if the allocator is controlling the size of the by calls to s break. So is that clear? 
好的，分配器会跟踪堆的大小。所以这很简单。每次都是这样。调用s break，这会增加堆的大小。请记住，我们假设在这种情况下，堆总是在增加。但是即使我们允许堆大小减小，也可能只是如果分配器通过调用s break来控制大小。那么清楚了吗？

发言人   05:06
So for UK, the higher the better, and for any sequence of allocates and frees, this max PK will be the same. That's constant, right? But what varies is h of k, and that depends on how efficient your allocator is using the heap storage question. So what we're doing is at any point in time after k plus one requests, we're evaluating the utilization of our heap up till that point. So it should be k, the max I is smaller than or k for I less than or equal to k? 
因此，对于UK，越高越好，对于任何分配和释放序列，此最大PK将是相同的。这是恒定的，对吧？但变化的是h of k，这取决于您的分配器使用堆存储问题的效率。所以我们正在做的是在k + 1个请求之后的任何时间点，我们都在评估到那时为止我们的堆的利用率。所以它应该是k，最大值I小于或等于k，而I小于或等于k？


发言人   05:57
Oh I'm sorry. 
哦，对不起。

发言人   06:11
Yeah, sorry. Good, good catch. So that should be an I we want to look at for all the requests that came before. Okay, any other questions? Okay? 
是的，对不起。好的，好的捕捉。所以这应该是我们想要查看之前收到的所有请求的一个我。好的，还有其他问题吗？好吗？

发言人   06:36
So last time we looked at some simple the basics of dynamic storage allocators. And today we're going to look at some more sophisticated techniques. Different data structures to store the free list. Primarily, we'll look at implicit allocators. So we'll get a sort of a brief survey of how garbage collectors work. Look at one, just one very simple kind of garbage collector, but it'll give you an idea of what that means. And then we'll finish. 
所以上一次我们看了一些简单的动态存储分配器的基础知识。今天我们要来看一些更复杂的技术。不同的数据结构来存储空闲列表。首先，我们将查看隐式分配器。因此，我们将对垃圾收集器的工作方式进行简要调查。看一个，只是一种非常简单的垃圾收集器，但它会让你了解这意味着什么。然后我们就结束了。


发言人   07:11
Up by looking at all the ways you can get yourself into trouble by using dynamically allocated storage. So you, once you start dynamically allocating storage, things can go really bad really quickly. So we'll go over some of those bad things that can happen, try to alert you to those so you don't do them in your programs. 
通过查看使用动态分配存储可能给自己带来麻烦的所有方式。所以，一旦你开始动态分配存储，情况可能会很快变得非常糟糕。因此，我们将回顾一些可能发生的不好的事情，尝试提醒您注意这些事情，以便您不要在程序中执行它们。

发言人   07:45
Okay, so we looked at how to store a free list in this sort of implicit form by just walking the entire heap and thereby sort of being able to visit all the free blocks. But we can do better actually have if we store the free list using as a doubly linked list. So we call these explicit free lists. So the idea with an explicit free list is that we pointers, we put the pointers. That implement the doubly link list inside the body of a free block where the old payload used to go. 
好的，所以我们研究了如何通过遍历整个堆来以这种隐式形式存储空闲列表，从而能够访问所有空闲块。但是如果我们将可用列表存储为双向链接列表，我们可以做得更好。所以我们称这些显式自由列表。因此，显式自由列表的想法是，我们使用指针，我们放置指针。这实现了旧有效负载所在的免费块的正文中的双重链接列表。


发言人   08:29
Allocated blocks look exactly the same as they did before. There's a header boundary tag, optional boundary tag, footer, and then the payload and any padding free blocks though, and the allocator is not allowed to touch anything in inside the payload of an allocated block. But free blocks are free. Nobody's using them. And so the allocator can put the pointers that implement the data structure inside what was the old payload. 
分配的块看起来与之前完全相同。有一个标题边界标记，可选的边界标记，页脚，然后是负载和任何可用填充块，并且分配器不允许接触已分配块的负载内的任何内容。但免费街区是免费的。没有人使用它们。因此，分配器可以将实现数据结构的指针放在旧负载中。


发言人   09:05
Logically, this just a simple doubly link list that you've all seen before. But actually, these things can be anywhere in memory. You here we have, we have a block of size 6 and it has a forward pointer that points to some other link, and it has a backwards pointer that points to this block, which happens to be have a greater memory address than it. So just the idea is you can't unless you, unless you go to great pains to maintain this sort of a dress ordered structure. These blocks can be sort of scattered anywhere in memory. 
从逻辑上讲，这只是一个你们之前见过的简单的双重链接列表。但实际上，这些东西可以出现在记忆中的任何地方。在这里，我们有一个大小为6的块，它有一个指向其他链接的前向指针，还有一个指向该块的后向指针，恰好该块的内存地址比它大。所以这个想法是你不能，除非你煞费苦心地保持这种着装有序的结构。这些块可以分散在内存中的任何地方。



发言人   09:57
Oh yeah, so this is after several just sort of indefinite number of max and freeze, yes? Oh, yeah, good question. So the question is, what would happen if you freed a block that was in between two free blocks? And so you have to coalesce. It gets a little tricky, and I'll show you in a second. Good, now allocating, oh yes, questions? 
哦，是的，所以这是在几个不确定的最大值和冻结之后，对吗？哦，是的，好问题。所以问题是，如果你释放了一个位于两个空闲块之间的块，会发生什么？所以你必须凝聚。这有点棘手，我马上就给你展示。好，现在分配，哦，是的，有问题吗？

发言人   10:32
So the question is, what happens with locality? So you still get, you still get block locality. These blocks are still contiguous. If you're scanning sort of a set of allocated blocks, it would be better if you could keep them all contiguous. So it's a really, and so there's a. You know, that's a trade off, I don't. It gets difficult if you think how can you maintain? So you don't really care about the locality of free blocks, right? 
所以问题是，地点会发生什么？所以你仍然可以，你仍然可以获得街区位置。这些区块仍然是连续的。如果您正在扫描一组已分配的块，如果您可以保持它们全部连续会更好。所以这是真的，所以有一个。你知道，这是一种权衡，我不知道。如果你认为你如何维护，就会变得很困难？所以你并不真正关心免费街区的位置，对吗？

发言人   11:09
You're just walking a linked list. Well, no, I shouldn't. You say that if you're walking that list, if you hit 1 1 free block, it would bring in a whole page. So it'd be better if you were walking, if the list, as much of that list was contained within that page. So you would benefit. You could benefit with both the allocated blocks because applications would be using them, and with free blocks, because the allocator would be walking that free list question. 
你只是在浏览一个链接列表。不，我不应该。你说，如果你在这个列表中走动，如果你达到了1个免费街区，它将带来一整页。所以如果你在走路，那就更好了，如果是列表，那么该列表的大部分内容都包含在该页面中。所以你会受益。您可以从分配的块中受益，因为应用程序将使用它们，并且可以从空闲块中受益，因为分配器将遍历空闲列表问题。


发言人   11:46
Does it make sense to try to have the programs that are passed? Pre predict. So even though say you only need, even though say you only allocating, if a couple of small structure, we know that you're going to allocate 1000 of them somehow pass that information that the allocator to learn, then you're going to try to. That's a really good question. 
尝试通过这些程序有什么感知吗？预先预测。因此，即使你只需要，即使你只分配，如果有几个小结构，我们知道你将以某种方式分配1000个结构，并传递分配器学习的信息，那么你将尝试。这是一个非常好的问题。

发言人   12:10
So the question is, would it be possible for an application to sort of give hints to the allocator that would increase, that would improve the allocator ISS performance or memory utilization? The answer, you absolutely could. If you did, it wouldn't be a general purpose allocator. So like Mali is a general purpose allocator. So, and it, there's no option, it doesn't provide any arguments in its interface for passing that information in. But it absolutely, if it had some knowledge about the future behavior of a program that could benefit, right? 
所以问题是，应用程序是否有可能给分配器一些提示，这些提示会增加，从而提高分配器的性能或内存利用率？答案是，你绝对可以。如果您这样做，它就不会是一个通用分配器。所以像Mali一样是一个通用的分配器。所以，它没有选项，它的接口中没有提供任何参数来传递该信息。但如果它对一个可能受益的程序的未来行为有一些了解，那绝对是这样的，对吗？


发言人   12:47
Especially like consider you always have this decision when you place an allocated block, whether to split that block or not? Well, if you knew that you were going to get a request for, if you split that block and you knew that you were going to get request coming in the future for sizes of the original block, then you wouldn't want to split it because then when you would just keep it unsplit. And then when you freed it, then you'd have a block that would be the right size for that future request. So you can absolutely benefit from that. 
尤其是当你放置一个分配的块时，考虑到你总是有这个决定，是否分割那个块？如果你知道你会收到一个请求，如果你分割那个块，并且你知道将来会收到原始块大小的请求，那么你就不会想分割它，因为那样你就可以保持它不分割。然后当你释放它时，你就会有一个块，它的大小适合未来的请求。所以你绝对可以从中受益。

发言人   13:21
So although you can't general purpose allocators, there's no provision for that kind of hinting, but there's nothing to prevent an allocator from doing predictions based on the previous pattern of requests. So if you're getting a pattern of requests that's alternating large block, small block, large block, small block, you could, you could exploit that, maybe predict that the next request will be for. The previous request was for a large block, the next one might be for a small block. And you could, that's a good question. Any other questions? Wizard, yes. 
因此，尽管您不能使用通用分配器，但没有提供这种提示，但没有什么可以阻止分配器根据先前的请求模式进行预测。因此，如果您收到的请求模式是交替的大块、小块、大块、小块，您可以利用它，也许可以预测下一个请求将是。上一个请求是针对一个大区块，下一个请求可能是针对一小部分区块。你可以问，这是个好问题。还有什么问题吗？巫师，是的。

发言人   14:07
I don't know, so the question is, are there intelligent allocators that do that kind of prediction? And if there are, I don't know of them, but I wouldn't say no. This. 
我不知道，所以问题是，是否有智能分配器来做这种预测？如果有的话，我不认识他们，但我不会说不。这个。

发言人   14:28
Track the size itself. What would happen if you end up with a free block thats a block just like in the middle of? Just a single. So the question is, what if you ended up with a free block that's a single block surrounded by two allocated blocks? Well, in fact, I mean, that's one of the invariants that a good allocator has to maintain. You should never have two contiguous free blocks. The allocator should always be cold and as much as it can. And if it does that coalescing, if it always does that coalescing, then there will never be two contiguous free blocks. Yes, question? 
跟踪大小本身。如果你最终得到一个免费的街区，就像在中间的街区一样，会发生什么？只有一个。所以问题是，如果你最终得到一个免费的区块，它是一个被两个分配的区块包围的区块呢？实际上，我的意思是，这是一个好的分配器必须维护的不变量之一。你永远不应该有两个连续的空闲块。分配器应该始终是冷的，并且尽可能多。如果它这样合并，如果它总是这样合并，那么永远不会有两个连续的空闲区块。是的，有问题吗？



发言人   15:19
Oh, you'll see when it comes into play when we free a block because you have to sort of stitch up. When you free a block, sort of stitch up the. Link list. And so you need both pointers. You can do it with singly linked list. So in the K and R book, there's an allocator that uses a singly linked list. But the disadvantage is that free requires a search. So it requires a search from the beginning of the list to find the previous block. 
哦，当我们释放一个街区时，你会看到它何时开始发挥作用，因为你必须缝合。当你腾出一个街区时，有点像缝合。链接列表。所以你需要两个指针。你可以用单链表来做到这一点。所以在K和R书中，有一个分配器使用了一个单链表。但缺点是免费需要搜索。因此需要从列表的开头搜索以查找前一个块。

发言人   15:56
Are there other questions? These are good, yes. How does? So the question is, for memory utilization, how does the header and footer count towards memory utilization? And so those are overhead that decrease memory utilization because they're not payload. So when we're computing memory utilization, we're doing it by we're using the payload, the aggregate payload to. To estimate our utilization or to compute our utilization. So anything that's not payload, sorry, is overhead, the overhead of one word. And everything we like allocate was also one word. So if we, if all of our payloads were one word and our overhead was one word, then there'd be 50%. 
还有其他问题吗？这些都很好，是的。如何？所以问题是，对于内存利用率，页眉和页脚如何计算内存利用率？因此，这些开销会降低内存利用率，因为它们不是有效负载。因此，当我们计算内存利用率时，我们通过使用负载 (聚合负载) 来完成。估计我们的利用率或计算我们的利用率。所以任何不是有效负载的东西，抱歉，是开销，一个词的开销。我们喜欢的一切都分配也是一个词。所以，如果我们所有的有效负载都是一个字，我们的开销是一个字，那么就会有50%。

发言人   17:02
Happen, but point. You still need like the. Yeah, so the question is, do you still need a boundary tag if you have these next and previous pointers? And the answer is yes, absolutely. And you'll see in a second why, yes? 
发生了，但也指向了。你仍然需要像这样的。是的，所以问题是，如果你有这些下一个和之前的指针，你还需要一个边界标签吗？答案是肯定的，绝对的。你马上就会明白为什么，是的？

发言人   17:33
Okay, that's a really good question. So what do you do if you have next and previous pointers? What happens if there's a request for a smaller block? So the answer is that all of those things, the header, the footer, the next and previous pointers impose a minimum block size. So if you have a one word header, one word footer, one word prev, and one word next, then your minimum block size is 4 B. And that would be with a zero sized payload. So you can never allocate a block smaller than your minimum block size. So it's very good, very good question. 
好的，这是一个非常好的问题。那么如果你有下一个和以前的指针，你会怎么做？如果有一个更小的区块的请求，会发生什么？所以答案是所有这些东西，页眉，页脚，下一个和之前的指针都施加了最小块大小。所以，如果你有一个单词的页眉，一个单词的页脚，一个单词的上一步，下一个单词，那么你的最小块大小是4 B。那将是一个零大小的有效载荷。因此，您永远不能分配小于最小块大小的块。所以这是一个非常好的问题。



发言人   18:15
So it makes a difference, right? Even though even though it looks like we're getting these, it looks like we're getting these pointers here for free, but we're not really because of this minimum block size. 
所以这就有区别了，对吧？尽管看起来我们得到了这些指针，但看起来我们在这里免费得到这些指针，但并不是因为这个最小块大小。


发言人   18:36
To allocate a gigantic block of the voice. Now, so to give you specific parts of that, say you want to allocate 100 strokes, can you allocate the size of 100 strokes and say, I guess lots of value for like you use it, right? But if you want to take the first half to make them there something and basically say all of this stuff might program to be ridiculous. So it's like you're supposedly asking for that one gigantic block and that's playing it off. Yeah, okay, so. The question is, can you just get one large block and then split it up? And I guess you're assuming that the request would be for equally sized objects. So, and that's a really good strategy, actually. 
分配一个巨大的语音块。现在，为了给你具体的部分，比如你想分配100个笔画，你能分配100个笔画的大小并说，我猜你使用它的价值很大，对吧？但是如果你想把前半部分变成一些东西，基本上说所有这些东西都可能是荒谬的。所以就像你应该要求那个巨大的区块一样，这就是在玩弄它。是的，好的，所以。问题是，你能不能只得到一大块，然后把它分开？我想你假设该请求将针对同等大小的对象。所以，这实际上是一个非常好的策略。

发言人   19:29
If you know or if you think that your workload is going to have, you can't do this in general purpose allocators. But for like a special purpose allocator, if you know that you're going to be asking for objects that are all the same size, like compilers, for example, maintain abstract syntax trees, and they're allocating nodes dynamically, and those nodes are the same size. So you can exploit that by just allocating a large chunk and then allocating all the objects of that size out of that chunk. It's very efficient. You don't even need pointers or anything. All you need is a bit vector to tell you which chunks are allocated and which chunks are free, and you also, as a side effect, you'll get that contiguous access. So if a program access those objects to be part of a link list, there something that it was going to traverse, you could allocate those in order and contiguously. Now with a general purpose allocator where you don't really know what's going to be requested. 
如果您知道或认为您的工作量将会增加，则不能在通用分配器中执行此操作。但是对于像特殊目的的分配器一样，如果您知道您将要要求所有大小相同的对象，例如编译器，则维护抽象语法树，它们正在动态分配节点，并且这些节点的大小相同。因此，您可以通过分配一大块，然后从该块中分配该大小的所有对象来利用这一点。它非常高效。你甚至不需要指针或任何东西。你所需要的只是一个位向量，告诉你哪些块被分配了，哪些块是空闲的，而且作为副作用，你也将获得连续的访问权限。因此，如果程序访问这些对象作为链接列表的一部分，它将遍历某些内容，您可以按顺序和连续地分配这些对象。现在使用一个通用分配器，您并不真正知道将要请求什么。


发言人   20:43
Absolutely, you could do that. You can make general assumptions about the sort of behavior of your programs. You could run traces, or like in the case of malloc La, you could look at the traces. But no, that's a really good thing. You can't just do if statements to say, well, if the size is 42 and then the next size is 24, then I know it's this trace. But you can look at a trace and say, there's an interesting pattern here. I'm going to account for that pattern. I'm going to optimize for that pattern, and that would just, and that's perfectly valid. That's just like taking advantage of your workload. That's what we do in systems all the time, yes. 
当然，你可以做到。你可以对程序的行为类型做出一般的假设。你可以运行跟踪，或者像malloc La的情况一样，你可以查看跟踪。但不，这真的是一件好事。你不能只做if语句说，好吧，如果大小是42，然后下一个大小是24，那么我知道这是痕迹。但你可以看一条轨迹并说，这里有一个有趣的模式。我将解释这种模式。我打算针对该模式进行优化，这将是完全有效的。这就像利用你的工作量一样。这就是我们在系统中所做的事情，是的。




发言人   21:31
Or can we divide it up at the end of the you just have a pointer to the main part, that payload, which is stored in some other? Oh, oh. So the question is, why can't we sort of have separate areas of the heap for the pointers and the payloads? Alright, so how, how about this are. 
或者我们可以在末尾分割它，你只需要一个指向主要部分的指针，即有效负载，它存储在另一个部分中？哦，哦。所以问题是，为什么我们不能为指针和有效载荷有单独的堆区域？好的，这个怎么样？


发言人   22:02
Oh, not okay. So the question is not why can't we split up payloads and link them together with pointers? The answer is that the application is expecting a contiguous block. You can't allocator, can't put anything in the payload. All I can do, all it's allowed to do, is return a contiguous block of the size that the application requested. And once it does that, it can't touch it. All right, good, good. 
哦，不好。所以问题不在于我们为什么不能拆分有效载荷并用指针将它们连接在一起？答案是应用程序期望一个连续的块。你不能分配，也不能在有效负载中放入任何东西。我所能做的就是返回一个与应用程序请求的大小相同的连续块。一旦它这样做了，它就无法触摸它。好的，好的，好的。



发言人   22:34
So let's look at how we'd allocate and free if we have this explicit list, how we would allocate and free blocks. So allocating is pretty simple. We'll have, so here's sort of a graphic of our free list. So we have forward pointers and backward pointers. And the idea is we want to allocate out of this middle block. So we allocate the block of the size that we need. And then we just update the forward and back pointers of the previous and next blocks to point to this new free block. Okay, so that's pretty simple. We're just we're updating 1, 2, 3, 4, 5, 6, 6 pointers. 
因此，让我们看看如果我们有这个明确的列表，我们将如何分配和释放块，我们将如何分配和释放块。所以分配非常简单。我们会有的，所以这里是我们免费列表的图形。所以我们有正向指针和反向指针。这个想法是我们想从这个中间块中分配。所以我们分配所需大小的块。然后我们只需更新上一个和下一个块的前进和后退指针，以指向这个新的空闲块。好的，这很简单。我们只是在更新1、2、3、4、5、6指针。


发言人   23:31
Now it gets trickier when we have to free because we require coalescing. So when you free a block that was previously allocated, the question is, what do you do with that free block? It wasn't in the free list because it was an allocated block. So now that you've freed the block, where do you put it? You've got to put it somewhere. So the simplest thing is this LIFO policy. So the simplest thing is just put it at the beginning of the list. So the last block freed is the first block allocated if it fits, so that's so called AED, LIFO. 
现在，当我们必须自由时，事情变得更加棘手，因为我们需要凝聚。所以，当你释放之前分配的块时，问题是，你如何处理这个空闲块？它不在可用列表中，因为它是一个已分配的块。现在你已经释放了这个块，你把它放在哪里？你必须把它放在某个地方。所以最简单的事情就是这个LIFO政策。所以最简单的方法就是把它放在列表的开头。因此，释放的最后一个块是分配的第一个块，如果合适的话，这就是所谓的AED，LIFO。


发言人   24:09
Now this is simple because you're always doing the same thing, you're just putting the block at the beginning of the list and it's constant time. You're just updating a few pointers. But the studies suggest that the fragmentation can be worse than the alternative technique, which is to keep the blocks ordered by address. So if you choose this address ordered policy, when you free an allocated block, you're going to somehow figure out, you're going to somehow place that block in the list so that the previous block begins at a smaller address and the next block begins at a larger address. So this generally involves some kind of search. You don't's just given this allocated block and you know it's dress. And so now you've got to somehow search the free list to find the proper place to insert it. 
现在这很简单，因为你总是在做同样的事情，你只是把这个块放在列表的开头，它是恒定的时间。你只是在更新一些指针。但研究表明，碎片化可能比替代技术 (保持块按地址排序) 更糟糕。因此，如果您选择此地址排序策略，当您释放分配的块时，您将以某种方式弄清楚，您将以某种方式将该块放置在列表中，以便前一个块从较小的地址开始，下一个块从较大的地址开始。所以这通常涉及某种搜索。你不只是给了这个分配的块，你知道它的衣服。所以现在你必须以某种方式搜索空闲列表，以找到合适的插入位置。



发言人   25:08
Now, I suppose you could do better if you had some kind of, so if you could speed up that search with some kind of balanced tree, that would be one option. But then the problem we always run into with balanced trees, usually one student, at least, somebody always tries to implement Mali with some kind of balanced tree, red, black tree or something. And it seems like a really good idea. But you have to realize that you're competing with with other techniques, specifically segregated lists that are very fast, that have very small constant factors. And even though even though ordered lists are, I think it's usually n log n to update an ordered tree binary or a tree, the constant factors can be quite large and so usually get nailed with the constant factors of maintaining the tree. And you don't get help. 
现在，我想你如果有某种类型的搜索可以做得更好，所以如果你可以用某种平衡树来加快搜索速度，那将是一个选择。但是，我们总是遇到平衡树的问题，通常至少有一个学生，总是有人试图用某种平衡树，红树，黑树或其他东西来实现Mali。这似乎是一个非常好的主意。但是你必须意识到你正在与其他技术竞争，特别是分离列表，它们非常快，具有非常小的固定因素。即使有序列表是，我认为更新一个有序二叉树或一棵树通常需要n个log，常数因素可能非常大，因此通常会受到维护树的常数因素的影响。你得不到帮助。



发言人   26:05
The search time is log n, but as we'll see with segregated lists. In the limit. In the limit. As the number of different size classes increases, the search time approaches constant time. And if you have size classes that cover ranges of powers of 2 and the search time reduces to log time anyway, because the size of each class is sort of now logarithmic the log. So, you know, I would suggest. 
搜索时间为log n，但正如我们将在分离列表中看到的那样。在极限内。在极限内。随着不同大小类别数量的增加，搜索时间接近恒定时间。如果你有覆盖2的幂范围的大小类，并且搜索时间无论如何都会减少到日志时间，因为每个类的大小现在都有点对数。所以，你知道的，我建议。

发言人   26:41
Just doing the simple thing. Usually whenever you're dealt with sort of large design space like malloc, you're better off doing the simple thing and then optimizing only when you see that you need to optimize. So remember last time we talked about this trick to eliminate the boundary tag, footer and allocated blocks? 
只是做简单的事情。通常当你处理像malloc这样的大型设计空间时，你最好做简单的事情，然后只有在看到需要优化时才进行优化。还记得上次我们讨论消除边界标签、页脚和分配块的技巧吗？

发言人   27:03
That's an example of an optimization you should defer so that wait, do the simple thing, and then try to improve incrementally by this optimization or another optimization. So this phenomena, a lot of programmers make the mistake of what we call premature optimization to try to think of all the fancy things they can do. And then they put all those in at the beginning. And before they even know that it needs to be optimized sort of the way you want to work on this. And any sort of complex problem like an allocator is to first do fairly simple things and then look and see where the slowdowns are, your inefficiencies are, and then just sort of hit those one after the other and optimize only for the things that are necessary. And this is a good example of that. OK, now to get to your question about freeing. 
这是一个优化的例子，你应该推迟等待，做简单的事情，然后尝试通过这个优化或另一个优化来逐步改进。所以这种现象，许多程序员犯了一个错误，即我们称之为过早优化，试图想到他们可以做的所有花哨的事情。然后他们把所有这些都放在开头。甚至在他们知道需要按照你想要的方式进行优化之前。任何复杂的问题，如分配器，首先要做相当简单的事情，然后查看并找出减速的地方，你的效率低下，然后一个接一个地打击这些问题，只优化必要的事情。这是一个很好的例子。好的，现在来谈谈你关于释放的问题。



发言人   28:11
Freeing is tough because we always have to do this coalescing because of this invariant that we can never have to free blocks, two adjacent free blocks. So let's go through each of those four cases that we went over last time and see how we would do it now that we have this explicit free list. 
释放是困难的，因为我们总是必须进行这种合并，因为这个不变量使得我们永远不能释放相邻的两个空闲块。那么让我们逐一回顾一下上次讨论的这四个案例，看看现在我们有了这个明确的免费列表，该怎么做。


发言人   28:32
So here we have the root of our free list pointing to the first block. In the free list, there's a null back pointer, and then there's a null pre pointer. And then the next next pointer points to some unspecified block. And so we have this yellow block, which is allocated, and now the application is called free free with a pointer that points to the beginning of this block. So what do we do? Well, this case, it is pretty simple because there's no coalescing, because both the predecessor and successor blocks are are allocated. 
所以在这里，我们的空闲列表的根指向第一个块。在空闲列表中，有一个空的返回指针，然后有一个空的前置指针。然后下一个指针指向某个未指定的块。所以我们有了这个黄色的块，它被分配了，现在这个应用程序被称为free free，它有一个指针指向这个块的开头。那么我们该怎么办？好吧，这种情况非常简单，因为没有合并，因为前置和后继块都被分配了。

发言人   29:09
Okay, so we just this newly freed block now becomes, we're going to do a LIFO policy, so this becomes the first block in the free list, and so we update the root to point to this newly freed block and we update the forward pointer of that block to point to what used to be the first block in the heap. Now I'm going to be careful. It's a little bit confusing because we've got sort of two notions of previous and next, right? Given some block, there's the predecessor block in memory, which may or may not be allocated or free. It may or may not be in a free list, and there's a successor block, okay, so we'll use predecessor and to distinguish. Adjacency in memory. And we'll use pre and next to denote adjacency in the free list. This block is the next block for the current block, and it has no previous block. 
好的，所以这个新释放的块现在变成了，我们将执行一个LIFO策略，所以这成为可用列表中的第一个块，因此，我们更新根以指向这个新释放的块，并更新该块的前向指针以指向曾经是堆中的第一个块的内容。现在我要小心。这有点令人困惑，因为我们有之前和下一个的两种概念，对吧？对于某个块，内存中有一个前任块，它可能会被分配，也可能不会被释放。它可能在空闲列表中，也可能不在空闲列表中，并且有一个后继块，好的，所以我们将使用前驱体来区分。记忆中的邻接关系。我们将使用pre和next来表示空闲列表中的邻接关系。此块是当前块的下一个块，并且它没有先前的块。



发言人   30:22
All right, now what about case 2? Remember case 2, the predecessor block is free and the successor block is alloc. And now we want to free this. What was an allocated block denoted by yellow? And we have this successor. 
好的，现在情况2怎么样？记住案例2，前一个块是free，后继块是alloc。现在我们想要释放它。用黄色表示的分配块是什么？我们有了这个继任者。


发言人   30:43
This predecessor block is part of the free list, it has previous and next blocks that are just part of the free list. So our root points, the first block in the list, and then eventually. You get to this free block, which points to this free block, which points to this free block. So what we have to do then is we have to coalesce these two blocks into one big free block. And then we have to splice it out and stick it at the beginning of the list. 
这个前趋块是可用列表的一部分，它的先前和下一个块只是可用列表的一部分。所以我们的根点，列表中的第一个块，然后最终。你会到达这个免费区块，这个区块指向这个免费区块，这个区块指向这个免费区块。所以我们要做的是将这两个区块合并成一个大的空闲区块。然后我们必须将其拼接出来并将其粘贴在列表的开头。

发言人   31:20
So what that looks like conceptually is we coalesced these two blocks now to form this one free block, and then we splice it out by having what was the, what was its previous block? Now point to what used to be the next block of the current block. Okay, so this. The pointer from this block now points to this block. And so we've effectively spliced that current block out of the free list. And then the root, we have the root point to that block. So that's now the new first block in the list. And then we have to update what used to be the first block in the list. So now it points back to the newly freed coalesced block. 
所以从概念上讲，这看起来像是我们现在合并这两个块以形成这个免费的块，然后我们通过具有先前的块来拼接它？现在指向当前块的下一个块。好的，所以这个。这个块的指针现在指向这个块。因此，我们有效地将当前的区块拼接出了空闲列表。然后是根，我们有该块的根点。所以现在这是列表中的第一个新块。然后我们必须更新曾经是列表中的第一个块的内容。所以现在它指向新释放的合并块。

发言人   32:20
So is that clear to everybody, yes? 
所以每个人都清楚吗？

发言人   32:27
Would the root be a global variable? It could be or it could be. There's two ways to do this, right? It could just be a global variable, or it could be. It could be a struct that like previous and next pointer. So sometimes it's easier if you keep the same. When you do a link, list the root. If you just make it the same as all the other nodes, it can simplify things. But yeah, it can be a global variable, a global scalar in the allocator. 
根是全局变量吗？它可能是，也可能是。有两种方法可以做到这一点，对吧？它可以只是一个全局变量，也可以是。它可以是一个类似于上一个指针和下一个指针的结构。所以有时候保持不变会更容易。当你做一个链接时，列出根目录。如果你只是使它与所有其他节点一样，它可以简化事情。但是，它可以是一个全局变量，一个分配器中的全局标量。


发言人   33:01
So now one thing that comes to mind. There is an optimization that we could do. In this case, do you see when we coalesce, we could just leave that block right there in the free list, although we've adopted. So the examples I'm going to show you are assuming a LIFO policy for insertion. We could just leave it there and just don't update anything, just increase, create this newly coalesced block. Then we don't require, in this case, we wouldn't require any freeload manipulation, but that would be one of these optimizations, right? Now? 
所以现在我想到的一件事。我们可以进行优化。在这种情况下，当我们结合时，你看到了吗，我们可以把那个块留在自由列表中，尽管我们已经采用了。所以我将向您展示的示例假设有一个用于插入的LIFO政策。我们可以把它留在那里，不更新任何东西，只增加，创建这个新合并的块。那么我们不需要，在这种情况下，我们不需要任何自由加载操作，但这将是这些优化之一，对吧？现在？

发言人   33:49
Case three, if you recall, is the case where the predecessor block is allocated and the successor block is freed. The successor block is free. So in this case, what we have to do is we have to create, we have to coalesce the newly freed block with the successor block, and then we have to splice it out in just the same way we did in case 2. So we splice it out of the list and then put it at the beginning of the list by pointing the root at it and then updating what used to be the first block in the list, updating its back pointer, its pre pointer to point to the this newly coalesced block. So this is completely symmetric with the case that we looked at before. 
第三种情况，如果你还记得的话，就是分配了前趋块并释放了后继块的情况。后继区块是免费的。在这种情况下，我们要做的就是创建，我们必须将新释放的块与后继块合并，然后我们必须以与案例2相同的方式将其拼接出来。因此，我们将其从列表中拼接出来，然后通过指向根将其放置在列表的开头，然后更新曾经是列表中第一个块的内容，更新其后退指针和前置指针以指向这个新合并的块。这与我们之前看到的情况完全对称。


发言人   34:48
Now we no longer have, it's a little bit trickier. If we just wanted to leave this block in the free list, we'd have to update all these pointers to point back to the beginning of the newly created block. So in this case, there's. No performance optimization rate. We're still updating the same number of pointers, whether we put it in the beginning of the list or if we if we splice or if we leave it there. 
现在我们不再有了，这有点棘手。如果我们只想将这个块留在可用列表中，我们必须更新所有这些指针以指向新创建的块的开头。所以在这种情况下，有。无性能优化率。我们仍在更新相同数量的指针，无论是将其放在列表的开头，还是将其拼接或保留在那里。



发言人   35:20
And now case 4 is that's the case where both the predecessor and successor blocks are free. So we have to apply the same splicing technique to both the predecessor block. We have to create this new coalesced block. And then we have to splice. We have to sort of splice it out by updating two different sets of. Of previous and successor blocks. So when we're finished with that, this newly coalesced block now is the first block in the heap in the free list. And we've spliced it out from these two different parts of the, of the free list. 
现在的情况是第四种情况，即前一个和后继的区块都是免费的。所以我们必须对两个前趋块应用相同的拼接技术。我们必须创建这个新的合并块。然后我们必须拼接。我们必须通过更新两组不同的来将其拼接出来。之前和后继区块的。所以当我们完成这个任务后，这个新合并的块现在是可用列表中堆中的第一个块。我们把它从空闲列表的这两个不同部分拼接出来。

发言人   36:20
So any questions about? This is where you really it, It looks really simple to do, but I guarantee you this will be. It's only like 200 lines of code. But some of the hardest code you'll have to write because you're sort of free of the C's type system. You have to do everything by explicitly casting. These pointers are just in the middle of arbitrary blocks. So it looks simple with the diagram, but you're going to have to be really careful when you do this. 
有什么问题吗？这就是你真正的地方，看起来非常简单，但我向你保证这将是。这只是大约200行代码。但有些最难的代码你必须写，因为你有点摆脱了C的类型系统。你必须通过显式转换来完成所有事情。这些指针正好位于任意块的中间。所以用这个图表看起来很简单，但是当你这样做的时候，你必须非常小心。

发言人   37:00
In fact, what I would suggest, the best suggestion I can give you is is to start with the implicit list allocator that we describe in the book, which is too slow to get any credit. It's a terrible allocator, but it contains all the basic ideas. And then write function. Write a function called insert block, and write another function called remove block that inserts a block into the free list and removes a block from the free list, respectively. And if you write, if you abstract it like that, if you use that kind of abstraction, it's pretty simple to convert the implicit list allocator to an explicit list allocator. It'll still be too slow to get. So then that'll go from like AF allocator to AB minus allocator. 
实际上，我的建议是，我能给你的最好建议是从我们在书中描述的隐式列表分配器开始，这个分配器太慢了，无法获得任何荣誉。这是一个糟糕的分配器，但它包含了所有的基本思想。然后写函数。编写一个名为插入块的函数，并编写另一个名为移除块的函数，分别将一个块插入到空闲列表中并从空闲列表中删除一个块。如果你这样抽象，如果你使用那种抽象，将隐式列表分配器转换为显式列表分配器非常简单。这还是太慢了。那么这将从像AF分配器到AB-分配器。



发言人   37:52
And then to really make a good allocator like an A allocator, you need to use segregated list, which we'll look at in a second. So the explicit list, now the allocation time is linear in the number of free blocks instead of the total size of the instead of the total size of the heap. So this is much faster when you have a lot of allocated blocks. It's a little more complicated because of all the splicing business. And you do need some extra space for these pointers, which increases the minimum block size and creates additional overhead. 
然后，要真正做出像分配器这样好的分配器，您需要使用隔离列表，我们将在稍后讨论。因此，显式列表中，现在分配时间是空闲块数的线性，而不是堆的总大小，而不是堆的总大小。所以当你有很多分配的块时，这要快得多。因为所有的拼接业务，这有点复杂。并且您确实需要一些额外的空间用于这些指针，这会增加最小块大小并产生额外的开销。


发言人   38:36
Now, the link list, explicit list allocators aren't really efficient enough to be used for sort of a general purpose real life allocator, but they are useful as part of a segregated list allocator. So you can have multiple free list, each of which is an explicit list, and it's fine for that application. 
现在，链接列表、显式列表分配器的效率并不足以用于通用的现实生活分配器，但它们作为隔离列表分配器的一部分非常有用。因此，您可以有多个空闲列表，每个都是一个显式列表，并且适用于该应用程序。

发言人   39:03
So let's look at our third method, which is to create what called a segregated free list, which is to have multiple free lists with different size classes. So the idea is that each class of sizes, block sizes, has its own free list, and that class can be singletons, maybe one particular size, or it can be a range of sizes. So you might have a number of different if your workload consists of a lot of these small blocks and you know that there's going to be a lot of requests for blocks of one through four, you can have different free lists for those small block sizes, and then after that, you can go and just do ranges of power of 2. So that's a common technique. 
让我们来看看第三种方法，即创建所谓的分离自由列表，它具有多个不同大小类的自由列表。所以这个想法是每个大小的类，块大小，都有自己的自由列表，这个类可以是单块，也许是一个特定的大小，或者它可以是一个大小范围。所以如果你的工作负载由很多这些小块组成，你可能会有很多不同的请求从1到4，你可以为那些小块大小创建不同的空闲列表，然后，你可以去做2的幂范围。所以这是一种常见的技术。


发言人   39:56
So here we have a size class that covers blocks from size 5 to 8, and then another size class that covers everything else. So the idea with a Se list allocators that given an array of these free list one, each one for some size class, if we want to allocate a block of size n, then we go to the appropriate free list. There's always going to be one free list for any n, and then we searched that list just like we did before for some size, a block size m greater than n? And then if we find it, then we place the new block. We place the block in that. In the block that we found, we split it, and we take the split block, and we put it into the appropriate size class. So the block that we split off may or may not belong to the current size class anymore. So we may have to move it and insert it into whatever the appropriate size class is. 
所以在这里，我们有一个大小等级，覆盖了从5到8的区块，然后是另一个大小等级，涵盖了其他所有内容。因此，使用Se列表分配器的想法是，给定这些空闲列表的数组，每个数组用于某个大小的类，如果我们想分配一个大小为n的块，那么我们转到相应的空闲列表。对于任何n，总是会有一个空闲列表，然后我们就像以前一样搜索该列表以获取一些大小，块大小m大于n？然后，如果我们找到它，那么我们就放置新的块。我们把方块放在那里。在我们找到的块中，我们将其分割，然后将分割的块放入适当的大小类中。因此，我们拆分的块可能不再属于当前大小类。所以我们可能需要移动它并将其插入到适当的大小类中。


发言人   41:09
If there's no block, if we can't find a block, then we have to try the next larger size class. So it's possible for a given size class, there might not be a block that fits. I mean, so we just have to, we go to the next size, we try the next larger class, and chances are we'll find a block that fits there. And you keep doing that until eventually, if you can't find it, you're eventually looking in the size class that covers all the rest, the last size class. And if then you can't find it, then the allocator has to allocate more memory by calling S break. 
如果没有区块，如果我们找不到区块，那么我们必须尝试下一个更大的大小类。因此，对于给定的大小类，可能没有适合的块。我的意思是，所以我们只需要转到下一个尺寸，尝试下一个更大的班级，很有可能我们会找到一个适合那里的区块。你一直这样做，直到最终，如果你找不到它，你最终会寻找覆盖所有其他部分的大小级别，即最后一个大小级别。如果找不到，分配器必须通过调用S break来分配更多内存。


发言人   41:56
To free a block, you coalesce like before, and then you place it on the appropriate list. So that's straightforward. And again, you have this option to try to maintain the listed address order or just do the simple thing and put it at the beginning of the list. So seg list allocators are. 
要释放一个块，你可以像以前一样合并，然后把它放在适当的列表中。所以这很简单。再次，您可以选择尝试维护列出的地址顺序，或者只是做简单的事情并将其放在列表的开头。所以seg列表分配器是。

发言人   42:17
By far the best type of allocator because they offer you improvements in both performance, throughput, and memory utilization. So they're faster, they have higher throughputs because the individual size classes are smaller than just like the one giant free list. But also you're searching, you know that the list that you're searching is going to be close to the size that you're looking for. So the chances of finding something quickly in that particular size class are higher than they are if you're just searching, you know, a single free list that holds all different size classes. So search is faster. So that increases. 
迄今为止最好的分配器类型，因为它们可以在性能、吞吐量和内存利用率方面提供改进。因此它们更快，它们具有更高的吞吐量，因为单个大小的类比像一个巨大的免费列表小。但是你也在搜索，你知道你要搜索的列表将接近你要查找的大小。因此，在该特定大小的类别中快速找到某些内容的机会比您只是在搜索时更高，您知道，包含所有不同大小类别的单个免费列表。所以搜索更快。这样就增加了。

发言人   43:05
Throughput, but the big thing about seist allocators is that, like we talked about before, they approximate best fit without sacrificing performance. Before. If we wanted to do best fit on a single free list, we had to search the whole free list and then choose the block that fit the best. In this case, we get best fit for free by virtue of having these size classes. And so this is. 
吞吐量，但关于seist分配器的重要之处在于，就像我们之前提到的，它们在不牺牲性能的情况下近似于最佳匹配。之前。如果我们想最适合单个空闲列表，我们必须搜索整个空闲列表，然后选择最适合的块。在这种情况下，我们通过拥有这些大小类来获得最适合的免费服务。这就是。


发言人   43:38
How you can improve your memory utilization? Yes, it's great fun time. 
你如何提高你的内存利用率？是的，这是一段非常有趣的时间。

发言人   43:51
Bytes or can we allocate? Oh, yeah, good question. So the question is break constant time. It is, but it's very expensive, so it's a syscall, so it has to pass from user space into the kernel that involves changing contexts, changing stacks. So syscalls, generally you can count on a Sysco being like several hundred microseconds. It's a non-trivial overhead. And so in that case, you want to amortize the cost of the break by allocating a somewhat larger chunk. But you have to be careful If you allocate too large of a chunk, then your memory utilization goes down. So it's a trade off, it's another one of these spacetime trade-offs question. 
字节还是我们可以分配？哦，是的，好问题。所以问题是打破常数时间。是的，但它非常昂贵，所以它是一个系统调用，所以它必须从用户空间传递到内核，这涉及到更改上下文，更改堆栈。所以系统调用，通常你可以指望一个系统调用的时间大约是几百微秒。这是一项不平凡的开销。因此，在这种情况下，您希望通过分配更大的块来分摊中断成本。但是你必须小心，如果你分配了太大的块，那么你的内存利用率就会下降。所以这是一个权衡，这是时空权衡问题的另一个问题。

发言人   44:43
So where do you store this array of free lists? So you store it in the beginning of the heap. Yeah, in fact, for your Mali lab, we require you to do that. We don't know. And the reason is we can't. That array affects in some small part, depending on how large that array is, it affects your memory utilization, and so it should be at the beginning of the heap. 
那么你要把这个空闲列表数组存储在哪里呢？所以你将它存储在堆的开头。是的，事实上，为了你的Mali实验室，我们要求你这样做。我们不知道。原因是我们不能。该数组影响了一小部分，这取决于该数组的大小，它会影响您的内存利用率，因此它应该在堆的开头。

发言人   45:16
There's allocators have been around forever. And the classic references canoes, 1973 text. And there's also this great paper, which you can get from the book's website from 1995 that does a survey of dozens and dozens of techniques. We're just scratching the surface here. So if you're really interested in this stuff, that paper is a fascinating read, and it may give you some ideas for your lab. 
有一些分配者已经存在很久了。经典参考独木舟，1973年文本。还有这篇伟大的论文，你可以从这本书的网站上获得，从1995年开始，它对数十种技术进行了调查。我们只是在这里触及表面。所以，如果你真的对这个东西感兴趣，那篇论文是一本引人入胜的读物，它可能会给你一些关于你实验室的想法。


发言人   45:52
Okay, now so far we're assuming that the application is responsible for both allocating storage and freeing storage. But there are a form of memory managers called implicit memory managers that do the freeing for you. So applications allocate space, but they never have to worry about freeing space. The system does that automatically. And so the idea is to identify so-called garbage, so areas of memory that can never be referenced anymore, and then free up those blocks. 
好的，到目前为止，我们假设应用程序既负责分配存储又负责释放存储。但是有一种叫做隐式内存管理器的内存管理器可以为你释放。所以应用程序分配空间，但它们永远不必担心释放空间的问题。系统会自动做到这一点。因此，这个想法是识别所谓的垃圾，即无法再引用的内存区域，然后释放这些块。



发言人   46:35
So what's garbage? Well, here's an example. We have a function foo that now Xs 128 B and stores the address in this pointer p, and then at some point when it returns from foo, this pointer is lost forever because p is a local variable on the stack. So once this function returns, the block of memory pointed to by p is garbage can never be referenced again because there's no way for the program to get access to that. And so an allocator will recognize at some point that this block of memory is garbage, and then it'll free those blocks by calling free. It's the same kind of exactly the same free call as we've discussed. It's called by the garbage collector, not by the application. 
那么什么是垃圾？这里有一个例子。我们有一个函数foo，现在Xs 128 B并将地址存储在这个指针p中，然后在某个时候当它从foo返回时，这个指针将永远丢失，因为p是堆栈上的局部变量。因此，一旦这个函数返回，p所指向的内存块就永远不能被再次引用，因为程序无法访问它。因此，分配器将在某个时候识别出这个内存块是垃圾，然后它将通过调用free释放这些块。这与我们讨论过的免费通话完全相同。它是由垃圾回收器调用的，而不是由应用程序调用。

发言人   47:28
You see this all different kinds of dynamic languages, and there's also variants available for C, but because of C's pointer properties, the garbage collectors for sea are conservative in the sense that there's some blocks won't be freed. There's some garbage blocks that won't be freed because the allocator can't determine that that they are indeed garbage. So it has to be careful. 
你会看到各种不同类型的动态语言，还有C的变体，但由于C的指针属性，sea的垃圾收集器是保守的，感知有一些块不会被释放。有一些垃圾块不会被释放，因为分配器无法确定它们确实是垃圾。所以必须小心。

发言人   47:59
Whenever there's a doubt it leaves, it doesn't reclaim the allocated block. So it gets to this question of like, how does the memory manager know when memory can be freed? And if we knew, if somehow we knew, we could predict all of the future requests. And then if we knew that there were no future requests to access that block, then we could free it. But we can't predict that. So we have to. But if there's no pointers, no pointers exist to a particular block, then we know that it can't be accessed. And so that we can predict if there's some way we can sort of scan the program, scan the memory, identify. 
每当有疑问时，它不会收回分配的块。所以问题就来了，内存管理器如何知道什么时候可以释放内存？如果我们知道，如果我们以某种方式知道，我们就可以预测所有未来的请求。然后，如果我们知道以后没有访问该块的请求，那么我们可以释放它。但我们无法预测。所以我们必须这么做。但是如果没有指针，不存在指向特定块的指针，那么我们知道它无法访问。这样我们就可以预测是否有某种方式可以扫描程序，扫描内存，识别。



发言人   48:50
All the pointers in that memory and see which blocks are pointed to. And if they're not pointed to by any pointer, then they're garbage by definition. 
查看该内存中的所有指针，并查看指向哪些块。如果它们没有被任何指针指向，那么它们就被定义为垃圾。

发言人   49:03
So to do this, though, it's difficult. So first of all, the memory managers has to be able to distinguish pointers from non pointers, which we can't do. And see they're, they're just these integral values. It could be we see this large integral value, this large long 8 B value, it could be pointing to a data structure, or it could just be a large integer. We don't know. And then we also, all pointers have to point to the start of a block, which is not true in C either. 
所以要做到这一点，虽然很困难。首先，内存管理器必须能够区分指针和非指针，这是我们无法做到的。看看它们，它们只是这些整体价值。它可能是我们看到的这个大的整数值，这个长的8 b值，它可能指向一个数据结构，也可能只是一个大整数。我们不知道。然后我们同样，所有的指针都必须指向一个块的开始，这在C中也不成立。



发言人   49:41
So if we have a pointer and we identify that it's a pointer, then we know that it points. It points to some block. If it points inside of a block, how do we find the beginning of that block? How do we know how big that block is. So it has to point to the beginning of the block where the header tells us size, and there can't be a way to hide pointer. So the property of being a pointer has to be some kind of static thing that's can't change. 
因此，如果我们有一个指针，并且我们确定它是一个指针，那么我们就知道它指向了。它指向某个区块。如果它指向一个区块内，我们如何找到该区块的开头？我们怎么知道那个块有多大。因此它必须指向标题告诉我们大小的块的开头，并且无法隐藏指针。所以指针的属性必须是某种无法改变的静态东西。

发言人   50:14
So that's sort of the challenges if you're thinking about how in the world could you implement a garbage collector? So those are some of the challenges that they present. And because of that, this has been the history of research in garbage collectors is old, it's ancient and ongoing. It's ISS still ongoing today, particularly in the context of parallel programs and garbage collecting programs that are running multiple threads. 
所以，如果你正在考虑如何实现一个垃圾收集器，这就是一种挑战？这些是它们带来的一些挑战。正因为如此，垃圾收集器的研究历史已经很古老，而且还在继续。它至今仍在进行中，尤其是在运行多线程的并行程序和垃圾收集程序的上下文中。


发言人   50:40
So there's a whole bunch of these things that people have looked at going all the way back to 1960. Today, we'll look at the lists, one of the simpler. Variants called mark and sweep. And we won't discuss the rest, but if you're interested in them, there's a pretty good book that that describes these things. 
所以人们从1960年开始就一直在研究这些事情。今天，我们来看看更简单的列表之一。称为标记和扫描的变体。我们不会讨论其余的内容，但如果你对它们感兴趣，有一本很好的书描述了这些事情。


发言人   51:03
Right, so how do we build an allocator? So we start by viewing memory as a directed graph, where each node in the graph corresponds to a block, a block, a heap block. And. An allocated heap block. And each edge is a pointer that's contained somewhere within that block, a pointer to another block. 
对，那么我们如何构建分配器？所以我们首先将内存视为一个有向图，其中图形中的每个节点对应于一个块，一个块，一个堆块。而且。分配的堆块。每条边都是一个包含在该块中的指针，指向另一个块的指针。

发言人   51:36
And then there's special nodes called root nodes that contain pointers into the heap, but they're not part of the heap. So for example, pointers that are stored on the stack, pointers that are stored in registers, they point to memory locations in the heap. Nothing, but they're outside of the heap. And we call those root nodes. So nothing points to them. Or at least if something does point to them, we don't care about what it is. 
然后还有一些称为根节点的特殊节点，它们包含指向堆的指针，但它们不是堆的一部分。例如，存储在堆栈上的指针，存储在寄存器中的指针，它们指向堆中的内存位置。什么都没有，但他们在堆之外。我们称之为根节点。所以没有什么能指向他们。或者至少如果有什么事情指向了它们，我们不在乎它是什么。

发言人   52:07
We're only concerned about characterizing nodes that correspond to memory in the heap. So we say that a node or a block is reachable if there's some path from a root node. From a root node to that block. And we've denoted those by green. So all of these green blocks in the heap are reachable. 
我们只关心对应于堆中内存的节点的特征。因此，我们说如果从根节点有一些路径，则一个节点或一个块是可及的。从根节点到该块。我们用绿色表示这些。因此，堆中的所有这些绿色块都是可访问的。

发言人   52:30
You can start at a root node and just follow some sequence of pointers to get to that node. Nodes that aren't reachable are called are garbage because there's no way to get to them from the root nodes. So there's no node inside the heap that points to them. And there's no node, there's no root node that points to them. So basically, there's just no path from a root node that'll get you to one of these nonspeaking or garbage nodes. And since they're non-readable, the application will never be able to reference them in the future. So we can predict with certainty that those are garbage and they can be freed. So basically, after we free these, then they're removed from the graph. 
您可以从根节点开始，然后按照一些指针序列到达该节点。无法访问的节点被称为垃圾，因为无法从根节点访问它们。所以堆中没有节点指向它们。并且没有节点，也没有指向它们的根节点。所以基本上，根本没有从根节点到这些非说话或垃圾节点之一的路径。由于它们不可读，应用程序将来永远无法引用它们。所以我们可以肯定地预测那些是垃圾，它们可以被释放。所以基本上，在我们释放这些之后，它们就会从图表中删除。




发言人   53:26
So now we can build a simple garbage collector on top of the existing MN free package. So you implement mlen free just like before, and then the program. Calls Mali just like before. And you do Mali exactly the same way until you run out of space by whatever definition you want to use of running out of space. Maybe you have some kind of maximum heap size you're willing to use, or at some point, the OS will just stop giving you virtual memory when you run out of space. 
现在我们可以在现有的MN免费包之上构建一个简单的垃圾回收器。所以你像以前一样实现了mlen free，然后是程序。像以前一样称呼马利。你以同样的方式做Mali，直到你用尽空间，无论你想要使用什么定义，空间用尽。也许你有某种你愿意使用的最大堆大小，或者在某个时候，当你空间不足时，操作系统将停止为你提供虚拟内存。


发言人   54:04
You add an extra mark bit into the header of each block. So this could be we have like three or four spare bits that we can use in the header. So we can denote one of those as the mark bit. And then our garbage collection. 
你将一个额外的标记位添加到每个块的标题中。因此，这可能是我们有三个或四个备用位可以在标头中使用。所以我们可以将其中一个表示为标记位。然后是我们的垃圾收集。


发言人   54:23
Our garbage collection phase when we run out of space consists of 2, 2 different sub phases. One is the mark phase, which starts at all the roots then, and it just traverses this from the roots. It traverses the set of of nodes that are reachable from the root, and it sets the mark bit in each one of those nodes. And then once after you finish marking all of the reachable blocks, then you sweep through the entire heap starting at the very beginning of the heap. And for you, look for all allocated blocks that aren't marked. Because they're not marked, they're not reachable, and they're garbage. So first, so you do this, so you sort of do 2. You do a search from the roots, and then you do a sweep of the entire heap. 
当我们的空间耗尽时，我们的垃圾收集阶段由2个不同的子阶段组成。一个是标记阶段，从所有根开始，它只是从根穿过这个阶段。它遍历从根可达的节点集，并在每个节点中设置标记位。然后在标记完所有可到达的块之后，从堆的最开始开始扫过整个堆。对于您来说，查找所有未标记的分配块。因为它们没有被标记，无法到达，而且它们是垃圾。所以首先，你这样做，这样你就可以做2个。你从根开始搜索，然后对整个堆进行扫描。


发言人   55:21
So let's say before mark, we, before the mark phase, we have a heap that looks like this. We have a single root that points to this block. And what we're going to do here, we're always going to point to the payload of the block. It's just a convention that we use. So we're pointing to the beginning of the block because we know that we know that the header is one word behind it. 
假设在标记之前，在标记阶段之前，我们有一个看起来像这样的堆。我们有一个指向此块的根。我们在这里要做的是，我们总是要指向区块的有效负载。这只是我们使用的惯例。所以我们指向块的开头，因为我们知道标题后面有一个单词。


发言人   55:52
So let's say, and in this case, the edges denote pointers that are contained in the block. So they're not the previous and next pointers that we were maintaining. These are just pointers that the application has put into those blocks. So we have, so here we have the root pointing to this, the central block, and then there's, and there's a pointer that points to this block, and there's another pointer that points to this block. And there's a pointer in this block that points to this block. So after we do the mark and we search these blocks, and all of the reachable blocks have the mark bits set, which is denoted by pink, then you see, and then the blocks that aren't marked, then we can free and return to the free list. 
那么假设，在这种情况下，边表示包含在块中的指针。所以它们不是我们维护的上一个和下一个指针。这些只是应用程序放入这些块中的指针。所以我们有，这里我们有指向这个中心块的根，然后有一个指向这个块的指针，还有另一个指向这个块的指针。这个块中有一个指针指向这个块。所以在我们做了标记并搜索这些块之后，所有可及的块都设置了标记位，用粉红色表示，然后你看到，然后没有标记的块，然后我们可以释放并返回到空闲列表。


发言人   56:47
So let's look at the assumptions for a simple implementation just to make sure this is clear. So the application calls new to get a pointer to a block with all the values cleared. It calls read Bi to read location I of block B, and it uses write Biv to write a value V into location I of block B, and then each block will have a header word, which we'll address as b of -1. And then the garbage collector, it has functions that it uses to identify whether a pointer, its input parameter, is indeed a pointer. So there's some way to distinguish a pointer from a non pointer. And it can get the length of some block, not including the header. And it can get a set of all of the roots. 
让我们来看一下简单实现的假设，以确保这一点清晰明了。,因此应用程序调用新获取一个指向清除了所有值的块的指针。它调用read Bi来读取块B的位置I，并使用write Biv将值V写入块B的位置I，然后每个块都有一个标头字，我们将其地址为-1的b。然后是垃圾回收器，它有一些函数用来识别一个指针，它的输入参数是否确实是一个指针。所以有一些方法可以区分指针和非指针。并且它可以获取某个块的长度，不包括标头。它可以得到所有根的集合。



发言人   57:44
So given those assumptions, we pseudocode for the mark step it takes. So this initially is a pointer, a root pointer. And then we check as our terminating condition, we check to see if that input is indeed a pointer. And if so, we return. And then we do a depth first traversal of the graph. And so we're doing a depth firsts reversal of the graph. And this is pointer is sort of our terminating condition for that depth first reversal. Then we check the mark bit. And if it's set, then that's another terminating condition. 
因此，鉴于这些假设，我们对其所需的标记步骤进行了伪代码。所以这最初是一个指针，一个根指针。然后我们检查作为终止条件，我们检查该输入是否确实是指针。如果是这样，我们回来。然后我们对图形进行深度优先遍历。因此，我们正在对图表进行深度优先的逆转。指针是深度优先反转的终止条件。然后我们检查标记位。如果设置了，那么这是另一个终止条件。


发言人   58:31
There's no reason to search Once we find a marked, a marked node, we know that all of everything reachable from that node is marked. So we can terminate, return, and just stop the search. If it's not set, then we set the mark bit, and then we look at each word in the block. And we recursively call mark on each one of those words. Now, each one of those words may or may not be a pointer. So if it's not a pointer, then mark will just return instantly, immediately. If it is a pointer, then it'll continue the recursive depth first search. So does that make sense? It's just the familiar depth first graph reversal that that we all know about. 
一旦我们找到一个标记的节点，就没有理由进行搜索，我们知道从该节点可到达的所有内容都已标记。所以我们可以终止、返回，然后停止搜索。如果没有设置，那么我们设置标记位，然后查看块中的每个单词。我们递归地在每个单词上调用mark。现在，这些单词中的每一个可能是也可能不是一个指针。因此，如果它不是指针，则标记将立即返回。如果它是一个指针，那么它将继续递归深度优先搜索。那有感知吗？这只是我们都知道的熟悉的深度第一图形反转。



发言人   59:23
And then the sweep. Sweep a pointer to the beginning of the heap, takes a pointer to the first block in the heap and a pointer to the end of the heap. And in a while loop, Then it scans the heap. 
然后是扫荡。清理指针到堆的开始，获取指向堆中第一个块的指针和指向堆结尾的指针。在一个while循环中，它会扫描堆。

发言人   59:40
Each block, if the mark bit is set, it clears it. If it's allocated, it frees it, right? And then it updates. And then it gets the address of the next block and then just continues until the end. 
每个块，如果设置了标记位，它将清除它。如果它被分配，它就会释放它，对吧？然后就最新进展了。然后获取下一个区块的地址，然后一直持续到最后。

发言人   01:00:09
So how would we do such a thing in C? Because all of these assumptions I made don't hold. 
那么我们在C中如何做这样的事情呢？因为我做的所有这些假设都不成立。

发言人   01:00:13
In C, you can't tell a pointer from a non pointer. Pointers can point anywhere. So what you could do? So the big issue is that if we get some value. We, if it is a pointer, it could point right into the middle of the block. So given that, so first of all, we don't know if that value really is a pointer. It could just be a big integer, but it also could be a pointer that's pointing into some data structure. 
在C中，你不能区分指针和非指针。指针可以指向任何地方。那么你能做什么呢？所以最大的问题是，如果我们获得一些价值。我们，如果它是一个指针，它可能指向块的中间。因此，首先，我们不知道该值是否真的是指针。它可能只是一个大整数，但也可能是指向某些数据结构的指针。


发言人   01:00:50
If it is a pointer, how do we find the beginning of the block? So what we could do is just assume that every value is a pointer. And then we could maintain a balanced tree to keep track of all the allocated blocks. 
如果它是一个指针，我们如何找到块的开头？所以我们可以做的就是假设每个值都是一个指针。然后我们可以维护一棵平衡树来跟踪所有分配的块。

发言人   01:01:05
And so whenever we encounter a particular value, we would search that binary tree to see, assuming it is a pointer, if it falls within the beginning and end of some allocated block. If that condition is true, then we assume that it's pointing that that's a pointer to an allocated block. And we assume that that block is reachable. Now, the reason it's conservative is because it really may not be a pointer. It might be this integer, and we'll assume it's a pointer and assume that the block that it purportedly points to is allocated, but it may in fact be not be a pointer. And the block that it points to is garbage. So with this scheme, we would leave some. 
因此，每当我们遇到特定的值时，我们会搜索该二叉树，假设它是一个指针，看看它是否落在某个分配块的开头和结尾之内。如果这个条件成立，那么我们假设它指向一个分配块的指针。我们假设该区块是可达的。现在，它保守的原因是因为它真的可能不是一个指针。它可能是这个整数，我们会假设它是一个指针，并假设它据称指向的块已经分配，但它实际上可能不是一个指针。它指向的区块是垃圾。所以在这个计划中，我们会留下一些。


发言人   01:01:51
Non-reportable Blocks We indicate that some non-reportable blocks are really reachable. Okay, so once, now that we've got this great tool to dynamically allocate memory, we can use it in our programs and shoot ourselves in the foot in all different kinds of ways. I'm going to try to help help you out here by identifying some of the perils and pitfalls that we can run into with with memory related operations or operations on memory. 
不可报告的块表明一些不可报告的块确实可及。好的，曾经，现在我们有了这个动态分配内存的伟大工具，我们可以在我们的程序中使用它，并以各种不同的方式攻击自己。我将通过确定与内存相关的操作或对内存的操作可能遇到的一些危险和陷阱来帮助你。


发言人   01:02:30
Opera errors involving memory are the worst, the worst kinds of bugs to try to find out. And the reason is that they're distant in both space and time. So let's say you write to the wrong memory location and corrupt some data structure. The right doesn't elicit any error. You only find out about that erroneous right when you try to reference that data structure or that particular a part of the data structure, which may be a part of the code that's way far away from the right that caused the problem both in space and distance lines of code. It could be a completely different function in a completely different module, but also in time, it may not. You may do the right. And then eons later, there's some read and it fails. 
涉及内存的Opera错误是最糟糕的，是试图找出的最糟糕的错误类型。原因是它们在空间和时间上都很遥远。因此，假设您写入错误的内存位置并损坏了某些数据结构。这个权利不会引发任何错误。只有当你试图引用那个数据结构或数据结构的特定部分时，你才会发现那个错误的权利，这可能是代码远离右边的一部分，导致了代码的空间和距离行的问题。它可能在完全不同的模块中是完全不同的功能，但也可能在时间上不是。你可以做正确的事。然后过了很多年，有一些阅读失败了。


发言人   01:03:20
So this is the fundamental thing that makes memory related bugs just so nasty. And big thing, another thing that makes them hard to deal with is people's misunderstanding and misuse of pointers. So usually an erroneous right is some, is some either a misunderstanding of pointers or an improperly initialized pointer. So it all boils down to these pointers. And so I'm going to show you how to understand pointers for the first time in your lives. 
这是使内存相关的错误如此令人讨厌的根本原因。还有一件让他们难以处理的事情，那就是人们对指针的误解和误用。因此，通常错误的权利是一些，是一些对指针的误解或初始化不当的指针。所以这一切都归结为这些指针。所以我将向您展示如何在您的生活中第一次理解指针。


发言人   01:04:00
I don't know about you, but when I learned C? I learned about pointers. I just knew about what a few different types of pointers were. And I did it by pattern matching. So int star knew was a pointer to an int. I knew that star star P was. An array? I knew that int star P, open bracket, close bracket was also an array, just a different way too express that arrays. So I had a small handful of pointer types that I could deal with, but I had no underlying understanding of what that meant or anything. It was just pure pattern matching, And I'll bet you that's the way you do it too. But that's all going to change today. 
我不知道你的情况，但是当我学习C的时候？我学过指针。我只知道几种不同类型的指针是什么。我是通过模式匹配完成的。所以int star知道是一个指向int的指针。我知道那个明星P是。数组？我知道int star P，左括号，右括号也是一个数组，只是数组的表达方式有所不同。所以我有一些指针类型可以处理，但我对这意味着什么或其他什么没有基本的理解。这只是纯粹的模式匹配，我敢打赌你也是这样做的。但这一切今天都会改变。



发言人   01:04:47
In order to really understand pointers, you need to understand the precedents of various operators in C, because the pointer types are declared using these operators. And so my copy of K and R has a dog ear at page 53. So this table comes from page 53 of K and R, and you should have a paper clip or have that folded over for reference. Now, the thing to notice is that function and array and these various struct operators have the highest priority, highest precedence. And then that's followed by unary operator. So the star, this is the dereference operator, the address of operator, they fall right below. The highest precedence operators, and then the binary versions of operators that you use in arithmetic operations or below those. So just remember that function, an array is higher than star. 
为了真正理解指针，您需要了解C中各种运算符的先例，因为指针类型是使用这些运算符声明的。所以我的K和R的副本在第53页有一个狗耳。所以这个表格来自K和R的第53页，你应该有一个回形针或将其折叠起来以供参考。现在需要注意的是，函数和数组以及这些不同的结构运算符具有最高优先级和最高优先级。然后后跟一元运算符。所以星号，这是取消引用运算符，运算符的地址，它们正好在下面。优先级最高的运算符，然后是您在算术运算中使用的运算符的二进制版本或更低的版本。所以请记住这个函数，数组高于星号。


发言人   01:06:01
The dereference. 
取消引用。

发言人   01:06:04
Now, the great thing about pointers, although they always seem really complicated, is that angos there's an algorithm for it. Constructing an English sentence that explains exactly what that pointer, what that definition of the pointer means. And if you're interested, it's in the K and R in section 5.12, but I'll explain it to you now. Now, I don't know how much in this class you're going to remember, but I guarantee you're going to remember this as the day you finally understood pointers. 
现在，指针的伟大之处在于，尽管它们总是看起来非常复杂，但angos有一个算法可以实现它。构建一个英语句子，解释指针的确切含义，指针定义的含义。如果您感兴趣，请在5.12节中的K和R中，但我现在会向您解释。现在，我不知道你在这堂课上会记得多少，但我保证你会记住这一天，因为你终于理解了指针。


发言人   01:06:47
All right, so here's how it works. You always start. This is a definition of a pointer of some kind. You always start with the variable name. 
好的，这是它的工作原理。你总是开始。这是某种指针的定义。你总是以变量名开始。

发言人   01:07:05
And then you use your precedence. Then you look for operators on either side of that variable name, and you choose the one that has the highest precedence. So we start with the variable. So we say p is a, then we look to the left and the right. There's nothing to the right, but there's a pointer symbol to the left. We say p is a pointer, and there's nothing more. And then we always end up with the type of thing that it points at. So p is a pointer to an int. 
然后你使用你的优先权。然后，您在该变量名称的两侧寻找运算符，并选择具有最高优先级的运算符。所以我们从变量开始。所以我们说p是a，然后我们看左边和右边。右边什么也没有，但左边有一个指针符号。我们说p是指针，没有别的了。然后我们总是最终得到它所指向的事物类型。所以p是一个指向int的指针。


发言人   01:07:48
So p is a pointer to some integer in memory. So we all know that one. That's pretty easy. Okay, what about the next one? You've probably seen something like this. Some programs declare RV using this notation. So this, you can have an optional size or not. So we start out, we say P is a well. Now in this case, there's operators to the left and the right. Remember, the array operator has higher precedence than the dereferencing operator, the pointer operator. So we say, so P is an AR 13 array of size 13. So there's nothing more. So we go to the left of pointers. So p is an array 13 of pointers to ins. 
所以p是指向内存中某个整数的指针。所以我们都知道那一个。这很容易。好的，那下一个呢？你可能见过这样的东西。一些程序使用这种表示法声明RV。所以，你可以有一个可选的大小，也可以没有。所以我们开始，我们说P是井。现在在这种情况下，左边和右边都有运算符。请记住，数组运算符的优先级高于取消引用运算符，即指针运算符。所以我们说，所以P是一个大小为13的AR 13数组。所以没有更多的了。所以我们去指针的左边。所以p是一个由指向ins的指针组成的数组13。


发言人   01:08:55
So p is an array. Of 13 pointers, each of which points to an end, in this case, p is just the name of the array. So by default, p is equivalent, is the address of the array. When you reference an array name, you're youre, addressing the address of the first element. 
所以p是一个数组。13个指针中的每一个都指向一个结尾，在这种情况下，p只是数组的名称。所以默认情况下，p是等效的，是数组的地址。当你引用一个数组名称时，你就是第一个元素的地址。

发言人   01:09:28
Okay, how about the next one? Here we're being, if we put parentheses around things, then we can be explicit. And this is a good practice. So here we're saying p, and we have to look at this one first because of the parentheses. So p is an array 13 of pointers to ints, so that's the same thing, and here we're just being more explicit. 
好的，下一个怎么样？在这里，如果我们在事物周围加上括号，那么我们就可以明确。这是一个很好的做法。所以这里我们说的是p，我们必须先看看这个，因为括号。所以p是一个由13个指向整数的指针组成的数组，所以这是同样的事情，在这里我们只是更加明确。


发言人   01:09:51
Now, what about star star p? So p is a pointer to a pointer to an end, so this is a different type of array. So p is a pointer to a pointer to an. End and typically, so this is another way to do arrays. So the same way that char star points to a string, this can point it to, it points to a pointer, but then you can index on. And each one of those then points corresponds to a pointer. Whoops. Here's another one now p, and because of the parentheses, we have to go left. So p is a pointer to an array 13 of ints. So p is in a pointer to an array. Of 13". 
那么，star p怎么样？所以p是指向结束的指针，因此这是一种不同类型的数组。所以p是一个指向指针的指针。通常情况下，这是另一种数组处理方式。因此，就像char star指向一个字符串一样，这可以指向一个指针，但你可以索引它。每一个点都对应一个指针。哎呀。这里现在是另一个p，由于括号，我们必须向左走。所以p是一个指向整型数组13的指针。所以p在指向数组的指针中。13个 “。

发言人   01:11:16
Now, what about this one? F is a function. Is it a function or a pointer? F is a function, right? Because of the precedence. So FFIs a function returning pointer to int. So if we go. P equal f then returns that initialized p to point to some int. 
现在，这个怎么样？F是一个函数。它是一个函数还是一个指针？F是一个函数，对吧？因为有优先权。所以ff是一个返回指向int的指针的函数。所以如果我们走了。P等于f，然后返回初始化的p指向某个int。

发言人   01:11:54
All right, and I'm going to do this one. Let's jump down in the interest of time. Totally ridiculous case. Just so you can see that this algorithm works. All right, so x is an array of pointers to function. Returning pointers to an array, 5 events. And if you ever use anything like that in your code, shame on. You all right? So there you go. Now you understand pointers simplest can be, and all you need is page 53 of K and R as a handy reference. All right, so we'll take the last five minutes and I'll show you some of the ways you can trip yourself up when you're accessing memory. 
好的，我要做这个。为了时间的利益，让我们跳下去吧。完全荒谬的案例。这样你就可以看到这个算法有效。好的，所以x是一个指向函数的指针数组。返回指向数组的指针，5个事件。如果你在代码中使用了类似的东西，那就太可耻了。你没事吧？所以你去那里。现在你明白了最简单的指针，你所需要的只是K和R的第53页作为方便的参考。好的，我们将在最后五分钟，我会向您展示一些在访问内存时绊倒自己的方法。


发言人   01:12:49
Okay, so first is the classic scanf bug. You, you've probably all done this where you forget to pass it the address of a variable. Instead you pass at the address. So scanf doesn't know where to put put the. Put the data, okay? 
好的，首先是经典的scanf错误。你可能都做过这个，忘记传递一个变量的地址。相反，您通过地址。所以scanf不知道把它放在哪里。把数据放进去，好吗？

发言人   01:13:09
Another common mistake is to read uninitialized. So you can't really assume that your heap data is initialized to 0. So here we're malloc in an array of nins, and then we're going through and we're doing, we're updating this vector, this y vector, we're reading yi, we're taking y, it's y I equal y I plus aij times xj. So we're, we're assuming that y, the malloc returns memory, that's all zeros. So that'll get you. 
另一个常见错误是读取未初始化。所以你不能真的假设你的堆数据初始化为0。所以这里我们是nins数组中的malloc，然后我们正在进行，我们正在更新这个向量，这个y向量，我们正在阅读yi，我们正在获取y，它是y I等于y I加上aj乘以xj。所以我们，我们假设y，malloc返回内存，那都是零。这样你就可以了。




发言人   01:13:47
It's also easy to allocate the wrong sized object. So here we want to create an array of n point of n pointers to ints. And then for each one, we want to allocate m ins. So we're creating a two dimensional array. And can you see the mistake which? Which line is buggy? This one? 
也很容易分配错误大小的对象。所以在这里，我们想要创建一个由n个指向整数的指针组成的数组。然后对于每一个，我们想要分配m个。所以我们正在创建一个二维数组。你看到错误了吗？哪条线有bug？这一个？

发言人   01:14:22
This one or this one? The first one, because we really want size of n star. So we're incorrectly assuming that ints are the same sizes as pointers is a. This assumption is true for 32 b code ints and pointers of the same size, but it's not true for 64 b. And so this is why when you when people port 32 b code to a 64 b machine, a lot of times it breaks because they have this assumption. 
这一个还是这一个？第一个，因为我们真的想要n颗星的大小。所以我们错误地假设int和指针的大小相同。这个假设对于相同大小的32 b代码指针是正确的，但对于64 b则不是。所以这就是为什么当人们将32 b代码移植到64 b机器时，很多时候它会中断，因为他们有这个假设。


发言人   01:14:55
OK, another way, it's easy to overwrite memory. So here, we're correctly creating this array. But then when we create each of the each of the subarrays, instead of I less than or equal to n were actually, we only created n of these things, but we're traversing n plus one because of this less than or equal. So this is a classic off by one bug. 
好的，另一种方式，很容易覆盖内存。所以在这里，我们正确地创建了这个数组。但是当我们创建每个子数组时，我们实际上不是I小于或等于n，而是只创建了其中的n个，但是我们正在遍历n加一，因为这个小于或等于。所以这是一个经典的一个错误。

发言人   01:15:21
Okay, another problem you thought with the code injection attacks from your attack lab, not checking the size of a buffer. So get S is a classic example of this. So that'll get you into trouble. 
好的，您考虑的另一个问题是来自攻击实验室的代码注入攻击，而不是检查缓冲区的大小。所以get S就是一个典型的例子。这样会给你带来麻烦。


发言人   01:15:36
Another classic mistake is misunderstanding pointer arithmetic. So if you increment a pointer. Then it's incremented by the size of the object that pointer points to. So if you increment an int star by one, it actually increments it by 4 because that's the size of an n? That's a really important distinction. And so people will often. So here it's assuming that incoming, so p is a pointer. And the programmer here assumed that he wants to increment the pointer to sort of traverse an array. So he doesn't understand point arithmetic. And so to get to the next in increments p by size event, this will really increment it by 16, not by four. 
另一个经典错误是误解了指针算术。所以如果你递增一个指针。然后按指针指向的对象的大小递增。所以，如果你把一个int星号增加一，它实际上会增加4，因为那是一个n的大小？这是一个非常重要的区别。所以人们会经常这样。所以这里假设输入，所以p是一个指针。这里的程序员假设他想递增指针以遍历数组。所以他不懂点算术。因此，为了以递增的方式到达下一个事件，这实际上会将其递增16，而不是4。

发言人   01:16:32
Okay, overriding memory, that's a really nasty one. And a lot of times this can happen if you don't understand the precedence of the of the operators that you're working with. 
好吧，覆盖记忆，这是一个非常讨厌的问题。如果您不了解正在使用的运算符的优先级，很多时候可能会发生这种情况。


发言人   01:16:45
So this is a heap, not the kind of heap we've been talking about, but the heap data structure. And this is a function to delete from a heap. And this actually is from my own code, I have to admit. And so I want to delete an element. I want to delete the first element of the heap, and then I want to reheat by it. So, and I want to, I want to return that. So I get the first element of the heap, I decrease the size of the heap, I take the last element and make that the first element. And now I want to decrease the size of the heap. This delete operation will delete the heap size by one. 
所以这是一个堆，不是我们一直在谈论的那种堆，而是堆数据结构。这是一个从堆中删除的函数。这实际上是我自己的代码，我不得不承认。所以我想删除一个元素。我想删除堆的第一个元素，然后我想通过它重新加热。所以，我想要还那个。所以我得到了堆的第一个元素，我减小了堆的大小，我取最后一个元素并使其成为第一个元素。现在我想减小堆的大小。此删除操作将删除堆大小一。


发言人   01:17:35
So notice here we pass size in as a pointer. And when this function returns, size should be updated. Size is a pointer, the value that it points to should be decremented, that's our intent, And we do it right here with the size minus minus star. So what we want to do is we want to dereference size and then decrement that value. But because the unary minus minus has higher precedence than the dereference, what we're really doing is we're decrementing the pointer and then dereferencing the value that's one word less than our size variable, all right, so these are nasty. And it would have been much cleaner if I had just put parentheses around like I intended, just parentheses, star size, parentheses. 
所以请注意，这里我们将大小作为指针传递。当此函数返回时，大小应该更新。Size是一个指针，它指向的值应该递减，这就是我们的目的，我们在这里用size减去star来执行。所以我们想要做的是取消引用大小，然后减少该值。但是因为一元减号的优先级高于取消引用，所以我们真正做的是减少指针，然后取消引用比我们的大小变量小一个词的值，好吧，所以这些很讨厌。如果我只是像我想要的那样加上括号，那就更干净了，只有括号，星形大小，括号。


发言人   01:18:33
Another way you can mess up is referencing forgetting. The local variables disappear. So if you have a function that returns an address of a local variable, no good, no good at all. It might be okay for a while until somebody, another function reuses that space. That could be a return address, it could be another function's local variable. 
另一种可能会搞砸的方式是提及遗忘。局部变量消失。所以，如果你有一个函数返回一个局部变量的地址，那就不好，一点也不好。可能暂时可以，直到有人，另一个函数重新使用那个空间。这可能是返回地址，也可能是另一个函数的局部变量。


发言人   01:18:59
Another terrible mistake, this is a really bad one, is freeing a block multiple times. Now, you know, from your understanding now of Malick, that's free, actually writes to the heap, it's coalescing, it's changing pointers, it's changing size, block sizes. So if you free a block that's already been freed, terrible things will happen. 
另一个可怕的错误，这是一个非常糟糕的错误，就是多次释放一个区块。现在，你知道，根据你现在对Malick的理解，它是免费的，实际上是写入堆，它正在合并，它正在改变指针，它正在改变大小，块大小。所以如果你释放一个已经被释放的块，可怕的事情就会发生。


发言人   01:19:22
Another thing you can do wrong is to reference a block. You forget that you freed a block, and then you reference it. So here we free this block x, and then we're referencing it here. Another big problem is memory leak, So failing to free block, so allocating some block in a function and then returning that block will stay there forever, right? Because it's garbage. So there's a number of ways to deal with memory bugs. 
你可能会做错的另一件事是引用一个块。你忘记了释放了一个块，然后引用了它。所以我们在这里释放这个块x，然后我们在这里引用它。另一个大问题是内存泄漏，因此无法释放块，因此在函数中分配一些块，然后返回该块将永远留在那里，对吗？因为它是垃圾。所以有很多方法可以处理内存错误。



发言人   01:19:52
Gdb is sometimes good, at least it'll tell you where a seg fault occurs. Then you've got to track down what the right sort of caused that seg fault, the best thing you can do, but gddp falls down whenever you're doing manipulation of complex data structures. It's just simple sort of looking one instruction at a time. 
Gdb有时候很好，至少它会告诉你哪里发生了seg错误。那么你必须追踪导致该seg故障的正确类型，这是你能做的最好的事情，但是每当你进行复杂数据结构的操作时，gddp都会崩溃。这只是一次查看一个指令的简单方式。

发言人   01:20:14
What you really need to do is identify for any complex data structure, like a heap, for example, is identify invariance for that structure, that that data structure should always maintain, and then you write a function that iterates over that structure, that data structure and checks that all those invariants are true. So for example, in an allocator, one of the invariances is that there should be no, there should never be two contiguous free blocks. So your consistency checker should go through the heap and make sure there's no no contiguous free blocks, or another invariant is that every free block should be in a free list somewhere, so your consistency checker would scan the heap, count the number of free blocks, and then scan the free list and make sure that the number of blocks in the free list is the same as the number of free blocks. So this idea of a consistency checker is something you'll use in your Mali lab, but it's also something you should use whenever you're updating any kind of complex data structure. 
你真正需要做的是为任何复杂的数据结构 (例如堆) 识别不变性，即该数据结构应该始终维护，然后编写一个函数来迭代该结构，该数据结构并检查所有这些不变量是否为真。因此，例如，在一个分配器中，一个不变性是不应该有，永远不应该有两个连续的空闲块。所以你的一致性检查器应该检查堆并确保没有连续的空闲块，或者另一个不变量是每个空闲块应该在某个空闲列表中，所以你的一致性检查器将扫描堆，计算空闲块的数量，,然后扫描空闲列表，确保空闲列表中的块数与空闲块数相同。所以一致性检查器的想法是你将在你的实验室中使用的，但它也是你在更新任何复杂数据结构时应该使用的东西。


发言人   01:21:21
And you know about valgrand. But the great thing about these heap checkers I'm passionate about heap checkers or consistency checkers. The really powerful thing about them is you write them to run silently. They don't print anything unless they find it a violation of the invariance. If you write your consistency checker like this, then you can use it like a probe. 
你知道瓦尔格朗。但是这些堆检测器的伟大之处在于，我对堆检测器或一致性检测器充满热情。它们真正强大的地方在于，你将它们编写为默默地运行。他们不会打印任何东西，除非他们发现它违反了不变性。如果你像这样编写一致性检查器，那么你可以像探针一样使用它。

发言人   01:21:45
So your program crashes. So you use this heap checker to do a binary search to isolate the cause. You put your heap checker here, everything's OK, and then later the program crashes. So now you stick the heap checker here, and now it the heap checker detects violation, so you know that the problem is somewhere here and you can just keep narrowing it down. So it's just like a probe, surgical probe that you can use to track down bugs. So if you do this, I don't know how anybody debugs Mali without this kind of tool. Okay, so that's it for today. Have a good weekend. We'll see you on Tuesday. 
所以你的程序崩溃了。因此，您可以使用此堆检查器进行二进制搜索以找出原因。你把你的堆检测器放在这里，一切都正常，然后后来程序崩溃了。所以现在你把堆检查器放在这里，现在堆检查器检测到违规，所以你知道问题在这里的某个地方，你可以不断缩小范围。所以它就像一个探针，外科手术的探针，你可以用它来追踪虫子。所以如果你这样做，我不知道没有这种工具如何调试Mali。好的，今天就到这里。周末愉快。我们将在周二见到你。

