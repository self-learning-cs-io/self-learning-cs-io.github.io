---
title: 操作系统工程 009-Multiprocessors and Locks
date: 2025-10-18 10:00:09
---


发言人   00:07
Good, how about Erica? How was the La of luck for you? I also thought it was okay, and I also had a bug with the copy and copy out, but got that result. So yeah. Yeah, I think it's one of the tricky things you think you might not think about when you start programming, but luckily user test will find it for you. 
很好，埃里卡怎么样？你的运气怎么样？我也认为这没问题，而且我在复制和复制方面也有一个错误，但得到了那个结果。所以是的。是的，我认为这是你开始编程时可能不会想到的棘手问题之一，但幸运的是，用户测试会为你找到它。

发言人   00:34
Caroline, the love is going good. I haven't finished yet actually. All so worry about copying, I guess most. 
卡罗琳，爱情会好起来的。实际上我还没有完成。大家都很担心抄袭，我想是最担心的。

发言人   00:52
But Kendall Garner? I think for the most part. Not too bad for me, probably that we were just probably just trying to figure out when it went below bounds of the stack. Into the guard page, basically. Good, okay. Well, so it's about time to get started. 
但是肯德尔·加纳？我认为大部分。对我来说还不错，可能我们只是想弄清楚它什么时候低于堆栈的边界。进入守卫页面，基本上。好的，好的。那么，是时候开始了。

发言人   01:23
So welcome to the next lecture in So 8, 1, wherever you are in whatever time zone. So today's lecture is but locked and you probably have seen walks in previous classes or at least been in touch with them in some way or another. 
欢迎来到8、1节的下一节课，无论你在哪个时区。所以今天的讲座是锁着的，你可能在以前的课堂上看到过散步，或者至少以某种方式与他们保持联系。

发言人   01:42
This lecture is a little bit of a conceptual lecture, may overlap a little bit with some things you've seen before for locks, but will have a little bit more of a kernel and OS focus. And that changes a couple things. So just to get started, you know, let's just remind ourselves, why we need locks, you know? And I guess the starting point is really that applications want to use multiple cores. And they want to use multiple cores to get performance. And so if an application actually. Want runs a multiple courses and presumably it wants this course or the parts of the application may invoke system calls, and so the kernel must be able to handle. 
这个讲座有点概念性，可能与你之前见过的一些关于锁的东西有些重叠，但会有更多的内核和操作系统的关注。这改变了几件事情。所以就开始吧，你知道的，让我们提醒自己，为什么我们需要锁，你知道吗？我猜起点实际上是应用程序想要使用多个内核。他们希望使用多个内核来获得性能。因此，如果实际应用程序。想要运行多个课程，大概它想要这个课程或应用程序的某些部分可能会调用系统调用，因此内核必须能够处理。

发言人   02:31
Handle parallel system calls. 
处理并行系统调用。

发言人   02:45
And that means that, you know, if sort of the system calls run in parallel on different courses, they may actually access shared data structures. The instructions in parallel. 
这意味着，你知道，如果一些系统调用在不同的课程上并行运行，它们实际上可能会访问共享的数据结构。指令并行。

发言人   03:04
And as you've seen by now, actually x-fi 6 has quite a number of shared data structures, whether it's the proc structures or, you know, ticks or, you know, you know, later we'll see the buffer CA, you know, there's actually a ton of shared data structures. And so if you have para lexis, you know, through a data structure in one of the, of course, there's a writer and the other course's a reader, you know, we basically locks to coordinate these updates through the shared data structure so that readers see ecosystem view. So we need locks, you know, if for controlled sharing or for correct sharing. 
正如你现在看到的，实际上x-fi 6有相当多的共享数据结构，无论是proc结构还是ticks，或者你知道的，你知道的，稍后我们会看到buffer CA，你知道的。实际上有吨共享的数据结构。因此，如果您通过其中一个数据结构拥有准词汇，当然，有一个作者和另一个课程的读者，您知道，我们基本上通过共享数据结构锁定以协调这些最新进展，以便读者看到生态系统视图。所以我们需要锁，你知道的，如果是为了受控共享或正确共享。

发言人   03:53
Now, this is in some sense, a little bit of a bummer because we want this parallel AIS. We want to run multiple system calls in parallel on a different courses. But unfortunately, if they show the data structures, the unique locks and locks, no serial lice, basically operations. And so in fact, locks in the end can limit performance. 
现在，这在某种感知上有点令人不行了，因为我们想要这个并行的AIS。我们希望在不同的课程上并行运行多个系统调用。但不幸的是，如果它们显示数据结构，独特的锁和锁，没有串行虱子，基本上就是操作。事实上，最终的锁可能会限制性能。

发言人   04:27
And so we're sort of in a tricky situation where now for correctness, we need locks, but for performance, they're not good. But there's going to be sort of a fact of life, and we'll see what can do about it. But that's sort of the top level scenario here. And you maybe just to really, you know, brings point to it. 
所以我们处于一个棘手的情况下，现在为了正确性，我们需要锁，但为了性能，它们并不好。但这将是一种生活现实，我们将看看能做些什么。但这在这里算是顶级场景。也许你只是为了真正地，你知道的，指向它。

发言人   04:48
Why do applications actually want to multiple course? And that really has to do with you technology trends, you know, over the last couple decades. And, you know, there's sort of this classic graph that sort of make these points. So let me, you pull up one of them, there's a little bit of a complicated graph, you know, there's years on the X axis and y axis, there's units, there are different types of units depending on which line we're looking at. But the thing that really to look at it is that what has happened in the last couple of years, just over the last decade, is that so starting in the 2000, that the clock frequency hasn't really increased anymore. So basically, this has plateaued or constant. And as a result, you know, basically single threat performance, of course, also basically has reached sort of a limit or plateau. 
为什么应用程序实际上想要多个课程？这真的与你的技术趋势有关，你知道，在过去的几十年里。而且，你知道，有一种经典的图表来阐述这些观点。所以让我，你拿出其中一个，有一个有点复杂的图表，你知道，在x轴和y轴上有年份，有单位，根据我们看的是哪条线，有不同类型的单位。但真正值得关注的是，在过去的几年里，就在过去的十年里，从2000年开始，时钟频率并没有真正增加。所以基本上，这已经达到了平台级或恒定不变。因此，你知道，基本上单一的威胁表现，当然也基本上达到了某种极限或稳定状态。


发言人   05:52
And yet, on the other hand, number, of course, or the number resistor should still be increasing over the same time period. So if you can like, you know, use statistics to make a single course or run faster, you, the only other option basically have to have multiple courses. And you see indeed, that sort of starting from 2001 or from the early 2000s, you know, the number, of course, has gone up. And so there's an application once more, Performance, you know, you know, can rely on a single core. It basically has to explode multiple cores. And also this means if an application is, you know, kernel intensive OS and intensive, you know, where it's like a server, then that means that the operating system also has to be run efficiently on multiple cores. And so that's the main reason, you know, that we're sort of very interested in, you know, parallelism within the kernel. Any questions about this? 
然而，另一方面，电阻器的数量，当然，在同一时间段内仍然应该增加。所以，如果你可以使用统计来制作单个课程或跑得更快，你唯一的其他选择基本上必须有多个课程。而且你确实可以看到，从2001年或者2000年代初开始，这个数字当然是上升的。所以有一个应用程序，性能，你知道，你知道，可以依赖于单核。它基本上必须爆炸多个核心。这也意味着，如果一个应用程序是内核密集型操作系统，就像一个服务器，那么这意味着操作系统也必须在多核上高效地运行。这就是主要原因，你知道，我们对内核中的并行非常感兴趣。对此有什么问题吗？

发言人   06:52
Okay, I assume that you've seen some of these graphs before, but it's good to remind us what the starting point of all the discussion is. So white locks, you know, already hinted at this. They therefore, for correctness, if we have readers and writers know Xing data structure, the thing that goes wrong is we want to avoid race conditions. 
好的，我假设你之前已经看过这些图表，但是提醒我们所有讨论的起点是什么是很好的。所以白色的锁，你知道，已经暗示了这一点。因此，为了正确性，如果我们有读者和作者知道数据结构，那么出现问题的原因是我们希望避免竞争条件。

发言人   07:23
So if you don't have logs, you know, we run the risk. You know, if we have shared data structures that we're going to have. We're going to have raised conditions. And it turns out that the race conditions are pretty annoying. And so just first, we got a little bit of sense of what it actually is. Let's look at the let's create a race condition in XV 6 and then sort of see how it actually shows up and then understand like like what actually happened? So here's our function k 3 in CA DOC you. So this is the function 3. 
所以如果你没有日志，你知道，我们就会冒这个风险。你知道，如果我们有我们将要拥有的共享数据结构。我们将提高条件。事实证明，竞争条件非常烦人。所以首先，我们对它究竟是什么有了一点感知。让我们来看看让我们在XV 6中创建一个竞争条件，然后看看它实际上是如何出现的，然后理解像实际发生了什么？这是我们在CA DOC中的函数k 3。这就是函数3。


发言人   08:00
After you free your page, it puts it on the free list. The kernel has a very simple data structure to keep the free list of all three pages so that one count meet a page that actually can grab it from the feedelity and see here. Allocation has one. The memory allocator has one lock Km lock. And here it actually updates the three list with the page that just has been read or the argument to read. So we're going to do is like just comment out these two squiring releases that basically mark the acquiring of the lock and then releasing the lock and this piece of code that sits in the middle that used to be is not being executed anymore anatomically. 
释放页面后，它会将其放在免费列表中。内核有一个非常简单的数据结构，可以保持所有三个页面的空闲列表，以便一个计数符合一个实际上可以从feedelity中获取它的页面，并在这里看到。分配有一个。内存分配器有一个锁定Km锁。这里实际上最新进展了三个列表，其中包含刚刚读取的页面或要读取的参数。所以我们要做的就是注释掉这两个squiring版本，这基本上标志着锁的获取，然后释放锁，这段位于中间的代码不再执行解剖学上的操作。

发言人   08:54
So let's. Do that and let me run. In q.u., so we'll compile it. And, you know, before I run it, and I noticed actually, we're already booted. And actually, presumably we have made some calls probably to K 3 as you probably, as you know. And so actually things seem to be working fine. So let's run user test. 
所以让我们。这样做，让我跑。在q.u.中，所以我们将编译它。而且，你知道，在我运行它之前，我注意到实际上，我们已经启动了。实际上，正如你所知道的，我们可能已经给K3打了一些电话。事实上，事情似乎运作良好。所以让我们运行用户测试。


发言人   09:20
Maybe it's interesting to think a little bit about this, What do you expect? Will this work? Will this not work? Anybody who tried it out? I think it could potentially lose some pages, but maybe it will not because maybe a race condition wouldn't occur. Yeah, so one of the things is that we're condition here. They might not happen. So let's run the user test and see actually what happens. 
也许思考一下这个问题很有趣，你还能期待什么？这会起作用吗？这会不起作用吗？有人试过吗？我认为它可能会丢失一些页面，但可能不会，因为可能不会发生竞争条件。是的，所以其中一件事是我们在这里有条件。它们可能不会发生。所以让我们运行用户测试，看看实际上会发生什么。


发言人   09:50
So here we started up taking a little while. Zoom might complain a little bit because running a lot of put a lot of load on my machine here, correct? If you probably know the q.u. simulating 3 cores here, and the screen cores might run in parallel. And so far, so good, You know, we're starting to pass tests. 
所以我们开始花一点时间。Zoom可能会抱怨一点，因为在这里运行很多会给我的机器带来很多负载，对吗？如果你可能知道q.u. 在这里模拟3个核心，屏幕核心可能并行运行。到目前为止，很好，你知道的，我们开始通过测试了。


发言人   10:21
That have a little bit slower because I'm running Zoom at the same time. Let's wait a couple more and just see what's going on. 
它稍微慢一些，因为我同时运行Zoom。让我们再等几个，看看发生了什么。

发言人   10:43
Okay, well, let's just go back to the slides, and then we'll check back in a little while and sort of see what actually happens. But you, as pointed out, these race conditions may appear or may not appear, right? Because it's always the case that every core or every time we call K 3, these two u lines are executed atomically, as they would have done. We have to lock. Then there's no problem. And the only problem is like if 2 frets of two processes executed at the same time, and so becomes in between. 
好的，那我们就回到幻灯片上，过一会儿我们再检查一下，看看实际发生了什么。但是，正如所指出的，这些竞争条件可能会出现，也可能不会出现，对吗？因为每个核心或每次我们调用k3时，这两行都是原子式执行的，就像它们本来应该做的那样。我们必须锁门。那就没问题了。唯一的问题就像两个过程中的2个烦恼同时执行，因此介于两者之间。



发言人   11:17
And look at this, actually, you know, while I'm talking, you know, we see actually there is a panic and so there's some race condition that can actually cause a panic. There are other race conditions that will show up as indeed, as mentioned or as we mentioned, that will show up as not enough. Some free pages or some pages get lost. So basically us test runs fine until the very end, but complaints saying, well, you lost some pages during all of the runs of us test, okay? So these race conditions can show up in different ways. They may happen, they may not happen. Clearly something happened here. So let's try to understand actually what goes wrong. 
看看这个，实际上，你知道，当我说话的时候，我们看到实际上有一种恐慌，所以有些种族条件实际上可能导致恐慌。还有其他竞争条件将会出现，就像我们之前提到的那样，或者正如我们之前提到的那样，它们将会表现得不够充分。一些免费页面或一些页面丢失。所以基本上我们的测试运行得很好，直到最后，但抱怨说，在我们所有的测试运行中你丢失了一些页面，好吗？因此，这些竞争条件可以以不同的方式出现。它们可能发生，也可能不会发生。显然这里发生了什么事。所以让我们试着理解到底出了什么问题。

发言人   12:01
Back to the lights. So the picture you should have in your head, like I said, there's this multiple cores that we're running. So here CPU is 0. So CPU 0 is executing instructions and CPU 1 is executing instructions, and they're both connected to a memory. 
回到灯光下。所以你应该在你的脑海中有一张图片，就像我说的，我们正在运行这个多核。所以这里的CPU是0。因此，CPU 0正在执行指令，CPU 1正在执行指令，并且它们都连接到内存。


发言人   12:25
If you like the back, think back up at the sche schematics that we shown a couple of times before effect. There's a DRAM controller, you know, that actually connects, you know, to the DRAM chips where all the stage is living or all the memory is living. I'm going to make that memory a little bit bigger because I want to. Have some place to draw. And so basically our tree list, you know, lives in. In memory. And let's say there's a freedom list with two pages on it. And. You know, both. Cpu's going call K 3 roughly at the same time. 
如果您喜欢背面，请回想一下我们在效果之前展示过几次的sche原理图。有一个DRAM控制器，你知道，它实际上连接到所有舞台或所有内存都活着的DRAM芯片。我要把那个记忆放大一点，因为我想这样做。有地方可以画画。所以基本上我们的树形列表，你知道，生活在。在记忆中。假设有一个有两页的自由清单。而且。你知道的，两者都有。Cpu大致同时呼叫K 3。

发言人   13:13
And so look at a little bit of the code again, just to make sure that we have to right in our head. So we look at K 3 get passed in some PA, a fiscal address that we're going to use to actually hook up into the free list. 
因此，再次查看一些代码，以确保我们必须在头脑中正确操作。所以我们看看K 3在某个PA中被传递，这是一个财政地址，我们将使用它来实际连接到免费列表中。


发言人   13:30
So you know CPU 0 has, you know, an R and that's pointing to some free page. Maybe, and CPU 1 has one, and we actually use another color for CPU 1. So if you all know is asking R, also it's pointing to some page, you know, that we want to hook into the free list, makes sense? 
所以你知道CPU 0有一个R，指向一些免费页面。也许，CPU 1有一个，我们实际上为CPU 1使用另一种颜色。所以，如果你们都知道是在问R，它也指向某个页面，你知道，我们想挂钩到免费列表中，感知？

发言人   13:59
And so, you know, we look back at the code, you know, the first thing they do is to update Rx to point to the free list. So let's assume that that CPU 1 runs first. What it will do is will put its pointer to the beginning of the, you know, wherever feed list is pointing to. And if, you know, CPR runs exactly at the same time then. It could run before CPU 0 executes a second instruction. And so it actually might do the same thing, you know, might actually also run that first instruction and update. 
所以，你知道，我们回头看代码，你知道，他们做的第一件事就是更新Rx以指向空闲列表。因此，让我们假设CPU 1首先运行。它要做的是将指针放在提要列表的开头，你知道的，无论提要列表指向哪里。如果你知道，CPR完全在同一时间运行。它可以在CPU 0执行第二条指令之前运行。所以它实际上可能会做同样的事情，你知道，实际上也可能运行第一个指令和更新。

发言人   14:51
And update the pointer 2. So now both are, you know, one from CPU 1 and from CPU 0, 1 from CPU 1 are pointing to the beginning of the feed list. And the feed list is also pointing to the beginning of the feed list. And so now there are two remaining instructions that are being executed in parallel. So we get back it again. You know the code. You know, the remaining instruction is being executed is actually updating the free list to point to R? And so, you know, you 0 and 1 going to execute these instructions maybe exactly in the same at roughly at the same time, but one is going to go first, correct? 
并更新指针2。所以现在两者都是，你知道，一个来自CPU 1，一个来自CPU 0，一个来自CPU 1，都指向源列表的开头。并且提要列表也指向提要列表的开头。因此，现在有两条剩余的指令正在并行执行。所以我们会再次回到它。你知道密码。你知道，剩下的指令正在执行，实际上是更新可用列表以指向R？所以，你知道，你0和1将在大致相同的时间执行这些指令，但其中一个将首先执行，对吗？

发言人   15:26
There's only one single Shi memory. And so one update is going to go first and the other one is going to go second. So let's say CPU 1 know goes first. And then what will then happen? Well, if CPO 1 goes first, the free list is going to be pointing to HR, right? And then CPU 2 runs. So now CPU 2 runs x, the x instruction. And so what it is going to do, it is going going to actually update a freel to point. 
只有一个单一的Shi记忆。因此，一个更新将首先进行，另一个更新将第二个更新。所以假设CPU 1知道先运行。然后会发生什么？好吧，如果CPO 1排在第一位，那么空闲列表将指向HR，对吗？然后CPU 2运行。现在CPU 2运行x，x指令。所以它要做的是，它将实际上更新一个点。

发言人   15:55
So here's our free list. And it actually is going to point to, are that actually have passed in. And so, you know, we have the setting now, correct, where we've lost, you know, basically one page, the R, you know, that actually CPU 0, actually three actually ended up not being on the free list at all. So we lost the pitch. And that one, you know, bad particular outcome. 
这是我们的免费名单。它实际上会指向那些实际上已经通过的。所以，你知道，我们现在有了设置，正确的，我们丢失了，你知道，基本上one page，那个实际上是CPU 0，实际上三个根本不在空闲列表中。所以我们输了球。而那个，你知道的，特别糟糕的结果。

发言人   16:25
Of course, there could be more bad outcomes because there could be more Cpu's actually trying to do the free list. They may observe, one of them may observe the three lists pointing temporarily to the CPU zeros are. And so we can start using that. Well, then immediately the free list is updated by the second CPU. The more is involved, you know, because we could actually get more bizarre outcomes than just the last page. Does this make sense? Any questions? 
当然，可能会有更多的坏结果，因为可能会有更多的Cpu实际尝试做免费列表。他们可能会观察到，其中一个可能会观察到三个临时指向CPU零的列表。所以我们可以开始使用它。那么，第二个CPU会立即更新空闲列表。涉及的越多，你知道的，因为我们实际上可以得到比最后一页更奇怪的结果。这有感知吗？有问题吗？

发言人   17:04
Okay, so do we, you ask? You know, the code does know the way to address this. One way in a very common way is to address this problem is to use a lock. So let me talk a little bit about locks in more detail. 
好的，你问我们呢？你知道，代码确实知道如何解决这个问题。一种非常常见的方法是使用锁来解决这个问题。所以让我更详细地谈谈锁。


发言人   17:26
So what is was the lock extraction? Well, it is just an object like any other sort of object in the kernel. Anything that has it. There's in fact, there's something called struct log that has some fields, you know, to maintain state about logs. And it has a pretty straightforward API. 
那么开锁是怎么回事？它只是一个对象，就像内核中的任何其他类型的对象一样。任何有它的东西。事实上，有一种叫做struct log的东西，它有一些字段，你知道的，用来维护日志的状态。它有一个非常简单的API。

发言人   17:49
You know, there's acquired, and in fact, there are only two calls go through this abstraction, which. Required, which takes the A pointer to a lock struck and a release. You know, that actually also takes a point of view to lock structures, to basically update the lock object. 
你知道，这是后天习得的，事实上，只有两个调用经过这个抽象。必需的，这需要一个指针指向锁定和释放。你知道，这实际上也需要从锁定结构的角度来更新锁定对象。

发言人   18:15
And basically the of the rule here is that. Choir. Forces the following rule that only one process. You know, can enter or can acquire the lock? So at any particular point in time, there's only going to be one process that is able to actually successfully acquire the lock And the other process, the visiting strain acquired a lock at the same time, has to wait until the first process actually calls the release. And so this sequence, the instructions between the choir and the lease or of a call to critical section. 
基本上这里的规则就是这样。合唱团。强制执行以下规则，即只有一个进程。你知道，可以进入或获得锁吗？因此，在任何特定时间点，只有一个进程能够成功获取锁，而另一个进程，即访问菌株同时获取锁，必须等到第一个进程实际调用释放。因此，这个序列，是合唱团和租约之间的指令，或者是对临界部分的呼叫的指令。

发言人   19:07
And one reason it's called the critical section is because this is sort of the fuse instruction together. To do, you need to do the update to our whatever shared data structure that's protected by the lock in an atomic fashion. And It insurers that basically you have multiple instructions in this, you know, between the car and release that they all are executed all together or N, and so there's never the case that basically these instructions in the critical section are interleaved as in the way that we saw in the race condition. And actually, exactly that is that what avoids these race conditions? Any questions about the lock obstruction? 
它被称为临界区的一个原因是，这是一种将指令融合在一起的方式。为此，您需要以原子方式更新由锁保护的任何共享数据结构。而且，保险公司基本上在汽车和发布之间有多个指令，它们全部一起执行，或者N，所以从来没有像我们在比赛条件中看到的那样基本上这些指令是交错的。实际上，这就是避免这些竞争条件的原因吗？有关于锁阻塞的问题吗？

发言人   19:55
Now, programs typically have. Menu locks and the fact minimum Xg 6 has manyu locks. And the reason to have many locks is because even the. 
现在，项目通常有。菜单锁和事实最小Xg 6具有manyu锁。拥有许多锁的原因是因为即使是。

发言人   20:13
Lock serializes the execution. Two processes know 1. Enter this critical section. Only one succeeds and the other one runs that critical section after the first one finishes. So there's no sort parallelism at all. 
锁序列化执行。两个过程知道1。进入这个关键部分。只有一个成功，另一个在第一个完成后运行关键部分。所以根本没有排序并行。

发言人   20:28
So if the kernel had only one lock, which is typically called the big kernel lock, then basically every system call in the kernel would be serialized. You would assist call 1 start gets the log, the big kernel lock does whatever it needs to do, and then releases the big kernel lock, and then basically returns use space, and then the second system called Theron. So we have a parallel application that runs once it runs system calls in parallel, suddenly, you know all the system poles actually run serially if we had only one lock. And so typically, a program like x 6 has, you know, manual locks because at least, you know, then we can get some parallelism. Because. If two system calls, for example, use two different blocks, then they can actually run completely in parallel without any sation, because they're basically using a different walk to serialize. 
因此，如果内核只有一个锁，通常被称为大内核锁，那么基本上内核中的每个系统调用都将被序列化。你将帮助调用1开始获取日志，大内核锁执行它需要做的任何操作，然后释放大内核锁，然后基本上返回使用空间，然后第二个系统称为Theron。所以我们有一个并行应用程序，一旦它并行运行系统调用，突然之间，你知道如果我们只有一个锁，所有的系统极点实际上都是串行运行的。通常，像x6这样的程序有手动锁定，因为至少这样我们可以得到一些并行处理。因为。例如，如果两个系统调用使用两个不同的块，那么它们实际上可以完全并行运行，没有任何位置，因为它们基本上是使用不同的行走来序列化。

发言人   21:30
Now there. Are sort of a couple of important points? Nobody really sort of enforces in this interface, you know, that you put in the acquirers and the losers, it's up to the program to do so. So if you want some particular piece of code to be atomic, then it's up to the developer to actually put these acquire releases it. And a clearly, as we'll see, and as you can imagine, and it's a little bit to it, can be tricky. And so it's important to realize that, you know, the locking is not actually done automatically for you. It's all up to the developer to figure out to associate locks with data structures and ensuring that the appropriate acquired leases are dead. 
现在那里。有几个要点吗？没有人真正在这个界面中强制执行，你知道，你把收购者和输家放在里面，这由程序来决定。因此，如果您希望某些特定的代码是原子的，那么由开发人员实际发布这些获取版本来决定。而且，正如我们将要看到的，正如你可以想象的那样，这有点棘手。因此，重要的是要意识到，你知道，锁定实际上并不是自动为你完成的。这完全由开发人员决定如何将锁与数据结构关联，并确保适当的获取租约已经失效。

发言人   22:23
So clearly ISS the case, the walk's limit in parallelism and therefore limit performance. And so then this raises the question when to lock? 
所以显然是这种情况，并行行走的限制因此限制了性能。那么这就提出了何时锁定的问题？

发言人   22:42
And you know I'm going to give you sort of a very conservative rule, but that's a good one as a starting point to think about things. So the conservative rule. Or maybe guideline is a better phrasing is that you two processes? Two processes access shared data structure. 
你知道我会给你一个非常保守的规则，但这是一个很好的起点。所以保守规则。或者指导方针是更好的措辞，是你们两个过程吗？两个进程访问共享数据结构。

发言人   23:17
And one is A, and one of them is a writer or an updater, meaning it's going to modify the shared data structure. Then you need a lock for that data structure. 
一个是，其中一个是写入器或更新器，意味着它将修改共享数据结构。那么你需要一个针对该数据结构的锁。

发言人   23:39
So this is a conservative rule, you know, sort of like a red flag when you're programming and you have a data structure that is accessed by multiple processes. And one can be a writer. At that point, you should be thinking, okay, there's a possibility of a race condition. You want to avoid this. In a race condition, you stick it a lock. We'll a lock guaranteed that this race nation can't happen. But the rule some way too strict. There are cases where it's okay, 3 processes access a shared data structure, and one is a writer. In particular, there are sort of styles of programming called block free programming that actually totally where these kinds of scenarios actually do happen. 
所以这是一个保守的规则，你知道，就像一个红旗，当你编程时，你有一个被多个进程访问的数据结构。一个人可以成为作家。在那个时候，你应该思考一下，好吧，存在竞争条件的可能性。你想避免这种情况。在竞争条件下，你把它锁起来。我们将确保这个种族国家不会发生。但是规则在某种程度上过于严格。在某些情况下，可以有三个进程访问共享数据结构，其中一个进程是写入程序。特别是，有一些被称为无块编程的编程风格，实际上完全发生了这些场景。

发言人   24:32
Anyway you want to do lock free programming is basically to get better performance or more parallelism. Lock free program is tricky, even more tricky than programming with locks. And you know, we'll talk about it at the end of the semester. 
无论如何，你想要进行无锁编程基本上是为了获得更好的性能或更多的并行性。无锁定程序很棘手，甚至比使用锁定编程更加棘手。你知道的，我们会在学期结束时谈论它。

发言人   24:46
We'll study some lock free styles of programming, particularly are common in operating system kernels. But basically for this lecture and most of the rest of the semester, we're going to do some thinking about the case. 
我们将研究一些无锁的编程风格，特别是在操作系统内核中常见的风格。但基本上，在这堂课和本学期剩下的大部分时间里，我们将对这个案例进行一些思考。

发言人   25:00
We, using locks, know to control sharing. And that is hard enough. You know, just using locks is not that straightforward EER. So it in one hand a little bit too strict because it's not always the case that, you know, in some cases too loose. You might just. You might even want to lose. You want to actually maybe want to use locks you to enforce some other properties, like you look at print diff. 
我们使用锁，知道如何控制共享。这已经够难的了。你知道，仅仅使用锁并不是那么简单。所以单手有点太严格了，因为情况并不总是如此，你知道，在某些情况下过于宽松。你可能只是。你甚至可能想要失去。你可能想要使用锁来强制执行一些其他属性，就像你查看print diff一样。

发言人   25:35
If we pass a string to PF, the X 6 kernel tries to at least get the whole string to be printed atomically and know there's no shared data stru in involved. But it's still useful to actually use a lock in that particular case because we want the output to be serialized. So this rule is not perfect, but it's a pretty good guidelines. Any questions about this rule? 
如果我们将一个字符串传递给PF，x6内核会尝试至少以原子方式打印整个字符串，并知道其中没有涉及共享数据结构。但是在这种特定情况下实际使用锁仍然很有用，因为我们希望输出被序列化。所以这个规则并不完美，但它是一个相当好的指导方针。对这个规则有什么问题吗？

发言人   26:04
I had a question not about this rule, but isn't it possible that two processes could acquire the lock at the same time? Would be able to modify the structure? Yeah, no, so. So part of the sort of contract the walk structure is, is that it's impossible to do pro to require a walk at the same time, if the rule is that ever there, No, there's never a case where two proxies actually acquire the lock, can hold the lock at the same time. We'll see in a second how do we implement that. But the API or the specification for require is there's only one walk holder at any given point in time or 0. 
我有一个问题不是关于这个规则，但是难道两个进程不能同时获取锁吗？能够修改结构吗？是的，不，那么。所以行走结构的一部分合同是，如果规则是，永远不会有两个代理实际获取锁的情况，那么就不可能要求同时行走。可以同时把锁打开。我们马上就会看到我们如何实现这一点。但是API或需求的规范是在任何给定的时间点只有一个行走持有者或0。


发言人   26:50
Okay, so you if we see the programming lock. Is problematic because of these race conditions? Now, of course, the particular race condition that we looked at in K 3 or that we created in Cray, you should look easily spotted in some ways. And the fact you, if you use a race detection tool, it would immediately find it. But they're more tricky cases. And so you may want wonder like, why couldn't like make, you know, you make locks or Google make locking automatic? 
好的，如果我们看到编程锁。由于这些竞争条件，有问题吗？当然，现在，我们在k3中看到的特定竞争条件或者我们在Cray中创建的特定竞争条件，在某些方面应该很容易被发现。而且事实上，如果你使用种族检测工具，它会立即找到它。但它们是更棘手的案件。所以你可能想知道，为什么不能像制作锁或谷歌自动锁定呢？

发言人   27:31
So like if you follow this sort of simple rule that I just stated, you know, then if we see shared data structure, then you know, operations and that shared data structure basically should require a walk. We should, we should associate a walk with the data structure and then every operation that actually. That is, that is performed on the. That data structure basically acquires or releases the lock. So one way to think about it may be in actually six terms, like every struct you know has a lock. And in that lock is automatically acquired when we do anything related to that struct. And this turns out to be too rigid. And this is why, you know, walking can not really be automatic. 
所以，如果你遵循我刚才说的这种简单规则，那么如果我们看到共享数据结构，那么你就知道，操作和共享数据结构基本上需要散步。我们应该，我们应该将步行与数据结构以及实际的每个操作相关联。也就是说，这是在执行的。该数据结构基本上获取或释放锁。因此，一种思考它的方式实际上可能有六个术语，就像你知道的每个结构都有一个锁。当我们执行与该结构相关的任何操作时，会自动获取该锁。结果证明这太僵硬了。这就是为什么走路不能真正自动的原因。

发言人   28:17
And so, so we've been operating systems. An example from an operating system is defaul let's say we have a call like rename that, move a file name from one directory to another directory. So let's say we have D1 x, and we rename it to D2 y. So we have a file name in the directory D1 x, and we rename it to D2 slash one. So the way, presumably, if we follow the rigid rule or like this rule of automatic walking, what would happen is, you know that rule. 
所以，我们一直在操作系统。一个来自操作系统的例子是defaul，假设我们有一个像重命名这样的调用，将文件名从一个目录移动到另一个目录。所以假设我们有D1 x，我们将其重命名为d2y。所以我们在目录D1 x中有一个文件名，我们将其重命名为D2斜杠1。所以，大概的方式是，如果我们遵循严格的规则或类似自动行走的规则，会发生什么，你知道这个规则。

发言人   28:55
And we have two objects. We have D1 and D2, right? And so we follow the rule, then basically the automatic rule, then we lock D1. You know, erase X? And it release the lock 4 D1. And then, you know, we do the second part update, you know, D2, lock D2 at y and release. D2? And then we're done. So this would be the sort of hypothetical scheme sort of you imagine would happen if we did automatic walking. And the point of this example is that we'll have the wrong outcome. And why is this a problematic scheme? Why is this not going to work? 
我们有两个物体。我们有D1和D2，对吧？所以我们遵循规则，然后基本上是自动规则，然后我们锁定d1。你知道吗，删除X？它会释放4 d1锁。然后，你知道，我们进行第二部分更新，你知道，D2，在y处锁定D2并释放。D2?然后我们就完成了。所以这将是一种假设方案，你可以想象如果我们进行自动行走会发生。这个例子的重点是我们将得到错误的结果。为什么这是一个有问题的计划？为什么这不会起作用？

发言人   30:03
So about the thing to think about is like this period. So we have done the first step, step 1, but not done step 2 yet. What could another process observe? 
所以，要思考的事情就像这个时期一样。所以我们已经完成了第一步，第一步，但还没有完成第二步。另一个过程可以观察到什么？

发言人   30:24
Anybody? The file would just be gone, yeah. Yeah, this there's between step 1 and 2. The file doesn't exist. 
有人吗？这个文件就会消失，是的。是的，这是在步骤1和2之间。该文件不存在。

发言人   30:41
And that is clearly wrong because the file does exist and just being renamed. And at every point in time, really, that it didn't exist. But by implementing it is in this way, it just appears that the file might actually not exist, even though it does. And so the real rate solution to this is what we need. And that we actually lock D1. And D2 first at the beginning of rename, then erase an F? And then release the locks for D1 and D2. Still makes sense. 
这显然是错误的，因为该文件确实存在，只是被重命名了。而且在每一个时间点，实际上，它并不存在。但是通过以这种方式实现它，它只是看起来该文件实际上可能不存在，即使它确实存在。因此，真正的利率解决方案就是我们所需要的。我们实际上锁定了d1。首先在重命名的开头使用D2，然后删除一个F？然后释放D1和d2的锁。仍然制造感知。

发言人   31:26
So here's example where we have an operation that regard needs multiple locks, and the locks can not really be associated with the two objects that are the arguments of this operation. It has to be decays that actually the operation itself first requires for both blocks, then performs the operations. And so there's automatic locking is not sort of directly possible. 
所以这里的例子中，我们有一个需要多个锁的操作，并且锁不能真正与作为此操作参数的两个对象相关联。它必须是衰减，实际上操作本身首先需要两个块，然后执行操作。因此，自动锁定并不是直接可能的。

发言人   31:51
There's going to be cases where is not because run or just naive scheme at least will run into problems. Any questions about this? 
会有一些情况，其中不是因为运行或仅仅是幼稚的计划至少会遇到问题。对此有什么问题吗？

发言人   32:06
Yeah, so could we just say that when we're accessing a data structure, we just have to access or we have to acquire all of the locks associated with all of the data structures we need at the beginning one? Yeah, so that'll be one way doing it. And I think that we quickly will come down to basically having a big kernel lock. And you're on the wrist. Basically, you have no parallelism anymore. So you want to do better than that, right? And I think this is always the tention of you can make things simpler by basically what's called, you know, coar screened blocking, but then, you know, you lose, lose performance or you may lose performance depending if the lock is contained or not. Yeah, makes sense, thank you. 
是的，所以我们能不能说，当我们访问一个数据结构时，我们只需要访问，或者我们必须获取与我们在开始时需要的所有数据结构相关的所有锁？是的，这将是一种方法。我认为我们很快就会归结为基本上拥有一个大的内核锁。你在手腕上。基本上，你不再有并行了。所以你想做得更好，对吗？我认为这始终是你的意图，你可以通过基本上所谓的 “遮挡” 来使事情变得更简单，但是，你知道，你会失去性能，或者你可能会失去性能，这取决于锁是否被包含。是的，很感知，谢谢。

发言人   32:53
So walk perspective. So there's different ways to think about locks and you know, there's three common ones and you know, go for all three of them and maybe that may help you to think about locks and maybe one of them is your favorite and you can use that one as your way of thinking about it. But there's probably helpful to see that there are actually different ways of thinking about locks. So first of all, you, one way to think about it is actually lots avoid. Lost updates or help? If you use locks correctly, you know locks can help avoiding lost updates. 
所以步行透视。所以有不同的方法来思考锁，你知道，有三种常见的方法，你知道，选择所有三种方法，也许这可以帮助你思考锁，也许其中一个是你最喜欢的，你可以把它作为你的思考方式。但是看到实际上有不同的思考锁的方式可能是有帮助的。首先，你，一种思考它的方式实际上是避免很多。失去了最新进展还是帮助？如果您正确使用锁，您知道锁可以帮助避免丢失最新进展。


发言人   33:38
And if you think about our early example in the Cao DOC, you know, the locked update is basically we lose one update to the K 3. And by putting lots in it you, we actually, we didn't lose that update. So that's one way of thinking about it. So a very low level way. 
如果你想想我们早期在Cao文档中的例子，你知道，锁定的更新基本上是我们失去了一个对k3的更新。而且通过把很多东西放进去，我们实际上并没有丢失那个更新。所以这是一种思考方式。这是一种非常低级的方式。

发言人   33:58
Another way to think about it is, you know, you can make walks. Make Volta staff operations. Atom? And so there's sort of the view of a critical section. You know, we have a fire walk. We do a whole bunch of steps or instructions. We executed all the instructions they release, and basically that whole critical section execute as an atomic operation and that sort of the, and also a fine way to think about locks. 
另一种思考方式是，你知道，你可以散步。让沃尔塔员工运营。原子？因此，有一种关键部分的观点。你知道，我们有一个火行走。我们会执行一系列步骤或指示。我们执行了他们发布的所有指令，基本上整个临界区都作为原子操作执行，这也是思考锁的一种很好的方式。

发言人   34:33
And then the third one that may be helpful is that really what locks do is locks health maintain an invariant. 
第三个可能有所帮助的是，锁真正的作用是锁的健康状态保持不变。

发言人   34:47
In Varian, for the shared data structure that you know, it's protecting. And what really is going on is that before a Cho, there's no lock holder. You know, that invariant holds when we acquire the lock and we do some operations, then temporarily the invariant may be violate it. But at the point that we do the release. And so if you think about our free list case, the invariant is you. The free pointer points through one other next pointer. And all the free pages are on a single list. And that's temporarily violated at the point. In the middle of the K 3, because multiple pointers actually point to the beginning of the free list. 
在Varian中，对于您所知道的共享数据结构，它正在保护。而真正发生的是，在一个Cho之前，没有锁的持有人。你知道，当我们获取锁并执行一些操作时，不变式保持不变，然后暂时不变式可能会违反它。但是在我们进行发布的时候。所以如果你考虑一下我们的自由列表案例，不变的就是你。自由指针指向另一个下一个指针。所有免费页面都在一个列表中。这在当时暂时被违反了。在k3的中间，因为多个指针实际上指向空闲列表的开头。

发言人   35:41
And then as we established at the end of it, so in you for, you know, the pre listed has a not so complicated variant, but like for more complicated Shi data structures can be a helpful way of thinking actually what the lock is doing for you. 
然后，正如我们在最后建立的那样，在你身上，你知道，预先列出的有一个不那么复杂的变体，但是对于更复杂的Shi数据结构，可能是思考锁对你的实际作用的有用方式。

发言人   35:56
And you see even in this with the K 3K, you know, all three lock perspective, a reasonable perspective and one of them brings more of a view than then one of the other ones and use that as way to think about locks. Any questions about this point? 
你可以看到，即使在这个使用K 3k的情况下，你也知道，所有三个锁视角，一个合理的视角，其中一个比另一个带来更多的视角，并以此作为思考锁的方式。对此有什么问题吗？

发言人   36:23
Okay, so I'm going to now run through a couple things, sort of. Undesirable properties or that can actually happen with locks. And we know like locks are necessary to fix a correctness problem to avoid these raised conditions, but walks themselves when in appropriately inappropriately used can also introduce their own set of problems. And so I want to talk a little bit about that. And so the obvious one, of course, is deadlock. 
好的，我现在要介绍几件事情。不良属性或锁定实际上可能发生的情况。而且我们知道，锁对于解决正确性问题以避免这些出现的条件是必要的，但是当使用不当时，它们也会引入自己的一系列问题。所以我想谈谈这个问题。因此，显而易见的问题当然是僵局。

发言人   36:57
Or hand you the simplest case, you know, it was a little bit boring, but I mean, worthwhile thinking about you. If you do an acquire, you know, a lock. And so you start the critical section. And in the critical section, you do another acquire off the same walk. What will happen? Can the second acquirer succeed? 
或者给你一个最简单的案例，你知道，这有点无聊，但我的意思是，值得考虑你。如果你进行收购，你知道的，一把锁。所以你开始临界部分。在临界区，你可以从同一个行走中获取另一个数据。会发生什么？第二个收购者能成功吗？

发言人   37:29
Well, with the spec that we've given early on you, this should be not allowed. And so basically the second acquire large block tool, the first acquirer released a lock, but that was, you know, the process itself. So basically, this will result in a deadlock. Now, this is a trivial example of the deadlock. And maybe, you know, there's interesting, in fact, there's a deadlock that X 3 6 2 text, you know, because when it sees that the same process requires the same walk again, it actually causes a panic. 
好的，根据我们早些时候给你的规格，这不应该被允许。因此，基本上第二个获取大块工具，第一个获取方释放了一把锁，但这就是过程本身。所以基本上，这将导致死锁。现在，这是死锁的一个微不足道的例子。也许，你知道，有趣的是，事实上，有一个X 3 6 2文本的死锁，你知道，因为当它看到相同的过程需要再次进行相同的行走时，它实际上会导致恐慌。

发言人   38:00
More interesting cases are when multiple locks are involved. 
更有趣的情况是涉及多个锁的情况。

发言人   38:03
So let's go to our previous example. Let's say we have the following. We have 4, 1, or I mean should be u 1. We have CPU 2. And CPU 1, you know, executes v namee directory 1x 2, directory 2 slash y. And CPU 2 executes at the same time rename. In the other, in the other direction, you know D2 a to the one, you know, when I say B, just to make the names different. So the critical of, thing to observe here is that CPU 1 runs and renamed from D1 to D2, and CPU 2 does exactly the opposite. That doesn't rename from D2 to D1. 
那么让我们回到之前的例子。假设我们有以下几点。我们有4、1，或者我的意思是应该是u 1。我们有CPU 2。和CPU 1，你知道，执行v名称目录1x2，目录2斜杠y。和CPU 2同时执行重命名。在另一个方向上，你知道d2a到其中一个，你知道，当我说B时，只是为了让名字不同。因此，在这里要观察的关键是CPU 1运行并从D1重命名为D2，而CPU 2则完全相反。不将D2重命名为d1。

发言人   39:09
So let's assume then we actually acquired the locks in the order of their arguments. And so what will happen, correct, is that in this case, you know, we'll acquire both locks. And we know from a previous example that is actually important, so we'll acquire. V1 lock. 
那么让我们假设我们实际上按照它们的参数顺序获取了锁。那么会发生什么呢，正确的是，在这种情况下，你知道，我们将获得两个锁。我们从前面的例子中知道这实际上很重要，所以我们将获得。V1锁。

发言人   39:28
And you, let's say they really run you through the concurrent. So at that point, you know, this other guy might actually, this other CPU might inquire D2 first because that is its first argument. And now, of course, D1, once they acquire D2. So I'll try to acquire G 2. Will it succeed? It won't succeed because you know, the other guy, you know, actually has to walk. And so this guy will stop here. And now p, let's look at the other CPU CPU 2 acquired two, it's not going to acquire D1 for its second environment, He's going to try to call is going to call acquired D1 and will it be able to proceed? 
而你，假设他们真的让你经历了并发过程。所以在这一点上，你知道，这个另一个人可能实际上，这个另一个CPU可能会首先询问D2，因为这是它的第一个参数。当然，现在是D1，一旦他们获得了d2。所以我会尝试获取G 2。会成功吗？它不会成功，因为你知道，另一个人，你知道，实际上必须走路。所以这个人会在这里停下来。现在，让我们看一下获取了两个的另一个CPU，它不会在第二个环境中获取D1，他会尝试调用将调用获取的D1，它会继续吗？

发言人   40:14
No, it won't be able to proceed, right? Because the CPU 1 actually has the walk and D1. And so here we, you know, sometimes this is called the deadly embrace, you know, Because in the way we acquired the order in which we acquired the locks, results actually in deadlock. 
不，它将无法继续，对吗？因为CPU 1实际上有walk和d1。所以在这里，你知道，有时这被称为致命的拥抱，你知道，因为我们获取锁的顺序的方式实际上导致了死锁。

发言人   40:41
Does that make sense, this example? And this is like a little bit of a more dangerous example effect of deadlock. You know, it's not an obvious problem. And the solution turns out, in some sense, reasonably simple. The solution is that, you know, if you have multiple locks, then you have to order the locks. And all operations have to acquire walks in that order. 
这就是感知例子吗？这就像是死锁的一个更危险的示例效应。你知道，这不是一个显而易见的问题。结果证明，在某些感知中，解决方案相当简单。解决方案是，你知道，如果你有多个锁，那么你必须订购锁。所有的操作都必须按照这个顺序获取行走。

发言人   41:17
So if you're a system designer, you have to decide that what the global order is for all lock objects. And so for example, in this case, we may want to say that D1 should be always ordered before D2. That means that when we execute the meaning, the rule of life is we always acquire the lower number. Directories first before we acquire the height or directory numbers. And then it will ensure that basically there's a global order. And this particular case just can not happen because you know, the lock order is going to be done for D1, D2 for this guy. This guy will acquire the locks exactly in the same global order, D1, D2. And then we don't have this deadly in bra. 
因此，如果你是一名系统设计师，你必须决定所有锁对象的全局顺序。因此，例如，在这种情况下，我们可能想说D1应该始终在d2之前排序。这意味着当我们执行意义时，生活的规则是我们总是获得较低的数字。在我们获取高度或目录号码之前，首先要使用目录。然后它将确保基本上有一个全球秩序。而这种特殊情况是不可能发生的，因为你知道，这个人的D1、D2都要执行锁定命令。这个人将以相同的全局顺序D1，d2获取锁。然后我们没有这种致命的胸罩。

发言人   42:09
Does it make sense? Any questions about this? 
它有感知吗？对此有什么问题吗？

发言人   42:22
So this indicates a little bit of a problem, even though like, okay, so it fixes the sort of deadlock problem by having a global order. This order is global and this is. An issue a little bit when designing a system, because hold on. 
这表明有一点问题，即使像，好的，它通过具有全局顺序来修复死锁问题。这个秩序是全球性的，而这就是。在设计系统时有一点问题，因为等等。

发言人   43:07
So if you think about the sort of block ordering. 
所以，如果你考虑区块排序的类型。

发言人   43:15
You know, that has to be sort of global. And so if one module, 1 M, you know, calls Ne in Marshall 2. And the collar and 1 G might actually, you need to be aware or could be you need to be aware actually, or what locks F acquired or one walk, you know N 2 uses. Because he and two uses some set of blocks. And you know, if we follow our lock ordering rule Jesus's got to make sure that if it has some locks that it acquires. All locks know from F and G together, actually in some global order. And so that really means that the sort of internals. The internals of M2, these terms of locks. 
你知道，这必须是全球性的。因此，如果有一个模块，1 m，你知道，在Mar.2中调用Ne。领子和1 g可能实际上，你需要意识到或者可能需要意识到，或者N 2使用的是什么锁或一个行走。因为他和两个使用了一些积木。你知道，如果我们遵循我们的锁排序规则，耶稣必须确保它有一些获得的锁。所有锁都从F和G一起知道，实际上以某种全局顺序。所以这真的意味着那种内部结构。M2的内部结构，这些锁的术语。

发言人   44:15
Must be visible to M1? So that N 1 can ensure that actually calls and two in the appropriate way. And in some ways, that is sort of an abstraction violation. Abstractions work out perfectly. You know? M1 doesn't really know, need to know anything about how M2 is implemented. And unfortunately, it locks are a common example where some of the internals of M2 might actually leak out, and one because M1 really needs to know. And so when you design a bigger system, this makes the modularity more complicated. 
必须对M1可见吗？这样，N 1就可以确保以适当的方式实际调用和调用两个。在某种程度上，这是一种抽象的违规行为。抽象完美地解决了问题。你知道吗？M1并不真正知道，需要知道M2是如何实现的。不幸的是，它锁定是一个常见的例子，其中一些M2的内部可能实际上会泄漏，而其中一个是因为M1确实需要知道。所以当你设计一个更大的系统时，这使得模块化更加复杂。

发言人   45:01
Oh, sorry, I was just wondering, does it need to be a complete ordering of Flux or can there be some blocks that are that can be ordered in whatever way they, it depends if like f and g share any locks? For example, if you look at XV 6, there are sort of multiple strands of lock orderings because some locks have nothing to do with other locks. So they're never acquired together. And so if they're never required to just join lock sets, if you will, and then only you have to make sure that the ordering in one particular lock set is global and the ordering in the other lock set is completely independent of the other ordering. So it is correct that there doesn't have to be a global ordering, but like all the functions that, you know, manipulate the same set sort of locks it, they need to agree on a global order, thank you. 
哦，对不起，我只是想知道，是否需要对通量进行完整排序，或者是否可以有一些块可以以任何方式进行排序，这取决于f和g是否共享任何锁？例如，如果你看XV 6，就会发现有多股锁排序，因为有些锁与其他锁没有任何关系。所以他们永远不会在一起。因此，如果他们不需要只是连接锁集，那么你只需要确保一个特定锁集中的排序是全局的，并且另一个锁集中的排序完全独立于另一个排序。因此，不一定必须有一个全局排序是正确的，但是就像所有操纵相同集合的函数一样锁定它，他们需要就全局顺序达成一致，谢谢。



发言人   46:04
Okay, so one another sort of challenge with locks, we've seen two challenges. One is deadlock, one is modularity. The second challenge or third challenge is just locks for performance. And we really hinted at this a couple of times, but it. Seems important enough to sort of put some emphasis on. And so basically, we want to get a performance. You need to split up data structure, right? If you have one big kernel lock, that will limit the performance to basically the performance of a single CPU. If you want performance, you want the performance scales with the numerous Cpu's, you got to split up. You need to split up data structures. 
好的，锁的另一个挑战，我们已经看到了两个挑战。一个是死锁，一个是模块化。第二个挑战或第三个挑战只是性能锁。我们确实暗示过几次，但是它。似乎足够重要，需要给予一些强调。因此，基本上，我们想要获得表演。你需要拆分数据结构，对吧？如果你有一个大的内核锁，那将限制性能基本上只有单个CPU的性能。如果你想要性能，你想要随着众多Cpu的扩展而扩展性能，你必须分开。你需要拆分数据结构。

发言人   47:06
And the best split? Is not obvious or can be a challenge? 
最好的分裂？这不是显而易见的，也可能是一个挑战？

发言人   47:18
You know, for example, you know, if you do associate the lock with every directory, should you associate the lock with every IO? Should you associate a lock with every process or not? Or is it better to sort of split the data structures in a different way? And if you make a change, you redesign sort of the locking discipline. And youve got to make sure that you're still maintain the invariant that actually the kernel is trying to maintain. And if you split locks, you also have to rewrite the code. You may have to need that. It may write, may need to, do you write a code to. 
你知道，例如，你知道，如果你确实将锁定与每个目录关联，那么你应该将锁定与每个IO关联吗？你应该将每个进程都关联一个锁吗？还是用不同的方式拆分数据结构更好？如果你做出改变，你就会重新设计某种锁定的纪律。而且你必须确保你仍然保持内核试图维护的不变量。如果你拆分锁，你还必须重写代码。你可能需要那个。它可能会写，也可能需要，你会写一个代码。

发言人   48:02
And so it turns out that basically. You sort refactor part of your kernel or part of your Appar program to get better performances by splitting data structure ops, introducing more walks. You know, it's just it's lot of work. You have to carefully think through that. You maintain the variants that you intended to maintain. You have to be ready code. And so in general, this is a lot of work and not easy. And so that sort a little bit of a negative, a new point, right? Because we want to get better at performance, that suggests more walks. And but then you, it's actually a lot of work. And so the general recipe how to go about this is to start, of course, green blocks. 
所以基本上证明了这一点。您可以对内核的一部分或部分应用程序进行排序重构，通过拆分数据结构操作和引入更多步来获得更好的性能。你知道，这只是很多工作。你必须仔细思考这个问题。您维护您打算维护的变体。你必须准备好代码。因此，总的来说，这是一项大量的工作，并不容易。所以这有点消极，是一个新的点，对吧？因为我们想要在表现上做得更好，这建议我们多散步。但是对于你来说，这实际上是很多工作。因此，如何实现这一点的一般方法是开始，当然，绿色方块。

发言人   49:05
And then measure. 
然后测量。

发言人   49:11
When running a bunch of applications and talk with your kernel and see whether you get actually any speed up, if they actually exploit multiple courses. And if they do, you're basically done. 
当运行一堆应用程序并与您的内核交谈时，如果它们实际上利用了多个课程，请查看您是否实际上获得了任何加速。如果他们这样做了，你基本上就完成了。

发言人   49:23
The walking design is good enough if you don't get speed up and basically means that some lock is contended. Multiple processes are trying to get the same lock and therefore they are serialized and therefore you don't get speed up. Then you have to rethink about, then you need to redesign. But the point is, you want to be guided now by these measurements because it may be decay is that you know some module that uses a quartz green block. It's not called in parallel often, and therefore, it is not necessary to actually redesign. And since redesign, there's a lot of work, you know, And you know, it also can complicate the reasoning about that code. You know, then it's a good idea not actually to do the redesign is it's not necessary. And so in general, a good rule of Th is you start with coarse made locks, measure whether contention appears in one of these locks, and then redesign that part of the system so that you get better very parallelism. 
如果你没有加速，步行设计就足够好，基本上意味着争夺了一些锁。多个进程试图获得相同的锁，因此它们被序列化，因此你无法提高速度。然后你必须重新考虑，然后你需要重新设计。但关键是，你现在想要由这些测量来指导，因为它可能是衰变，你知道一些使用石英绿色块的模块。它并不经常被并行调用，因此不需要实际重新设计。而且自从重新设计以来，还有很多工作需要做，你知道，而且你知道，它也可能使代码的推理复杂化。你知道，那么实际上不进行重新设计是一个好主意，因为它不是必要的。因此一般来说，一个好的规则是从粗糙的锁开始，测量其中一个锁中是否出现冲突，然后重新设计系统的这一部分，以便获得更好的并行性。

发言人   50:30
Does all make sense? Any questions so far? 
都有感知吗？到目前为止有什么问题吗？

发言人   50:39
Okay, let's look at. Let's look at in x 6, some code, understand a little bit how this locking sort of worked out in practice in XV 6. And so I'm going to go back to. To the this screen, really need this and I want to look at view artt because we start talking about locking there. On Monday. And I want to look at a little bit more in detail. And now that we know a little bit more about locks and also illustrate a couple of interesting points, So first, you know, it turns out you, I went over to, you know, was just looking at lock. 
好的，让我们来看看。让我们看一下x6中的一些代码，稍微了解一下这种锁定方式在XV 6中的实践中是如何实现的。所以我要回去了。到这个屏幕，真的需要这个，我想看看view art，因为我们开始谈论在那里锁定。在周一。我想再详细看看。现在我们对锁有了更多的了解，也说明了一些有趣的点，所以首先，你知道，原来你，我只是在看锁。




发言人   51:35
You know, it turns out that the UAR actually has only one lock. So you can think about this as a reasonable coarse grain design at this particular point, at least for the UART. And that particular lock protects basically the UART transmission buffer and right pointer and the read pointer. So when we transmit, you know, the right pointer points to the next free slot in the transmission buffer, and the re pointer is the next slot that actually needs to be transmitted. This is our standard design for parallelism or for producer consumer parallelism. So let me go back. And it out. 
你知道，事实证明，UAR实际上只有一个锁。因此，您可以将此视为在此特定时刻的合理粗粒度设计，至少对于UART是这样。这个特定的锁基本上保护了UART传输缓冲区和右指针以及读取指针。所以当我们传输时，正确的指针指向传输缓冲区中的下一个空闲插槽，而重新指针则是实际需要传输的下一个插槽。这是我们针对并行或生产者消费者并行的标准设计。那么让我回去。然后就出来了。

发言人   52:20
Okay, case study. New York. And there's basically a buffer and there's a read point. There's a right pointer or write read index and read index. This has to go to the UART displayed. And this is the writer. Or printf, maybe that actually sticks characters into this buffer, okay? And so, you know, what we can see is that the lock, you know, the lock has multiple roles. One is to basically protect this data structure. 
好的，案例研究。纽约。基本上有一个缓冲区和一个读取点。有一个正确的指针或写入读取索引和读取索引。这必须转到显示的UART。这是作者。或者printf，也许这实际上会将字符插入到这个缓冲区中，好吗？所以，你知道，我们可以看到的是，锁有多个角色。一是基本上保护这个数据结构。

发言人   53:11
This data structure has some mean variance, namely the read to proceed the right. Anything between r and w are characters that need to be sent. Anything between w and r are things that actually are empty slots. And the logs that basically help us maintain that invariant. 
这个数据结构有一些平均方差，即读取继续进行正确的操作。r和w之间的任何内容都是需要发送的字符。在w和r之间的任何东西实际上都是空槽。而日志基本上帮助我们保持这种不变。

发言人   53:34
So here we are code again, and you know, that's look at the Cho. So here's you are put C and you know, the first thing you know, you work with CDO is actually, you know, grab the lock and then stick the character. If there's a place in the buffer, stick the bear character in the buffer and starch, you know, the printing and then releases the lock. So if 2 processes at the same time call your art, put C, then this lockable insurer, that one character from the first process goes in the first lot, and then second character, the second process goes in the next lot and happened end up in the same slot. And this is like a clear example where lock helps us to. Avoid the race condition because otherwise the second process might overwrite. 
所以我们在这里再次编码，你知道，这是看Cho。所以这里是你把C放进去，你知道，你使用CDO的第一件事实际上是，你知道，抓住锁，然后粘贴字符。如果缓冲区中有一个地方，将熊字符粘贴在缓冲区中，然后进行淀粉打印，然后释放锁。所以，如果两个进程同时调用你的艺术，把C放进去，那么这个可锁定的保险公司，第一个进程中的一个字符进入第一个批次，然后第二个字符，第二个进程进入下一个批次，最后发生在同一个插槽中。这就像一个明显的例子，锁帮助我们。避免竞争条件，否则第二个进程可能会覆盖。


发言人   54:35
The first process is character. So that's one part. So then when, if you go look at, and we did that a little bit before, if you look at start, you know, we see a couple more things going on. The we see actually that the? The buffer is not if the. Buffer is not empty. Then we know that basically there's a bunch of characters that are being progressed or being sent and, you know, the walk, you know, make sure that we don't really overwrite any of those. 
第一个过程是性格。这就是其中的一部分。那么什么时候，如果你去看，我们之前也做过，如果你看一下开始，你知道，我们看到还有几件事情正在发生。我们实际上看到了什么？如果缓冲区不是。缓冲区不为空。然后我们知道基本上有一堆字符正在进行或被发送，你知道的，行走，你知道，确保我们不会真正覆盖其中的任何一个。


发言人   55:11
And so anything that's sort of at the tail end of the queue is actually being processed by the UART. Itself, so tail end. Is in flight? And we make sure that we basically don't modify or interfere with that particular aspect by grabbing a lock. 
因此，任何在队列末尾的东西实际上都由UART处理。它本身，所以尾端。在飞行中？并且我们确保我们基本上不会通过抓住锁来修改或干扰那个特定方面。

发言人   55:38
And then finally, the sort of more and more thing is that the rights to the register of the UART, like the Thr register, of which one, there's only one, you basically the lock insurers you remember to do. Our star just called with the lock held insurers that basically there's only one writer to the Ta to register. And so another sort of invariant or another aspect that the locking enforces is that hardware register. Have one writer. 
然后最后，越来越多的事情是注册UART的权利，就像Thr注册一样，其中只有一个，你基本上是你记得去做的锁保险公司。我们的明星刚刚打电话给持有保险公司的锁，基本上只有一个作家需要注册。因此，锁定强制执行的另一种不变量或另一个方面是硬件寄存器。有一个作家。

发言人   56:16
Okay, now there's one other interesting thing that I want to talk a little bit about, and that is if you are just done correct, the hardware was done, then there was an interrupt. And as you know, we noted before, you are stark. The collar. It's on the collar to require the walk to ensure we know multiple entities are running to the right register. And so viewer interrupt itself could run in parallel with another process that's called Pnf, some process called printf that runs a CPU 0, and on CPU 1 actually takes the UI to interrupt because maybe it's doing nothing. And so it's ready to take the interrupt at any particular point in time. And it will call UART start. 
好的，现在还有一件有趣的事情我想谈一下，那就是如果你刚刚完成了正确的工作，硬件已经完成，那么就会发生中断。正如你所知，我们之前注意到，你是鲜明的。领子。需要步行确保我们知道多个实体正在运行到正确的寄存器，这是项圈上的要求。因此，查看器中断本身可以与另一个称为Pnf的进程并行运行，另一个称为printf的进程运行CPU 0，并且在CPU 1上实际上需要UI来中断，因为它可能什么也不做。所以它已经准备好在任何特定的时间点接受中断。它将调用UART start。


发言人   57:09
And it has to be the case, correct? You know, we want to ensure that there's a single writer through these hardware register or to protect invariance actually of the transmission buffer you we have the acquired lock, and so it is the case that in XV 6 actually that interrupts, you know, can run, you know, so the bottom half of the driver can run truly concurrent on on different processors with the top half of the driver. And so therefore interrupt functions also require walks. And in fact, in this particular case, you know, requires the one walk that there's actually in the UART and then calls UAR storage and then releases the lock. And I'll come back to in that in a second because there's a little bit tricky news in implementing a walk in such a way that this actually works out correctly. And the thing that actually you should be worried about is that I'll actually talk about in a second. Let me postpone that until I get there. Okay, so any questions about this sort simple example of lock use in new? 
这一定是事实，对吗？你知道，我们希望确保通过这些硬件寄存器只有一个编写器，或者保护传输缓冲区的不变性，我们已经获取了锁，因此在XV 6中，中断实际上可以运行，你知道，因此驱动程序的下半部分可以真正地在不同的处理器上并发运行，而驱动程序的上半部分则是不同的处理器。因此，中断功能也需要遍历。事实上，在这种特殊情况下，你知道，需要在UART中进行一次遍历，然后调用UAR存储并释放锁。我一会儿再回来讨论这个问题，因为在实施步行时会有一些棘手的消息，要确保它能够正确地工作。实际上你应该担心的是，我马上就会谈到。让我推迟一下，直到我到达那里。好的，对于这种在new中使用锁的简单示例，有什么问题吗？


发言人   58:31
Okay, let me let me talk about implementing a walk. And so the spec is that only one process can acquire lock. There's no more than one lock holder at any given point in time. And we now want to look and understand actually how you implement a walk in such a way that that actually is guaranteed. Let me first write a broken lock so that we understand what the challenge is. Or broken acquirer? 
好的，让我谈谈如何实施散步。因此，规范是只有一个进程可以获取锁。在任何给定的时间点，没有超过一个锁持有者。现在我们想看看并理解你是如何以一种实际保证的方式实施散步的。让我先写一个破碎的锁，以便我们理解挑战是什么。还是收购方破产？

发言人   59:05
So now we know what the challenge is actually in implementing choir. 
现在我们知道实施合唱团的实际挑战是什么。

发言人   59:10
So here's my broken one. So Construct takes in a truck. Lock star L, and you know, what it does is it follows. It has an infinite loop. Well, one. You know, if. L is block 0, meaning nobody holding it. Then presumably the caller, she grabbed the log. And then we set our lock to one. And, you know, at that point, we got the lock so we can return nothing to do anymore and close the loop if we didn't get the lock, because when the lock was one, it means somebody else is holding the lock. 
这是我的坏掉的。所以建筑需要一辆卡车。锁定明星L，你知道，它所做的就是跟随它。它有一个无限循环。好的，一个。你知道，如果。L是0号区块，意思是没有人持有它。然后大概是打电话的人，她抓起了日志。然后我们将锁设置为1。而且，你知道，在那个时候，我们得到了锁，所以我们可以不再返回任何事情，如果我们没有得到锁，就关闭循环，因为当锁是一时，这意味着其他人正在持有锁。

发言人   59:58
So we just keep spinning and we wait, go around the loop over and over and over until at some point, you know, hold, lock, hold or release, which will set lock will set lock to 0. And, you know, so what's wrong with this particular implementation? I think two processes might read that it's not locked at the same time. Yeah, so there's a race condition here. Let's just to make sure that the race is right here. 
所以我们只是继续旋转，等待，一遍又一遍地循环，直到在某个时刻，你知道，保持，锁定，保持或释放，这将设置锁定为0。而且，你知道，这个特定的实现有什么问题吗？我认为两个进程可能会同时读取它没有被锁定的信息。是的，这里有一个竞争条件。让我们确保比赛就在这里。

发言人   01:00:39
We can have basically two Cpu's coming in. So if we're going to talk the time diagram, you know CPU 1, CPU 0, CPU 1, you know, this is statement A, maybe this is statement B, both CPU 1, you know, reach your statement A and CPU 0 n CPU 0 1, both for each statement A, so they both see locked being 0 and then the above execute B? Okay, so here they see lock to 0. This guy see locked to 0. And so they both executed statement B, and both have acquired a lock, and which violated the spec of this particular function. This makes sense? So it turns out to solve this problem. 
我们基本上可以有两个Cpu进来。所以如果我们要讨论时间图表，你知道CPU 1，CPU 0，CPU 1，你知道，这是语句A，也许这是语句B，CPU 1，你知道，到达你的语句A和CPU 0 n CPU 0 1，对于每个语句A，所以他们都看到locked为0，然后执行上面的B？好的，所以在这里他们看到锁定为0。这个人看到锁定在0。因此他们都执行了语句B，并且都获取了一个锁，这违反了这个特定函数的规范。这就感知了？所以事实证明可以解决这个问题。

发言人   01:01:38
And so to get a correct implementation, there's multiple ways of going about it. But the most common way to rely basically on the special Hartford and instruction and hardware instruction, basically what it does, and thus this test and this set atomically. And so the solution to this problem is hardware. Test and set support. 
因此，为了得到正确的实现，有多种方法可以实现。但是最常见的方式基本上依赖于特殊的Hartford指令和硬件指令，基本上它的作用是什么，因此这个测试和这个集合是原子的。因此，这个问题的解决方案是硬件。测试和设置支持。


发言人   01:02:17
And the way you can think about it on risk 5, this instruction actually is the atomic memory operation swap that we're going to be using and basically boils down to the test and NSF. And basically with the hardware guarantees, if you will. So we take this, it takes two arguments or three arguments and address a register 1 R 1 and the register 2. And essentially, what the hardware does just conceptually is basically it locks the address a few oil. We'll talk about that in a second a little bit more, but it locks address it. 
你可以考虑风险5，这条指令实际上是我们将要使用的原子内存操作交换，基本上可以归结为测试和NSF。基本上包括硬件保障，如果你愿意的话。所以我们接受这个，它接受两个或三个参数，并访问寄存器1和寄存器2。从本质上讲，硬件在概念上所做的基本上是将地址锁定几油。我们稍后会再详细讨论这个问题，但它会锁定地址。

发言人   01:03:01
Puts in a temporary variable value that actually is at that particular address? And then? Write the value of R 1 real into that address, and then basically puts the value that was at the originally at the address into the temporary value that the original value that was actually addressed actually into an R2 real. And then basically in walks and returns. And, you know, in this lock, if you will, guarantees that basically this test where the result of the test is returned into R2 real and the set actually happened atomically. And so this is a hardware instruction. 
输入一个临时变量值，实际上在那个特定的地址？然后呢？将r1个real的值写入该地址，然后基本上将该地址最初的值放入临时值中，原始值实际上被寻址为R2个real。然后基本上是散步和返回。而且，你知道，在这个锁中，如果你愿意，基本上保证了这个测试的结果被返回到R2 real中，并且这个集合实际上是原子地发生的。因此，这是一个硬件指令。

发言人   01:03:50
Most processor have an Arwa instruction like this because it's a convenient way to actually implement locks, And so basically what we've done is we've reduced sort of the automictic of this from or software lock implementation to basically a hardware lock implementation and. So the processor might implement this in many different ways. So basically, the instruction set itself, there's like a specification that doesn't actually say how it's implemented. And it is very dependent in the actual implementation of. This is dependent. On how the memory system exactly works? 
大多数处理器都有这样的Arwa指令，因为这是实际实现锁定的方便方式，所以基本上我们所做的是将这种自动化从软件锁实现简化为基本上硬件锁实现。因此，处理器可能以许多不同的方式实现这一点。基本上，指令集本身就像一个规范，实际上并没有说明它是如何实现的。它非常依赖于实际的实施。这是依赖的。关于记忆系统究竟是如何工作的？

发言人   01:04:44
So for example, if the modu processor share a single memory controller that retail writes to memory, then the memory controller can actually support this operation, can basically allow basically set the lock in a particular address, let you know 1 processor, do two operations or three instructions, and then maybe will unlock. And so since all the processor, the region, right? Go for this memory controller, the memory controller can do the ordering or the blocking. If the memories are in this processor sitting on a shared bus, it's often the bus arbiter that can actually do that, where the bus arbiter has support for basically executing two memory operations in an atomic way If it's a if the processes have cache, then it's sort of typically part of the cache behavior protocol where the Ke years protocol will ensure that if there's a writer, you know that that particular the cache line that holds, you know, the value that we want to update ends up in one single cache and then, you know, basically the processors can sort of lock that single cache line across two operations. 
因此，例如，如果modu处理器共享一个零售写入内存的内存控制器，那么内存控制器实际上可以支持此操作，基本上可以允许在特定地址中设置锁定，让您知道1个处理器，执行两个操作或三个指令，然后可能会解锁。因此，由于所有的处理器，区域，对吧？使用这个内存控制器，内存控制器可以进行排序或阻止。如果内存位于共享总线上的处理器中，通常总线仲裁器可以实际执行此操作，其中总线仲裁器支持基本上以原子方式执行两个内存操作，如果进程有缓存，那么它通常是缓存行为协议的一部分，Ke年协议将确保如果有一个写入程序，你知道那个特定的缓存行，你知道，我们想要更新的值最终会在一个缓存中，然后，你知道，基本上，处理器可以在两个操作之间锁定单个缓存线。

发言人   01:05:57
And so the implementation of this can be done in many different ways, but conceptually what's going on is like you walk the address, you read the original value, you store in the new value and you return your value does that make sense? To make that, to see how we can use that instruction, let's actually look at the implementation of acquire and release in XV 6. And then we'll expose a couple of other interesting details. So let me first bring up spin locked at H, spin locked at H, as you can see, it's pretty straightforward. It has this flight block exactly as in our pseudode, and then it has two other things for debugging, namely the name of the lock and the CPU of the last current CPU that actually is holding the lock. And this is mostly to print out debugging messages. For example, if you do to acquires on the same CPU. Okay, so then let's look at. 
因此，这可以通过许多不同的方式实现，但从概念上讲，就像你遍历地址，读取原始值，存储新值并返回你的值一样，这感知吗？为了做到这一点，看看我们如何使用这个指令，让我们实际看看XV 6中获取和释放的实现。然后我们将展示其他一些有趣的细节。所以让我先提出旋转锁定在H，旋转锁定在H，正如你所看到的，它非常简单。它有与我们的伪代码完全相同的飞行区块，然后它还有另外两件用于调试的东西，即锁的名称和实际持有锁的最后一个当前CPU的CPU。这主要是为了打印出调试消息。例如，如果您要在同一CPU上获取。好的，那么让我们来看看。


发言人   01:07:06
The implementation? 
实施？

发言人   01:07:12
And so let's start out with acquirer. And let's first look at this loop. So this is actually the sort of test and set loop that I just talked about. It turns out that in. The C standard actually defines one of these atomic operations. And so the C standard actually has a function that says sync, block, test, and set. And basically, it specifies the behavior that I just described, correct? And then every processor basically is required, you know, to implement that behavior. And since most processors have a matching sort of test and set hardware instruction, this turns out to be reasonable, straightforward, or approach to implement. 
所以让我们从收购方开始。让我们先看看这个循环。这实际上就是我刚刚谈到的测试和设置循环的类型。结果证明了这一点。C标准实际上定义了这些原子操作之一。因此，C标准实际上具有同步、阻止、测试和设置的功能。基本上，它指定了我刚才描述的行为，对吗？然后每个处理器基本上都是需要的，你知道的，来实现这个行为。而且由于大多数处理器都有匹配的测试和设置硬件指令，这证明是合理的、简单的或实现方法。


发言人   01:07:58
And so in fact, if we look at kernel that a.m., you know, we can look at the assembling structures and see exactly, you know, what the risk 5 processor does so. Here is our assembly instructions for choir. And let's see, here are atomic swap instruction. 
事实上，如果我们在上午看内核，你知道，我们可以看组装结构，确切地看到风险5处理器的作用。这是我们合唱团的组装说明。让我们看看，这里有原子交换指令。



发言人   01:08:28
So as you can see, an. Atomic swap, basically, it is called with the registering A five. And the input and output also ends up in a five. And as one is to hold the address. And if it's not equal, we return. And otherwise, basically, we go back now to jump back to. Double check. I change the right thing here. Move A for a six if not equal to go to 0x 20 plus 22. It's a little bit hard to calculate, but that basically, in one case, we branch out and in the other case we branch back. So it made it easier to just look at the C code. 
正如你所看到的，一个。原子交换，基本上，它是通过注册一个5来调用的。并且输入和输出也最终会变成5。而且一个人要拿着地址。如果它不相等，我们就返回。否则，基本上，我们现在回到原来的样子。双重检查。我在这里改变了正确的事情。如果不等于，则将A移动到6，以转到0x20加22。这有点难以计算，但基本上，在一种情况下，我们进行了分支，而在另一种情况下，我们又进行了分支。这样只需要查看C代码就更容易了。


发言人   01:09:19
So let's go away in here. So what happens? So if the, if the lock is not held, what will be the value of L lock? Well, l lock will be 0. And so we call the steps and set, what will happen is we'll write a one in lock, we return the previous value. So if the previous value is 0, then we, because that means that nobody what's holding the lock and we fall through and we're done with this y loop. 
所以我们就离开这里吧。所以发生了什么？所以，如果锁没有被持有，L lock的价值是什么？好吧，l锁将为0。因此，我们调用步骤并设置，将发生的是我们将编写一个锁定的，我们返回先前的值。因此，如果之前的值为0，那么我们，因为这意味着没有人持有锁，我们失败了，我们完成了这个y循环。

发言人   01:09:49
Now let's say the value was one. So the locked was actually locked. Well, what we'll do instruction do, it'll read, you know, the old value, put that on a site, correct? That one actually in this case, and then write new one into that location. But that will change nothing because we already locked and the function will return one, indicating that actually in the previous hold that it was already locked. And so in that case, it's unequal to 0. And so it will spin, and we'll keep spinning, boom, till locked. Actually, you said back to 0 and zoom. That will happen in the release. Any questions about this? 
现在我们假设价值是一。所以这个锁实际上是锁着的。好的，我们要做的是指令，它会读取旧的值，把它放在网站上，对吗？在这种情况下，实际上是一个，然后在该位置写入新的。但这不会改变什么，因为我们已经锁定了，该函数将返回一个，表明实际上在之前的保持中它已经被锁定。在这种情况下，它不等于0。所以它会旋转，我们会继续旋转，繁荣，直到锁定。实际上，你说回到0和缩放。这将在发布中发生。对此有什么问题吗？

发言人   01:10:51
No questions, okay. So that basically, you know, let's look at corresponding the releases operation and. And here's the lease operation. And if you look at the kernel a.m. again. That instruction. So let's hope the release is probably right after a few years release. So the release actually also uses this atomic swap instruction. And putting basically zero into S 1. And so there's a guarantee. Is is basically that this atomic update A to L locked or Lk locked running a zero into Lk locked is an atomic operation. 
没有问题，好的。因此，基本上，让我们看看相应的发布操作和。这是租赁操作。如果你再看看内核上午。这个指示。所以让我们希望这个版本在发布几年后可能是正确的。因此发行版实际上也使用了这个原子交换指令。基本上把零放到S 1中。所以有一个保证。基本上，这个原子更新A到L锁定或Lk锁定运行0到Lk锁定是一个原子操作。




发言人   01:11:46
Many of you ask, why not just use store instruction to actually rank 0? And anybody may want to guess why, why that might not work or what the problem could be. Because then some other process might be writing the one to the log or no, or I think another 0. But that can be the case, right? Yeah, well, it could be. Okay, so there could be two processes or two Cpu's writing to L walk at the same time, right? 
很多人会问，为什么不直接使用存储指令来实际排名为0呢？任何人都可能想猜测为什么，为什么那可能不起作用或问题可能是什么。因为那时其他进程可能正在将其中一个写入日志或否，或者我认为另一个0。但事实确实如此，对吗？是的，有可能。好的，那么可能有两个进程或两个Cpu同时写入L walk，对吗？

发言人   01:12:18
But I think what the question really is for many people, I often assume this too, is that when you do a single story structure that is sort of like an atomic operation. And now there's not always the case. You know, for example, if you, and it really depends on the architectural implementation, like for example, if the cache here protocol works or the cache system works using cache lines, where a cache line may be bigger than an integer, typically bigger than an integer, then really what is happening is the first operation is loading the cache line and then updating the cache line. So in fact, a store instruction basically has sort of 2 micro operations in it, and you can get the wrong result. 
但我认为对于许多人来说，真正的问题是，我也经常假设，当你做一个单层结构时，有点像原子操作。但现在情况并非总是如此。你知道，例如，如果你真的取决于架构实现，例如，如果这里的缓存协议有效，或者缓存系统使用缓存线有效，其中缓存线可能大于整数，通常大于整数，那么真正发生的是第一个操作是加载缓存行，然后更新缓存行。实际上，一个存储指令基本上有两个微操作，你可能会得到错误的结果。

发言人   01:12:59
And so? 
所以呢？

发言人   01:13:02
To avoid having to understand anything of the hardware implementation of Jack and whether integers, operations, or atomic or not, or writing through 64 b 64 memory values in atomic operation, you know, we use the risk five operation that is guaranteed to be executed atomically. Does that make sense? Yes, okay, so just just for your amusement, atomic swap is not the only instruction that exists. So here's the risk five manual and lists a whole bunch of the atomic operation. So there's an atomic ends and atomic or there's an max min. They all can read and write a value in an atomic operation. 
为了避免不得不理解Jack的任何硬件实现，无论是整数、操作还是原子操作，或者在原子操作中写入64个内存值，您知道，我们使用保证以原子方式执行的风险五操作。感知了吗？是的，好的，所以只是为了娱乐，原子交换并不是唯一存在的指令。这里是风险五手册，列出了一大堆原子操作。所以有一个原子末端和原子或者有一个最大最小值。它们都可以在原子操作中读取和写入值。


发言人   01:13:58
Okay, okay, so there's a couple other things that I want to point out in this particular implementation. And let me start again, go back to acquire. So one of the first things the acquire function does is it turns off interrupts. And what you could do is understand why that is the case. And so for now I'm going to go back to our UART example code. And you think a little bit about this. And so we're going to think about the case. 
好的，好的，在这个特定的实现中我还想指出其他一些事情。让我重新开始，回到获取。因此，获取函数所做的第一件事就是关闭中断。你可以做的是理解为什么会这样。所以现在我将回到我们的UART示例代码。你可以稍微思考一下这个问题。所以我们要考虑这个案子。



发言人   01:14:37
Query is actually maybe incorrectly implemented and does not turn off in interrupt ups. So, and the way to think about this is if we go through your food seed, and here, let's say urp c runs. And acquires the lock? And but does not turn off interrupts? What can happen? 
查询实际上可能没有正确实现，并且在中断启动时不会关闭。所以，思考这个问题的方式是，如果我们检查你的食物种子，这里，让我们说urp c运行。并获得锁？但不关闭中断吗？会发生什么？


发言人   01:15:03
Give everybody a couple seconds to think about it. But if you have an idea or why it might be wrong, jump in. 
给每个人几秒钟思考一下。但是如果你有一个想法或者为什么它可能是错误的，就跳进去。

发言人   01:15:18
Perhaps it could be interrupted because of because of the clock and then something happens and it needs to print something else and it tries to do your puts. You again already taken. Yeah, that might be a possible scenario. 
也许它可能会因为时钟而被打断，然后发生了什么事情，它需要打印其他东西，并尝试做你的放置。你又已经采取了。是的，这可能是一种可能的情况。

发言人   01:15:37
There's a much more direct example for this. So let's just say you are putsy, you know, grind, lock and the universe basically transmitting some character. So one that you dumb transmitting character, what does it do? It causes an interrupt, correct? And you are interrupt runs. What you are interrupt do? It grabs the same walk, you know, that puts these holding, right? So what will happen here if there's only one CPU? And so there's no other CPU where this interrupt could be running? 
这里有一个更直接的例子。所以我们就说你是putsy，你知道，研磨，锁定和宇宙基本上传输一些特征。所以，你这个愚蠢的传播角色，它有什么作用？这会导致中断，对吗？你正在中断运行。打断一下你在做什么？它抓住了同样的步行，你知道，这让这些握着，对吧？如果只有一个CPU，这里会发生什么？所以没有其他CPU可以运行这个中断？


发言人   01:16:12
Well, we have a deadlock, right, because the current CPU is holding the lock as part of you put C, then later the interrupt came in and the first thing it tries to do is actually required the lockdown's already held. And in fact, in the case of XV 6, we'll get a panic because the same CPU is actually trying to acquire the same walk again. So basically, you know what? 
好的，我们有一个死锁，对吧，因为当前CPU正在持有锁作为你把C放进去的一部分，然后中断进来，它尝试做的第一件事实际上需要已经持有的锁定。实际上，在XV 6的情况下，我们会感到恐慌，因为同一CPU实际上正在尝试再次获得相同的行走。所以基本上，你知道吗？

发言人   01:16:39
Acquire or spin lock deals with sort of two different types of concurrency. You know, one, the sort of concurrency between two different Cpu's. And we got to make sure that like, for example, we have the interrupted function runs on a different CPU that basically we don't get a raise on the transmission buffer. But if they run in the same CPU, we've got to make sure that it's still a topic and that it's not being interrupted. And therefore, we actually turn our interrupts off in acquire, and they're only turned on again at the end of release when the lock actually has been released. And at that point is safe again you to take these interrupt routes because the lock actually is not released anymore. There was not aqui holding it, not health anymore, does that make sense? 
获取或旋转锁定处理两种不同类型的并发。你知道，第一，两个不同Cpu之间的并发类型。我们必须确保，例如，我们有中断的函数在不同的CPU上运行，基本上我们不会在传输缓冲区上增加。但是如果它们在同一个CPU上运行，我们必须确保它仍然是一个主题，并且不会被中断。因此，我们实际上在获取时关闭了中断，并且只有在锁实际被释放时才会再次打开它们。并且在那个时候你再次采取这些中断路由是安全的，因为锁实际上不再被释放了。没有人拿着它，不再有健康，这让感知吗？



发言人   01:17:28
Okay, there's one more subtle thing in this implementation that I want to talk about and that we need to deal with. And that is memory ordering. 
好的，在这个实现中还有一个微妙的事情，我想谈谈，我们需要处理。这就是记忆的排序。


发言人   01:17:53
So example, if you think about locked is, let's say, acquire shifts locked to one, maybe we have a critical section in which x shift x plus one and then choir release, you know, says lock to 0. So you sort of think about the instruction stream that's being executed on a particular CPU, you know? So these are sort of the instructions that are being executed. Now, if the code were just purely sequential. The. Compiler or the processor or reorder instructions, you know, just to get better performance. For example, if it were a sequential stream, would it be okay to move this instruction to afterwards? Would that change the correctness of the single stream of execution? 
例如，如果你考虑锁定是，比如说，获取移位锁定为1，也许我们有一个临界区，其中x移位x加一，然后合唱团释放，你知道，说锁定为0。所以你有点考虑在特定CPU上执行的指令流，你知道吗？所以这些是正在执行的指令。现在，如果代码只是纯粹顺序的。这个。编译器或处理器或重新排序指令，你知道，只是为了获得更好的性能。例如，如果它是一个顺序流，那么可以将此指令移动到后面吗？这会改变单一执行流的正确性吗？

发言人   01:18:58
No, not really, right? Because lock the necks are totally independent of each other. There's no relation to it. So it'd be perfectly fine if it were sequential execution. The x is moved after the lock log zero, so that you on the single, single serial execution, that's okay. And in fact, so in fact, processors, you do this all the time. You know, they do speculative execute stuff or expectedly executing instructions. And so that can result in basically these instructions reorderings the compiler does it to you to maybe optimize some code path and also will reorder instructions as long as results in the same S execution. 
不，不是真的，对吧？因为锁住的脖子是完全独立的。这与它没有任何关系。所以如果是顺序执行就完全没问题了。将x移动到锁日志归零之后，这样您就可以执行单个串行执行了，没关系。事实上，处理器，你一直都在做这个。你知道，他们做推测性的执行事情或预期执行指令。因此，这可能会导致基本上这些指令重新排序，编译器会对您进行操作，以优化某些代码路径，并且只要导致相同的执行，就会重新排序指令。

发言人   01:19:44
But clearly, during concurrent execution, this would be disaster, right? Because if A was a require and this was our release, and basically what we've done, we moved the critical section outside of the acquiring the release, and then we totally incorrect. And so that is wrong, wrong in a concurrent execution. 
但很明显，在并发执行期间，这将是一场灾难，对吧？因为如果A是一个要求，而这就是我们的版本，基本上我们所做的，我们将关键部分移到了获取版本之外，然后我们完全不正确。所以这是错误的，在并发执行中是错误的。

发言人   01:20:12
And so for bit or tell the compiler and the hardware not to do this, something that's called a memory fence or something, I synchronize. There's an instruction that basically says, like any loads of stores before this point, you are not allowed to move beyond this point. And so release has this and acquiring has this. And so, for example, this x plus x plus one, if that was updated after the acquire and before the release, that x plus x plus one has to stay before of this particular memory synchronization point. And so it will not be, there will be no trouble with memory ordering. So this is the reason why seeing synchronizes there both in the release and also there's one in the acquire. Does that make sense? 
因此，请告诉编译器和硬件不要这样做，这被称为内存栅栏或同步的东西。有一个指令基本上说，就像任何在这一点之前的商店一样，你不允许超过这一点。因此，释放有这个，获取有这个。因此，例如，如果x加x加一在获取之后但在发布之前被更新，那么x加x加一必须保留在此特定的内存同步点之前。所以不会有，记忆排序不会有问题。这就是为什么在发布和获取中都看到同步的原因。感知了吗？



发言人   01:21:06
I have a question? Is it is it by convention that the start of? The port. So I guess I guess the compiler could figure out that there is an instruction before the lock is even acquired and that it can be just as well moved after the lock is released. Can that happen? Or will it encounter the barrier and see that? 
我有问题吗？这是按照惯例开始的吗？港口。所以我想编译器可能会发现在获取锁之前有一个指令，并且在锁释放后也可以移动它。这会发生吗？或者它会遇到障碍并看到它吗？

发言人   01:21:38
We'll see, you know, in this case, Greg, a car has a barrier and at least has a barrier. So anything that happened before locked except one will happen before that. It will never pass that instruction. So this is a barrier. So if you will, this is a barrier one and this is barrier 2. And so that means that any instruction before here, stay here, any instruction between will happen between the two, between the client and release. And then instruction after will stay after the release, okay? 
我们会看到，你知道，在这种情况下，格雷格，一辆汽车有一个屏障，至少有一个屏障。所以在锁定之前发生的任何事情，除了一件以外，都会在那之前发生。它永远不会通过那个指令。所以这是一个障碍。所以如果你愿意的话，这是一个屏障，这是屏障2。这意味着在此之前的任何指示，在此处停留，在此之间的任何指示都将在客户端和发布之间发生。之后的指示将在发布后保留，好吗？

发言人   01:22:11
Okay, okay, so I'm running, you know, close to the end. So let me just actually wrap up here. 
好的，好的，所以我正在跑步，你知道，接近终点。所以让我在这里总结一下。

发言人   01:22:27
So the locks, you know, locks are good for correctness. 
所以锁，你知道的，对正确性有好处。

发言人   01:22:40
But can be bad for performance? 
但可能对性能有害吗？

发言人   01:22:48
Which is sort of a bummer, correct? Because one reason we actually got into locks is basically to get correctness during parallel execution. But the locks actually limit parallel execution. That's one. And two locks complicate. Programming and you will experience that in some of the labs that we're going to be doing. In fact, from now on, we'll see lock showing all the time. And that will give us at least, you know, some thought. 
这有点令人无法接受，对吗？因为我们实际上陷入锁的一个原因基本上是为了在并行执行期间获得正确性。但是锁实际上限制了并行执行。这是一个。而且两个锁很复杂。编程，您将在我们将要进行的一些实验室中体验到这一点。事实上，从现在开始，我们将看到锁一直显示。这至少会给我们一些思考。

发言人   01:23:18
You know, it's going to be necessary to understand like why the locks are there and what they protect. But they're sort of inherent. If you do parallel programming, you need to use locks. And so, you know, if you want to avoid the complications due to locks, you know, a couple things you could do share if you don't have to. 
你知道，有必要理解为什么锁在那里以及它们保护什么。但它们是固有的。如果你进行并行编程，你需要使用锁。所以，你知道，如果你想避免由于锁而导致的并发症，你知道，如果你不必分享一些事情，你可以做。

发言人   01:23:42
If you don't have shared data structures, these range conditions can not happen and there. And so you don't need locks. 
如果您没有共享的数据结构，这些范围条件就不会发生。所以你不需要锁。

发言人   01:23:51
And so you don't need this complicated programming. But typically you will have some shared data structures you will do, you will need locks. And I think the thing to do is start, of course, grained. And then move to playing grained is necessary based on, you know, measurements you want to determine. You make sure that the lock is actually coned, you know, before you actually start redesigning. And then finally, you know, use a race detector to. One of these race detector tools to actually finds problems or race conditions because you put the locks or you put acquiring the releases in the wrong place. And in fact, you still have races. 
所以你不需要这种复杂的编程。但通常情况下，您将拥有一些共享的数据结构，您将需要锁。我认为要做的事情当然是开始粒度化。然后移动到播放粒度是必要的，基于你想要确定的测量。你要确保锁实际上是锥形的，你知道，在你真正开始重新设计之前。最后，你知道的，使用种族检测器。其中一种竞赛检测器工具可以实际发现问题或竞赛条件，因为您将锁定或将获取释放放在错误的位置。事实上，你仍然有种族。

发言人   01:24:32
Okay, so this is a quick introduction to locks. We're going to talk a lot more about locks and the basically for the rest of the semester that we'll up and we'll talk a little bit more about lock free program in the end and see how that is done in kernels. Okay, so when you stop here so that anybody who has to go to somewhere else can go, but if you have any more questions can feel free, please feel free to ask them. We have a question in the chat. Isn't the fence instruction unnecessary because the Amo swap instruction can have the acquire release ordering? So the two things, the sync instructions there, both for the compiler and for the hardware. 
好的，这是对锁的快速介绍。我们将更多地谈论锁，基本上在剩下的学期中，我们将讨论更多关于锁的问题，最后我们将更多地谈论无锁程序，看看它是如何在内核中完成的。好的，所以当你在这里停下来，以便任何必须去其他地方的人都可以去，但如果你还有任何问题可以随时问他们。我们在聊天中有一个问题。围栏指令不是不必要的，因为Amo交换指令可以有获取发布顺序吗？所以有两件事，同步指令，既针对编译器，也针对硬件。

发言人   01:25:25
Yeah I'm jumping off to start office hours, but I think there's still more questions in the how do you do it for the compiler? Only the compiler notes for which architecture it is compiling. And so we will know whether it actually has to ensure the appropriate fences, you know, for whatever architecture is running on and whatever memory consistency model it has. So this gets into a little bit more complicated Discussion is that every piece of hardware has a memory model. And the compiler, the site, you know, given the memory model for that particular architecture, what actually it can do and what it can not do? 
是的，我要开始办公时间了，但我认为在编译器如何做到这一点上还有更多的问题？只有编译器注释它正在编译的体系结构。因此，我们将知道它是否实际上必须确保针对运行的任何架构以及它所拥有的任何内存一致性模型设置适当的围栏。因此，这需要更复杂的讨论，即每个硬件都有一个内存模型。而编译器，这个网站，你知道的，考虑到那个特定架构的内存模型，它实际上能做什么，不能做什么？

发言人   01:25:59
And I guess my question was that like the F instruction only becomes unnecessary if you call Amos swap, like Dow dot release and. Like putting in the sink in there, that will sync. But the compiler ordering and then the. 
我猜我的问题是，只有当你调用Amos swap (如Dow dot release) 时，像F指令才变得不必要。就像把水槽放在那里一样，它会同步。但是编译器排序然后。

发言人   01:26:25
Memory ordering and the out of ordering. Yeah, machinery using the fence instruction as well. The fence instructions only unnecessary in the case that you do dot RL. So it seems like it wouldn't detect that. So how would you do it? So the compiler enforces the ordering on its end, but you already cover it using the Amazons if you. It's a very good question. And it's a more sophisticated acquiring. These implantation would be like specialized acquire release implementation or release implementation for risk life. We would probably do more sophisticated things than we do where we pretty, of course, grain by just issuing that fence instruction. 
记忆排序和无序排序。是的，机器也使用围栏指令。围栏说明只在你做点RL的情况下不必要。所以它似乎检测不到那个。那么你会怎么做呢？因此编译器在其末尾强制执行排序，但是如果您使用amazon已经涵盖了它。这是一个非常好的问题。这是一个更复杂的收购。这些植入就像是专门的获取发布实施或风险生命的发布实施。我们可能会做更复杂的事情，而不是仅仅通过发布围栏指令来处理我们美丽的地方。

发言人   01:27:08
The, but it's slightly complicated and so if you, if you're interested in this, the memory model for the risk drive is really complicated. So if you look at the instruction manual for the impre instructions, there's a whole chapter dedicated, you know, to memory ordering and tells you what they have for the compiler should do in this particular case. So using the compiler would pick up on the fact that we just put that assembly instruction inside of there, and it wouldn't reorder any of the memory accesses on its own. 
但它有点复杂，所以如果你对此感兴趣，风险驱动的记忆模型真的很复杂。所以，如果你看一下impre指令的使用手册，有一整章专门讨论内存排序，并告诉你在这种特定情况下编译器应该做什么。因此，使用编译器将发现我们只是将汇编指令放在那里，并且它不会对任何内存访问进行重新排序。

发言人   01:27:47
Sorry, this synchronized library function is a library function and can be implemented in different ways. And this is one particular implementation. And the library function is by the compiler. But is there like the option for the compiler to do optimization where it itself moves the loads and stores around? Yes, do. So how do you prevent that without emitting the F instruction? That's not just curious, I guess what I'm saying is that. 
抱歉，这个同步库函数是一个库函数，可以以不同的方式实现。这是一个特定的实现。库函数由编译器提供。但是编译器是否可以选择在移动加载和存储的位置进行优化？是的，做。那么在不发出F指令的情况下如何防止这种情况呢？这不仅仅是出于好奇，我想我在说什么。

发言人   01:28:21
Maybe what I'm saying is that basically this indication, the synchronize basically both tells compiler and hardware, but the compiler could actually implement synchronize differently. It knows that it can't move things around, but it doesn't have to issue defense instruction on the risk 5. It knew that it was running in a particular way on the risk 5. But isn't the risk five memory model like loose enough to wear? The out of order machinery could reorganize stuff. 
也许我的意思是，基本上这个指示，同步基本上既告诉编译器又告诉硬件，但编译器实际上可以以不同的方式实现同步。它知道它无法移动东西，但它不必发布风险防御指示。它知道它以特定的方式运行在风险中。但是风险五记忆模型不是足够宽松，可以磨损吗？出了问题的机器可以重新组织东西。

发言人   01:28:50
So you do need like the acquire, like the whole point of having, okay, so they're more. They're more complicated interfaces and seeing synchronize. And which give the compiler writer more, gives the programming more freedom, and will give the compiler and sort of decouple the compiler part and the processor part. So for example, I think there's a flag that you can pass in, you know, to say that there's a release consistent, synchronized, You know, I don't know the details right out of my head. But if you look into this, this is sort of the coarse grained interface. And they're more fine grained interfaces that give the programmer more control. 
所以你确实需要像收购一样，像拥有的全部意义，好吧，所以它们更多。它们是更复杂的接口，可以看到同步。这将给编译器作者更多，给编程更多的自由，并将给编译器和处理器部分解耦。例如，我认为有一个标志，你可以传入，你知道，说有一个发布一致、同步的，你知道，我不知道我脑子里的细节。但是如果你仔细观察，这有点像粗粒度的接口。它们是更细粒度的接口，给程序员更多的控制。

发言人   01:29:32
Thank you? 
谢谢？

发言人   01:29:36
I have a few questions. One is, how do you like for having multiple threads and one processor? Do you argue in roughly the same way as we did for multiple processors? So can you repeat that question just to make sure I? We, I think, I don't think we really talks about multiple threats. We mostly talked about multiple Cpu's. So for multiple threads is the, I guess the solution the same for when you have multiple Cpu's? Like do you have the same arguments there? More or less, at least conceptually, is the right way to think about it. 
我有几个问题。一个是，你喜欢如何拥有多个线程和一个处理器？你的观点是否与我们针对多处理器所做的大致相同？所以你可以重复那个问题以确保我吗？我们，我想，我不认为我们真的在谈论多重威胁。我们主要讨论了多个Cpu。所以对于多线程来说，我想当你有多个Cpu时，解决方案也是一样的吗？你们有相同的论点吗？或多或少，至少在概念上，是正确的思考方式。

发言人   01:30:21
So if you have multiple frets but only one CPU, it still decays that you want to ensure that certain kernel code sequences are executed atomically. And so you still have, there's a notion of critical sections. You might not need locks or lease explicitly, but you do need a way of sort of turning on interrupts off and on in a particular piece of code. So if you look at older operating system kernels, they typically don't have really lock and acquire in the kernel because they soon are running on a single processor. But they do have something like locks know to basically turn off interruption and interrupts on and off. 
因此，如果您有多个烦恼但只有一个CPU，它仍然会衰减，您希望确保某些内核代码序列以原子方式执行。所以你仍然有一个关键部分的概念。你可能不需要显式锁定或租用，但你需要一种在特定代码片段中关闭和打开中断的方法。因此，如果您查看较旧的操作系统内核，它们通常在内核中没有真正的锁定和获取，因为它们很快就会在单个处理器上运行。但是它们确实有锁知道基本上关闭中断和中断打开和关闭的东西。

发言人   01:31:03
Okay, I see. And my other question was actually on the slide with, the yard picture, the buffer. Yeah, is it? Yeah, that one. Is it always the case that the read is going to be like lagging behind? I didn't understand that. 
好的，我明白了。我的另一个问题实际上是在幻灯片上，有庭院图片和缓冲区。是吗？是的，那个。阅读总是会落后的情况吗？我不明白。


发言人   01:31:27
Yeah, okay, so the, so this goes to the display, Yeah, whatever is in this, basically this is the sequence of characters that needs to go through the display and the writer basically is appending more and more and more characters. And so the writers going that way and basically the readers following the writer because can't print the character that hasn't been put into buffer yet. And so, you know, the UART puts things on the display. You know, we'll, you know, start basically putting the first connector as in this slot you onto the display. Meanwhile, printer could come in, multiple printers come in that they put more characters in here so that the right pointers based standing here. And then when this one character is displayed, then the UAR will move up this pointer to display the next character, actually. So the U is always lagging a little bit behind the writer until the point that it catches up, right where R and w are the same. And at that point, basically, that means that there's no character anymore in the buffer. 
是的，好的，所以这就转到显示，是的，无论其中有什么，基本上这是需要通过显示的字符序列，并且作者基本上是附加越来越多的字符。因此作者走那条路，基本上读者跟随作者，因为无法打印尚未放入缓冲区的字符。所以，你知道，UART把东西放在显示器上。你知道，我们基本上会开始把第一个连接器放在这个插槽上。同时，打印机可以进来，多台打印机进来，它们在这里放入更多的字符，以便正确的指针基于站在这里。然后当显示这一个字符时，UAR将向上移动此指针以显示下一个字符。因此，U总是落后于写入器一点，直到它赶上来，就在R和w相同的地方。这时，基本上，这意味着缓冲区中不再有字符。

发言人   01:32:35
Oh, okay, I see that makes, that makes a lot more sense. Okay, thank you so much welcome. Any more questions? Just us left here. Okay guys, see you later. 
哦，好的，我明白了，这使得更多的感知。好的，非常感谢，非常欢迎。还有什么问题吗？只有我们离开这里了。好的，伙计们，待会儿见。
