---
title: 计算机网络 032 Principles Packet Switching End to End Delay
date: 2025-10-19 10:00:31
---

发言人   00:00
In the first video on packet switching, I told you about what packet switching is and why it was used for the internet. Packet switching is going to feature very prominently throughout this course. So we're going to spend quite a bit of time on it. And many of the properties of the internet followed directly from the choice of packet switching. So in this video I'm going to give you some useful definitions for propagation delay and packetization delay. And we're going to use those definitions to come up with an expression for the end to end delay of a packet across a network. I'm also going to tell you about queueing delay and how it makes the end to end delay unpredictable. So let's start with some useful definitions. 
在关于分组交换的第一个视频中，我告诉了您分组交换是什么以及为什么它被用于互联网。分组交换将在本课程中占据非常突出的位置。所以我们将在这方面花费相当多的时间。而互联网的许多属性直接源于分组交换的选择。因此，在本视频中，我将为您提供一些有关传播延迟和打包延迟的有用定义。我们将使用这些定义来得出网络上数据包的端到端延迟的表达式。我还将告诉你排队延迟以及它如何使端到端延迟不可预测。让我们从一些有用的定义开始。



发言人   00:43
We'll start with the definition of propagation delay. So the propagation delay is the time that it takes a single bit of information to travel over a link at propagation speed C, so look at the picture here, and you'll see we have the computer on the left, and we're going to consider the time that it takes for a bit to propagate from the one on the left to the one on the right. Time The propagation delay, or T sub L, is simply L over c? So the propagation delay is simply determined by how long the link is l in our case, and the speed that a bit travels C, we use the variable C in most of the links we're interested in, because c is the speed of propagation is very close to the speed of light. For example, in a twisted pair of electrical cables, a bit propagates at about 70% of the speed of light, and then in optical fiber, the speed of propagation is a tiny bit slower. 
我们将从传播延迟的定义开始。因此，传播延迟是一位信息以传播速度C在链路中传播所需的时间，因此请看这里的图片，您会看到左侧有计算机。我们将考虑从左侧传播到右侧所需的时间。传播延迟或T sub L，仅仅是L在c上？因此，传播延迟简单地取决于链接的长度，在我们的情况下是l，以及比特传播的速度C，我们在大多数我们感兴趣的链接中使用变量C，因为c是传播速度非常接近光速。例如，在一对双绞线电缆中，一个比特以光速的约70% 传播，而在光纤中，传播速度稍微慢一些。

发言人   01:44
In most of our examples, we'll assume that the bit propagates at two times 10 to the 8 m per second, which is which is close enough. There you go, there's the bit going along the link. Let's have a look at that again. It's the speed or the time at which it takes to propagate over the link. So for example, if we were considering how long it would take a bit to travel, 1000 kilometers or a million met in an optical fiber where the propagation speed was two times 10 to the 8 m per second. Well, t sub L is 1000 times 10 to the three divided by two times 10 to the 8 or 5 milliseconds. 
在我们的大多数例子中，我们假设比特以两倍的速度传播，即每秒8米，这已经足够接近了。你去那里，有一点点沿着链接前进。让我们再看看这个。它是指它在链路上传播所需的速度或时间。例如，如果我们考虑行进一段时间需要多长时间，在一根光纤中传输1000公里或一百万公里，其传播速度为两倍10的8米每秒。好吧，t sub L是1000乘10的3除以2乘10的8或5毫秒。

发言人   02:24
In a little bit. We're going to look at some examples, and you're going to do some examples in the multiple choice exercises embedded in the video. Notice that the propagation delay doesn't depend on the data rate of the link, doesn't matter if the link is running at 1 kb per second or at 10 Gb per second. The propagation delay is just a function of the speed of propagation of each bit and the length of the cable. 
在一点点。我们将看一些例子，你将在视频中嵌入的多项选择练习中做一些例子。请注意，传播延迟并不取决于链路的数据速率，无论链路以每秒1 kb还是每秒10 Gb的速度运行都无关紧要。传播延迟只是每个位的传播速度和电缆长度的函数。



发言人   02:52
Another useful definition is the packetization delay. This is the time from when the first bit of a packet is put onto the link until the last bit is put onto the link. Let's take a look at an example here. So see that packet there going onto the link, the time that it takes to put all of the bits under the link is going to be a function of the number of bits we're putting onto the link and the distance between them, or the number of bits per second that we can put onto the link. So essentially, the data rate of a link is determined by how close together we can pack the bits, if, for example, the link runs at 1 Gb per second, we can put on the, we can put 1 b onto the link. Every now a second. We'll see in a later video about physical links what actually limits the data rate of a link. So the packetization delay is determined by how fast we can put bits on the link or the data rate are. 
另一个有用的定义是分组延迟。这是从数据包的第一位被放到链路上直到最后一位被放到链路上的时间。让我们来看看一个例子。所以看看那个数据包进入链路，将所有位放在链路下所需的时间将是我们放入链路的位数和它们之间距离的函数。或我们可以放入链路的每秒位数。因此，基本上，链路的数据速率取决于我们可以将比特打包在一起的距离，例如，如果链路以每秒1 gb的速度运行，我们可以将1 b放在链路上。现在每一秒。我们将在稍后的视频中看到物理链路是什么实际限制了链路的数据速率。因此，数据包化延迟取决于我们在链路上放置比特的速度或数据速率。

发言人   03:51
If a link runs at 1 kb per second, we can put a thousand new bits onto the link every second. If it runs at 10 Gb per second, then we can put 10 billion b onto the link. Every second. They look at a couple of examples. If you had a 64 B packet, that's 512 b, it would take 5.12 microseconds to be transmitted onto 100 Mb per second link, why is that? Well, t sub p equals p over r, so p in our case, is 64 times 8, 512 divided by r and r would be 100 times 10 to the 6. 
如果一个链接以每秒1 kb的速度运行，我们每秒可以在链接上放置一千个新位。如果它以每秒10 Gb的速度运行，那么我们可以在链接上放置100亿Gb。每一秒钟。他们看了几个例子。如果你有一个64 B的数据包，也就是512 b，传输到每个第二个环节100 Mb需要5.12微秒，为什么呢？好吧，t子p等于p除以r，因此在我们的情况下，p是64乘以8，512除以r，r将是100乘以10的6。

发言人   04:29
Another example, a kilobit packet takes 1.024 seconds to be transmitted onto a 1 kbps link. So where did this 1.024 come from? Well, this is useful, useful example here, because the 1 kbps, sorry, the 1 kb packet that we see here, 1 kb when we're measuring a number of bits in a packet or in memory. One kilome, as you know, is 1024 or 2 to the power of 10. So that's why we have 1.024 seconds in order to transmit it onto a 1 kbps link. So in this case, it's a little bit confusing. 1 kbps means 1000 b per second, whereas the 1 kb in the packet is 1024 b. 
另一个例子是，一个千位数据包需要1.024秒才能传输到1 kbps的链路。那么这个1.024是从哪里来的呢？嗯，这是一个有用的例子，因为我们在这里看到的1 kbps的数据包，抱歉，1 kb的数据包，当我们测量数据包或内存中的位数时，1 kb。正如你所知道的，1千米是1024或2的10的幂次。这就是为什么我们有1.024秒的时间将其传输到1 kbps的链路上。所以在这种情况下，有点令人困惑。1 kbps意味着每秒1000 b，而数据包中的1 kb是1024 b。

发言人   05:18
This is standard throughout networking, and we'll see this happen over and over again. So notice that the packetization delay is only a function of the length of the packet, that's p here. And the rate at which we can put bits onto the link, or r bits per second, makes no difference how long the link is or how fast bits pro propagate along it. 
这是整个网络的标准，我们将看到这种情况一次又一次地发生。请注意，数据包化延迟仅是数据包长度的函数，即这里的p。并且我们可以将比特放入链接的速率，或者每秒r位，对于链接的长度或沿其传播的速度没有影响。


发言人   05:53
So next, we're going to see how we can use our two different types of delay to determine the overall end to end delay. That's the time it takes a packet to go across the network from the source to the destination. So the end to end delay is the time from when we send the first bit on the first link. That would be over here until the last bit of the packet arrives at the destination B? So we can calculate the end to end delay by adding up the propagation and packetization delays on every link along the path. That is, we can look at those numbers that we calculated before for how long it takes a packet from the first bit until the first bit is sent, until the last bit arrives on this link here, and then we can add it to the time on here, on here, and on here. So in our case, that's going to depend on the length of the first length and the rate at which it runs. And then we can use our expressions to calculate the u to n delay. 
所以接下来，我们将看看如何使用两种不同类型的延迟来确定整体端到端延迟。这是数据包通过网络从源到达目的地所需的时间。所以端到端延迟是从我们在第一个链接上发送第一个位开始的时间。这将是在这里，直到数据包的最后一点到达目的地B？因此，我们可以通过将路径上每个链接的传播和打包延迟相加来计算端到端延迟。也就是说，我们可以查看之前计算的数据包从第一点到第一点发送所需的时间，直到最后一点到达此链接所需的时间，然后我们可以将其添加到这里、这里和这里的时间中。所以在我们的情况下，这将取决于第一个长度的长度和它运行的速率。然后我们可以使用我们的表达式来计算u到n的延迟。


发言人   07:05
And we're going to come up with an expression that looks like this. The end to end delay t equals the sum of the first of all the delay here, which is the packetization delay, the time that it takes to put the packet onto the link, and then the time it takes for 1 b to propagate along that link. So we're going to sum up all of those to get the end to end delay. 
我们将提出一个看起来像这样的表达式。端到端延迟t等于此处所有延迟的第一个延迟之和，即打包延迟、将数据包放入链路所需的时间，然后是1 b沿该链路传播所需的时间。所以我们将总结所有这些，以获得端到端的延迟。

发言人   07:31
Let's look at this in a little bit more example because I think it'll become a bit clearer. So in our example here, the packet is going to traverse 4 links. So we're going to repeat the process on every link along the path. And it's going to look something like this. Here we're taking a closer look by stretching out the links and the switches and remove the rest of the network just to make a little bit clearer. 
让我们再看看这个例子，因为我认为它会变得更清晰一些。因此，在我们的示例中，数据包将遍历4个链接。所以我们将在路径上的每个链接上重复这个过程。它会看起来像这样。在这里，我们通过延伸链接和交换机并删除网络的其余部分来进行更仔细的观察，以便更加清晰。


发言人   07:59
This here is a timeline. And this timeline, with time increasing from the left to the right, is going to show how bits propagate and how the whole, whole packet propagates from A over to B? So the first bit is going to take L 1 over C, that's the length of that first length divided by the propagation speed. It's going to take that number of seconds to propagate from A to S 1. So here we can see the bit starting from here and then propagating along the link. L 1 over C is the time and this is it. Pre propagating the distance from A to S 1. 
这是一个时间线。这条时间线，随着时间从左到右的增加，将显示比特如何传播，以及整个数据包如何从面向企业传播？因此，第一个位将在C上占用L 1，这是第一个长度的长度除以传播速度。从A传播到S 1需要那么多秒。所以在这里我们可以看到从这里开始的位，然后沿着链接传播。L 1 over C是时间，就是这个。预传播从A到S 1的距离。

发言人   08:49
After we sent the first bit, it's going to take P over R 1 second until we can put the last bit of the packet under the link. So after p over R 1, we've put the last bit under the link. And then at the time L 1 c plus P over R 1, that last bit will arrive at switch S 1. Okay, so at this point, by the time we get to this point here, the entire packet has arrived at S 1. 
在我们发送了第一个位之后，它将花费P/R 1秒的时间，直到我们可以将数据包的最后一位放在链接下。所以在p超过R 1之后，我们把最后一位放在链接下面。然后在r1上的L 1 c加P时，最后一位将到达开关s1。好的，那么在这一点上，当我们到达这一点时，整个数据包已经到达了S 1。

发言人   09:27
So internet routers are what we call store and forward devices. What that means is that the switch S 1 is going to wait until the whole packet arrives, until it looks up the address and decides where to send it next. It could instead start forwarding the packet after it had just seen the header and not wait for the whole packet to arrive. That's something we call cut through switching. But internet routers generally don't do that in a later video. And in some of the exercises, we'll see examples of cut through packet switches. 
因此，互联网路由器就是我们所说的存储和转发设备。这意味着交换机s1将等待整个数据包到达，直到它查找地址并决定下一步将其发送到哪里。它可以在刚刚看到标头后开始转发数据包，而不必等待整个数据包到达。这就是我们所说的 “切入” 转换。但互联网路由器通常不会在稍后的视频中这样做。在一些练习中，我们将看到直通数据包交换机的示例。

发言人   09:59
But getting back to our example, which is a store and forward network where every switch is going to store and forward the packets, switch S 1 is going to look at the packet after it's completely arrived. And then it's going to send it on to the next link. It's going to send it on to S 2. So here we can see that packet going on to S 2. So just as before, it takes L 2 over C for the first bit to arrive at S 2, and then the last bit will arrive P over R2 seconds later. And we can just repeat this whole process for each of the links in turn until we get to B, so the overall end to end delay expression is just the sum of those from end to end, which is the same expression we had before. 
回到我们的例子，这是一个存储和转发网络，每个交换机都将存储和转发数据包，交换机1将在数据包完全到达后查看数据包。然后它会把它发送到下一个链接。它将把它发送到S 2。所以在这里我们可以看到那个数据包发送到S 2。所以和以前一样，第一个比特到达S 2需要经过L 2经过C，然后最后一个比特将在R2秒后到达P。我们可以对每个链接依次重复这个整个过程直到我们得到面向企业，因此总的端到端延迟表达式只是端到端延迟表达式的总和，这与我们之前的表达式相同。

发言人   10:53
Okay, so it turns out I've only told you part of the story. Let me tell you the rest of the story. See, the thing about packet switching is that your packets share the links with packets from other users. When several packets show up at the same time, wanting to go on the same link, you can see this here. We've got packets coming from here, maybe from another link entering the packet switch, and from here coming in the packet switch from another link, all wanting to go on this outgoing link from S 2 to S 3. When this happens, all of the packets are going to have to fight or contend for that outgoing link. So when several packets show up at the same time, wanting to go on the same link, in this case from S 2 to S 3, then some of the packets have to wait in the router's queue. And this little symbol here, see there's a little red symbol. 
好的，结果我只告诉了你故事的一部分。让我告诉你故事的其余部分。请参阅，分组交换的好处是您的数据包与来自其他用户的数据包共享链接。当多个数据包同时出现，想要进入同一链接时，您可以在这里看到这一点。我们收到了来自这里的数据包，可能来自另一条链路进入数据包交换机，也可能来自这里的数据包从另一条链路进入数据包交换机，所有的数据包都希望从S 2到S 3的出站链路。当这种情况发生时，所有的数据包将不得不为该传出链接而战斗或竞争。因此，当多个数据包同时出现，想要进入同一条链路时，在这种情况下从S 2到S 3，那么一些数据包必须在路由器的队列中等待。这个小符号在这里，看到有一个红色的小符号。

发言人   11:48
Here is the picture that I'm going to draw for a cue. Some people call it a packet buffer. 
这是我要画的图画作为提示。有些人称之为数据包缓冲区。

发言人   11:56
In general, let's say first come first serve queue in which the packets are going to depart in the same order that they arrive. We're going to say that the link from S 2 to S 3 is congested because there are lots of packets queued waiting to travel along it. The packet buffer helps prevent us from having to drop any packets. The bigger the buffer is, the less likely we are to have to drop a packet that wants to travel across the link. So these packet buffers, they're going to be in all of the switches. 
一般来说，让我们先到先得服务队列，其中数据包将以它们到达的相同顺序离开。我们要说的是，从S2到S3的链路出现拥塞，因为有很多数据包排队等待传输。数据包缓冲区有助于防止我们不得不丢弃任何数据包。缓冲区越大，我们就越不可能丢弃希望在链路上传输的数据包。因此，这些数据包缓冲区将位于所有交换机中。

发言人   12:25
Every packet switch has buffers and they're fundamental to packet switching. If we didn't have packet buffers, then we'd lose a packet every time two packets showed up at the same time, wanting to travel across a link. So packet buffers are our friends, but the packet buffers themselves are going to change our expression for the end to end delay. 
每个分组交换机都有缓冲区，它们是分组交换的基础。如果我们没有数据包缓冲区，那么每次两个数据包同时出现时，我们就会丢失一个数据包，想要通过链路传输。所以数据包缓冲区是我们的朋友，但是数据包缓冲区本身将改变我们对于端到端延迟的表达。

发言人   12:46
If our packet arrives and the queue has some packets in it, then it's going to delay the time that it can be forwarded onto the next link because it can have to wait for the packets that are ahead of it to leave first before our packet gets to go. So I've just shown this here as Q2 of t, meaning it's going over the link from S 2. And I've said it's Q2 of t because it's going to vary with time. It's going to depend on how many other packets are showing up from other users. So if there are three packets ahead of us, we'll have to wait for three packetization delays before it's our turn to go. I've shown this just in one queue. Of course, this can be in all of the switches along the way, just makes the figure a bit more complicated. So I've just shown it in Q2. 
如果我们的数据包到达并且队列中有一些数据包，那么它将延迟可以转发到下一个链接的时间，因为它可能必须等待前面的数据包首先离开，然后我们的数据包才能离开。所以我刚刚在这里将其显示为t的Q2，意味着它来自S 2的链接。我说过它是t的Q2，因为它会随着时间而变化。这将取决于有多少其他数据包从其他用户显示出来。因此，如果我们前面有三个数据包，我们将不得不等待三次打包延迟，然后轮到我们去。我只是在一个队列中展示了这一点。当然，这可以在整个过程中的所有开关中，只会使图形更加复杂。所以我刚刚在q2中展示了它。

发言人   13:37
So our end to end delay now has a third component to it. It has in it the packetization delay that we saw before, that's p over R sub I, then it has the propagation delay over the link, and then it has this new expression qi of t, which is the delay of the packet in the queue waiting for other packets. And this could be 0 if there are no other packets, of course. But in general, it's going to be some low non veterinarian value because we don't know whoever else is sending packets at the same time. So the most important thing to note here is everything is deterministic except the queueing delay p over r sub I, Li over c, they're both deterministic. It's qi sub qi of t, the queueing delay, that is the variable component. And to convince you that really in practice there are, there is variability. I'm going to show you an example in a moment. 
所以我们的端到端延迟现在有了第三个组成部分。它里面有我们之前看到的打包延迟，即p over R sub I，然后它有在链路上的传播延迟，然后它有这个新的表达式qi of t，即队列中等待其他数据包的延迟。当然，如果没有其他数据包，这可能是0。但总的来说，它将是一些低的非兽医价值，因为我们不知道还有谁在同时发送数据包。因此，这里需要注意的最重要的事情是，除了排队延迟p over r sub I，Li over c之外，一切都是确定性的，它们都是确定性的。它是t的qi sub qi，排队延迟，即可变分量。并说服你，在实践中确实存在着可变性。我一会儿会给你看一个例子。

发言人   14:38
One last thing, so you may have noticed that I that I used the British spelling for queueing, that's not because I'm English, but it's very common when talking about the internet to spell queueing. Q UE UE I N G seems like too many vowels, I know, but this was the convention adopted by Kling Rock, one of the pioneers and inventors of the internet back in the 1960s. But you'll see both, both the UK and the us belling, and that's just fine. 
最后一件事，你可能已经注意到，我使用了英国的queuing拼写，这不是因为我是英语，但在谈到互联网时，拼写queuing是很常见的。我知道，似乎有太多的元音，但这是19 60年代互联网的先驱和发明者之一Kling Rock所采用的惯例。但你会同时看到英国和美国都在belling，这很好。

发言人   15:06
So in summary, here's our overall expression for the end to end delay. It's taking into consideration the queueing delay at each packet switch along the way. It's really important to remember that the queueing delay is unpredictable. It depends on the traffic sent by other users in the network. As far as we're concerned, the queueing delay is a random variable. It's the only random variable in our expression for end to end delay. Everything else is deterministic. So in case you don't believe me that the endo end delay is unpredictable, we're going to measure it. 
总之，这是我们对端到端延迟的整体表达。它考虑了沿途每个分组交换机的排队延迟。非常重要的是要记住排队延迟是不可预测的。它取决于网络中其他用户发送的流量。就我们而言，排队延迟是一个随机变量。它是我们表达式中唯一用于端到端延迟的随机变量。其他一切都是确定性的。因此，如果您不相信endo结束延迟是不可预测的，我们将进行测量。

发言人   15:37
I'm going to use a very widely used tool called ping ping to measure the end to end delay between my computer and other computers in the internet. Ping is going to measure this end to end delay. In fact, it's going to measure the round trip time, which is the end to end delay. It's the sum of the end to end delay in both directions. You'll find the ping command on your computer and you can use it to repeat the measurements I'm about to do on your own computer. And it's kind of a fun thing to do. 
我将使用一种非常广泛使用的工具，称为ping，来测量我的计算机与互联网上其他计算机之间的端到端延迟。Ping将测量端到端的延迟。实际上，它将测量往返时间，即端到端延迟。它是两个方向上端到端延迟的总和。你会在你的电脑上找到ping命令，你可以用它来重复我要在你自己的电脑上进行的测量。这是一件有趣的事情。


发言人   16:05
We can measure the delay of packets across the internet using the ping command. I'm going to show you an example of the ping command right now. So I'm going to ping from my computer to Princeton, do EU Princeton is university in New Jersey in the United States. It's about 4000 km or 2.5 thousand miles from where I am. And as I do this, you can see over on the right hand side, it's showing me the time that it takes for the packets that I send to go to Princeton and back again. So let's see if I can highlight these. So if you see them like here, these are the times of the packets to go there and back again. So those numbers there are about 100 milliseconds corresponding to the time that it takes for a packet to go there and back, or the round trip time. 
我们可以使用ping命令测量互联网上数据包的延迟。我现在将向您展示一个ping命令的示例。所以我要从我的电脑ping到普林斯顿，普林斯顿是美国新泽西州的大学。离我所在的地方大约4000公里或25000英里。当我这样做时，你可以在右边看到，它向我展示了我发送的数据包到达普林斯顿并再次返回所需的时间。让我们看看能否突出这些。所以如果你看到它们像这里一样，这些是数据包去那里和回来的时间。因此，这些数字大约为100毫秒，对应于一个数据包往返所需的时间，或往返时间。


发言人   16:55
Let's see how that compares, say, with by ping to, let's try the University of xingwana in Beijing in China. So we're going to see that's a lot further away. That's about 10000 km away from me, or about 6000 miles. And you can see that the ping times are much greater. So if I can just highlight those, we can see those there more like 200 milliseconds. So I used ping to measure a few hundred RTT values from my computer at Stanford, Princeton, and as I said earlier, it's about 4000 km or 2.5 thousand miles away. 
让我们看看这与之相比如何，比如说，让我们试试中国北京的兴瓦纳大学。所以我们会看到距离更远。那离我大约10000公里，或者说大约6000英里。你可以看到ping时间要大得多。所以如果我可以突出那些，我们可以看到那些在200毫秒左右。所以我用ping从我在斯坦福普林斯顿的电脑上测量了几百个RTT值，正如我之前所说，它离我大约4000公里或2.5千英里远。


发言人   17:40
The graph shows the CDF. That's the cumulative distribution function for the values that I measured. So 0%, this means that none of the values were below this value here, which is about 100 milliseconds. And 100% of them were less than, let's say, 300 milliseconds. A little hard to tell on this graph here. So this shows the range and also the variation in the values that I measured. And the overall variance is about variation is about 50 milliseconds. And the 90% of the samples fell between 100 and 120 milliseconds. 
图表显示了CDF。这是我测量的值的累积分布函数。所以0%，这意味着这里没有任何值低于这个值，大约是100毫秒。其中100% 小于，比如说300毫秒。在这个图表上有点难以分辨。这显示了我所测量的值的范围和变化。总体方差约为50毫秒。90% 的样本在100到120毫秒之间。

发言人   18:30
Now let's look what happened when I repeated the experiment from Stanford to Tsinghua University, which is in Beijing. In China, it's a lot further away. It's about 10000 km away or 6000 miles. And as I would expect, the RTT values are much larger because the propagation delay is much higher. But also notice that the RTT samples have much greater variance. They vary by a lot more. Look at this value over here. These, this range of values, they're varying by a lot more than the ones over the shorter length from Stanford to Princeton. So that variation here comes from the queueing delay. 
现在让我们看看，当我从斯坦福到北京的清华大学重复这个实验时，发生了什么。在中国，距离更远。大约在10000公里或6000英里之外。正如我所料，由于传播延迟要高得多，因此RTT值要大得多。但也请注意，RTT样本具有更大的方差。它们相差很大。看看这里的这个值。这些，这个范围内的值，它们的变化比从斯坦福到普林斯顿的较短长度内的值要多得多。因此，这里的变化来自排队延迟。

发言人   19:11
My packets are encountering more queues, more congestion, more other users, more other users traffic when they're going across the Pacific to China. My packets meet meet other packets in the router buffers along the way. And so they get held up. They have to wait for longer. And I guess probably because there are more hops I'm more likely to encounter other people's packets along the way with a range of about 200 milliseconds. Yeah, it's about 320 down here. And maybe they're going up to about 520 with a range of about 200 milliseconds. 
我的数据包在穿越太平洋到中国时遇到更多的队列，更多的拥塞，更多的其他用户，更多的其他用户流量。我的数据包在途中遇到路由器缓冲区中的其他数据包。所以他们被阻碍了。他们必须等待更长的时间。我猜可能是因为有更多的啤酒花，我更有可能在大约200毫秒的范围内遇到其他人的数据包。是的，这里大约是320。也许它们会在大约200毫秒的范围内上升到大约520。

发言人   19:47
The queueing delay is making up almost half of the overall end to end delay. That's pretty high. In fact, that's kind of unusually high, which is why I showed you this as an example, just to get the point across. 
排队延迟几乎占整体端到端延迟的一半。这相当高。事实上，这是一种异常高的情况，这就是为什么我把这个作为一个例子给你看，只是为了表达观点。

发言人   19:58
In summary, the end to end delay is determined by three components. The first is the propagation of the lay along the links, which are determined by the lengths of the lengths and the propagation speed. The second is the packetization delay, which is determined by the length of the packet and the data rate of each link. The third is the queued delay, which is determined by the congestion and the queueing delay in the buffers and the routers along the path. 
总之，端到端延迟是由三个组成部分决定的。第一个是线路沿链路的传播，这是由长度和传播速度确定的。第二个是数据包化延迟，它由数据包的长度和每条链路的数据速率决定。第三个是排队延迟，这是由拥塞和缓冲区中的排队延迟以及路径上的路由器所决定的。

发言人   20:23
This is the end of the video on Endo. Endo lay in packet switching. In the next video I will be explaining what some of the consequences are of this variable queueing delay, particularly on real time applications which frequently use playback buffers to absorb this variation. 
这是Endo视频的结尾。Endo存在于分组交换中。在下一个视频中，我将解释这种可变排队延迟的一些后果，特别是在经常使用回放缓冲区来吸收这种变化的实时应用程序中。