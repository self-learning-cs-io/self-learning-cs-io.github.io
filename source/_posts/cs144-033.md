---
title: 计算机网络 033 Principles Packet Switching Playback buffers
date: 2025-10-19 10:00:32
---

发言人   00:00
By now you know how to calculate the end to end delay of a packet across the network, and you know that the queueing delay makes the end to end delay variable. Most of the applications that we use don't particularly care about this variability in end to end delay. For example, when we're downloading a web page or sending an email, we wanted to complete quickly, but we don't particularly mind if individual packets take 10 or 12 milliseconds to reach the other end. But there are some applications that really do care. They have to care about the queued delay, particularly what we call real time applications like streaming video and voice. So let's take a look at an example. 
到目前为止，您已经知道如何计算网络上数据包的端到端延迟，并且您知道排队延迟使端到端延迟可变。我们使用的大多数应用程序并不特别关心端到端延迟的这种可变性。例如，当我们下载网页或发送电子邮件时，我们希望快速完成，但我们并不特别介意单个数据包需要10或12毫秒才能到达另一端。但有一些应用程序真的很关心。他们必须关心排队延迟，特别是我们所说的实时应用，如流媒体视频和语音。让我们来看一个例子。


发言人   00:39
Over the next few minutes I'm going to explain why queueing delay makes life hard for these applications. It serves as a good illustration of queueing delay and how we might mitigate the problem in practice, basically because the applications don't know precisely when the packets are going to show up, they can't be sure they will have a voice or video sample in time to deliver it to the user. And so they build up a reserve of packet in something called the playback buffer. 
在接下来的几分钟里，我将解释为什么排队延迟使这些应用程序的生活变得困难。它可以作为排队延迟的一个很好的例子，以及我们如何在实践中缓解这个问题，基本上是因为应用程序并不准确地知道数据包何时出现，他们无法确定他们是否及时拥有语音或视频样本来将其传递给用户。因此，他们在称为回放缓冲区的东西中建立了数据包储备。

发言人   01:11
So we're going to take a look at playback buffers. You've actually all seen a playback buffer before this is a, this is a little screenshot from the bottom of a YouTube client and the red line on the left over here, this shows the video that we've already watched. This here is the point of playback. This dot shows where we've got to, and this area over here is this gray line shows the video that has been buffered or the packets that have been buffered that have not yet been played back to the user and this is the part that we're going to be interested in. 
所以我们将看一下回放缓冲区。在这之前，你们都看过播放缓冲区，这是YouTube客户端底部的一个小截图，左边的红线在这里，这显示了我们已经观看过的视频。这就是回放的重点。这个点显示了我们要去的地方，这里的灰色线条显示了已经缓冲的视频或已经缓冲的数据包，这些数据包尚未播放给用户，这是我们感兴趣的部分。


发言人   01:53
This here is the playback buffer. So the client deliberately tries to build up that playback buffer to try and get ahead just in case some of the packets are delayed or they don't arrive in time, and in case there's some kind of temporary outage. So when designing the playback buffer, we have to think about how far ahead we want the buffer to get. So if we were to build up the buffer all the way over here and build up more packets, then we've absorbed more data, and we can write out more variability in the queueing delay if we make it very short down here, if there's a big change or big change in the queueing delay or a sudden increase in the queueing delay, we may run out of packets because they may not show up in time. So designing this playback buffer is pretty key to making this application work. 
这里是播放缓冲区。因此客户端故意尝试建立回放缓冲区，以尝试向前推进，以防某些数据包延迟或无法及时到达，以及出现某种临时中断。因此，在设计播放缓冲区时，我们必须考虑我们希望缓冲区提前多远。所以如果我们在这里建立缓冲区并建立更多的数据包，那么我们就吸收了更多的数据，如果我们在这里使队列延迟非常短，我们可以写出更多的变化。如果队列延迟发生大的变化或突然增加，我们可能会耗尽数据包，因为它们可能不会及时出现。所以设计这个播放缓冲区是使这个应用程序工作的关键。

发言人   02:45
So how much we want to accumulate in the buffer where we start playing the back, back the video to the user is key. So let's a let's take a closer look at this, This is the point that we're playing. This is the amount that we buffer. This is the contents of the plate mode buffer. 
所以我们希望在缓冲区中累积多少，从那里我们开始播放视频，并将视频返回给用户是关键。让我们仔细看看这个，这就是我们要玩的重点。这是我们缓冲的金额。这是印版模式缓冲区的内容。


发言人   03:03
If we look down into a little bit more detail. So we're going to take as an example this, this, this setup here. So imagine we're watching a YouTube video on the laptop on the right, so over here and it's streaming video from the server, the YouTube server on the left over here. So we're going to assume that the video is being streamed at 1 mbps. Now this is just a made up number. There's all sorts of rates that it could be streamed out. This is just going to make make it easy for us to think about and it's going to pass through several routers along the path 1, 2, and 3 on the figure here. But it could be many more than that be very common for our packets to go through 10 or 15 routers on the path from YouTube to our to our client. 
如果我们往下看更多细节。所以我们将在这里以这个设置为例。想象一下，我们正在右边的笔记本电脑上观看YouTube视频，这里是来自服务器的流媒体视频，左边的YouTube服务器在这里。因此，我们将假设视频以1 mbps的速度流式传输。现在这只是一个由数字组成的。有各种各样的费率可能会被流出去。这将使我们更容易思考，它将沿着图中的路径1、2和3穿过几个路由器。但是从YouTube到我们再到我们的客户端的路径上，我们的数据包经过10或15个路由器可能比这更常见。

发言人   03:52
And the thing that we're going to be concerned mostly most about is the. 
而我们最关注的事情是&hellip;&hellip;

发言人   03:59
The queueing delay here. So there's three places where we can experience queueing delay. And that variable queueing delay is going to mean that our packets show up at slightly unpredictable times. So let's look at a graph of what this might look like. This graph shows the cumulative number of bytes sent by the server over time as a function of time. Because it's sending at a fixed rate of 1 mbps, it means that the line is straight. The cumulative number of bits or bytes that it's sent a function of time is a straight line. And so after one second, it will have seen a megabit a million bits, and after 10 seconds, it will have sent 10 million b because of the variable queueing delay in the network, the cumulative arrivals at the laptop look a little bit different. 
这里的排队延迟。因此，我们可以在三个地方体验排队延迟。而可变的排队延迟意味着我们的数据包出现在略微不可预测的时间。让我们来看看这个可能的样子的图表。此图形显示了随时间变化的服务器发送的累计字节数。因为它以1 mbps的固定速率发送，这意味着线路是直的。它发送的比特或字节的累积数量随着时间的函数是一条直线。因此，一秒后，它将看到一兆位，十秒后，由于网络中的可变队列延迟，它将发送一千万字节，笔记本电脑的累积到达看起来有点不同。

发言人   04:51
They might look like this. So you see this wheely line that I've got here, what does this mean? It means that if we take the first bite here, because they're all arriving in first come first serve of order, we can just draw horizontally across here and see when a particular byte arrived. So this one arrived here after that delay. So the x axis is going to tell you how long that particular, that particular byte took together. 
他们可能看起来像这样。所以你看到我这里的这条线，这是什么意思？这意味着如果我们在这里进行第一次咬合，因为它们都按顺序先到先到，我们可以在这里水平绘制并查看特定字节何时到达。所以这个在延迟之后到达了这里。因此，x轴将告诉您该特定字节在一起花费了多长时间。

发言人   05:15
Notice I'm saying bits and bytes, it doesn't matter what our units are here. So if we would take any point on here, let's say this, this particular byte, and we draw horizontally. I'm not very good at drawing straight lines, but that's supposed to be horizontal. And right here is the time at which that particular bite arrived at the laptop. So you can see that the delay is measured by the horizontal distance, the horizontal distance here, and you can see that it's a variable number depending on the queueing delay encountered by each of the individual packets. 
注意，我说的是比特和字节，这里的单位是什么并不重要。所以如果我们在这里取任何一点，比如说这个特定的字节，我们就水平绘制。我不太擅长画直线，但应该是水平的。而这里就是那个特定的叮咬到达笔记本电脑的时间。因此，您可以看到延迟是由水平距离测量的，这里的水平距离，您可以看到它是一个可变的数字，具体取决于每个数据包遇到的排队延迟。

发言人   05:51
We can also see for at a given time, at a given time, how big the amount of buffering along the path, basically how many bytes are in the path from the server to the client. And that would be shown by the vertical distance here, because it says that at a particular time, this is the number that have been sent, and this is the number that have been received. So we can tell quite a lot of information from this graph. And we're going to be seeing some more examples at this time of graph later. 
我们还可以看到在给定时间，沿路径缓冲的量有多大，基本上从服务器到客户端的路径中有多少字节。这将在这里显示为垂直距离，因为它表示在特定时间，这是已发送的号码，这是已接收的号码。因此，我们可以从这个图表中得知相当多的信息。稍后在图表的这个时候，我们将看到更多的例子。

发言人   06:25
Horizontal axis is the delay, the vertical axis. It tells us how many bytes are buffered right now in the network. Okay, so let's get back to get back to our example. So the biggest component of the delay is the propagation and packetization layer. That's the fixed component. 
水平轴是延迟，垂直轴是延迟。它告诉我们现在网络中有多少字节被缓冲。好的，让我们回到我们的例子。因此，延迟的最大组成部分是传播和数据包化层。这是固定组件。

发言人   06:47
So we actually know quite a bit about the shape of this line, so the actual shape could look very different, I just made up this shape, however, we do know a couple of things. 
所以我们实际上对这条线的形状有相当多的了解，所以实际的形状可能看起来非常不同，我只是做了这个形状，但是，我们确实知道几件事情。

发言人   07:00
First, the overall end to end delay can't be less than the paganization and propagation delay, they're a lower bound, so this has a lower bound in the horizontal distance between the between the two here, whoops. It also has an upper bound. So the buffers in the routers, the packet buffers here, there a finite size. So there's a maximum delay that any packet can experience going through one of those buffers. So if we add up the maximum of each of these, add it to the packetization delay and the propagation delay, it's going to represent an upper bound. So we have a lower bound, and we have an upper bound. But the upper bound is not very useful because it can be very, very large. 
首先，整体端到端延迟不能小于分页和传播延迟，它们是一个下限，因此在这里两者之间的水平距离上有一个下限，哎呀。它也有一个上限。路由器中的缓冲区，这里的数据包缓冲区大小是有限的。因此，任何数据包通过这些缓冲区之一都有一个最大延迟。因此，如果我们将每个最大值相加，将其添加到打包延迟和传播延迟中，它将代表一个上限。所以我们有一个下限，我们有一个上限。但是上限并不是很有用，因为它可能非常大。

发言人   07:44
In practice, these routers may have half a second of buffering. So if we're going through many hops, it would mean a ridiculous difference between the lower bound and the upper bound. So that's of not much use to us. 
实际上，这些路由器可能有半秒的缓冲。因此，如果我们经历许多跳跃，这将意味着下限和上限之间存在荒谬的差异。所以这对我们没有多大用处。

发言人   08:03
We also know that the cumulative arrivals on the right hand side are non decreasing. In other words, this value is always increasing because it's the cumulative number of bytes. And obviously, we can't have a negative number of bytes show up. Finally, one more thing that we know is because we know how fast or there is an upper bound on the rate of that of that last link, it could be 100 megabit per second link or a gigabit per second link. It tells us that the instantaneous arrival rate here, the gradient of this line here, can't exceed the speed, the data rate of that link. 
我们也知道，右侧的累积抵达人数是不会减少的。换句话说，这个值总是在增加，因为它是累计的字节数。显然，我们不能出现负数的字节数。最后，我们知道的另一件事是，因为我们知道最后一个链接的速度有多快，或者有一个上限，它可能是每第二个环节100兆或每第二个环节千兆。它告诉我们这里的瞬时到达速率，这条线的梯度，不能超过该链接的速度和数据速率。

发言人   08:40
Okay, so with all of those caveats, let's look at what the client actually needs to do to make all of this work. 
好的，所以有了所有这些注意事项，让我们看看客户实际需要做什么才能使所有这些工作正常工作。

发言人   08:50
So this red line here shows the playback rate of the video to the user. So what this tells us is that at this time here, it's playing back the first byte that was sent by the server, which is, of course, the first byte received by the receiver. So if at any point we take a horizontal line across here, it will tell us the time that a particular byte was sent, received, and then played back. What that means is that the horizontal distance here tells us so in, for example, in the. The horizontal distance here tells us how long a particular byte has been buffered. So at any one time, we can tell how long it sat in the playback buffer before it was played back to the receiver. 
所以这里的这条红线显示了视频向用户的回放速率。所以这告诉我们的是，在这个时候，它正在播放服务器发送的第一个字节，当然也是接收方收到的第一个字节。因此，如果在任何时候我们在这里划过一条水平线，它将告诉我们特定字节被发送、接收和播放的时间。这意味着这里的水平距离告诉我们，例如，在。这里的水平距离告诉我们一个特定的字节被缓冲了多长时间。因此，在任何时候，我们都可以知道它在回放缓冲区中被回放到接收方之前坐了多长时间。

发言人   09:46
We also know how many bytes there are in the playback buffer. It's the vertical distance here at any one time. It tells us what the occupancy of the playback buffer is. So we can see that the playback buffer was very small to start with. It accumulates, it accumulates, it accumulates, gets to a very large value here, then gets smaller as we fall behind. As we fall behind, fall behind, fall behind, almost goes empty here. We're very lucky that there must have been some bites that showed up late. We just avoided underrunning the buffer and then at some time we build up a little bit more etc as we go up here. 
我们也知道回放缓冲区中有多少字节。这是任何时候这里的垂直距离。它告诉我们播放缓冲区的占用情况。所以我们可以看到播放缓冲区一开始非常小。它积累，积累，积累，在这里得到一个非常大的值，然后随着我们的落后而变小。当我们落后，落后，落后，这里几乎空无一人。我们非常幸运，一定有一些咬晚了。我们只是避免了缓冲区运行不足，然后在某个时候我们在这里建立了更多的东西。

发言人   10:23
Okay, so we're playing back at a constant 1 Mb per second. That's what's being played back to the user. So this is a good example, we pick the right value. We waited long enough, we build up enough buffer, everything worked out fine in the end. So if we take a look inside, inside the client, it looks roughly like this. So the playback buffer is a buffer held in the memory of the of the client. The client is picking the playback point that's that's whats this here, this is the point at which it's that it's reached. That's that dot that we see on the YouTube client after the bytes have been taken out of the playback buffer, they put into a video decoder to turn them back into to video and then played out on the screen. 
好的，我们以每秒1 Mb的速度回放。这就是正在向用户播放的内容。所以这是一个很好的例子，我们选择了正确的值。我们等待足够长的时间，建立足够的缓冲，最后一切都进展顺利。所以，如果我们看一下客户端的内部，它大致看起来像这样。因此，播放缓冲区是保存在客户端内存中的缓冲区。客户端正在选择回放点，这就是这里的内容，这是它到达的点。这就是我们在YouTube客户端上看到的那个点，在字节被从播放缓冲区中取出后，它们被放入视频解码器中，将它们转换回视频，然后在屏幕上播放。


发言人   11:13
Okay, then let's look at an example of when things don't quite work out fine. So the same example, again, byte sent by the server on the left, received by the laptop on the right. But in this particular case, we didn't wait long enough before playing out the first byte. You can see that here, we've waited a little less time from when the first byte was received until we play out that first byte. And of course, once we start playing out the bytes, we're committed. We've got to play them out at 1 Mb per second. Otherwise, we can't keep putting the video on the screen. So on this particular case here, everything looks fine to start with. 
好的，那么让我们来看一个例子，当事情不太顺利时。同样的例子，左边的服务器发送的字节，右边的笔记本电脑接收的字节。但在这种特殊情况下，我们在播放第一个字节之前没有等待足够长的时间。你可以看到，在这里，我们从收到第一个字节到播放第一个字节等待的时间少了一点。当然，一旦我们开始播放字节，我们就会被承诺。我们必须以每秒1 Mb的速度播放它们。否则，我们不能一直把视频放在屏幕上。所以在这个特定的情况下，一切看起来都很好。

发言人   11:53
The buffer has a nice occupancy, nice occupancy, nice occupancy. It gets smaller and smaller and smaller until eventually at this point here, we have a problem. The buffer goes empty, which means we've got no, no bytes to decode and put onto the screen. So all of this area here is a time in which we're in deficit, this is not good. 
缓冲区占用得很好，占用得很好，占用得很好。它变得越来越小，直到最终在这里，我们有一个问题。缓冲区为空，这意味着我们没有要解码并放到屏幕上的字节。所以这里的所有这些都是我们处于赤字状态的时候，这不是好事。

发言人   12:13
What does the client do? Well, we've all seen this before, it has to make the buffer bigger, and it does this by rebuff Hering by freezing the screen, waiting for some bytes to accumulate and so that it can continue. Okay, so if you've been watching a video over this particular video right now, over a slow link, or if you're a long way away and you have your packets are going through many routers, you might experience a rebuff Hering event watching this video. You can fix the problem by streaming at a slower rate or just simply by downloading the video ahead of time. So in summary, in with a playback buffer, when we have packet switching end to end delay as variable, we use a playback buffer to absorb the variation. 
客户做什么？嗯，我们都见过这个，它必须使缓冲区变大，它通过冻结屏幕来拒绝，等待一些字节累积以便继续来实现。好的，如果你现在一直在通过这个特定的视频观看视频，或者是通过慢速链接，或者如果你距离很远，并且你的数据包通过许多路由器，那么你可能会在观看此视频时遇到拒绝事件。您可以通过以较慢的速率流式传输或只是提前下载视频来解决问题。因此，总之，在使用播放缓冲区时，当分组交换端到端延迟为变量时，我们使用播放缓冲区来吸收变化。


发言人   13:00
We could just make the playback buffer very big, but then the video would be delayed at the start. That was the time that we were waiting for the first byte to arrive Until we play it out under the screen, we could make the buffer bigger, But if we were to make that buffer bigger, then we would have to delay the starting point of the video, which would be kind of annoying when we're watching our videos. So therefore, applications try to estimate the delay. They try and estimate the delay from the server to the laptop, set the playback value, and then resize the buffer if the delay changes. 
我们可以让播放缓冲区变得非常大，但这样视频在开始时就会延迟。这是我们等待第一个字节到达直到我们在屏幕下播放的时间，我们可以将缓冲区变大，但是如果我们要将缓冲区变大，那么我们将不得不延迟视频的起点。当我们看我们的视频时，这可能会有点烦人。因此，应用程序尝试估计延迟。他们尝试估计从服务器到笔记本电脑的延迟，设置回放值，然后如果延迟发生变化，调整缓冲区大小。


发言人   13:33
Okay, so now let's go back to our original expression for the end to end delay. So now we've seen that it has these three components to it, packetization delay, propagation delay, and then the variable queueing delay. And the queueing adds variable and unpredictable delay to the path and to the packets from end to end. 
好的，现在让我们回到最初的端到端延迟表达式。现在我们已经看到它有这三个组成部分，打包延迟，传播延迟，然后是可变排队延迟。并且队列增加了路径和数据包从头到尾的可变和不可预测的延迟。

发言人   13:56
Okay, so in summary, end to end delay consists of components. The first two are fixed propagation delay, which is the time that it takes for a bit to propagate over a link. The packetization delay, which is the time that it takes to put a packet onto a link, and then the queueing delay, which is variable, which is dictated by the time that a packet spends in the buffers, in the routers along the path. Some applications, as we saw, use playback buffers to absorb this variable queueing delay to help the applications stream the video back to us at a fixed rate. So this is the end of packet switching 2. I will see you again in packet switching 3, where I'm going to tell you about a simple deterministic model that helps us understand this variable queueing delay. 
好的，总的来说，端到端延迟由组件组成。前两个是固定传播延迟，即一个位在链路上传播所需的时间。数据包化延迟，即将数据包放置到链路上所需的时间，然后是排队延迟，即可变的，由数据包在路径上的路由器中在缓冲区中花费的时间决定。正如我们所看到的，一些应用程序使用播放缓冲区来吸收这种可变队列延迟，以帮助应用程序以固定速率将视频流返回给我们。所以这就是分组交换2的结束。我会在分组交换3中再次见到你，在那里我将告诉你一个简单的确定性模型，它可以帮助我们理解可变的排队延迟。
